ID,source,min_yearly_salary,max_yearly_salary,company_link,description
1008923026706,Glassdoor,$84K,$124K,http://www.deere.com/,"There are over 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we're all about at John Deere. And it's why we're investing in our people and our technology like never before! Here the world's brightest minds are tackling the world's biggest challenges. If you believe one person can make the world a better place, we'll put you to work. RIGHT NOW.

John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regards to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity or expression, status as a protected veteran, or status as a qualified individual with disability.

Primary Location: United States (US) - Illinois - Chicago
Function: Technology (CA)
Title: Data Engineer - 102983
Onsite/Remote:Partial Remote Position

Your Responsibilities
As a Data Engineer, for John Deere Financial (JDF) group, located in Chicago, IL you will join a team to create data platform for advanced analytics and model building in order to enable efficient customer services in various area such as automatic loan approvals. Our team partners with product managers and data practitioners to design, scale, and deliver full stack data solutions. In this role you will:
Develop data model and data pipeline, build rest APIs to provide data to downstream systems
Perform debugging and fixing application issues, root cause analysis and help in proactive/preventive maintenance
Follow test driven development approach
Help in technical debt reduction and follow clean code principles
Follow Security by design principles to define security framework around data pipelines and APIs
Work as Agile team member and participate in back log refinement, sprint planning, sprint review, sprit retrospective
VISA Sponsorship is NOT available for this position.
What Skills You Need
Working knowledge of ETL, Data Modeling, Data Warehousing, and working with large-scale datasets
Working knowledge of API Development experience (specifically Rest APIs using Java, Spring boot)
Working knowledge of Data Engineering and the respective tools and technologies (e.g., Apache Spark, Databricks, Python, SQL DB, NoSQL DB, Data Lake concepts)
Working Knowledge of AWS services such as Lambda, RDS, ECS, API Gateway, S3 etc.
What Makes You Stand Out
Passionate, creative and have the desire to learn new complex technical areas
Accountable, curious, and collaborative with an intense focus on product quality
Skilled in interpersonal communications
Experience working in an agile team environment
Education
Ideally you will have a degree or equivalent related work experience in the following:
Bachelor’s degree in either Computer Science, Computer Engineering, Software Engineering, MIS, or other IT related discipline.
What You'll Get
At John Deere, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. Additionally, we offer a comprehensive reward package to help you get started on your new career path, including:
Flexible work arrangements
Highly competitive base pay and performance bonuses
Savings & Retirement benefits (401K and Defined Benefit Pension)
Healthcare benefits with a generous company contribution in the Health Savings Account
Adoption assistance
Employee Assistance Programs
Tuition assistance
Fitness subsidies and on-site gyms at specific Deere locations
Charitable contribution match
Employee Purchase Plan & numerous discount programs for personal use

Follow this link to learn more about our Total Rewards Package https://bit.ly/3XCd8fL

The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.

The terms of the applicable benefit plans, and all company actions administering or interpreting these plans, continue to control. Deere & Company reserves the right to suspend, amend, modify, or terminate the Plan(s) in any manner at any time, including the right to modify or eliminate any cost-sharing between the company and participants. Changes, which can be made at any time, are made by action of the company's board of directors, or to the extent authorized by resolution of its board of directors, or by the Deere & Company Compensation Committee. In the event of a conflict between the language of the official Plan Documents and this document, the language of the official Plan Documents will control.

ACA Section 1557 Nondiscrimination Notice
The John Deere Health Benefit Plans for Salaried Employees and The John Deere Benefit Plan for Wage Employees comply with applicable Federal civil rights laws and do not discriminate on the basis of race, color, national origin, age, disability, or sex."
1008917609806,Glassdoor,$99K,$140K,https://www.fortegra.com/,"We are looking for a Data Engineer to join our technology organization. As a Data Engineer you will implement strategies for modernizing and remediating legacy platforms by leveraging existing tools as well as implementing new data platform capabilities. You will implement new technologies, design ETL processes, and administer databases. In addition, you will be part of the team developing critical insight for the company and supporting every function of the organization. You will take responsibility for identifying and solving issues concerning data management to improve data quality. As we grow our footprint in Azure, you will have the opportunity to lead transformation projects. You will be part of a high performing team working on mission critical projects with visibility across the organization.

Responsibilities:
Design, develop , build, and own robust and high-performance data pipelines and APIs.
Gain a thorough understanding of the business and the data strategy to support that business.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, dbt and Azure technologies.
Take ownership of the data quality and articulate opportunities for continuous improvement, think of data as a product!
Define and document cloud solution architecture(s) including technical designs and diagrams.
Create and document unit test scripts.
Develop a strong customer focus, ownership, urgency, and drive.
Be a team player that everyone wants to work with.
Be a critical stakeholder in architectural decisions and evaluating systems implementations.
Troubleshoot and assist in resolving all issues pertaining to data management.
The above cited duties and responsibilities describe the general nature and level of work performed by people assigned to the job. They are not intended to be an exhaustive list of all the duties and responsibilities that an incumbent may be expected or asked to perform.
Qualifications:
B.S. in Computer Science, Engineering or equivalent required.
Experience with deploying Azure Infrastructure as Code and building CI/CD pipelines using GitHub /Azure DevOps and such other source control environments is required.
Azure cloud certified engineers will be preferred.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Deep knowledge with Python.
Strong experience in SQL and strong knowledge of data warehousing and ETL best practices.
Excellent verbal, written, and interpersonal communication skills. Ability to articulate technical solutions to both technical and business audiences.
Ability to influence and build relationships with engineering and data science teams, technology leadership, external service providers, infrastructure, and enterprise architecture teams.

Additional information
Full benefit package including medical, dental, vision, life, company paid short/long term disability, 401(k), tuition assistance and more."
1008922669040,Glassdoor,$70K,$101K,https://www.alertinnovation.com/,"Alert Innovation, now powered by Walmart, is a fast-growing venture on a mission to reinvent retail through robotics. We've partnered with Walmart to develop our Alphabot® technology, which is currently being deployed at stores throughout North America.
Alert Innovation is a growing start-up with a mission to re-invent retailing through robotics. We are seeking to hire collaborative people who love their work and want it to be meaningful.
As a Data Engineer on the Service & Support Team, you will play a hands-on-role in the development of the data pipelines, setting up data warehouse, and create dashboards for visualization with a goal to make data accessible, and enable the team and the organization to effectively use data to identify bottle necks and make decisions to optimize site performance. The ideal candidate possess strong aptitude for Data, enjoys problem solving, able to multitasks and effectively manage priorities on the incoming data requests.

WHAT WILL YOU DO?
Create data models, reports & analyses to support business needs and convert raw data into meaningful insights through interactive and easy-to-understand dashboards and reports.
Translate team's needs into data solutions using visualization tools like Power BI and Tableau.
Recommend technical approach to data pipeline development and understand the correct schemas to future-proof data pipelines.
Develop queries and reports for internal and external stakeholders.
Review, improve and optimize existing ETL/SQL queries, dashboard views, and procedures while implementing best practices for data extraction and storage.
Work on implementation of technology needed to facilitate the transfer of data and integrations with internal and third-party applications.
Propose, define, review and test data warehouse modifications to fill identified data gaps and improve report design efficiency, including custom tables and views.
WHAT ARE WE LOOKING FOR?
Data Warehousing and Data Mining Experience.
Hands-on experience in extracting data from various data sources and building data models (Star Schema/Snowflake).
Experience in requirement analysis, design, and prototyping.
Experience resolving complex issues in creative, efficient, and effective ways.
Have strong working knowledge of SQL and relational databases.
Experience with cloud data platforms (experience with Azure is a plus).
Demonstrated proficiency transferring data between cross-platform applications.
Ability to write clean, readable, and maintainable code and documentation in Java and/or Python (experience with both not required).
Excellent written & oral communication skills, and strong organizational & planning skills.
B.S. in Computer Science, Data Engineering, or related field. MS is a plus.
3+ years of experience with data visualization tools like Power BI or Tableau.
1+ year of experience within machine learning, computer vision and/or artificial intelligence is a must. Equivalent Master's-level course work is acceptable.
VALUES
All members of Alert Innovation practice the following values as part of their daily responsibilities and model these values as she/he leads or supports their teams.
The Golden Rule: Extraordinarily powerful in its simplicity and depth: ""Treat others as you would want to be treated"".
The Power of Person: The contribution of every single person in a company is important, and the performance of the entire company can only be maximized when every person strives to achieve his/her full potential and to contribute to the best of his/her ability.
The Power of Team: The Power of Person becomes amplified exponentially when a group of people working effectively as a team create ""performance synergy"", whereby the capacity to perform as a team is much greater than the sum of the individual members' capacities.
The Power of Truth: We strive to see the world as it is, not as we want or imagine it to be, because only then can we make it better. This core value manifests itself through questioning, probing, testing, measuring, validating, verifying, proving, listening with an open mind, and making fact-based decisions. It also fosters transparency and honesty with others, as well as self-examination and self-honesty.
WHAT DO WE OFFER?
Alert Innovation offers a highly competitive salary for each job family and level within the Boston-area market in which we are based.
Every employee is granted stock options that vest over four years.
Full-time employees receive a generous benefits package starting on your first date of employment:
No fixed limits on the number of workdays that you can take off for personal reasons, including vacations. You take what you need keeping in mind the demands of your team's workload.
9 Paid Holidays.
Medical, Dental, Vision, Life Insurance, and 401K + company match.
Tuition & work-related training reimbursement programs.
Employee Assistance Program to assist with emotional health, parenting, eldercare, nutrition, legal and financial consultation needs.
The above list is only a summary of some of our benefits and is not meant to be a comprehensive explanation. To hear more, please visit: https://www.alertinnovation.com/boston-robotics-jobs/
Alert Innovation offers a safe work environment for its employees and partners. All employees, contractors, interns, and visitors are required to be fully vaccinated. Additional COVID precautions, such as wearing face masks, hand washing, and hand sanitizing are also common practice in all Alert Innovation facilities. We are a flexible work environment and offer on-site and hybrid work schedules based on team requirements.

Alert Innovation is proud to be an Equal Employment Opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.
Alert Innovation's recent awards include:
EXCLUSIVE BENEFITS FOR OUR FULL-TIME TEAM MEMBERS:
Comprehensive Health Care Options: Choose from a range of health plans tailored for you, and extend those benefits to your dependents.
Unlimited PTO: Salaried employees receive unlimited paid time off for vacation, holidays, and personal days.
Eye & Dental Care: We've got you and your family covered with top-notch vision and dental insurance.
Secure Your Future: Take advantage of our competitive 401(k) matching, stock purchase plans, and equity opportunities.
Peace of Mind: Comprehensive life and disability insurance options.
Parental Leave: Embrace the joys of parenthood with up to 12 weeks of fully paid maternity/paternity leave.
Exclusive Discounts: Shop and save with special Walmart discounts, both in-store and online.
Dine & Energize On Us: Enjoy daily complimentary lunches, beverages, and a variety of snacks to keep you fueled throughout the day.
Join us and experience the best in employee care and benefits!
Learn more about why we were named a 2022 Best Place to Work at alertinnovation.com/careers.
Alert Innovation is proud to be an Equal Employment Opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics."
1008920179416,Glassdoor,$64K,$88K,http://www.amberpharmacy.com/,"Amber Specialty Pharmacy is searching for a Data Engineer to work with end users to gather business requirements for new and existing reports, dashboards and scorecards. Create ETL processes to make data available for reporting. Develop business intelligence reports, dashboards, and scorecards.
This position is Hybrid, working 2 days in the office 3 remotely.

Primary Responsibilities:
Understands SQL programming with strong analytical skills
Develops Business Intelligence Reports, Dashboards and Scorecards
Creates ETL processes to make data available for reporting
Integrates reports, dashboards and scorecards
Collaborates with end users to gather business requirements
Works with BI reporting tools such as SQL Server Reporting Services, MicroStrategy
Designs, creates, and maintains external customer reports as well as internal reports
Manages and performs data cleansing, de-duplication, and harmonization of data received from and potentially used by multiple systems
Develop and maintain SSIS projects and packages utilizing Visual Studio/C#
Develop and maintain multiple internal support applications and external web and mobile platforms utilizing Visual Studio/C#
Works with staff to determine availability of data, offer alternatives when data is not available and troubleshoot report issues
Attends and is prepared to participate in department, company, and industry meetings
Reports to work when scheduled and works expected number of hours
Performs other job-related duties and special projects as required
This position is an office-based position with possible telecommuting or working from home
Required Qualifications:
One to three years of hands-on experience developing with MS SQL Server, MicroStrategy (or relative BI development experience), .NET Core/C# preferred
Experience with SQL server queries, query analyzer, profiler, SSIS and SSRS
Ability to work with and protect extremely confidential patient and employee information
Educational Requirements:
Associate or Bachelor’s degree in computer science, MIS, or a related field preferred
Equivalent work experience in a similar or related position may be substituted for education requirements.

#AmberSpecialtyPharmacy"
1008923444714,Glassdoor,$80K,$118K,https://www.nomihealth.com/,"Nomi Health was founded in 2019 as a direct healthcare company with a simple yet bold mission: rebuild the healthcare system so it is accessible and affordable for everyone. We are rebuilding the healthcare system by cutting costs, confusion, and complexity through direct contracts and payment with providers, deep data dives, and convenient patient care.

We are looking for a talented Data Engineer to join our team in Austin, Texas. You will be responsible for the design, implementation, maintenance of our data pipelines to integrate with our platform ensuring data is accessible, clean, and optimized. This is hybrid working onsite 3 days a week (Tuesday, Wednesday, Thursday).
How you will make an impact
Design, implement, and maintain efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Nomi’s platform
Support automated processes for complex data analysis, management, and visualizations that incorporate data governance
Make decisions on complex data issues regarding technical approach for project components and reporting requirements
Design and implement data model changes that align with Nomi’s standards
Develop and execute testing strategies to ensure high quality data
Work with different teams within Nomi to reach end goals
What we are looking for
Hybrid working onsite 3 days a week (Tuesday, Wednesday, Thursday) in our Austin office
2+ years in data engineering or related field
Skilled with NoSQL and SQL (Snowflake)
AWS (preferred but not required) resources such as lambdas, docDB, EC2Data first approach
Experience with Python, Git, and Jira
Experience with sensitive data is a bonus
Nomi’s journey is just starting in delivering disruptive healthcare solutions, in partnership with like-minded employers, public sector organizations, advisors (brokers/consultants), and payers/TPAs. We are dedicated to our mission to remove healthcare hurdles and rebuild healthcare the way it should have always been: for everyone.

The system must change, and we’re the ones to do it. Join us on the journey.
Benefits/Perks
Medical, dental, and vision
401(k) with company match
Fully funded HSA
Open PTO
Continuous learning
Free counseling
Family leave
Learn more about us
LinkedIn
Twitter
Facebook
Glassdoor"
1008923082177,Glassdoor,$76K,$113K,http://abouthealthcare.com/,"ABOUT offers a flexible, purpose-built solution that empowers hospitals and health systems to operate as one connected network of care. We enable easy access for clinicians to move patients into and out of the acute care setting - getting them to the next, best care setting faster and easier. Complemented by our clinical experts and best practices, we provide health systems the necessary controls and insights to grow with resilience, drive clinician effectiveness, and improve patient outcomes.
SUMMARY:
Services as a technical expert on our data layer. Discusses customer needs, maintains and updates databases, warehouse or marts. Tunes and ensures optimal database and server performance. Assists with reporting and analytics to meet business intelligence requirements and ensures overall integrity, quality and related system maintenance.
ESSENTIAL FUNCTIONS:
This class specification lists the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform job-related duties other than those contained in this document and may be required to have specific job-related knowledge and skills.
Discusses needs, operations and data requirements with staff or customers and outlines system capabilities and approaches to pull, maintain and analyze system data.
Work with other data engineers to design and maintain scalable data models and ETL pipelines
Help design, build, and improve the infrastructure for ingesting, storing, securing and transforming data at a scale
Help design and build systems to monitor and analyze data
Provide technology ownership for data solutions for projects that the team has been tasked with.
Work with a cross functional team of business analysts, architects, engineers, data analysts to formulate technical requirements.
Design and build data pipelines from various data sources to a target data warehouse using batch data load strategies utilizing cloud technologies.
Conceptualizing and generating infrastructure that allows data to be accessed and analyzed effectively.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
Perform periodic code reviews and test plans to ensure data quality and integrity.
Provide input into strategies that drive the team forward with delivery of business value and technical acumen.
Execute proof of concepts, where appropriate, to help improve our technical processes.
Provides analysis, interpretation and counsel regarding the application and usage of systems, business intelligence and reporting to improve policies, programs, and practices.
Provides research and feedback to resolve management and customer questions and requirements; assists with receiving customer feedback and coordinating resources and responses as required.
Analyzes and reviews operations, results, feedback, and related information on an ongoing to as needed basis to determine trends, draw conclusions, interpret findings, and presents results, proposals, and recommendations to management.
Ensures the accuracy of operational databases, reports, and related details through audits, queries, and operational reviews; works with teams to resolve discrepancies.
Interprets and applies department policies and procedures and assists with applicable laws, rules, and regulations; receives guidance within these areas as needed.
Contributes to the efficiency and effectiveness of the department's service to its customers by offering suggestions and directing or participating as an active member of a work team.
Performs other duties as assigned.
QUALIFICATIONS:
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required.
Need to Have:
Candidates must be local to the Minneapolis St Paul area and able to work on-site 2-3 business days/week
Bachelor’s Degree in Information Technology or related field and 5 years of related experience; or equivalent education and experience.
Ability to work on site in our St Paul office 2-3 business days/week; parking reimbursement provided
4+ years of experience in managing data/databases (Proficient in SQL)
4+ years of experience in translating business requirements into technical data solutions on a large scale.
Nice to Have:
Prior experience working in a private equity-funded organization.
Healthcare technology experience.
Experience with Mirth or a similar integration or ETL tools
Required Knowledge and Skills
Required Knowledge:
Research and troubleshoot potential issues presented by stakeholders within the data ecosystem.
Experience with Data Modeling, Data warehousing
Strong analytical and interpersonal skills.
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
Advanced principles, practices and techniques of managing data , databases and system analytics.
Specialized understanding of data engineering, reporting and management.
Understanding of the administration and oversight of data, system and business intelligence programs, policies, and procedures.
Various methods to identify and resolve analytical problems, questions, and concerns.
Basic methods and approaches to analyze and improve business operations.
Understanding of applicable laws, codes, and regulations.
Computer applications and systems related to the work.
Principles and practices to serving as an effective project team member.
Methods to communicate with staff, coworkers, and customers to ensure safe, effective, and appropriate operations.
Correct business English, including spelling, grammar, and punctuation.
Required Skills:
Performing advanced data engineering duties in a variety of assigned areas.
Overseeing and administering business intelligence and data analytical systems.
Using standard, customized, and complex data analytics tools.
Training others in policies and procedures related to the work.
Identifying, documenting, and reporting on system and data administration.
Serving as a team member and the development and management of projects.
Operating in both a team and individual contributor environment.
Using initiative and independent judgment within established department guidelines.
Contributing effectively to the accomplishment of team or work unit goals, objectives, and activities.
Establishing and maintaining effective working relationships with a variety of individuals.
ABOUT Values
Passion
We have a passion for people—more specifically, keeping people at their best by getting them to the right care, right away. Why? Because in our line of work, time saves more than lives. It preserves quality of life. Which enables the people we’re passionate about to continue chasing their own passions.
Courage
How many great stories of breakthrough and triumph involve adhering to the status quo? We’ve been at this for years, and we’ve counted zero so far. For as scary as stepping out of our comfort zone is, taking bold leaps to leave it in our dust can be downright terrifying—and worth it. Every. Single. Time.
Determination
We like to think we’re pretty smart. And we owe a pretty big part of our success to date to our many bright minds. But it’s our tireless work ethic, refuse-to-lose attitude and understanding that there will always be opportunity to improve that keep us on top of our game. And ahead of our competition.
Humility
We are not chest-pounders. We are faithful-doers, lesson-learners and wisdom-sharers. For us, it’s not about individual accolades—or even our achievements as a company. Contributing to a better healthcare that keeps people at their best—patients and clinicians alike—is reward enough.
Curiosity
Today, we are in an amazing place. But we only got here because we never stopped asking “what if” and pushing ourselves to create “what is.” While some fear the unknown, we embrace our industry’s toughest questions. Because answering them makes a powerful statement: There is not impossible, only undiscovered.
Accountability
As much as we may strive for perfection, we’re anything but perfect. When we slip up, we don’t hide from it. We own it, and we grow from it. Setting an example for our peers, our partners, and our profession as a whole. Because it’s important to recognize that process is never a straight line forward.
We also value the employee experience, so we offer a full benefits package, including medical, dental, vision, supplemental insurances, parking reimbursement, and a flexible time off policy.
PHYSICAL/MENTAL REQUIREMENTS:
Mobility to work in an office setting, use standard office equipment and stamina to sit for extended periods of time; strength to lift and carry up to 10 pounds; vision to read printed materials and computer screens; and hearing and speech to communicate in person or over the telephone.
Travel as needed to support company and customer initiatives. Work on Site at our St Paul office may be required and ABOUT reserves the right to change the location of the role at any time.
This role may involve work on federal government contracts that require additional federal background investigations, training, and federal badging. As such, you will required to submit personal information to the government and be fingerprinted and photographed at your local Department of Veteran Affairs Medical Center.
ABOUT is also an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law."
1008923100899,Glassdoor,,,,"As a Data Engineer, you'll work with AI team members to operationalize data pipelines and ML tasks, with the goal to make an impact across the federal government.
We know that you can't have great technology services without amazing people. At MetroStar, we are obsessed with our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers.
If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below!
What you'll do:
Provide day-to-day support for deploying Python-native ML pipelines and perform data engineering tasks to enable AI/ML capabilities.
Present results to a diverse audience in presentation or report form.
Support architectural leadership, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements
Support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas.
What you'll need to succeed:
More than eight (8) years of experience in Data/ML engineering. If school experience is used, at most that would contribute to 2 years of actual experience.
Experience with ETL, Data Labeling, and Data Prep.
Experience designing, implementing, and maintaining data architecture and services to be used for AI/ML. Additionally, operationalizing and maintaining AI/ML models in production.
The ability to perform data analytics on program-related or system-related activities. This will include assessing performance and manual processes and implementing methods/algorithms to automate/optimize.
A bachelor's degree in Computer Science, Information Technology Management or Engineering, or other comparable degree or experience.
The ability to obtain and maintain DHS Suitability.
Like we said, we are big fans of our people. That's why we offer a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades.
Don't meet every single requirement?
Studies have shown that women, people of color and the LGBTQ+ community are less likely to apply to jobs unless they meet every single qualification. At MetroStar we are dedicated to building a diverse, inclusive, and authentic culture, so, if you're excited about this role, but your previous experience doesn't align perfectly with every qualification in the job description, we encourage you to go ahead and apply. We pride ourselves on making great matches, and you may be the perfect match for this role or another one we have. Best of luck! – The MetroStar People & Culture Team
What we want you to know:
In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.
MetroStar Systems is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of MetroStar Systems.
Not ready to apply now?
Sign up to join our newsletter here."
1008923064013,Glassdoor,,,,
1008917759257,Glassdoor,$78K,$114K,http://www.parkmobile.io/,"Location/City: Atlanta, GA
To Power Smart Mobility for Every Driver and Vehicle, Everywhere
For decades, parking was a hassle. Then in 2008, ParkMobile launched with a simple goal: make parking easier. Today, our team is committed to creating tech-based solutions that power smart mobility and make parking hassles of the past obsolete. We do this by creating innovative solutions that connect parking and mobility ecosystems, eliminating friction while maximizing convenience and efficiency. At ParkMobile we offer agile frameworks and incentives for innovators and problem solvers, all at the perfect spot for work and play at the heart of midtown Atlanta.
We’re experiencing exciting growth. We’re looking for more people to join our team and help shape a product used by more than 50 million people.

We are seeking a highly skilled and experienced Data Engineer to join our dynamic team. As a Senior Data Engineer, you will play a crucial role in designing, building, and maintaining our data infrastructure, ensuring that data is accessible, reliable, and scalable for analytics and business decision-making.
Responsibilities:
1. Data Pipeline Development:
Collaborate with cross-functional teams to understand data requirements and design data pipelines to ingest, process, and transform data from various sources.
Develop, optimize, and maintain ELT (Extract, Load, Transform) processes to ensure efficient data extraction and loading.
Implement data quality checks and monitoring mechanisms to ensure data accuracy, quality, and consistency.

2. Data Architecture:
Design and maintain data storage solutions, such as data warehouses, data lakes, and database systems, that align with business needs and scalability requirements.
Evaluate and recommend appropriate data technologies and tools to support data processing and analytics.

3. Data Modeling:
Develop and maintain data models and schemas to facilitate data access and analytics.
Collaborate with data scientists and analysts to define data requirements and create data models that enable advanced analytics and reporting.

4. Performance Optimization:
Monitor and optimize data pipelines and database performance to ensure fast and efficient data retrieval and processing.
Identify and resolve performance bottlenecks and data-related issues.

5. Data Security and Compliance:
Implement and enforce data security best practices, ensuring the confidentiality, integrity, and availability of sensitive data.
Ensure compliance with data privacy regulations and industry standards.

6. Documentation and Collaboration:
Create and maintain documentation for data engineering processes, data pipelines, and data models.
Collaborate with other teams, such as data scientists, analysts, and software engineers, to support their data needs and projects.

7. Continuous Learning and Innovation:
Stay updated with the latest trends and technologies in data engineering and analytics.
Identify opportunities for innovation and process improvements within the data engineering domain.

Qualifications:

Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.
3+ years as a Data Engineer, with a strong track record of designing and implementing data solutions.
Proficiency in programming languages such as Python, Java, or Scala.
Hands-on experience with data warehousing technologies (e.g., AWS Redshift, Google BigQuery, Snowflake) and ETL tools (e.g., dbt, Coalesce, Talend).
Strong database knowledge, including SQL and NoSQL databases (e.g., PostgreSQL, MySQL, SQL Server, MongoDB, Cassandra).
Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud) and related services.
Excellent problem-solving skills and the ability to work effectively in a collaborative team environment.
Strong communication skills to convey technical concepts to non-technical stakeholders.
Experience with data governance, data security, and compliance is a plus.
What you’ll enjoy about joining our Team
We believe in work/life balance. Seriously. Our team members' well-being is just as important to us as their work. We are humans first, employees second. We offer a ton of competitive perks, including:
Unlimited PTO
Medical, dental, and vision coverage
401K Matching
Casual Dress
Paid Parental Leave
Flexible Work Hours
Learning and Development Opportunities
Company Social Events - happy hours, outings, and more
Pet Insurance
Company Community Service Events
About ParkMobile
At ParkMobile, we aim to build an inclusive culture where differences are used to inform better creative, strategic, and business decisions. We actively seek diversity of backgrounds, education, beliefs, and ways of thinking. We look to create a culture where everyone can belong because we believe that people do their best work when they can show up every day as their authentic selves.
ParkMobile is an equal-opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
1008918183446,Glassdoor,$74K,$111K,https://www.hhglobal.com/,"DATA ENGINEER
In every office around the world, HH Global offers an entrepreneurial culture that sets ambitious goals and looks beyond the status quo.
At HH Global, we reward sharp, unconventional thinkers who are motivated to create their own success. Our winning culture draws from employees who step up to the challenge of solving tough problems and making a difference. We dream big, so our clients can dream bigger.
RESPONSIBILITIES
Document new reporting features or bugs from both internal and external users
Coordinate testing of reports with users
Manage an accurate and visible task and project list and meet regularly for input on prioritization.
Analyzes data, identifies trends and outliers, and recommends solutions when appropriate.
Coordinate with team members overseas
Create and maintain system protocols by writing and updating procedures; this includes documentation and writing SQL stored procedures.
Generate standard or custom reports summarizing business, financial, or economic data for review by executives, managers, clients, and other stakeholders. This will involve using T-SQL, SSIS, SSRS, and other report writing tools.
Willingness to learn new reporting technologies such as Microsoft Power BI, Tableau, or Qlikview
Participate in physical and virtual meetings as required to facilitate functional requirement gathering and report development.
Maintain or update business intelligence tools, databases, dashboards, systems, or methods
Assist with project management activities by identifying project milestones, phases, and elements; tracking activities, resolving problems, and publishing progress reports.
Manage timely flow of business intelligence information to users.

REQUIREMENTS
Bachelor’s degree in a business or technology related discipline
2+ Years work experience
Working knowledge of SQL
Microsoft Business Intelligence Suite (SSRS, SSIS, SSAS)
Experience with Azure cloud environment: Azure SQL Database, Azure Data Factory
Strong Microsoft Excel skills related to data analysis and manipulation
Proven ability to document and prioritize issues raised by others
Ability to prioritize tasks and directly support the department managers.
Good troubleshooting and error isolation skills.
Ability to work independently on assigned tasks as well as to accept direction on given assignments.
Must be able to interact and communicate with individuals at all levels of the organization.

Your resume will be reviewed by a member of our Recruiting team and we’ll reach out to you directly if there’s a fit. We’re using video conferencing software (Microsoft Teams) to conduct our interviews, but all interviews will be live with a member of our Recruiting or Hiring teams.
Equal Employment Opportunity Employer: HH Global is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation, gender, gender identity and gender expression, or any other characteristic protected by law.
#LI-AF1
#Remote"
1008922655846,Glassdoor,,,http://www.bpcs.com/,"Senior Data Engineer, Azure
Senior Data Engineer
Remote-US Only
Who is Blueprint?
We are a technology solutions firm headquartered in Bellevue, Washington, with a strong presence across the United States. Unified by a shared passion for solving complicated problems, our people are our greatest asset. We use technology as a tool to bridge the gap between strategy and execution, powered by the knowledge, skills, and the expertise of our teams, who all have unique perspectives and years of experience across multiple industries. We're bold, smart, agile, and fun.
What does Blueprint do?
Blueprint helps organizations unlock value from existing assets by leveraging cutting-edge technology to create additional revenue streams and new lines of business. We connect strategy, business solutions, products, and services to transform and grow companies.
Why Blueprint?
At Blueprint, we believe in the power of possibility and are passionate about bringing it to life. Whether you join our bustling product division, our multifaceted services team or you want to grow your career in human resources, your ability to make an impact is amplified when you join one of our teams. You'll focus on solving unique business problems while gaining hands-on experience with the world's best technology. We believe in unique perspectives and build teams of people with diverse skillsets and backgrounds. At Blueprint, you'll have the opportunity to work with multiple clients and teams, such as data science and product development, all while learning, growing, and developing new solutions. We guarantee you won't find a better place to work and thrive than at Blueprint.
What will I be doing?
Blueprint is looking for an Azure, Senior Data Engineer to join us as we build cutting-edge technology solutions! This is a fast-paced role that needs a dedicated and passionate individual focused on team and client satisfaction! The ideal candidate will have a solid background in consulting, with demonstrating experience in leading clients through the process of building modern data estates. You will also be responsible for mentoring any junior developers on the engagement.
Responsibilities:
Develop and implement effective data architecture solutions using Databricks and Lakehouse
Optimize and tune data pipelines for performance and scalability
Monitor and troubleshoot data pipelines to ensure data availability and reliability
Collaborate with data scientists, analysts, and other stakeholders to understand their data needs and build solutions that enable them to extract insights from data
Implement best practices for data governance, data security, and data quality to ensure data integrity across all data sources
Create and maintain documentation related to data architecture, data pipelines, and data models
Stay up to date with emerging technologies and best practices in data engineering and big data processing
Mentor and train other data engineers on best practices for data engineering and Databricks usage
Provide thought leadership in the Databricks and Lakehouse space, both within the organization and externally
Qualifications:
Bachelor's degree in computer science or equivalent experience
At least 5+ -years of experience as a data engineer
At least 5+ years of experience with SQL Development (ETL transformations, stored procedure)
Data Ingestion experience from inception to Gold Medallion
Strong understanding of data engineering, data warehousing, data modeling, data governance, and data security best practices
At least 3-5 -years of experience programming with PySpark performing various transformations
Design, build, implement and maintain our data infrastructure to power analytics and ML
Partner with engineers, producers and designers to deliver data insights that impact our players
Contribute to our investments into various open-source and 3rd party tools to build a system that scales with the company
Collaborate with our Data Scientists and Analytics Engineers to make pipeline implementation faster, more straightforward, and more trustworthy driven decisions that will shape our business
2-5+ years building large scale data infrastructure on Spark/Databricks or similar
3+ years experience working with real-time data ingestion/processing
Working knowledge of Databricks DLT(Delta Live Table) and Unity Catalog a plus
Experience with relational and non-relational database technologies (i.e., NoSQL, blob storage, etc.)
Experience with data wrangling skills with csv, tsv, parquet, and json
Experience designing, building and optimizing Big Data platforms that are robust, scalable and reliable
Excellent problem-solving and troubleshooting skills
Salary Range
Pay ranges vary based on multiple factors including, without limitation, skill sets, education, responsibilities, experience, and geographical market. The pay range for this position reflects geographic based ranges for Washington state: $146,400 to $175,100 USD/annually. The salary/wage and job title for this opening will be based on the selected candidate's qualifications and experience and may be outside this range.
Equal Opportunity Employer
Blueprint Technologies, LLC is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, age, disability, sex, gender identity or expression, orientation, veteran/military status, religion, national origin, ancestry, marital, or familial status, genetic information, citizenship, or any other status protected by law.
If you need assistance or a reasonable accommodation to complete the application process, please reach out to: recruiting@bpcs.com
Blueprint believe in the importance of a healthy and happy team, which is why our comprehensive benefits package includes:
Medical, dental, and vision coverage
Flexible Spending Account
401k program
Competitive PTO offerings
Parental Leave
Opportunities for professional growth and development"
1008920771652,Glassdoor,,,http://www.dedhamgroup.com/,"About Us:
Our mission at Pulse Analytics is to help decision-makers in oncology and other specialty therapeutic areas, identify and reduce access barriers across the healthcare industry, ensuring patients have access to the treatments they need. Our web-based decision support application connects healthcare industry organizations and key influencers to deliver targeted quality insights to support our client’s customer engagement strategies. We are currently growing and are looking to bring on talented and driven individuals to help build the future of B2B healthcare data analytics products

This role is for someone who is excited about architecting data infrastructure and building out data platforms from the ground up. As a Data Engineer, you will have the opportunity to work on key data delivery initiatives – automating data extraction processes and enhancing data sources for our clients. If you are passionate about leveraging data to drive business decisions and thrive in a dynamic environment, we want to hear from you.

In this role you will:
Design, build, and maintain efficient data pipelines from various sources to support key business initiatives.
Perform data cleansing and validation processes to ensure the integrity and quality of data used for analysis.
Act as a data evangelist within the company, promoting the value and impact of data science and engineering initiatives.
Collaborate closely with leadership, software engineers, and product managers to understand data requirements and align data solutions with business objectives.
Work alongside Business Analysts to identify opportunities for automated data acquisition and deliver high-quality data that drives actionable insights.
Develop and implement data governance policies and procedures to ensure the security, privacy, and quality of data.
Requirements

Minimum Qualifications:
3+ years of experience as a Data Engineer or in a similar role
Proficiency in Python and SQL, with the ability to write complex scripts and queries
Strong knowledge of data modeling, data warehousing, and ETL pipeline development
Understanding of data management fundamentals and data storage principles
Exceptional problem-solving and communication skills
Experience with cloud platforms such as AWS, Azure, or Google Cloud
Proficiency in Cloud Orchestration tools such as Airflow, Dagster, or Prefect

Preferred Qualifications:
Bachelors degree in Computer Science or related field
Experience with Big Data Technologies (e.g. Hadoop, Hive, Spark)
Familiarity with the AWS Ecosystem (e.g. AWS S3, AWS Athena, AWS Glue)
Knowledge of Distributed Systems
Benefits

Company Culture and Values:
At Pulse Analytics, we foster a collaborative and innovative environment where your ideas are heard and valued. Our core values:

Service: We adopt a client-first approach to solutions
Agile: Being flexible in our approach allows us to adapt and iterate quickly to client demands or needs
Innovation: We strive for excellence, embrace risk-taking, and take bold actions to innovate and improve
Transparency: When everyone is on the same page, we produce our best work
Ownership: Everyone is a product owner and operates with integrity and self-accountability

Perks and Benefits:
401k match
Medical, Vision, and Dental Insurance Coverage
Casual dress code
Remote work flexibility
Generous PTO/Vacation
Stipend for conferences

The expected base salary for this position ranges from $115,000 - $150,000. It is not typical for offers to be made at or near the top of the range. Salary offers are based on a wide range of factors including relevant skills, training, experience, education, and, where applicable, licensure or certifications obtained. Market and organizational factors are also considered. In addition to base salary and a competitive benefits package, successful candidates are eligible to receive a discretionary bonus.

The Dedham Group is an equal opportunities employer and does not discriminate on the grounds of gender, sexual orientation, marital or civil partner status, pregnancy or maternity, gender reassignment, race, color, nationality, ethnic or national origin, religion or belief, disability or age. Our ethos is to respect and value people’s differences, to help everyone achieve more at work as well as in their personal lives so that they feel proud of the part they play in our success. We believe that all decisions about people at work should be based on the individual’s abilities, skills, performance and behavior and our business requirements. The Dedham Group operates a zero tolerance policy to any form of discrimination, abuse or harassment.

#LI-REMOTE

#LI-YK1"
1008921127430,Glassdoor,,,http://www.eteaminc.com/,"Job Title :- Data engineer (10+ years candidate required)
Job Location :- Remote

Job Description :-
LinkedIn is Mandatory
Description:-
Bachelors degree in the areas of Computer Science, Engineering, Information Systems, Business, or equivalent field of study required
7+ years of experience in working with data solutions.
3+ years of experience coding in Python, or Scala or similar scripting language.
3+ years of experience in developing data pipelines in AWS Cloud Platform (preferred), Azure, or Snowflake at scale.
2+ years Experience in designing and implementing data ingestion with real-time data streaming tools like Kafka, Kinesis or any similar tools.SAP/Client or other cloud integrations are preferred.
3+ years experience working with MPP databases such as Snowflake (Preferred) , Redshift or similar MPP databases.
2+ years experience working with Serverless ETL processes (Lambda, AWS Glue, Matillion or similar)
1+ years experience with big data technologies like EMR, Hadoop, Spark, Cassandra, MongoDB or other open source big data tools.
Knowledge of professional software engineering best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Experience designing, documenting, and defending designs for key components in large distributed computing systems
Demonstrated ability to learn new technologies quickly and independently
Demonstrated ability to achieve stretch goals in a very innovative and fast paced environment
Ability to handle multiple competing priorities in a fast-paced environment
Excellent verbal and written communication skills, especially in technical communications
Strong interpersonal skills and a desire to work collaboratively
Experience participating in an Agile software development team, e.g. SCRUM
Job Responsibilities :
Responsible for the building, deployment, and maintenance of critical scalable Data Pipelines to assemble large, complex sets of data that meet non-functional and functional business requirements
Work closely with SMEs, Data Modeler, Architects, Analysts and other team members on requirements to build scalable real time/near real time/batch data solutions.
Contributes design, code, configurations, and documentation for components that manage data ingestion, real time streaming, batch processing, data extraction, transformation, and loading into Data Lake/Cloud Data Warehouse/MPP (Snowflake/Redshift/similar Technologies ) .
Owns one or more key components of the infrastructure and works to continually improve it, identifying gaps and improving the platforms quality, robustness, maintainability, and speed.
Cross-trains other team members on technologies being developed, while also continuously learning new technologies from other team members.
Interacts with technical teams across and ensures that solutions meet customer requirements in terms of functionality, performance, availability, scalability, and reliability.
Performs development, QA, and dev-ops roles as needed to ensure total end to end responsibility of solutions.
Keep up with current trends in big data and Analytics , evaluate tools and pace yourself for innovation.
Mentor Junior engineers ,create necessary documentation and Run-books while still being able to deliver on goals"
1008918753803,Glassdoor,$83K,$116K,,
1008921178437,Glassdoor,,,,
1008923436029,Glassdoor,$75K,$123K,http://www.luf.co/,"Software Engineer Level 1 - Big Data:

You enjoy working with Big Data and want to step in to a well functioning team with established processes and protocols.

Location: :Annapolis Junction, MD

The Software Engineer will be responsible for: :developing, maintaining, and enhancing complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of extremely large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports.

Required Development Skills::
Java,
Spring,
MapReduce or Portable MapReduce and technologies such as Hadoop, Hive, Pig, etc

Desired Skills:
Maven
Tradecraft experience
Experience building connected components

Requirements::
TS/SCI with Polygraph level Clearance
B.S. degree in Computer Science or related discipline is required
4 additional years of experience may be substituted for a Bachelor’s degree
Seven (7) years of Experience with computer systems engineering and/or software development

What We Offer::
Get Real Mentorship! :Senior level mentors are available across the technical spectrum, such as software architecture, DevSecOps, and other specialized domains
Competitive Pay
Flexibility and autonomous work with frequent collaboration
Continuing Education and Workforce Development
Positive work environment with professionals, no drama!
Professional growth and mentorship
Flexible Schedule

LufCo provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws."
1008919179967,Glassdoor,$68K,$107K,https://www.imamedicalgroup.com/,"IMA Medical Group is seeking to hire a full-time Data Engineer (SQL $ SSIS Developer). The SQL/SSIS Developer is responsible for implementing solutions to improve data reliability and quality by combining raw information from different sources to create consistent and machine-readable formats. The candidate is required to have both SQL development and SSIS programming skills and experience.
IMA Medical Group is a visionary and dynamic company focused on high-quality primary care services, with doctors and professionals dedicated to the health and well-being of the elderly. With more than 22 locations throughout Central Florida, we reiterate our commitment to provide quality medical care and an exceptional experience at each visit. We recognize the hard work that our employees put in and offer competitive pay, excellent benefits and an awesome work environment.
As a FULL-TIME EMPLOYEE, YOU WILL BE ELIGIBEL TO RECIEVE OUR AMAZING BENEFITS SUCH AS:
Low-Costs Medical, Dental and Vision Insurance effective the 1st day of the following month after your start date
Employer Paid Life Insurance & Long-Term Disability Insurance
Voluntary Short-Term Disability and Life Insurance
Voluntary Illness and Accidental Insurance
401K Savings and retirement plan
Health Care Flexible Spending Account (FSA)
Paid Time Off
3 days of Floating Holidays + 6 additional Federal paid Holidays
Paid Bereavement Leave
Employee Assistance Program (EAP)
Other Perks and Discounts
(SSIS, SQL, Functions and Triggers, Stored Procedures, Views, SSAS and any BI experience is a plus)

DUTIES AND RESPONSIBILITIES:
Design and develop SQL Server queries, DML, stored procedures, functions, views and triggers to be used during the ETL process.
Designing and developing SSIS / SQL ETL solutions to acquire and prepare data from numerous upstream systems for processing.
Builds data transformations with SSIS including importing data from files, moving data from one database platform to another.
Debug and tune SSIS or other ETL processes to ensure accurate and efficient movement of data.
Analyze and organize raw data.
Evaluate business needs and objectives.
Interpret trends and patterns.
Conduct complex data analysis and report on results.
Build algorithms and prototypes.
Combine raw information from different sources.
Explore ways to enhance data quality and reliability.
Identify opportunities for data acquisition.

SUPERVISORY RESPONSIBILITIES?
This job has no supervisory responsibilities.

QUALIFICATIONS:
Bachelor’s degree in computer science, information technology, or a related field.
3-5+ years of experience.
Extensive knowledge of SQL & SSIS.
Proven work experience as an SQL developer.
Strong project management & communication skills.
Ability to troubleshoot and solve complex technical problems.
Great numerical and analytical skills.

CORE COMPETENCIES:
Diversity - Demonstrates knowledge of EEO policy; Shows respect and sensitivity for cultural differences; Educates others on the value of diversity; Promotes a harassment-free environment; Builds a diverse workforce.
Ethics - Treats people with respect; Keeps commitments; Inspires the trust of others; Works with integrity and ethically; Upholds organizational values.
Determined Safety and Security - Observes safety and security procedures; Determines appropriate action beyond guidelines; Reports potentially unsafe conditions; Uses equipment and materials properly.
Interpersonal Skills - Focuses on solving conflict, not blaming; Maintains confidentiality; Listens to others without interrupting; Keeps emotions under control; Remains open to others' ideas and tries new things.
Customer Service - Manages difficult or emotional customer situations; Responds promptly to customer needs; Solicits customer feedback to improve service; Responds to requests for service and assistance; Meets commitments.
Attendance/Punctuality - Is consistently at work and on time; Ensures work responsibilities are covered when absent; Arrives at meetings and appointments on time.
Teamwork - Balances team and individual responsibilities; Exhibits objectivity and openness to others' views; Gives and welcomes feedback; Contributes to building a positive team spirit; Puts success of team above own interests; Able to build morale and group commitments to goals and objectives; Supports everyone's efforts to succeed.
Exemplary Professionalism - Approaches others in a tactful manner; Reacts well under pressure; Treats others with respect and consideration regardless of their status or position; Accepts responsibility for own actions; Follows through on commitments.
Dependability - Follows instructions, responds to management direction; Takes responsibility for own actions; Keeps commitments; Commits to long hours of work when necessary to reach goals; Completes tasks on time or notifies appropriate person with an alternate plan.

JOBS SPECIFIC COMPETENCIES:
Adaptability - Adapts to changes in the work environment; Manages competing demands; Changes approach or method to best fit the situation; Able to deal with frequent change, delays, or unexpected events.
Analytical - Synthesizes complex or diverse information; Collects and researches data; Uses intuition and experience to complement data; Designs work flows and procedures.
Business Acumen - Understands business implications of decisions; Displays orientation to profitability; Demonstrates knowledge of market and competition; Aligns work with strategic goals.
Change Management - Develops workable implementation plans; Communicates changes effectively; Builds commitment and overcomes resistance; Prepares and supports those affected by change; Monitors transition and evaluates results
Design - Generates creative solutions; Translates concepts and information into images; Uses feedback to modify designs; Applies design principles; Demonstrates attention to detail.
Initiative - Volunteers readily; Undertakes self-development activities; Seeks increased responsibilities; Takes independent actions and calculated risks; Looks for and takes advantage of opportunities; Asks for and offers help when needed.
Innovation - Displays original thinking and creativity; Meets challenges with resourcefulness; Generates suggestions for improving work; Develops innovative approaches and ideas; Presents ideas and information in a manner that gets others' attention.
Motivation - Sets and achieves challenging goals; Demonstrates persistence and overcomes obstacles; Measures self against standard of excellence; Takes calculated risks to accomplish goals.
Oral Communication - Speaks clearly and persuasively in positive or negative situations; Listens and gets clarification; Responds well to questions; Demonstrates group presentation skills; Participates in meetings.
Organizational Support - Follows policies and procedures; Completes administrative tasks correctly and on time; Supports organization's goals and values; Benefits organization through outside activities; Supports affirmative action and respects diversity.
Planning/Organizing - Prioritizes and plans work activities; Uses time efficiently; Plans for additional resources; Sets goals and objectives; Organizes or schedules other people and their tasks; Develops realistic action plans.
Problem Solving - Identifies and resolves problems in a timely manner; Gathers and analyzes information skillfully; Develops alternative solutions; Works well in group problem solving situations; Uses reason even when dealing with emotional topics.
Project Management - Develops project plans; Coordinates projects; Communicates changes and progress; Completes projects on time and budget; Manages project team activities.
Quality - Demonstrates accuracy and thoroughness; Looks for ways to improve and promote quality; Applies feedback to improve performance; Monitors own work to ensure quality.
Quality Management - Looks for ways to improve and promote quality; Demonstrates accuracy and thoroughness.
Quantity - Meets productivity standards; Completes work in timely manner; Strives to increase productivity; Works quickly.
Strategic Thinking - Develops strategies to achieve organizational goals; Understands organization's strengths & weaknesses; Analyzes market and competition; Identifies external threats and opportunities; Adapts strategy to changing conditions.
Technical Skills - Assesses own strengths and weaknesses; Pursues training and development opportunities; Strives to continuously build knowledge and skills; Shares expertise with others.
Written Communication - Writes clearly and informatively; Edits work for spelling and grammar; Varies writing style to meet needs; Presents numerical data effectively; Able to read and interpret written information.

PHYSICAL DEMANDS AND WORK ENVIRONMENT:
Occasionally required to stand
Occasionally required to walk
Continually required to sit
Continually required to utilize hand and finger dexterity
Occasionally required to climb, balance, bend, stoop, kneel or crawl
Continually required to talk or hear
While performing the duties of this job, the noise level in the work environment is usually ____ (quiet; moderate;)
The employee must occasionally lift and /or move more than 25 pounds / frequently lift and/or move up to 10 pounds / continually lift and/or move up to 5 pounds
Specific vision abilities required by this job include: Close vision

ARE YOU READY TO JOIN OUR TEAM?
We understand your time is valuable and that is why we have a very quick and easy application process. If you feel that you would be right for this position. please fill out our initial 3-minute, mobile friendly application so that we can review your information. We look forward to meeting you!

IMA Medical Group is an Equal Opportunity Employer (EOE) and we comply with all federal, state and local anti-discrimination laws, regulations and ordinances.
IMA Medical Group participates in E-Verify, as required by the Florida Medicaid program
IMA maintains a drug-free workplace in accordance with applicable Federal and State laws."
1008923183511,Glassdoor,,,,
1008922659492,Glassdoor,$70K,$94K,http://www.nuvera.com/,"Job Title
Data Engineer I
Job Family
Job Description
Nuvera Fuel Cells, LLC is a manufacturer of heavy-duty, zero-emissions hydrogen fuel cell stacks and engines for mobility applications. With facilities located in the U.S. and Europe, Nuvera provides clean, safe, and efficient products designed to meet the rigorous needs of industrial vehicles and other transportation markets.
Nuvera is a subsidiary of Hyster-Yale Group, Inc., which designs, engineers, manufactures, sells, and services a comprehensive line of lift trucks and aftermarket parts marketed globally primarily under the Hyster® and Yale® brand names. Hyster-Yale Group is a wholly owned subsidiary of Hyster-Yale Materials Handling, Inc. (NYSE:HY). Hyster-Yale Materials Handling, Inc. and its subsidiaries, headquartered in Cleveland, Ohio, employ approximately 7,600 people worldwide.
We are seeking a Data Engineer I. This role will improve Nuvera’s methods and systems for data management and analysis; expand usage of databases and develop custom front-end visualizations for product performance insights; ensure data systems are optimized for efficiency and aligned with latest industry developments and best practices.
Essential Job Responsibilities:
Create and maintain well-structured relational databases for efficient storage of Nuvera product performance data.
Develop and support automation scripts which populate product databases directly via Nuvera test stands
Establish interface to monitor for proper functionality of automated processes and quickly alert engineers to breakdowns
Create front-end visualizations (ie. dashboards) for engineers to interact with system data for both standardized analyses and ad-hoc investigations
Stay up to date with new software packages and technologies which can facilitate more rapid front-end development; participate in trainings and/or continued learning as appropriate
Work with Senior Software Engineers to ensure data systems are properly architected for enterprise deployment with a focus on data security according to industry best practices.
Support Systems and Test Engineers to develop and debug Python code for a variety of applications.
Required Job Qualifications (unless otherwise noted):
Educational Background
Bachelor’s in Computer Science or Computer Engineering
or Bachelor’s in Relevant Engineering Discipline (Mechanical/Chemical/Electrical) plus Master’s in Data Engineering/Data Analytics
Previous Work Experience
0-2 years demonstrated success developing and implementing advanced data systems in either a professional or co-op role.
Special Skills, Experience and Abilities
Solid grounding in data systems fundamentals: relational databases, tables and data types, normalization, indexes, query optimization.
Preference for broader knowledge of engineering fundamentals: thermodynamics, fluid dynamics, heat & mass transfer.
Strong knowledge of coding best practices and Python programming language
Familiarity with query and statement commands for a variety of DBMS including MySQL and PostgreSQL.
Facility with Microsoft Office suite (Excel, PowerPoint, Word)
Strong and proactive problem solving, debugging, and troubleshooting abilities
Ability to work both independently and in team contexts, Comfort with a rapid development pace and ability to multitask, Strong interpersonal and communication skills
Physical requirements/Work environment
Laboratory and office work environments. This position has an emphasis on analytics of information which originates from physical systems and will therefore require occasional interaction with hardware in a laboratory or pilot plant setting.
Ability to lift components weighing up to 35 lbs. is required.
Travel Required
Up to 5% domestic travel may be required.
Nuvera Fuel Cells, LLC. is an Equal Opportunity Employer. Veterans/Disabled and other protected categories. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Nuvera participates in e-Verify.
Job ID
JC1001
Employment Type
Full time
Work Hours
40
Travel Required
Primary Location
Nuvera US Billerica, MA
Address
129 Concord Road Building 1
Zip Code
01821
Field-Based
No
Relocation Assistance Available
No
We are an equal opportunity employer with an excellent benefit package including medical, dental and life insurance, 401(k) and profit sharing.
EOE/Minorities/Females/Veterans/Disabled"
1008922930240,Glassdoor,,,,
1008923510669,Glassdoor,,,http://www.honda.com/,"A great experience starts with you!
Honda Center welcomes fans, performers, and athletes from around the globe. Our team members are an integral part of the event experience through their interactions with guests. Whether you’re looking to create a great guest experience at a concert, support business growth and development, work behind-the-scenes during an Anaheim Ducks game, or anything in-between, this is your opportunity to start the next chapter of your career story and help create a one-of-a-kind fan experience at Honda Center.
Once you've had a chance to explore our current open positions, apply to the ones you feel best suit you, as an applicant, you can always see your application status in your profile.
Job Title:
Data Engineer
Pay Details:
The annual base salary range for this position in California is $109,550 to $133,895 per year. The starting pay for the successful candidate depends on various job-related factors, including but not limited to the candidate’s geographic location, job-related knowledge, skills, experience, education/training, internal value, peer equity, external market demands, and organizational considerations.
ocV!BE, a premier mixed-use community and live entertainment district, is coming to Anaheim in 2026! This $4+ billion, 100-acre, mixed-use community will surround its anchor, Honda Center, with new live entertainment venues, dining and retail offerings, and public amenities. From intimate clubs to a new 6K-capacity concert venue, ocV!BE will provide a full range of entertainment, activating the District daily for the enjoyment of its guests.
ocV!BE’s District Insights Group (DIG) is a holistic data practice that initiates and conducts activities across existing business units (primarily the Anaheim Ducks and Honda Center). Overtime, the DIG’s scope will expand to encompass all phases of the ocV!BE district, building upon learnings, platforms, standards, and practices developed between now, the ocV!BE’ District Phase 1 opening and beyond. The DIG represents hybrid expertise between both Business Intelligence (BI) and Consumer Intelligence (CI) practices. DIG’s team will evolve to represent fully dedicated resources for both BI and CI while remaining organized within the single, holistic Insights practice inclusive of data enrichment and predictive analytics enabled by Machine Learning and Generative AI.
The Data Engineer will be responsible for designing and delivering data platform solutions to support all aspects of data analytics practice and software engineering projects. Responsible for participating in the core data engineering work associated with the design and implementation of Data Strategy, Information Architecture and Governance projects to ensure the security, integrity, and availability of information with appropriate technical documentation and QA activities. Conduct data modeling and associated research, development, deployment, monitoring, and ongoing maintenance to ensure efficient, stable, scalable, and highly secure cloud data infrastructures for the enablement of data-driven business decision making. Manage the data engineering requirements associated with third party technology integrations. Lead the implementation of all data engineering projects, designing and communicating/translating business requirements into data engineering solutions across departments and operating entities. Responsible for implementing data transformation pipelines and data ingestion points to collect data from external data sources according to specifications provided by technical and business leadership. Serve as the organization’s primary Database Administrator (DBA), providing associated support and oversight of the organization’s Database Administration priorities.
Responsibilities
Design and implement data engineering facets of Data Strategy, Information Architecture and Governance projects to ensure the security, integrity, and availability of information with appropriate technical documentation and QA activities in accordance with organizational systems, standards, specifications, and requirements
Lead the implementation of data engineering projects
Design and communicate data engineering solutions based on business requirements
Implement data transformation pipelines and data ingestion points to collect data from external data sources
Motivate and communicate data engineering considerations across multiple levels of the department, including non-technical, non-data savvy audience (ability to translate data engineering technical communication into highly relatable, non-technical terms)
Develop strategies, refine/evolve existing, and develop new, initiatives with your team to advance on an organizational and technical levels across the core focus areas of the DIG and the operations it supports
Provide a consistent/successful interface between Engineering Development and Product Management
Develop leadership skills within the organization and mentor other leaders
Development, measurement, and management of key metrics for group's performance
Drive high throughput and all connected key metrics on a strategic level
Standardize the development process where needed, allow local differences where advantageous
Perform other duties and projects as assigned

Requirements
Proven track record of designing and delivering data management solutions in complex cloud environments
Experience in setting up and maintaining/evolving data platforms in cloud environments such as AWS, Azure, GCP (Azure being a requirement)
Experience with Snowflake
Foundational understanding of Data & Analytics Architectures, definition of KPIs/metrics and insight requirements
Proficient in Python and system-level languages like Go, Rust, Java
Strong technical knowledge of distributed data processing frameworks such as Spark, Flink, Arrow and similar (PySpark being a requirement)
Knowledge of workflow tools such as Airflow, Kubeflow, Jira and similar
Proficient in SQL and Document DBs, and performance tuning of queries: ensuring solutions are both scalable and maintainable
Skills
Minimum of 5 years of experience as a Data Engineer and Database Administrator
Graduate degree in Computer Science, Mathematics, Engineering, or other STEM
Experience with enterprise-scale, multi-application (platform) systems
Experience with data and software engineering direction within the ML/AI space
Experience synthesizing data and creativity to deliver transformation business results
Excellent written and verbal communication skills
Understanding of, and interest in expanding expertise around, Large Language Models (MML)/ Generative AI and its emerging role in data, analytics, prediction and the future of broader insights platforms and practices
Able to understand business requirements and translate them into data engineering and related analytics projects that deliver solutions to business challenges and/or support capitalizing on business opportunities
Knowledge, Skills, and Experience
Education - Bachelors Degree
Certifications Required – NA
Experience Required – 5+ Years
JM2023
Company:
ocV!BE Sports & Entertainment, LLC
Our Commitment:
We are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, parental status, military service, medical condition or any protected category prohibited by local, state or federal laws. We are firm believers that diversity and inclusion among our team members are critical to our success, and we seek to recruit, develop, and retain the most talented people from a diverse candidate pool.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!"
1008920161263,Glassdoor,,,,
1008922898158,Glassdoor,,,,"Blackwell Security Inc. is a start-up backed by venture capital, focused on bridging the technology gap in healthcare. Our purpose-built ecosystem provides comprehensive cybersecurity managed services for life sciences and healthcare. We are building a customizable product that ensures health systems have access to a suite of security solutions, with built-in visualization and optimization to ensure the safety of patient information.
As we continue to build out our core team, we are adding a Data Engineer to our Engineering Team. You will be working cross-functionally with business domain experts, analytics, and engineering teams to design and implement our Data models. You will design, implement, and scale data pipelines that transform billions of records into action and insight.
This is a unique opportunity to jump into an early-stage start-up at a pivotal time and make a meaningful impact. If you thrive in a small, growing environment and love the energy of start-ups, this is the role for you!
While our headquarters are in Detroit, Michigan, this is a remote role but ideally a candidate would live in Detroit or Minneapolis, location of our core Engineering Team. This role is not eligible for visa sponsorship.
What you will do in the Data Engineer role:
Collaborate with engineering to build and maintain an enterprise data ecosystem including ingestion, storage, organization and interface.
Analyze the business and technical requirements for data systems and applications; Coordinate the integration of IT policies, procedures and development practices.
Translate business requirements into data models that are easy to understand and used by different disciplines across the company.
Design, implement, build/enhance pipelines that deliver data with measurable quality under the SLA.
Partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service.
Champion the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements.
Own and document foundational company metrics and benchmarks with clear definition and data lineage.
Identify, document and promote best practices.
Design and architect data systems, focusing not only on performance and scalability, but also on crafting a beautiful user experience.
Define/Implement data visualizations & UX for external/internal customers.
Taking a thoughtful approach to decision making; balance speed and quality, with a focus on tangible results.
Explore Blackwell’s data to discover trends and opportunities, identify what questions we should be asking of our data.
Analyze & evaluate transactional system data for transformation and use in reporting, analytics, and AI/ML.
Evaluate and establish early strategies and usage of AI (machine learning, generative AI, etc.).
Qualities and skills for success in the Data Engineer role:
Bachelor's degree in Computer Science, Engineering, or related technical or business field.
Attention to detail, and Agile development experience.
Experience with Python and AWS services.
Experience with various data storage systems, RDBMS, Document/NoSQL DBs, etc.
Experience implementing data pipelines via methods such as ETL, ELT, EL/TL, DaaS, Data Lake or ODS.
Experience experimenting with and applying AI (machine learning, generative AI, etc.) in an enterprise environment.
Experience working with multi-customer multi-tenant environments preferred. Experience with cybersecurity data is not required but is a plus.
Adaptable and focused on solutions.
Equal Employment Opportunity
We’re proud to be an equal opportunity employer and welcome our employee’s differences, regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or Veteran status. Difference makes us better. Join us."
1008920636281,Glassdoor,,,,
1008920881597,Glassdoor,$79K,$118K,https://www.thecervantesgroup.com/,"Data Engineer – Hybrid, 2 days onsite in Boston, NYC, Dallas or Miami
Role Description:
The Data Engineer will build and maintain data pipelines to support data lakes and analytics use cases. This person will be responsible for managing and optimizing data processing systems and infrastructure across various entities under the parent company and should specialize in specific solutions (e.g., Scala, Java, microstrategy) or functional domains such as big data, ingestion, or modelling, etc. The Data Engineer will also provide Level 2 Support of the data lake.
Job Duties:
Package and deploy releases and changes to pre and post-production environments while testing the releases through technical and business validation.
Conduct regular testing to identify bugs/performance issues and ensure it works smoothly.
Lead data pipeline execution, testing, cutover, and data modernization solution while identifying opportunities for automating tasks.
Assemble large, complex data sets that meet non-functional and functional business requirements in addition to helping to establish Data Engineering architecture strategy, best practices, and standards for data lake support engineering.
Design and build reliable, scalable data infrastructure with leading privacy and security techniques to safeguard data using AWS technologies.
Assemble large, complex data sets that meet non-functional and functional business requirements and prepare technical design specifications.
Build Data Flows mapping Source systems and Process flows and work with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues.
Collaborate with cross-functional teams to understand end user needs to be translated into technical solutions while monitoring scheduled production related tasks in the system(s) and resolving any questions or issues as needed to ensure accurate and timely results.
Education & Requirements:
Bachelor's Degree in Computer Science or related field.
5-7+ years’ experience in data engineering creating data pipelines.
5-7+ years’ experience in AWS and other technologies such as S3, AWS Glue, PySpark, Scala.
Expertise in AWS Data Lakes.
Must be able to build frameworks for data ingestion pipeline both real time and batch using best practices in data modeling.
Plus:
Bilingual in English & Spanish (verbal, written) is a huge plus
Job Type: Full-time
Pay: From $1.00 per year
Schedule:
8 hour shift
Ability to commute/relocate:
Dallas, TX: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
How many years of experience do you have as data engineer?
How many years of experience do you have creating data pipelines?
Do you have experience with PySpark?
Salary expectations (annually in USD).
Education:
Bachelor's (Required)
Experience:
AWS: 5 years (Required)
S3: 4 years (Required)
Scala: 4 years (Required)
Data lake: 4 years (Required)
Work Location: Hybrid remote in Dallas, TX 75201"
1008923404505,Glassdoor,,,http://www.prismhr.com/,"Do you have a passion for building data architectures that enable smooth and seamless product experiences? Are you an all-around data enthusiast with a knack for ETL? We're hiring Data Engineers to help build and optimize the foundational architecture of our product's data.
We’ve built a strong data engineering team to date, but have a lot of work ahead of us, including:
Migrating from relational databases to a streaming and big data architecture, including a complete overhaul of our data feeds
Defining streaming event data feeds required for real-time analytics and reporting
Leveling up our platform, including enhancing our automation, test coverage, observability, alerting, and performance
As a Data Engineer, you will work with the development team to construct a data streaming platform and data warehouse that serves as the data foundations for our product.
Help us scale our business to meet the needs of our growing customer base and develop new products on our platform. You'll be a critical part of our growing company, working on a cross-functional team to implement best practices in technology, architecture, and process. You’ll have the chance to work in an open and collaborative environment, receive hands-on mentorship and have ample opportunities to grow and accelerate your career!
Responsibilities:
Build our next generation data warehouse
Build our event stream platform
Translate user requirements for reporting and analysis into actionable deliverables
Enhance automation, operation, and expansion of real-time and batch data environment
Manage numerous projects in an ever-changing work environment
Extract, transform, and load complex data into the data warehouse using cutting-edge technologies
Build processes for topnotch security, performance, reliability, and accuracy
Provide mentorship and collaborate with fellow team members

Requirements:
Bachelor’s or Master’s degree in Computer Science, Information Systems, Operations Research, or related field required
3+ years of experience building data pipelines
3+ years of experience building data frameworks for unit testing, data lineage tracking, and automation
Fluency in Scala is required
Working knowledge of Apache Spark
Familiarity with streaming technologies (e.g., Kafka, Kinesis, Flink)

Nice to Have:
Experience with Machine Learning
Familiarity with Looker a plus
Knowledge of additional server-side programming languages (e.g. Golang, C#, Ruby)

Please note: This position can be remote/telecommute. Notice for candidates located in the following states: CA, CO, NJ, NY, WA: The base salary range for this position is between $100,000 - $150,000 (salary is dependent on location, experience, knowledge, and skills based on the responsibilities outlined in the job description).
#LI-REMOTE
PrismHR is a fast-paced SaaS company which provides customers with a cloud-based payroll process software application. PrismHR also provides professional services including system implementation consulting, custom configurations, and training. Lastly, via the Company’s Marketplace platform customers and end users access other human resources and employee benefits applications from PrismHR’s Marketplace Partners.
Diversity, Equity and Inclusion Program/Affirmative Action Plan:
We have transformed our company into an inclusive environment where individuals are valued for their talents and empowered to reach their fullest potential. At PrismHR, we strive to continually lead with our values and beliefs that enable our employees to develop their potential, bring their full self to work, and engage in a world of inclusion.

Ensuring an inclusive environment for our employees is an integral part of the PrismHR culture. We aren't just checking a box, we are truly committed to creating a workplace that celebrates the diversity of our employees and fosters a sense of belonging for everyone. This is essential to our success. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about our roles but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for these open roles or other open roles. We particularly encourage applicants from traditionally under-represented groups as we seek to increase the diversity of our workforce and provide fair opportunities for all.

As a proud Equal Opportunity and Affirmative Action Employer, PrismHR encourages talent from all backgrounds to join our team. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations.

The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers.
Privacy Policy: For information about how we collect and use your personal information, please see our privacy statement available at https://www.prismhr.com/about/privacy-policy.
PrismHR provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at PrismHR: taglobal@prismhr.com. Please indicate in the subject line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response.
#LI-ML1
vlsNrOjLD3"
1008922724136,Glassdoor,,,http://www.quadranttechnologies.com/,"Responsibilities:
Job Description:
As an Azure Data Engineer, you will be expected to design, implement, and manage data solutions on the Microsoft Azure cloud platform.
Key Responsibilities:
Collaborate with cross-functional teams to gather, analyze, and document business requirements for data integration projects.
Develop and maintain robust data pipelines using Azure Data Factory and Databricks ensuring seamless data flow between systems.
Expertise in Native SQL, Dynamic SQL, spark SQL, Azure SQL and ability to write complex stored procedures.
Design and implement complex stored procedures to support data transformation and Implement business validation logic.
Strong algorithmic programming skills
Work closely with the team to ensure data quality, integrity, and accuracy across all systems.
Utilize Databricks for advanced data processing and analysis.
Experience on OLTP (Online Transaction Processing) systems using SQL Server and contribute to their enhancement and optimization.
Qualifications:
Bachelor’s degree in computer science, Information Technology, or a related field.
[Specify the number of years] years of experience in data integration and database development.
Proficiency in Core SQL and Azure SQL.
Extensive experience with Azure Data Factory and Databricks.
Strong expertise in designing and implementing complex stored procedures.
Excellent problem-solving skills and attention to detail.
Job Types: Permanent, Full-time
Pay: $50.00 - $55.00 per hour
Expected hours: 40 per week
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
6 years
Schedule:
Day shift
Monday to Friday
Work Location: In person"
1008920546438,Glassdoor,,,http://www.tailwindtech.com/,"About Us:
Tail Wind Informatics Corporation -Microsoft Solutions Partner- is a dynamic and innovative IT consulting services company that specializes in delivering Data Architecture and Business Intelligence solutions. We are currently seeking a talented and experienced Data Engineer to join our team and play a crucial role in managing and optimizing data infrastructure. If you are passionate about data, have a strong background in Microsoft technologies, and enjoy solving complex data challenges, we want to hear from you!

Position Overview:
As a Data Engineer at Tail Wind, you will be responsible for designing, developing, and maintaining data pipelines and systems on the Azure cloud platform. You will work closely with cross-functional teams to ensure that data is accurate, accessible, and supports data-driven decision-making. The ideal candidate has hands-on experience with Azure Data Factory, SQL, Stored Procedures, Python, Databricks, Snowflake, Azure Synapse Analytics, and Power BI.
Key Responsibilities:
Design, build, and maintain data pipelines and ETL processes using Azure Data Factory.
Develop and optimize SQL queries, stored procedures, and scripts for data transformation and extraction.
Understand data requirements and ensure data availability.
Implement data quality checks and data validation processes to ensure data accuracy and consistency.
Leverage Python for data manipulation, automation, and data integration tasks.
Utilize Databricks for advanced data processing, transformation, and analytics.
Manage and optimize data storage.
Work with Azure Synapse Analytics or Snowflake to build and maintain data warehouses and analytics solutions.
Create interactive reports and dashboards using Power BI for data visualization and insights.
Stay up-to-date with the latest data technologies and best practices.
Qualifications:
Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience).
3+ years of experience as a Data Engineer with a focus on Microsoft technologies.
Strong proficiency in Azure Data Factory, or related product, for ETL processes and data orchestration.
Proficiency in SQL, including the ability to write complex queries and stored procedures.
Experience with Python for data manipulation and automation.
Knowledge of Databricks for big data processing and analytics.
Familiarity with Snowflake or Azure Synapse Analytics for data warehousing.
Proficiency in Power BI for data visualization and reporting.
Strong problem-solving skills and attention to detail.
Excellent communication and teamwork abilities.
Why Join Tail Wind?
Competitive salary and benefits package.
Opportunity to work with cutting-edge technologies and solve challenging data problems.
Collaborative and innovative work environment.
Professional development opportunities and support for various certifications.
Application Process:
To apply for this position, please click ""apply for this job"" at the top of the page, then upload and submit a current copy of your resume.
*Salary will be determined based on the results of a Technical Interview*
Tail Wind Informatics Corp., is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive, healthy environment for all employees. We look for people that love what they do, want to learn, earn and enjoy life to the fullest.

No agencies please."
1008919253530,Glassdoor,,,http://www.highbridgeusa.com/,"THIS IS A W2 ONLY REQ - NO C2C - NO SUBS

Our client, is the global leader in optimized resource management. They have nearly 200,000 employees worldwide. The client designs and provides water, waste and energy management solutions which contribute to the sustainable development of communities and industries.
They are now looking to hire a Sr Data Engineer on a contract basis. This is onsite 2 days a week in the Paramus office. The ideal candidate must have:
More than 4 years of experience developing with Python.
4+ years performing with production environments in a DevOps culture managing code composed of multi-developer teams, following industry best practices.
4+ years SQL development experience.
Experience with data modeling
4+ years bash scripting experience.
Strong experience with Git, CI/CD (preferably GitLab) and Docker.
Experience deploying and running services in Cloud Big Data platforms such as BigQuery.
Strong experience with GCP services.
Experience designing and building data pipelines using tools Google Data Fusion (CDAP) or other ETLs.
Knowledge with CDC design patterns and their challenges.
Experience with DAG workflows orchestration such as Prefect.
Experience with NoSQL databases is a plus (i.e Firestore, MongoDB).
Experience designing and developing APIs is a plus (i.e using FastAPI, Flask).
Nice To Have: Google Cloud Data Engineer

Education / Experience / Background:
MS degree in Computer Science or computer related field from an accredited institution.
5+ years hands proven experience as a Data Engineer or similar role.
5+ years of strong experience building, running and maintaining datalake(s) and warehouse(s) in a cloud environment."
1008918390820,Glassdoor,$85K,$116K,https://www.plexusworldwide.com/,"We're hiring a Data Engineer II to join our growing team of data experts.
About this position
We are looking for a Data Engineer II to join our growing team of data experts. You're responsible for expanding and optimizing our data and data pipeline architecture and data flow and collection for cross-functional teams. The Data Engineer II will support our software developers, database architects, and data analysts on data initiatives. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. You will provide mentorship and guidance on best practices and design principles. You will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.

Who will love this job?
A creative problem solver, you are energized by roadblocks and have a knack for troubleshooting problems in stride and solving them calmly, coolly, and collectedly.
A team steward, you are motivated to do your best work and strive to elevate the entire team
An excellent communicator, you have a knack for explaining technical processes concisely and work well with cross-functional internal teams.

What you'll do
You create and maintain optimal data pipeline architecture.
You assemble large, complex data sets that meet functional and non-functional business requirements.
You mentor Data Engineer I team members, providing guidance on best practices and design principles.
You engage in advanced data modeling and architecture tasks.
You champion performance tuning, troubleshooting, and optimization of datasets to ensure efficient data
delivery.
You identify, design, and implement internal process improvements: automating manual processes, optimizing
data delivery, re-designing infrastructure for greater scalability, etc.
You build the infrastructure required for optimal extraction, transformation, and loading of data from a variety
of data sources using SQL and big data technologies.
You build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition,
operational efficiency, and other key business performance metrics.
You collaborate with stakeholders including the Executive, Product, Data and Design teams to assist with data
related technical issues and support their data infrastructure needs.
You partner with data and analytics experts to strive for greater functionality in our data systems.
You're responsible for writing complex queries for reporting and the application consumption.
You can troubleshoot and provide root cause analysis for database software and data integrity issues.
You Should Have
You have 5+ years of experience in a Data Engineering role.
You have attained a Bachelor Degree in Computer Science, Statistics, Informatics,
Information Systems or another quantitative field. A Master's degree is preferred
You have deep understanding of SQL and experience with multiple relational and NoSQL database solutions.
You have expertise in optimizing ETL/ELT pipelines and data modeling.
You have experience with version control systems and CI/CD pipeline development.
You have performed root cause analysis on internal and external data and processes to answer specific
business questions and identify opportunities for improvement.
You're collaborative and can work with cross-functional teams in a dynamic environment.
You have demonstrated subject matter expertise to mentor junior team members.
You have strong analytic skills related to working with unstructured datasets.
You can create processes and procedures supporting data transformation, data structures, metadata, dependency
identification and workload management.
You understand message queuing, stream processing, and highly scalable 'big data' data stores.
You are highly organized and have demonstrated strong project management skills.
About Plexus
Plexus Worldwide is a leading direct-sales company founded in Scottsdale, Arizona, where it remains a top employer and economic driver. For the past 14 years, Plexus had been focused on igniting hope, health, and happiness, through their science-backed nutritional products and skincare, as well as an exciting home-based entrepreneurial opportunity.
As a 6-time Best Places to Work winner, the company enjoys a strong organizational culture and has a deep commitment to giving back to communities in need.
Our Core Values
We contribute to the overall growth and success of Plexus by embracing the Plexus core values:
We are One Plexus.
We are accountable.
We get the job done right.
We empower others.
Benefits
401k program with a company match and immediate vesting.
Quarterly bonuses based on company profitability.
Weekly drawings for gift cards and cash.
Thank you for taking the time to apply for an opportunity with our One Plexus team! If you had any issues during the application process, please contact us directly at careers@plexusworldwide.com.
#LI-hybrid"
1008920923557,Glassdoor,$67K,$90K,http://www.hcahealthcare.com/,"Introduction
Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As an Associate Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Associate Data Engineer to help us reach our goals. Unlock your potential!
Job Summary and Qualifications
Position Summary
Data Engineers within HCA’s Information and Analytics organization are responsible for defining and implementing data management practices across the enterprise. This contract position will focus primarily on enterprise data management and migrating of data to the cloud. This role requires working closely with the different data teams and requires ‘self-starters’ who are proficient in problem solving and capable of bringing clarity to complex situations.
Data Engineers are expected to source and incorporate new data sources into the Enterprise Data Ecosystem. The responsibilities will include writing, testing, and reviewing ETL pipelines for defining and implementing data management practices across the enterprise
This candidate will have a history of increasing responsibility in a small multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement solutions with minimal supervision.
This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team environment.
Major Responsibilities:
Implement data migration pipelines from Teradata to the cloud
Implement enterprise data management practices, standards, and frameworks for Data Integration
Develop, manage, and own full data lifecycle from raw data acquisition through transformation to end user consumption
Analyze requirements, design data pipelines and integrate those solutions for customer environments
Understanding of fundamental cloud computing concepts
Translate business requirements into technical design specifications
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Maintains a holistic view of information assets by creating and maintaining artifacts that illustrate how information is stored, processed, and accessed
Provide guidance on technology choices and design considerations for migrating data to the Cloud
Experience with building consumable data lakes, analytics applications and tools
Designing the cloud environment from a comprehensive perspective, ensuring that it satisfies all of the company’s needs
Performing activities such as deployment, maintenance, monitoring, and management inside the cloud framework that has been created
Work closely with individuals across the technology organizations to help promote awareness of the data architecture and ensure that enterprise assets of competence are leveraged
Education & Experience:
Bachelor's degree required
Less than 1 year of experience in Information Technology required
Less than 1 year of experience in Cloud Technologies required
Or equivalent combination of education and/or experience
Knowledge, Skills, Abilities, Behaviors:
Teradata ETL experience using BTEQ and SQL scripts.
Extensive experience with relational database management systems; Teradata, Oracle or SQL Server preferred.
Knowledge of ETL tools such as such as StreamSets, Cloud Data flow, Connect ETL etc.
Advanced SQL skills, including the ability to write, tune, and interpret SQL queries; tool specific experience in the RDBMS's listed above is ideal
Experience with Oracle, SQL Server, and other database platforms.
Scripting experience with Unix/Linux.
Experience with Git and GitHub version control.
Experience with relational databases such as Teradata and public cloud technologies such as, GCP Big Query, GCP Data Catalog and Azure Data Bricks preferred
Advanced SQL skills, including the ability to write, tune, and interpret SQL queries; tool specific experience in the RDBMS's listed above is ideal. Experience with GCP Big query is preferred
Experience with Cloud Data Flow, Airflow, Cloud Composer, Streamsets or managing streaming data is strongly preferred
Ability to troubleshoot, maintain, reverse engineer and optimize existing ETL pipelines.
Experience with Cloud Data Flow, Airflow, Cloud Composer, Cloud Data Fusion, Data Catalog, Kafka, DataProc, GitHub, Streamsets or managing streaming data is strongly preferred
NoSQL, Hbase, Cassandra, MongoDB, In-memory, Columnar, other emerging technologies
Ability to analyze and interpret complex data, and offer solutions to complex clinical problems.
Ability to work independently on assigned tasks.
Strong written and verbal communication skills including the ability to explain complex technical issues in a way that non-technical people may understand.
Excellent problem-solving and critical thinking skills.
Knowledge of IT governance and operations.
HCA Healthcare has been recognized as one of the Worldâ€™s Most Ethical CompaniesÂ® by the Ethisphere Institute more than ten times. Â In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
Be a part of an organization that invests in you! We are reviewing applications for our Associate Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
1008919183423,Glassdoor,,,https://www.americanexpress.com/,"You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.
As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. American Express offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology of #TeamAmex.
How will you make an impact in this role?
You will be part of a core engineering team that develops critical technology solutions to ensure that as an enterprise we are meeting stringent financial regulatory expectations that uses large swaths of data for customers across 20+ countries spread across globe, communicating with multiple technology systems that enable critical business and technology functions.
demonstrated ability in the development, deployment and operations of (relational) database applications across development, test and production environments
proven experience in developing effective test cases that are integrated into CI/CD pipelines
2-3 years of experience in developing observability capabilities into solutions to enable the critical identification of root causes of failures, in time sensitive processes.
2+ years of proficiency with SQL
Minimum Qualifications
Bachelors degree in Computer Science or related field
Preferred Qualifications
Exposure to Public Cloud platforms (GCP, AWS, Azure) a plus
Salary Range: $85,000.00 to $150,000.00 annually + bonus + benefits
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible working model with hybrid, onsite or virtual arrangements depending on role and business need
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions."
1008920645885,Glassdoor,,,,
1008923162032,Glassdoor,,,http://www.highmarkhealth.org/,"Company :
Highmark Health
Job Description :
JOB SUMMARY
This job architects and engineers solutions associated with analytic data for the organization and, working closely with the IT teams, assists with the design, build, and upkeep for these solutions. This includes creating pathways for analysts to access operational, derived, and external data sets. The incumbent is responsible for the operation of Data Platforms as they are associated with analytic data discovery. This job also includes creating and maintaining GCP data flow jobs ensuring efficiency and reliability. Overseeing and enhancing the Terraform codebase, ensuring its scalability, performance, and security. Designing and implementing ELT pipelines to amass core member listening system data, facilitating efficient cohort processing. You should be able to adapt to emerging technological advancements and incorporate them into the existing system where beneficial. Perform other duties as assigned, ensuring the continued growth and efficiency of the Member Listening System.
ESSENTIAL RESPONSIBILITIES
Receiving some direction, work closely with IT to architect and engineer solutions to provide views for the Analytic Data Warehouse. This would include working with the proper the teams, assisting with the design, building out the design, and providing upkeep for the solution.
Assemble, test, process, and maintain the Analytic Discovery Platform for the analytics organizations. This will include working to maintain pipelines with key analytic platforms throughout the organization.
Work with alternative analytic data systems to incorporate them into the operational data flow for the Analytics Teams. This may include products purchased by the organization that must be ingested or modeled/derived data maintained by analytic teams.
Complete tasks associated with a project. Meet with customers as part of a team lead by Lead or Senior.
Other duties as assigned.
EDUCATION

Required
Bachelor's Degree in Computer Systems Analysis, Data Processing, Healthcare Informatics, Management Information Systems, or related field or relevant experience and/or education as determined by the company in lieu of bachelor's degree.

Preferred
None
EXPERIENCE
Required
3 - 5 years of Data Analytics Experience
Preferred
1 - 3 years of Data Warehousing Experience
1 -3 years of Database Administration Experience
1 - 3 years of Healthcare Industry Experience
Proficiency in Python leveraging Apache Beam and Dataflow modules.
Strong experience with GCP services including but not limited to BigQuery, CloudSQL, Pub/Sub and GCS.
Solid understanding of Terraform.
Experience with GCP Composer or Airflow.
Demonstrated ability in building and maintaining data pipelines and platforms
LICENSES OR CERTIFICATIONS
Required
None
Preferred
None
SKILLS
Microsoft Office
SAS
Language Requirement (other than English)
None
Travel Required
0% - 25%
PHYSICAL, MENTAL DEMANDS and WORKING CONDITIONS
Position Type
Office-Based
Teaches / trains others regularly
Occasionally
Travel regularly from the office to various work sites or from site-to-site
Rarely
Works primarily out-of-the office selling products/services (sales employees)
Never
Physical work site required
Yes
Lifting: up to 10 pounds
Occasionally
Lifting: 10 to 25 pounds
Rarely
Lifting: 25 to 50 pounds
Never
Disclaimer: The job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title. It may not contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees to do this job.
Compliance Requirement: This position adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies.
As a component of job responsibilities, employees may have access to covered information, cardholder data, or other confidential customer information that must be protected at all times. In connection with this, all employees must comply with both the Health Insurance Portability Accountability Act of 1996 (HIPAA) as described in the Notice of Privacy Practices and Privacy Policies and Procedures as well as all data security guidelines established within the Company’s Handbook of Privacy Policies and Practices and Information Security Policy. Furthermore, it is every employee’s responsibility to comply with the company’s Code of Business Conduct. This includes but is not limited to adherence to applicable federal and state laws, rules, and regulations as well as company policies and training requirements.
Pay Range Minimum:
$57,700.00
Pay Range Maximum:
$106,700.00
Base pay is determined by a variety of factors including a candidate’s qualifications, experience, and expected contributions, as well as internal peer equity, market, and business considerations. The displayed salary range does not reflect any geographic differential Highmark may apply for certain locations based upon comparative markets.
Highmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, age, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, age, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.
EEO is The Law
Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Sexual Orientation/Gender Identity ( https://www.eeoc.gov/sites/default/files/migrated_files/employers/poster_screen_reader_optimized.pdf )
We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact number below.
For accommodation requests, please contact HR Services Online at HRServices@highmarkhealth.org
California Consumer Privacy Act Employees, Contractors, and Applicants Notice"
1008918194812,Glassdoor,$81K,$120K,http://www.mcdonalds.com/,"Company Description

McDonald’s evolving Accelerating the Arches growth strategy puts our customers and people first, and uses our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.
Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)
Our growth pillars emphasize the meaningful role technology plays as the leading, global omni-channel restaurant brand. Technology enables the organization through digital technology, and improving the customer, crew and employee experience each and every day.
Global Technology forging the way
Leading the digitization of our business is the Technology organization made up of intrapreneurs who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of cutting-edge opportunities for the business. At McDonald’s you get to solve technology innovation challenges at an incredible scale, and work across global teams who are always eager for a challenge. This provides access to exciting career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.

Job Description

McDonald’s Global Technology – Data & Analytics team is looking to hire a Data Engineer who has a deep understanding of data product lifecycle, standards and practices. You will be responsible for building scalable and efficient data solutions to support the company's data products and analytics initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Your expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role in delivering high-quality data products and enabling data-driven decision-making.
Responsibilities:
Builds and maintains relevant and reliable data products that support the business needs. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development engineering. Helps to define business rules that determines the quality of data, assists the product owner in writing test scripts that validates business rules, and performs detailed and rigorous testing to ensure data quality
Develops a solid understanding of the technical details of data domains, and clearly understands what business problems are being solved
Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).
Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.
Collaborating with data scientists and analysts to understand data requirements and ensure data accuracy, integrity, and availability.
Building and optimizing data integration workflows to connect data from different systems and platforms.
Monitoring and troubleshooting data pipelines, identifying and resolving performance issues and bottlenecks.
Ensuring data security and compliance with data governance policies and regulations.
Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to improve data systems and processes.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed. For instance, early morning/late evening hours to coordinate with teams in India

Qualifications

Requirements:
Bachelor's or Master's degree in Computer Science or related engineering field and deep experience with AWS infrastructure
5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.
7+ years of proficiency in programming languages commonly used in data engineering, such as Python.
3+ years of hands-on experience with big data processing frameworks, such as Apache Spark.
5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.
Working knowledge of relational and dimensional data design and modeling in a large multi-platform data environment
Solid understanding of SQL and database concepts.
Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Expert Knowledge of data, master data and metadata related standards, processes and technology
Ability to drive continuous data management quality (i.e. timeliness, completeness, accuracy) through defined and governed principles
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent communication and collaboration skills to work effectively in cross-functional teams.
Preferred Requirements:
Experience with JIRA and Confluence as part of project workflow and documentation tools is a plus
Experience with Agile project management methods and terminology a plus
Experience with Prometheus, Grafana

Additional Information

McDonald’s is committed to providing qualified individuals with reasonable accommodations to perform the essential functions of their jobs. Additionally, if you (or another applicant of whom you are aware) require assistance accessing or reading this job posting or otherwise seek assistance in the application process, please contact recruiting.supportteam@us.mcd.com
McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
Nothing in this job posting or description should be construed as an offer or guarantee of employment."
1008923472845,Glassdoor,,,http://www.crfusa.com/,"Posted on October 12, 2023
About the Position
The Data Engineer is responsible for supporting the implementation of projects focused on collecting, aggregating, storing, reconciling, and making data accessible from disparate sources to enable analysis and decision making. The Data Engineer will play a critical role in the data supply chain by ensuring stakeholders can access and manipulate data for routine and ad hoc analysis. The Data engineer will additionally support the full lifecycle of data from sources through analytics to action.
The Data Engineer must be an experienced user of Power BI. The Data Engineer will develop scalable, reliable, and high-impact solutions leveraging the Azure cloud platform to create a modern enterprise data platform. The Data Engineer will work closely with business stakeholders and data analysts to understand the data needs and design, implement, and maintain Power BI reports, dashboards, and visualizations.
Key Responsibilities & Accountabilities
Translate business requirements to technical solutions leveraging strong business acumen
Analyze current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services
Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
Deliver of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
Design and Build Azure Data Pipelines using Databricks.
Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
Expose data to end users using Power BI or any other modern visualization platform or experience
Implement effective metrics and monitoring processes
About You
Bachelor’s degree in Computer Science (or related field), or equivalent work experience
Minimum of 4 years data engineering experience
Demonstrated experience of turning business use cases and requirements to technical solutions
Experience in business processing mapping of data and analytics solutions.
Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.
Strong team collaboration and experience working with remote teams
The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration
Experienced in Data Transformation using ETL/ELT tools such as AWS Glue, Azure Data Factory, Talend, EAI
Knowledge in business intelligence tools such as Power BI, Tableau, Qlik, Cognos TM1
Knowledge of Azure Data Factory, Azure Data Lake, Relational Databases SQL DW, and SQL, Azure App Service is required. Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus
Experienced in Cloud Data-related tool such as Microsoft Azure, Amazon S3
Ability to leverage on variety of programming languages & data management/processing tools to ensure data reliability, quality & efficiency
Knowledge of Python is a plus
Designing and building Data Pipelines using streams of IOT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
Organizational Policies
Community Reinvestment Fund USA, Inc is an affirmative action equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status or any other characteristic protected by law.
Candidates must reside in and be authorized to work in the United States without sponsorship.
CRF’s Theory of Change
CRF’s Theory of Change is the strategic framework used to guide its work. While CRF’s mission remains constant, the Theory of Change outlines how it contributes to the changes it seeks.
The challenge CRF works to address
The current economic system, perpetuated by institutional racism, individual biases and disparities, is unjust. It fosters the inequities that are causing widening disparities in incomes, wealth, and opportunity gaps.
A just economy that works for all
CRF’s Theory of Change is underpinned by the conviction that small businesses are the backbone of our economy, employing nearly half of the U.S. workforce and generating two-thirds of new jobs. CRF believes that providing small businesses equitable access to capital and support services is essential to creating a just economy that works for all.
CRF activates its mission by:
Co-creating and deploying innovative financial products and services that address the barriers and inequities small businesses operated by historically excluded people face.
Designing and managing financial programs that attract incremental impact capital to communities with a history of underinvestment.
Orchestrating a network of trusted small business support organizations enabled by technology.
Growing the capacity of community development finance organizations.
Helping small businesses navigate the complexities of the small business support ecosystem.
CRF STANDS IN SOLIDARITY
Community Reinvestment Fund, USA (CRF) stands in solidarity with all fighting for social justice, equity, and transformational change. They know that the social changes taking place today will yield a lasting positive impact on the lives of millions.
DIVERSITY, EQUITY & INCLUSION:
CRF is dedicated to building and sustaining a truly diverse, equitable, and inclusive culture. These are not just words on a page – Diversity, Equity & Inclusion are top priorities for the organization, and tie deeply to each of their core values and overall vision for the future. CRF is an equal opportunity employer that evaluate applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law.
CORE VALUES
Create Equitable Economic Opportunities, Lead Through Collaboration, Transform Through Innovation, Excel In All They Do, Act with Integrity.
How We Help
Together with its partners – including community leaders, nonprofit lenders, financial institutions, foundations and more – CRF is creating new strategies and technologies that build stronger local economies, create jobs and support economic mobility.
CRF is headquartered in Minneapolis, Minnesota. For a more detailed description of the incredible work we do, how we do it, and who we are, please visit www.crfusa.com.
Department:
Data and Analytics
Location:
Minneapolis, MN – remote work is available
Salary:
$85,000 to $105,000 Annually (exempt)
What We Offer
A collaborative working environment comprised of driven and highly engaged individuals committed to diversity, equity, and inclusion and the mission, vision and values of CRF. CRF is proud to extend its employees a wide array of benefits including, but not limited to:
Health and dental insurance
403B and Roth IRA
Paid Time Off (PTO)
Wellness Program
Educational Assistance
Long-Term and Short-Term Disability
Life Insurance
Flexible schedules and telecommuting options
10 Federal Holidays plus 2 Floating Holidays
How to Apply
To apply for this or other positions, please send your resume to: recruiting@crfusa.com
Community Reinvestment Fund USA, Inc is an affirmative action equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status or any other characteristic protected by law.
CRF USA, Inc. requires all employees to be vaccinated for COVID-19. As a condition of hire with CRF USA, Inc. candidates must be able to show proof of vaccination for COVID-19 prior to an extension of an offer of employment. Accommodations will be considered for disabilities or sincerely held religious beliefs.
Candidates must reside in and be authorized to work in the United States without sponsorship."
1008923102776,Glassdoor,,,,"Overview
The Institute for Defense Analyses (IDA) is a non-profit Federally Funded Research and Development Center. IDA provides answers to questions posed by the Department of Defense and other agencies that require careful analysis. IDA’s goal is to deliver objective, evidence-based, actionable analyses and advice focused on results.
The Information Technology and System Division (ITSD) focuses on cybersecurity and other cyberspace challenges of national and global significance. ITSD approaches the growing cyber threat from the perspectives of operations and business, technology and systems, and policy and law, with a particular emphasis on where and how these perspectives intersect. This intersection, also known as “cyber in the seams,” addresses the evolution of cyber as a national security function.

Responsibilities
ITSD has an immediate opening for a data engineer to join our fulltime professional research staff and to work as a member of study teams and at the direction of senior study leaders and analysts. Incumbent will generally perform fact-finding tasks, discover and investigate relevant technologies, develop preliminary analyses, and shape findings and recommendations for the team. Incumbent will be expected to be familiar with standard information collection, compilation, summary and analysis methods; and able to develop or apply appropriate methods to support the needs of particular studies or analyses.

Duties include:
Participate in developing and maintaining information sources and contacts as directed; may attend meetings to collect information related to projects.
Collaborate with senior study leaders to develop, construct, test, and maintain the data architecture for research projects or portfolios.
Create information models using ontologies and taxonomies and other semantic models.
Implement information models in relational or graph databases as appropriate.
Employ programming languages like SQL, NoSQL, OWL, RDF, SPARQL, R, or Python to create data pipelines, linking data sources and ensuring that data pipelines are reliable and efficient.
Manipulate, transform, and organize data to prepare for analysis and visualization.
Research topics independently, compile data, and present information both orally and in writing.
Interact with government or industry representatives.
Contribute to the creation/writing of project report(s) or paper(s).

Qualifications
A minimum of a bachelor’s degree in computer science, Information Technology, Data Science, Computer Engineering, or an inter-disciplinary program that encompasses several of these fields of study. Masters preferred.
Demonstrated ability to identify sources, and assemble and organize large, complex data sets for which subsequent quantitative and qualitative analyses is desired.
Understanding of data-intensive, web-based semantic technology is desired.
Strong communication (oral and written) and interpersonal skills is required.
Ability to contribute effectively to a team approach to problem solving is required.
Ability to obtain and maintain necessary security clearance.
Successful completion of a criminal background check is required.
U.S. Citizenship is required

Ability to obtain and maintain a security clearance is required

IDA is an equal opportunity employer committed to providing a fair recruiting process and working environment free from discrimination. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identify, national origin, disability or protected veteran status. Click here to learn more about IDA's commitment to diversity, equity, and inclusion."
1008919648039,Glassdoor,$74K,$115K,http://www.acculynx.com/,"We are seeking a highly skilled and motivated Data Engineer with expertise in creating and managing data lakes and data warehouses. In this role, you will be responsible for designing and implementing efficient data storage and processing solutions using Microsoft SQL Server, Azure Data Factory, and Azure Synapse Analytics. You will collaborate closely with financial planning analysts and other stakeholders to understand their data requirements and build scalable solutions to support their analytical needs.

Responsibilities:
Develop and optimize SQL queries to extract insights from large datasets, leveraging the capabilities of SQL Server.
Design and develop data lakes and data warehouses using industry best practices, ensuring high performance, scalability, and data quality.
Collaborate with FP&A Analysts to understand their data requirements and translate them into technical specifications for data models and schemas.
Extract, transform, and load (ETL) data from various sources into the data lake and data warehouse, ensuring data integrity and consistency.
Monitor and maintain the performance and health of the data lake and data warehouse, implementing necessary optimizations and troubleshooting any issues that arise.
Implement data governance and security measures to ensure compliance with regulatory requirements and protect sensitive information.
Collaborate with cross-functional teams to integrate data from different systems and sources, ensuring data consistency and accuracy across the organization.
Stay up-to-date with emerging technologies, tools, and trends in data engineering and analytics, and evaluate their potential application to improve existing systems and processes.

Requirements:
Bachelor's degree in Computer Science, Engineering, or a related field.
Proven experience designing and implementing data lakes and data warehouses, preferably using Microsoft SQL Server and Azure Synapse.
Strong proficiency in SQL and database management systems.
Experience with data integration, ETL processes, and data modeling concepts.
Familiarity with cloud platforms (e.g., Microsoft Azure, AWS, Google Cloud) and their data-related services.
Knowledge of data governance, data security, and regulatory compliance practices.
Strong analytical and problem-solving skills, with the ability to analyze complex datasets and derive meaningful insights.
Excellent communication and collaboration skills to work effectively with FP&A Analysts and cross-functional teams.
Self-motivated and able to work independently as well as in a team environment.

Join our dynamic team and contribute to the development of a robust data infrastructure that empowers our FP&A Analysts to derive valuable insights and drive informed decision-making."
1008922656619,Glassdoor,$89K,$133K,http://www.fanduel.com/,"ABOUT FANDUEL GROUP
There are more ways to win, here at FanDuel. We're willing to bet on it.
THE ROSTER…
At FanDuel Group, we give fans a new and innovative way to interact with their favorite games, sports and teams. We're dedicated to building a winning team and we pride ourselves on being able to make every moment mean more, especially when it comes to your career. So, what does ""winning"" look like at FanDuel? It's recognition for your hard-earned results, a culture that brings out your best work—and a roster full of talented coworkers. Make no mistake, we are here to win, but we believe in winning right. That means we'll never compromise when it comes to looking out for our teammates. From creatives professionals to cutting edge technology innovators, FanDuel offers a wide range of career opportunities, best in class benefits, and the tools to explore and grow into your best selves. At FanDuel, our principle of ""We Are One Team"" runs through all our offices across the globe, and you can expect to be a part of an exciting company with many opportunities to grow and be successful.
WHO WE ARE…
FanDuel Group is an innovative sports-tech entertainment company that is changing the way consumers engage with their favorite sports, teams, and leagues. The premier mobile gaming destination in the United States, FanDuel Group consists of a portfolio of leading brands across sports betting, iGaming, horse racing, advance-deposit wagering, daily fantasy sports. In addition, FanDuel Group operates FanDuel TV its broadly distributed linear cable television and leading direct-to-consumer OTT platform. FanDuel Group has a presence across all 50 states with approximately 17 million customers and 25 retail locations. The company is based in New York with offices in Los Angeles, Atlanta and Jersey City, as well as in Canada, Scotland, Ireland, Portugal, Romania and Australia. FanDuel Group is a subsidiary of Flutter Entertainment plc, (LON: FLTR) the world's largest sports betting and gaming operator with a portfolio of globally recognized brands.
THE POSITION
Our roster has an opening with your name on it
Data drives our organization. In this role, you will serve as a key technical resource, bridging the gap between front-line data issues and complex data solutions. You will play a pivotal role in troubleshooting, analyzing, and resolving data-related issues while ensuring platforms are running optimally You will serve a large group of customers: the engineering teams building our online applications, data scientists mining our data and training our models, and our analysts who make the data mean something.
We are looking for Data Engineers or experienced engineers from other disciplines who may be looking to make the move to a big data environment. If this describes you, read on – we want to hear from you!
THE GAME PLAN
Everyone on our team has a part to play
Issue Resolution: Handle escalated data and platform related issues, providing solutions in a timely manner.
Collaboration: Work alongside engineering teams and stakeholders to offer expertise on more complex issues.
Data Integrity: Ensure data accuracy and consistency across platforms and systems.
Documentation: Maintain and update technical documentation related to data processes and issue resolutions.
Support ETL/ELT pipelines built using Python and Databricks.
Leverage your SQL skills to troubleshoot issues related to SQL
Oversee and administer data workflows with Apache Airflow and DBT.
Support a broad suite of platforms across our data ecosystem including Redshift, Tableau, Athena, Spectrum, Spark, Hadoop, Trino, Kafka.
Leadership and teaching within a cross-functional team, embodying a willingness to grow and to grow those around you and actively seek continued learning opportunities.
Apply your experience and intellect as part of an autonomous team with end-to-end ownership of key components of our data infrastructure.
Serve as a mentor to more junior engineers not only in cultivating craftsmanship but also in achieving operational excellence – system reliability, automation, data quality, and cost-efficiency.
THE STATS
What we're looking for in our next teammate
Working SQL knowledge and experience working with relational databases
Experience building processes supporting data transformation, data structures, metadata, dependency, and workload management
Show proficiency in understanding ETL processes
Demonstrate the ability to optimize data pipelines
Knowledge of data integrity and relational rules
Understanding of AWS and Google Cloud
Ability to quickly learn new technologies is critical
Comfortable writing Python scripts
PLAYER CONTRACT
We treat our team right
From our many opportunities for professional development to our generous insurance and paid leave policies, we're committed to making sure our employees get as much out of FanDuel as we ask them to give. Competitive compensation is just the beginning. As part of our team, you can expect:
An exciting and fun environment committed to driving real growth
Opportunities to build really cool products that fans love
Mentorship and professional development resources to help you refine your game
Flexible vacation allowance to let you refuel
Hall of Fame benefit programs and platforms
FanDuel Group is an equal opportunities employer and we believe, as one of our principal states, ""We Are One Team!"" We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. We believe FanDuel is strongest and best able to compete if all employees feel valued, respected, and included. We want our team to include diverse individuals because diversity of thought, diversity of perspectives, and diversity of experiences leads to better performance. Having a diverse and inclusive workforce is a core value that we believe makes our company stronger and more competitive as One Team!
#LI-Hybrid"
1008923404500,Glassdoor,,,,"Data Engineer DyD

WHO WE ARE:
At HHS Tech Group (HTG), our work matters, and each of us makes a difference in the lives of people every day.
HTG is a leader in developing and delivering innovative, purpose-built modular software and technology solutions to clients in the commercial and government sectors.
WHAT WE DO:
HHS Tech Group creates innovative, purpose-built technology products and solutions, resulting in value and positive, quantifiable impact for our clients and those they serve.
Our people bring our software to life through collaborative relationships with our clients, working as a team, and helping to solve complex problems that create positive personal and community impact for the people our clients serve.
Each day, our software products and our people are making a difference.
OUR PEOPLE MATTER MOST:
Improving the lives of others and making an impact daily is no simple task. We are dedicated to our team’s professional and personal growth and well-being. Some key rewards and benefits include:
Generously sponsored Medical Insurance
Fully paid premiums on dental, vision, life, and disability insurance.
Generous 401k matching program (100% match up to 6%)
Tuition and Certification reimbursement
Open PTO policy
Join us!
WHO WE ARE HIRING: Data Engineer DyD

WHAT YOU WILL DO:
HHS Technology Group is expanding. We create software products relevant to the healthcare insurance domain. Our growth trajectory is fantastic. We are leveraging data science to create healthcare insurance software to identify data trends which would indicate fraud waste and abuse scenarios as well as third-party liability, thusly allowing the insurance provider to recover their funds, which may have been paid erroneously. This is a fully remote role.

MINIMUM QUALIFICATIONS:

2+ years of work experience with ETL
Expert-level skills in writing SQL
Python and SQL/MongoDB skills are must requirements.
Experience with Big Data technologies such as Spark
Experience with AWS Big Data technologies such as AWS Glue/EMR, S3, AWS Athena
Experience with Data warehouses such as Snowflake/Redshift
Knowledge of processing Claims/EMR/EHR/Provider / Member datasets.
Experience with NodeJS, ReactJS

DESIRED SKILLS:

Ability to multi-task, take initiative, assume accountability, work independently, and self-manage duties and responsibilities, as well as intuitively having the ability to pivot focus between tasks according to priorities to achieve maximum efficiency.
Experience with Apache AirFlow
Working with HIPAA and Secure Data transfers (TLS 1.2+ standards)
Understand data s3 Data encryption standards for HIPAA data (AES 256 +)
Data pipeline building and preparing documentation and flow charting.
Working with a client's technical team to ensure efficient processing of data.

HHS Technology Group’s flagship product, Discover your Provider (DyP) is a provider relations/provider enrollment solution. Components of this modular software can be re-purposed or built upon to deliver cloud based technical web services solutions.

Applicants for employment in the US must have work authorization that does not, now or in the future, require sponsorship of a visa for employment authorization in the United States.
EEO Statement
HHS Technology Group is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.
NI3tKHsl6f"
1008922960211,Glassdoor,$81K,$113K,https://www.infosys.com/,"Infosys is seeking an GCP Data Engineer with experience working in a Big Data ecosystem. The position will primarily be responsible interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation and Design. You will play an important role in creating the high-level design artifacts. You will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition and warranty. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued.

Required Qualifications:
Candidate must be located within commuting distance of Irving, TX, Tampa, FL, Alpharetta, GA, or Bridgewater,NJ OR be willing to relocate to the area. This position may require travel in the US and Canada. This is hybrid position. Candidate needs to visit office as per requirement.
Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education.
US citizens and those authorized to work in the US are encouraged to apply.
Minimum 4 years of experience with Information Technology
Atleast 2 years of hands on-experience working with technologies like – GCP with data engineering – data flow / air flow, pub sub/ kafta, data proc/Hadoop, Big Query.
Atleast 3 years of ETL development experience with strong SQL background
Hands-on experience of building and operationalizing data processing systems
Atleast 2 years’ of experience in NoSQL databases and close familiarity with technologies/languages such as Python/R, Scala, Java, Hive, Spark, Kafka
Atleast 2 years of experience with any traditional RDBMS (e.g., Teradata, Oracle, DB2).
Minimum 1 year of experience working with data platforms (Data warehouse, Data Lake, ODS).
Prior experience working with tools to automate CI/CD pipelines is must. (e.g., Jenkins, GIT, Control-M)
Preferred Qualifications:
GCP (google cloud platform) experience
Data analysis / Data mapping skills
Experience in data manipulation JSON and XML
Ability to work in team in diverse/ multiple stakeholder environment
Ability to communicate complex technology solutions to diverse teams namely, technical, business and management teams

The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.

About Us
Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.

Visit www.infosys.com to see how Infosys (NYSE: INFY) can help your enterprise navigate your next.

Infosys is an equal opportunity employer and all qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, spouse of protected veteran, or disability."
1008923664012,Glassdoor,,,https://www.teamibr.com/,"The Senior Data Engineer must be able to meet the key criteria below:
Location: 100% telework
Years' Experience: 10+ years
Education: Bachelor’s in IT related field
Security Clearance: IBR is a federal contractor. Applicants must be able to meet the requirements to obtain an Public Trust security clearance. NOTE: United States Citizenship is required.
Work Authorization: Must show that applicant is legally permitted to work in the United States.
Employment Type: Full-Time, W-2
Key Skills:
10+ years of IT experience focusing on enterprise data architecture and management
Experience with Databricks required
8+ years experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling
Experience with ETL and ELT tools such as SSIS, Pentaho, and/or Data Migration Services
Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization)
Experience with AWS environment, CI/CD pipelines, and Python (Python 3) a bonus
Overview
Do you want to help build a portfolio of next-generation mobile-enabled data collection systems and enterprise portals? As a Data Engineer at IBR, you will support the Agile based engineering of a robust, secure, and scalable enterprise web portal solutions hosted in AWS. This position will work closely with the solutions delivery team to supporting the operations team performing Deployment, Systems Integration Testing, and Operations & Maintenance activities.
Responsibilities
Plan, create, and maintain data architectures, ensuring alignment with business requirements
Obtain data, formulate dataset processes, and store optimized data
Identify problems and inefficiencies and apply solutions
Determine tasks where manual participation can be eliminated with automation.
Identify and optimize data bottlenecks, leveraging automation where possible
Create and manage data lifecycle policies (retention, backups/restore, etc)
Create, maintain, and manage ETL/ELT pipelines
Create, maintain, and manage data transformations
Maintain/update documentation
Create, maintain, and manage data pipeline schedules
Monitor data pipelines
Create, maintain, and manage data quality gates (Great Expectations) to ensure high data quality
Support AI/ML teams with optimizing feature engineering code
Spark updates
Create, maintain, and manage Spark Structured Steaming jobs, including using the newer Delta Live Tables and/or DBT
Research existing data in the data lake to determine best sources for data
Create, manage, and maintain ksqlDB and Kafka Streams queries/code
Maintain and update Python-based data processing scripts executed on AWS Lambdas
Unit tests for all the Spark, Python data processing and Lambda codes
Maintain PCIS Reporting Database data lake with optimizations and maintenance (performance tuning, etc)
Qualifications
10+ years of IT experience focusing on enterprise data architecture and management
Experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling
Experience with Databricks, Structured Streaming, Delta Lake concepts, and Delta Live Tables required
Additional experience with Spark, Spark SQL, Spark DataFrames and DataSets, and PySpark
Data Lake concepts such as time travel and schema evolution and optimization
Structured Streaming and Delta Live Tables with Databricks a bonus
Experience leading and architecting enterprise-wide initiatives specifically system integration, data migration, transformation, data warehouse build, data mart build, and data lakes implementation / support
Advanced level understanding of streaming data pipelines and how they differ from batch systems
Formalize concepts of how to handle late data, defining windows, and data freshness
Advanced understanding of ETL and ELT and ETL/ELT tools such as SSIS, Pentaho, Data Migration Service etc
Understanding of concepts and implementation strategies for different incremental data loads such as tumbling window, sliding window, high watermark, etc.
Familiarity and/or expertise with Great Expectations or other data quality/data validation frameworks a bonus
Understanding of streaming data pipelines and batch systems
Familiarity with concepts such as late data, defining windows, and how window definitions impact data freshness
Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization)
Indexing and partitioning strategy experience
Debug, troubleshoot, design and implement solutions to complex technical issues
Experience with large-scale, high-performance enterprise big data application deployment and solution
Understanding how to create DAGs to define workflows
Familiarity with CI/CD pipelines, containerization, and pipeline orchestration tools such as Airflow, Prefect, etc a bonus but not required
Architecture experience in AWS environment a bonus
Familiarity working with Kinesis and/or Lambda specifically with how to push and pull data, how to use AWS tools to view data in Kinesis streams, and for processing massive data at scale (UNICORN) a bonus
Experience with Docker, Jenkins, and CloudWatch
Ability to write and maintain Jenkinsfiles for supporting CI/CD pipelines
Experience working with AWS Lambdas for configuration and optimization
Experience working with DynamoDB to query and write data
Experience with S3
Knowledge of Python (Python 3 desired) for CI/CD pipelines a bonus
Familiarity with Pytest and Unittest a bonus
Experience working with JSON and defining JSON Schemas a bonus
Experience setting up and management Confluent/Kafka topics and ensuring performance using Kafka a bonus
Familiarity with Schema Registry, message formats such as Avro, ORC, etc.
Understanding how to manage ksqlDB SQL files and migrations and Kafka Streams
Ability to thrive in a team-based environment
Experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior level of management
Physical Demands
Position consists of sitting for long periods of time, bending, stooping, crouching, and lifting up to 20 pounds. Frequently uses hands/fingers for manipulation of keyboard and mouse.
Work Environment
Work is performed primarily indoors in a well-lit office environment. The environment is normally air conditioned, but conditions may change dependent upon circumstances. Work may need to be performed in a fast-paced environment requiring quick thinking and rapid judgements. Employee will be exposed to a wide variety of clients in differing functions, personalities, and abilities.
About IBR
Imagine Believe Realize, LLC (IBR) is an emerging small business focused on delivering software and systems engineering solutions to government and commercial clients. Our talent acquisition strategy is tailored to career seeking candidates who embrace continuous learning and desire to grow as a professional in the software/systems engineering industry. We strive to enhance our team members ability to thrive in the workplace by creating a proper work/life balance and first-class benefits package that includes:
Nationwide medical, dental, and vision insurance
3 weeks of Paid Time Off and 11 Paid Federal Holidays
401k matching
Life Insurance, Short-Term Disability, and Long-Term Disability at no cost to our employees
Flexible spending accounts and Dependent Care spending accounts
Wellness incentives
Reimbursement for professional development and certifications
Training assistance opportunities
Upon hire and in compliance with federal law, all persons hired are required to verify identity and eligibility to work in the United States, and to complete the required employment eligibility verification and background check. IBR is a Federal Contractor.
Imagine Believe Realize, LLC is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate based upon race, age, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.”
Learn more at http://www.teamibr.com
If alternative methods of assistance are needed with the application process, additional contact information has been provided below:
info@teamibr.com
407.459.1830
Job Type: Full-time
Pay: $131,243.38 - $158,056.53 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Vision insurance
Experience level:
10 years
Schedule:
Monday to Friday
Work Location: Remote"
1008922656617,Glassdoor,$101K,$146K,http://www.fanduel.com/,"ABOUT FANDUEL GROUP
There are more ways to win, here at FanDuel. We're willing to bet on it.
THE ROSTER…
At FanDuel Group, we give fans a new and innovative way to interact with their favorite games, sports and teams. We're dedicated to building a winning team and we pride ourselves on being able to make every moment mean more, especially when it comes to your career. So, what does ""winning"" look like at FanDuel? It's recognition for your hard-earned results, a culture that brings out your best work—and a roster full of talented coworkers. Make no mistake, we are here to win, but we believe in winning right. That means we'll never compromise when it comes to looking out for our teammates. From creatives professionals to cutting edge technology innovators, FanDuel offers a wide range of career opportunities, best in class benefits, and the tools to explore and grow into your best selves. At FanDuel, our principle of ""We Are One Team"" runs through all our offices across the globe, and you can expect to be a part of an exciting company with many opportunities to grow and be successful.
WHO WE ARE…
FanDuel Group is an innovative sports-tech entertainment company that is changing the way consumers engage with their favorite sports, teams, and leagues. The premier mobile gaming destination in the United States, FanDuel Group consists of a portfolio of leading brands across sports betting, iGaming, horse racing, advance-deposit wagering, daily fantasy sports. In addition, FanDuel Group operates FanDuel TV its broadly distributed linear cable television and leading direct-to-consumer OTT platform. FanDuel Group has a presence across all 50 states with approximately 17 million customers and 25 retail locations. The company is based in New York with offices in Los Angeles, Atlanta and Jersey City, as well as in Canada, Scotland, Ireland, Portugal, Romania and Australia. FanDuel Group is a subsidiary of Flutter Entertainment plc, (LON: FLTR) the world's largest sports betting and gaming operator with a portfolio of globally recognized brands.
THE POSITION
Our roster has an opening with your name on it
FanDuel Group is looking for an experienced Senior Data Engineer with deep understanding of large-scale data handling and processing best practices in a cloud environment to help us manage our systems at scale. As our data is a key component of the business used by almost every facet of the company, including product development, marketing, operations, and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability.
Our competitive edge comes from making decisions based on accurate and timely data. As a seasoned expert you will be responsible for overseeing the technical aspects of the data support team. You not only handle the most intricate data-related challenges but also provide leadership, strategic direction, and mentorship to other engineers.
THE GAME PLAN
Everyone on our team has a part to play
Advanced Issue Resolution: Tackle the most challenging data-related problems, often requiring deep dives and innovative solutions.
Strategic Leadership: Guide the direction of data support initiatives and processes, ensuring optimal efficiency and evolution.
Mentorship: Mentor and develop junior engineers, fostering a culture of continuous learning and improvement.
Process Improvement: Identify and implement enhancements in the support process to reduce ticket volume and improve resolution time.
Stakeholder Communication: Act as a primary liaison between the data support team, users and higher management, communicating issues, solutions, and strategic insights.
Support ETL/ELT pipelines built using Python and Databricks.
Leverage your SQL skills to troubleshoot issues related to SQL
Oversee and administer data workflows with Apache Airflow and DBT.
Support a broad suite of platforms across our data ecosystem including Redshift, Tableau, Athena, Spectrum, Spark, Hadoop, Trino, Kafka.
THE STATS
What we're looking for in our next teammate
Advanced working SQL knowledge and experience working with relational databases
Experience building processes supporting data transformation, data structures, metadata, dependency, and workload management
Show proficiency in understanding complex ETL processes
Demonstrate the ability to optimize data pipelines
Knowledge of data integrity and relational rules
Understanding of AWS and Google Cloud
Ability to quickly learn new technologies is critical
Comfortable writing Python scripts
PLAYER CONTRACT
We treat our team right
From our many opportunities for professional development to our generous insurance and paid leave policies, we're committed to making sure our employees get as much out of FanDuel as we ask them to give. Competitive compensation is just the beginning. As part of our team, you can expect:
An exciting and fun environment committed to driving real growth
Opportunities to build really cool products that fans love
Mentorship and professional development resources to help you refine your game
Flexible vacation allowance to let you refuel
Hall of Fame benefit programs and platforms
FanDuel Group is an equal opportunities employer and we believe, as one of our principal states, ""We Are One Team!"" We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. We believe FanDuel is strongest and best able to compete if all employees feel valued, respected, and included. We want our team to include diverse individuals because diversity of thought, diversity of perspectives, and diversity of experiences leads to better performance. Having a diverse and inclusive workforce is a core value that we believe makes our company stronger and more competitive as One Team!
#LI-Hybrid"
1008921178659,Glassdoor,$103K,$139K,http://www.lineagelogistics.com/,"A Senior Data Engineer is accountable for the design and implementation of Lineage's data assets. Specifically, this includes being responsible for developing normalized, dimensional, and hybrid data models to support reporting, analytics, and APIs used by other internal and external applications.
The Data Engineer will focus on the following:
1. Data Ingestion - moving source system data to central data assets
2. Data Modeling - determining field-level data usage
3.Data Wrangling - identifying queries/algorithms to efficiently transform data from source system formats to a unified RDBMS schema
4.Data Quality - ensuring complete and uninterrupted data mappings from source to central data assets
Job Description:
A Senior Data Engineer is accountable for the design and implementation of Lineage's data assets. Specifically, this includes being responsible for developing normalized, dimensional, and hybrid data models to support reporting, analytics, and APIs used by other internal and external applications. The Data Engineer will focus on the following:
Data Ingestion - moving source system data to central data assets Data Modeling - determining field-level data usage Data Wrangling - identifying queries/algorithms to efficiently transform data from source system formats to a unified RDBMS schema Data Quality - ensuring complete and uninterrupted data mappings from source to central data assets
At Lineage, we leverage cloud services, best-of-breed technologies, and external teams to augment our capabilities with sufficient capacity. This means that in addition to being a great technologist and individual contributor, you need to be able to review and collaborate with partners to ensure that we get the same quality from them too.
As a company, Lineage Logistics leverages state-of-the-art technology to meet our customers' needs, assist in our international growth, and create an infrastructure that enables Lineage to lead the industry.
As the ideal candidate for this position, you will exhibit the technical expertise, business acumen and flexibility required to successfully work with all levels of Lineage's organization.
Essential Job Functions:
Perform detailed data analysis and translate business requirements into logical and physical data models
Lead complex technical data discussions on modeling, integration, and overall technology solutions and design
Possess the ability to a create robust, scalable, and sustainable data architecture that supports requirements and provides for future expansion
Integrate additional data sets into the Operational Data Store to support organizational needs
Re-engineer existing physical data structures and recommend efficiencies as it relates to data storage and retrieval
Automate, monitor, and support data mappings, and re-design if required to make them faster and/or more reliable
Design and implement system components which reconcile and audit the results of the extract/transform or conversion of data from source systems to the target structures
Manage and provide guidance to employee and contract resources
Work closely with others to help ensure the physical design meets the functional and performance requirements of the applications utilizing the data
Collaborate with report and API developers on data mapping and report / application design
Requirements:
Possess prior experience in designing and building data ingestion and storage solutions
Exhibit knowledge related to full life cycle experience in Data Modeling, Data Integration, and Master Data Management
Architect and implement data structures for reporting solutions
Mastery of SQL with ability to perform analytical queries as well as updates to data sets
Grow and maintain a broad and deep knowledge of data technologies and techniques
Possess a willingness to be coached and proactively seek feedback
Handle multiple assignments/projects simultaneously
Properly set priority and order for work
Work in a fast-paced, agile environment
Ask for help and provide it to others
Understand your skills and your talents and apply them appropriately
Learn and apply new technologies and business concepts
Maintain personal accountability for getting things done on time and with quality results
Demonstrate excellent verbal and written communication skills including the ability to explain technical concepts to business leaders
Be willing and able to travel on occasion (<1 week per month)
Education and/or Experience:
5+ years - Data Engineering / Modeling experience; delivering both logical models and physical designs with experience translating business needs into data requirements
A degree in Computer Science, a related discipline, or equivalent work experience of 6+ years overall IT or the equivalent combination of education, training and experience from which comparable skills can be acquired
Experience with cloud-based data platforms
Experience with a mix of relational database technologies like Microsoft SQL-Server, Oracle, PostgreSQL, MySQL, etc.
Preferred Skills:
Previous Supply Chain or Logistics industry experience strongly preferred
Experience working with data from the following technologies is a plus: ERP, WMS, TMS, CRM, HRIS
Prior software development experience is also preferred
Why Lineage?
This is an excellent position to begin your career path within Lineage! Success in this role enables greater responsibilities and promotions! A career at Lineage starts with learning about our business and how each team member plays a part each and every day to satisfy our customers' requirements. Beyond that, you'll help us grow and learn on our journey to be the very best employer in our industry. We'll ask you for your opinion and ensure we do our part to keep you developing and engaged as we grow our business. Working at Lineage is energizing and enjoyable. We value respect and care about our team members.
Lineage is an Equal Employment Opportunity Employer and is committed to compliance with all federal, state, and local laws that prohibit workplace discrimination and unlawful harassment and retaliation. Lineage will not discriminate against any applicant on the basis of race, color, age, national origin, religion, physical or mental disability or any other protected status under federal, state and local law.
Benefits
Lineage provides safe, stable, reliable work environments, medical, dental, and basic life and disability insurance benefits, 401 retirement plan, paid time off, annual bonus eligibility, and a minimum of 7 holidays throughout the calendar year."
1008918720557,Glassdoor,$77K,$112K,http://www.hatci.com/,"Job Description:

Location: Superior Township, MI
Job Level: Senior Engineer
Level of Education: B.S. or M.S. (preferred) Computer Science, Computer Engineering, Electrical Engineering, or a combination of education and equivalent experience
Level of Industry Experience: Minimum 3 years in data analysis in automotive or IT realm
Job Type: Full-Time
Starting Date: ASAP
Job Description:
Hyundai America Technical Center, Inc. (HATCI) is currently seeking a Info Big Data (IBD) engineer at our Superior Township, MI facility. This position is in the department of Infotainment & Connected Car System SW Development that undertakes various innovation projects related to infotainment and connected car systems software development for the next generation vehicle software architecture as well as production application of SW features and service contents.
Core Responsibilities
Implement processes & tool development to capture and analyze Info Big Data (IBD)
Big Data Infrastructure: Design, develop, and maintain our Big Data infrastructure, ensuring high scalability, performance, and reliability.
Data Pipelines: Create and optimize data pipelines using Python and Shell scripting to ingest, transform, and store data from various sources.
Performance Optimization: Continuously monitor and fine-tune the Big Data systems to achieve optimal performance and minimal latency.
Troubleshooting: Proactively identify and resolve issues related to data processing, storage, and performance to ensure smooth and uninterrupted data workflows.
Understanding of Infotainment, Connected Car, & Server for the vehicle environment is beneficial
Support Hyundai-Kia Engineering teams to solve field customer complaints
Collaborate with internal/external project partners such as content providers, prototyping services, university labs, and tech suppliers
Draw implications & values based on analysis result for Specification improvement & ideation
Ensure data analysis environment is fully operational
Lead N. America IBD committee with various stakeholders
Develop IBD dashboard and publish periodic IBD reports to various teams and management
Participate global IBD projects with overseas R&D
Travel up to 15% of time domestically and internationally.

Experience and Skills:
Basic Qualifications
B.S. in Computer Science, Computer Engineering, Electrical Engineering or a combination of education and equivalent experience
Minimum 3 years of industry working experience in data analysis & big data
Experience in general purpose and high-level programming languages; Python, R, SQL, and SCALA
Able to adapt to agile work scope with shifting priorities, demands, and timelines
Comfortable with blank-slate initiatives as well as on-going established projects
Good communication skills and ability to develop/keep good relationship with tech experts from R&D Center and internal counterpart teams
Preferred Qualifications
M.S. Computer Science, Computer Engineering, Electrical Engineering or a related field
Experience with Big data-processing architecture
Strong knowledge with Database optimization & data ingestion techniques
Experience in general purpose and high-level programming languages; Python, R, SQL, and SCALA
Knowledge of Android/iOS development for automotive technologies
Understating of Big Data frameworks
v Candidates applying for positions with Hyundai and KIA must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
v HATCI is an Equal Opportunity Employer including Disabled and Veteran. VEVRAA Federal contractor
From: Hyundai America Technical Center, Inc. (HATCI)"
1008918774090,Glassdoor,,,https://www.logic2020.com/,"Company Description

We’re a seven-time “Best Company to Work For,” where intelligent, talented people come together to do outstanding work—and have a lot of fun while they’re at it. Because we’re a full-service consulting firm with a diverse client base, you can count on a steady stream of opportunities to work with cutting-edge technologies on projects that make a real difference.
Logic20/20's Global Delivery Model creates a connected experience for Logicians across geographies. You'll have access to projects in different locations, the technology to support Connected Teams, and in-person and online culture events in our Connected Hub cities.

Job Description

As a Big Data Engineer working for Logic20/20, you'll be joining a team at one of the nation's largest utility companies in California to work on a Public Safety Power Shutoff dashboard, a tool that provides information to the public about potential power outages due to extreme weather conditions such as high winds, wildfires, and other natural disasters.
Hear more about these efforts as Jeff Lovington shares his experience working in Data Science and Machine Learning for the Energy & Utilities sector.
About the team
The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.
“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics

Qualifications

Must have:
4+ years of proven professional experience working in the IT industry
3-5 years of demonstrated experience in building big data solutions with PySpark
Minimum 3 - 5 years experience in application development using Python
Minimum 3 - 5 years of experience working with Spark
Hands-on development experience in building distributed Big Data solutions including ingestion, caching, processing, consumption, logging & monitoring
Strong technical communication skills
Big Data and Open Source technical experience
Experience developing SaaS application backends and APIs using a variety of tools
Experience turning abstract business requirements into concrete technical plans
Proficiency with algorithms (including time and space complexity analysis), data structures, and software architecture
Ability to learn quickly, evaluate and embrace new technologies
Preferred:
Experience with Palantir’s Foundry, Databricks, Spark M

Additional Information

All your information will be kept confidential according to EEO guidelines.
Compensation range: $125,000 - $155,000 annually
About Logic20/20
To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic
Core Values
At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity & Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.
Logic20/20 Benefits
Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).
You will have
PTO & Paid Holidays – Worry-free time off to recharge and pursue your personal goals
Community & Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities
Referral Programs & Bonuses – Employee, project, and sales referral programs with paid incentives
Equal Opportunity Statement
We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.
To learn more about our DE&I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion
Privacy Policy
During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy."
1008922980008,Glassdoor,,,,
1008922901459,Glassdoor,,,,
1008918164314,Glassdoor,,,https://www.ltimindtree.com/,"Role and Responsibilities:
Should be able write complex and efficient -SQL queries.
Should be able design & Implement end-end data pipelines using cosmos and ADF.
Problem analysis and troubleshooting complex & “large volume of dataset’s” data issues.
Strong communication skills: should be able to communicate complex information to technical and non-technical stakeholders.
Should be able write complex and efficient -SQL queries.
Should be able to design & Implement end-end data pipelines using big data technologies
Problem analysis and troubleshooting complex and large data sets.
Skills required:
Cosmos + SQL experience, Azure data bricks, Power BI, Kusto.
Knowledge of Azure Data Factory, ADLS.
Experience on Data bricks.
Individuals with strong technical background in SQL, SQL Server, data engineering, BI, Kusto, Data Analysis and strong knowledge of Data Warehousing Concepts.
Should be able to Lead the onsite Team of 5 members.
Customer facing, code development and review of dev
T-SQL queries, Performance tuning
Proven experience in strong Data Analysis dealing with large volume of datasets.
Proven experience in Design & Implementation of end-end data pipelines.
Should have strong knowledge of Data Warehousing concepts.
Should have very good experience in BI tools (but not limited to)a. Reporting tools like Power BI
Cosmos and scope scripts
Microsoft Big Data Technologies
Knowledge on Azure Data Factory
About US:
LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 750 clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com.
Equal Employment Opportunity Policy:
LTIMindtree provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics.
To view our privacy notice please click –LTIMindtree Privacy Policy Statement - LTIMindtree
Job Type: Full-time
Salary: $86,460.46 - $110,000.00 per year
Benefits:
Health insurance
Paid time off
Schedule:
Monday to Friday
Ability to commute/relocate:
Bellevue, WA 98007: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person"
1008923087111,Glassdoor,,,,"About OncoHealth

OncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.

About the Role

The Data Engineer - Quality is responsible for the ownership of the data quality framework to support the enterprise data and analytics team. The primary goal for this role is to set data quality standards and combine them with data pipelines to deliver robust enterprise and product data solutions. This role will conduct validation of data originating from both external and internal source systems. Development and delivery of metrics and data content to support the business quality need across a suite of data products and lines of business. The Data Engineer - Quality will ensure establishment of visibility into the quality and content of data assets in various platforms through reports and dashboards for end user subscription.
Lead in innovation and implementation of the enterprise data quality framework by designing, developing, documenting, and performing data pipelines with embedded data quality dimensions
Design, develop, document, and maintain standards for data quality assurance and ensure these standards are followed throughout the organization
Implement solutions via new Enterprise Data Platform (Databricks) and existing environments (MSSQL, python) to evaluate and analyze data content
Analyze incoming data feeds for completeness, content, and data expectation
Identify trends and analysis for data content across time and healthcare dimensions
Design and develop testing frameworks for regression of ETL processes and data repositories
Provide test case coverage and defect metrics to substantiate release decisions
Work in conjunction with data engineers, analysts, data stewards, and business owners to ensure that data meets the business needs
Work with internal engineers, analyst, and leaders to understand content and quality of data required to support production deliveries
Participate in enterprise data governance efforts to ensure data quality metrics meet the necessary requirements for managing a complex data ecosystem
Establish data quality metrics, thresholds, and reports for enabling business users to actively manage their data estate
Develop and design quality solutions by studying information needs; conferring with users; studying flow, data usage, and work processes; understanding data product needs across a suite of product/business deliverables
Partner with enterprise data and analytics, project management, and internal organization to manage enterprise data initiatives
Manage enterprise data initiatives with demonstratable project management skills
Communicate to senior leaders across the organization on status of enterprise data quality and data governance initiatives
Lead technical implementations of ongoing enterprise data programs
About You
Bachelor’s degree or relevant experience required. MBA or related Master’s preferred.
4-7 years of data quality engineering experience or relevant educational attainment required.
Project and team leadership experience preferred.
The ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and speaks comfortably from a technical perspective with clients, business partners, and across their team.
Strong technical security expertise and data management, with experience in an agile operating model.
Systems/Tools: Python, Databricks, SQL, NoSql, Azure
About the Location

OncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA, Plantation, FL and Guaynabo, PR. We are open to employees nationwide, but work primarily in the Eastern and Central Time Zones.

Our Culture

Taking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!

We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!
OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.

The Opportunity

The cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!

Our Current Solutions

Through the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.

OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.

OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.

OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support."
1008922994547,Glassdoor,$78K,$107K,https://medifastinc.com/,"About the Opportunity
At Medifast, our team members are relentless in our mission of driving Lifelong Transformation, One Healthy Habit at a Time®. When you join Medifast, you become part of a dynamic, fast-growing community of highly motivated, like-hearted people who share a passion for promoting health and wellness. Just as OPTAVIA Coaches inspire Clients to reach their personal wellness goals, at Medifast, we inspire each other to bring our best to work each day to further our shared mission. If you want to build a rewarding career that makes lives better on a daily basis, Medifast may be the perfect place for you.
Medifast is looking for a talented Data Engineer to join our team on our exciting pursuit to transform and leverage a data-driven enterprise to impact every customer along their health journey. If you are creative and love building data products, we are innovating with new technologies and seeking curious, passionate, and diverse team members to drive change and impact our business. In this role, our Director of Data Engineer will collaborate across all of Medifast. While this position will exist in our data enterprise, you will partner with many amazing technologists, product managers, and internal and external business partners.
Overview of Position
A Data Engineer II is responsible for developing data structures and algorithms as well as maintaining data processing software like databases, data structures, or algorithms to process data. Their duties include coordinating with company Executives and other professionals to create unique data infrastructure, running tests on their designs to isolate errors and updating systems to accommodate changes in company needs.
II. Job Responsibilities
Assembling large, complex sets of data that meet non-functional and functional business requirements.
Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies.
Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition.
Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues.
Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues.
III. Scope
Data engineering needs across business functions. Managing geographically dispersed internal/external team members.
IV. Knowledge, Education, Skills & Abilities
Bachelor’s Degree in CS, IT, or Engineering
Solid understanding of performance tuning concepts for relational and distributed database systems
Strong understanding of the full lifecycle of data engineering, through maintenance and monitoring
3+ years of experience programming in Python
3+ years of experience programming in SQL
5+ years in data engineering focused on data enrichment, data integration and data warehouse projects
3+ years building data analytic pipelines to enable artificial intelligence or machine learning efforts
3+ years writing artificial intelligence software
3+ years writing software to build and data pipelines between relational databases, NoSQL databases, API’s, flat files, and external sources
3+ years of AWS experience in services like RedShift, Amazon Redshift Spectrum, AWS Glue, AWS DMS, Kafka, etc.
1-3 years of Linux experience
3+ years of experience with Relational DB / NoSQL experience (PostgreSQL and Amazon Redshift or similar) with specific implementation on AWS cloud
3+ yrs experience with different DBMS like Oracle, SQL Server, MySQL, etc
Exposure to open source and proprietary cloud data pipeline tools such as Airflow, Glue and Dataflow
Experience with data serialization languages such as JSON, XML, YAML
Hands-on experience with Transactional and Dimensional data modeling methodologies (Eg: Normalization, Star Schema, Snowflake Schema)
3+ yrs experience with data mapping, data transformation and handling different data formats – CSV, XML, JSON, JMS
At Medifast, Relationships Are At The Center Of What We Do!
We thrive by elevating our connections with one another as well as with our Coaches & Clients. We believe that everyone has the potential to be OUTSTANDING. The Medifast culture is built on seven core values: integrity, courage, teaming, accountability, empowerment, partnership and diversity. These values aren’t just words on a page – they are celebrated as a core part of the company’s philosophy.
We Lead By…
Mastering Relationships: We build trust, promote collaboration and we are reliable.
Being Innovative: We strive to improve things in our areas of influence; test, refine and expand within the business strategy; and reach beyond real and perceived boundaries.
Simplifying: We are committed to making things measurable, repeatable and scalable; focusing on outcomes not activities; and eliminating complexity to increase focus.
Anticipating: We predict long-term business and organizational needs; challenge assumptions; and expect and prepare for the unexpected.
More About Medifast
About Medifast®:
Medifast (NYSE: MED) is the health and wellness company known for its habit-based and Coach-guided lifestyle solution OPTAVIA®, which provides people with a simple, yet comprehensive approach to help them achieve lasting optimal health and wellbeing. OPTAVIA’s lifestyle plans deliver clinically proven health benefits as well as evidence-based tools, including scientifically developed products and a framework for habit creation reinforced by independent Coaches and Community support. As a physician-founded company with a 40+ year history, Medifast is a leader in the U.S. weight management industry. The company continues to innovate and build upon its scientific and clinical heritage to fulfill its mission of offering the world Lifelong Transformation, One Healthy Habit at a Time®. Medifast was recognized in 2023 by Financial Times as one of The Americas' Fastest Growing Companies and in 2022 as one of America's Best Mid-Sized Companies by Forbes. For more information, visit MedifastInc.com and OPTAVIA.com and follow @Medifast on Twitter.
Thank you for taking the time to learn more about Medifast.
#LI-CB1"
1008922164291,Glassdoor,$96K,$128K,http://www.hcahealthcare.com/,"Introduction
Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As a Principal Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Principal Data Engineer to help us reach our goals. Unlock your potential!
Job Summary and Qualifications
HCA Healthcare ITG
Job Summary:
The role requires working closely with others, frequently in a matrixed environment, and with little supervision. As a Principal Data Engineer/Architect level, the role requires 'self-starters' who are proficient in problem solving and capable of bringing clarity to complex situations. It requires contributing to strategic technical direction and system architecture approaches for individual projects and platform migrations. The culture of the organization places an emphasis on teamwork, so social and interpersonal skills are equally important as technical capability. Due to the emerging and fast-evolving nature of GCP/Big Data technology and practice, the position requires that one stay well-informed of technological advancements and be proficient at putting new innovations into effective practice.
Responsible for leading GCP development efforts, driving adoption and appropriate use of technology and consulting on internal and external development efforts to ensure code quality and sound architecture. This position that assumes the responsibility for project success and the upward development of team members technical skills. They are the development team's point of contact that must interface with business partners of varying roles ranging from technical staff to executive leadership. In addition, this candidate will have a history of increasing responsibility in a multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement cutting-edge technical data solutions with minimal supervision.
As a Principal Data Engineer/Architect, you will work closely with all team members to create a modular, scalable solution that addresses current needs, but will also serve as a foundation for future success. The position will be critical in building the team’s engineering practices in test driven development, continuous integration, and automated deployment and is a hands-on team member who actively coaches the team to solve complex problems. She / he will be responsible for the design, development, performance and support of the Cloud Platform components.
This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team (consultant and employee) environment. In addition, the applicant must be willing to train and mentor other developers to prepare them for assuming the responsibilities.
General Responsibilities:
Responsible for building and supporting a GCP/Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
Bring new data sources into GCP/HDFS, transform and load to databases.
Lead projects in delivering the data and projects on-time
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Leads efforts to design, development, deploy, and support software systems
Experience with HL7, FHIR, and Whistle mapping.
Collaborates with business analysts, project lead, management and customers on requirements
Participates in large-scale development projects involving multiple areas outside of core team
Designs fit-for-purpose products to ensure products align to the customer's strategic plans and technology road maps
Demonstrates deep understanding and coaches’ value-based decision making and Agile principles across teams
Coaches team on clinical data, existing system structure, constraints and deficiencies with product
Shares knowledge and experience to contribute to growth of overall team capabilities
Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems
Work closely with management, architects and other teams to develop and implement the projects.
Actively participate in technical group discussions and adopt any new technologies to improve the development and operations.
Focuses on customer satisfaction
Rapidly prototypes and delivers just-in-time solutions
Gather requirements, designs, constructs and delivers solutions with minimal team interaction
Works in an environment with rapidly changing business requirements and priorities
Demonstrates deep understanding and acts as a leader in the team’s continuous integration and continuous delivery automation pipeline
Work collaboratively with Data Scientists, business, and IT leaders throughout the company to understand Cloud/Big Data needs and use cases.
Education, Experience and Certifications:
Bachelor's Degree in computer science or related field – Required
Master's Degree in computer science or related field – Preferred
3+ years of experience in Data Engineer – Required
1+ year(s) of experience in Healthcare – Preferred
10+ years of experience in Information Technology – Required
GCP Cloud Professional Data Architect certification – Preferred
GCP Cloud Professional Data Engineer certification – Preferred
Other Required Qualifications:
A successful candidate will have:

Strong understanding of best practices and standards for GCP application design and implementation.
Two Year of hands-on experience with GCP platform and experience with many of the following components:
GCS, Cloud Run, Cloud Functions
Bigtable, Cloud SQL
Kafka, Pub/Sub
Python, Golang, Spark, Scala or Java
BigQuery, Dataflow, Data Fusion
CICD process and Logging & Monitoring
OpenShift, Docker
Experience with Unstructured Data, Real-Time Streaming with GCP
Ability to multitask and to balance competing priorities.
Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support.
Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.
A successful candidate may have:
Experience in Healthcare Domain
Experience in Patient Data
Experience with Natural Language Processing (NLP)
Azure/AWS Cloud experience
Hands-on experience with Cloudera Distributed Hadoop (CDH)
Hardware/Operating Systems:
Linux, UNIX
GCP
Distributed, highly-scalable processing environments
Databases:
NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies
Build Systems – TFS, Github
Ability to integrate tools outside of the core Cloud ecosystem
Physical Demands/Working Conditions
Prolonged sitting or standing at computer workstation including use of mouse, keyboard, and monitor.
Requires ability to provide after-hours support.
Occasional Travel: The job may require travel from time- to-time, but not on a regular basis.
HCA Healthcare’s Information Technology Group (ITG) delivers healthcare IT products and services to HCA Healthcare's portfolio of business and partners, including Parallon, HealthTrust and Sarah Cannon.

For decades, ITG has been a pioneer in the industry, leading the transformation of healthcare into a new era of quality and connectivity. ITG relies on the breadth of the organization and depth of technical expertise to advance and enhance today’s healthcare and to enable our physicians and clinicians to provide world-class, innovative care for patients.

ITG employees rally around the noble cause of transforming healthcare through technology and find inspiration in the meaningful work they do—creating a culture that follows our mission statement which begins by saying “above all else we are committed to the care and improvement of human life.”

If you want a career in technology and have a heart for healthcare, apply your expertise to a mission that matters.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.
""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
Be a part of an organization that invests in you! We are reviewing applications for our Principal Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
1008922981415,Glassdoor,,,http://www.ferring.com/,"Job Description:
As a privately-owned, biopharmaceutical company, Ferring pioneers and delivers life-changing therapies that help people build families and live better lives. Our independence helps us cultivate an entrepreneurial spirit and long-term perspective that enables us to achieve growth and scale, while remaining agile and true to our ‘people first’ philosophy. Built on a 70-year plus commitment to science and research, Ferring is relentless in its pursuit of science that drives powerful discoveries and therapies to help people build families, stay healthy, and stand up to the world’s oldest enemy: disease.

As the Data Engineer you will ensure Ferring US get the Data and Analytics services required to support the launch of our products. You will join at the beginning of our journey to transform an existing Azure based solution. Working closely with Global team based in Europe and external partners you can growth with us and make an impact.

With Ferring, you will be joining a recognized leader, identified as one of “The World’s Most Innovative Companies” by Fast Company, and honored by Fortune with inclusion on its “Change the World List,” for addressing society’s unmet needs. Ferring US is also Great Places to Work® Certified, distinguishing it as one of the best companies to work for in the country.

Responsibilities:
Design and deliver data pipelines using our Databricks, Data Factory platform.
Communication with end users and data owners to gather requirements.
Participate in troubleshooting of existing pipelines.
Propose & implement improvements to our platform and processes.
Providing application support and maintenance according to service level agreements, internal IT standards and guidance, and the ITIL Framework (incident, change and problem management)
Ensuring all tasks are performed in compliance with security and quality aspects described in related standard operating procedures.

Requirements:
University degree in Computer Science
2-5 years' experience in data engineering working using Python.
Experience building data pipelines/ETL and familiarity with design principles of modern Analytics.
Experience with DataBricks, DataFactory.
Experience with Cloud infrastructure (preferred Azure)
Excellent communication skills and very capable of building & keeping good working relation with end users.
Capable to work as part of a Global team in a hybrid (Remote/Office) work environment.

Ferring + you
At Ferring, we offer competitive total compensation along with an exceptional range of flexible benefits, personal support and tailored learning and development opportunities all designed to help you realize your full potential both in life and at work. From working hours that respect your lifestyle, a culture that is welcoming and equitable, and the chance to work with the industry’s most impressive people, these are just some of the ways we live our ""People First"" philosophy.

Our Compensation and Benefits
At Ferring, base salary is one part of our competitive total compensation and benefits package and is determined using a salary range. The base salary range for this role is $77,000 to $143,000, which is the reasonable estimate of the base compensation for this role. The actual amount paid may differ based on non-discriminatory factors such as experience, knowledge, skills, abilities, education and primary work location. Additional compensation for this role will be provided based on competitive annual incentive compensation targets in the form of an annual bonus - payouts are based on individual and company performance.

Benefits for this role include comprehensive healthcare (medical, dental, and vision) with a premium differential, inverse to base salary, to be paid by employees, a 401k plan and company match, short and long-term disability coverage, basic life insurance, wellness benefits, reimbursement for certain tuition expenses, sick time of 1 hour per 30 hours worked, vacation time for full time employees to accrue up to 120 hours in the first four (4) years of employment, and 160 hours in the fifth (5th) year of employment as well as 12 to 13 paid holidays per year. We are proud to offer 26 weeks of paid parental leave, learn more about the parental leave offering in our benefits package here.

Ferring is an equal opportunity employer. All aspects of employment will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local laws.

Join our team and your voice will be heard, and your contributions will be valued. If you love to come up with new ways to make a positive difference and see them through, you will fit right in.

We are proud to be an Affirmative Action/Equal Opportunity Employer (including Disability/Protected Veterans). We maintain a drug-free workplace.

Location:
Parsippany, New Jersey"
1008923787249,Glassdoor,$66K,$101K,http://www.embtel.com/,"We EMBTEL, Inc one of the fastest growing IT Staffing & Recruitment Company in the US. We are U.S. Federal Govt. approved vendor and Certified Minority Business Enterprise (MBE) company. We have an urgent requirement with our client/Implementation partner. The job details are given below - https://embtel.com/careers/ https://www.linkedin.com/jobs/search/?f_C=15556444&geoId=92000000
Title: Python PySpark/ Data Engineer
Location: Plano, TX
H1B Transfer will work, but local candidate will get 1st preference.
Job Description:
6+ years of professional work experience designing and implementing data pipelines in a cloud environment is required. 5+ years of experience migrating/developing data solutions in the AWS cloud is required. 2+ years of experience building/implementing data pipelines using Databricks or similar cloud database. Expert level knowledge of using SQL to write complex, highly optimized queries across large volumes of data. Hands-on object-oriented programming experience using Python is required. Professional work experience building real-time data streams using Spark and Experience in Spark. Knowledge or experience in architectural best practices in building data lakes
Submission Format:
Need Resume, and photo id with below details.
Candidate Full Name

Phone:

Email ID

Current Location

Availability to start on the project

Next 3 days availability for Screening (WebEx/Skype, etc

We EMBTEL, Inc one of the fastest growing IT Staffing & Recruitment Company in the US. We are U.S. Federal Govt. approved vendor and Certified Minority Business Enterprise (MBE) company. We have an urgent requirement with our client/Implementation partner. (https://embtel.com/careers/ https://www.linkedin.com/jobs/search/?f_C=15556444&geoId=92000000)"
1008923047269,Glassdoor,$93K,$155K,http://www.tubagroup.com/,"Tuba Group is a small federal contracting business and a CMMI® Level 3 Rated, ISO9001:2015 certified organization. with a primary focus in accounting, financial, systems, technical, engineering, administrative, management, and subject matter expertise services accounting and auditing service. Our mission is to provide value-added solutions that contribute to the success of government agencies, small businesses and independent professionals by leveraging the skill and talent our most valuable resources - our people
Security Clearances Required:
Must have DoD Secret clearance
Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC)
Position Description Summary
Responsibilities:
Responsible for the engineering of big data solutions and multi-tiered data environments. Experience with large scale big data deployments in Government and large commercial environments preferred. Key requirements include:
Leads initiatives utilizing big data solutions to provide actionable insights for addressing strategic and tactical mission objectives.
Experience with Hadoop-based technologies (Cloudera, Hortonworks, MapReduce, Hive, HDFS).
Experience with NoSQL technologies (e.g., MongoDB, Cassandra) (d) Ability to design data models using Enterprise Data modeling tools (ERWin, Visio).
Builds high-performance algorithms, prototypes, and data models using required programing languages (e.g., Python, C/C++, Java, Perl, Scala).
Analyzes and develops data set processes for data ingestion, modeling, mining.
Experience integrating Big Data solutions with SAP technologies.
Skills & Experience:
Senior Level: 5+ years of relevant experience.
Must be experienced in the following or equivalent technologies:
(The backend is what manages the core business logic of Rabbit. It provides information to the user-facing frontend about what data DOD has received on candidates and stores the results of user activities done on the frontend (such as reviewing candidates or adding employers) in a database.) Python.
Flask, FastAPI, or other microweb framework equivalent.
An Object Relational Mapping toolkit like SQLAlchemy or equivalent.
Github.
Data analysis libraries such as Pandas.
AWS.
S3 - Used as code triggers and intermediate result storage.
CloudTrail - Used to analyze logs.
Lambda - Used as serverless compute for small functions.
ECS Fargate - Used as serverless compute for large functions.
Infrastructure:
Terraform - Used to manage AWS infrastructure
Education:
Undergraduate degree required.
Tuba Group, Inc. is an Equal Opportunity/Affirmative Action Employer. Tuba Group does not discriminate in any of its programs or activities on the basis of race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other basis prohibited by applicable law.
All qualified applicants will receive consideration for employment without regard to race color, religion, sex, sexual orientation, gender identify, national origin, or protected veteran status and will not be discriminated again on the basis of disability."
1008922514260,Glassdoor,,,http://www.swift-technologies.com/,"Lead Data Engineer
Location: Atlanta, GA
Duties:
4+ years of Python application development experience.
Must have hands-on experience of at least 2 years on the AWS services specially Lambda, EventBridge, Cloudwatch, S3, DynamoDB, Kinesis, Cloud Formation, Systems Manager, etc.
Should know how to deploy the services on AWS using AWS Cloud formation (especially using CDK Stack in python).
Must have 2 years of experience on REST API integration using any python framework like Flask, Django, etc.
Data Lake hands-on experience of 2 years (using AWS Lake formation, AWS Glue and Athena).
2+ years of experience in Kinesis data stream and firehose delivery stream for real time data integration.
Must have at least 3 years of experience on DynamoDB and SQL.
Must have experience of working with micro-services.
Must know how to debug your code and should be able to think about edge case scenarios.
Good To Have:
Hands-on experience on AWS Pipes is a Bonus
Hands-on experience of 2+ years on pytest
Job Type: Full-time
Pay: $55.00 - $65.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Vision insurance
Experience level:
10 years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 4 years (Preferred)
SQL: 4 years (Preferred)
Data warehouse: 4 years (Preferred)
Work Location: In person"
1008922146296,Glassdoor,$75K,$113K,http://www.amgen.com/,"HOW MIGHT YOU DEFY IMAGINATION?
You’ve worked hard to become the professional you are today and are now ready to take the next step in your career. How will you put your skills, experience and passion to work toward your goals? At Amgen, our shared mission—to serve patients—drives all that we do. It is key to our becoming one of the world’s leading biotechnology companies, reaching over 10 million patients worldwide. Come do your best work alongside other innovative, driven professionals in this meaningful role.
Data Engineer
Live
What you will do
Let’s do this. Let’s change the world. In this vital role you will be part of the established technical/engineering team, develop web UI interface, plus data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.
Be a key team member assisting in design and development of the data pipeline for Global Data and Analytics team
Collaborate with Data Architects, Business SME’s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions
Serve as system admin to manage AWS and Databricks platform;
Adhere to best practices for coding, testing and designing reusable code/component
Able to explore new tools, technologies that will help to improve ETL platform performance
Participate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams
Win
What we expect of you
We are all different, yet we all use our unique contributions to serve patients. The professional we seek will have these qualifications.
Basic Qualifications:
Master’s Degree
OR
Bachelor’s degree with 2 years Data Engineering and/or and Software Engineering experience
Or
Associate’s degree 6 years of Data Engineering and/or Software Engineering experience
Or
High school diploma and 8 years of Data Engineering and/or Software Engineering experience 1
Preferred Qualifications:
Experience with software development (Java, Python preferred), end-to-end system design
Experience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL; SQL performance tuning
Experience with web development, java script, html, CSS, any web framework or microservice architecture
Experience with software DevOps CI/CD tools, such Git, Jenkins
Experience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, DynamoDB, and API gateway
Experience with docker container, Kubernetes container orchestration
Experience with Apache Airflow and Apache Spark; Spark performance turning
Experience with Tableau Dashboard and Tableau Server
Experience with Pharmaceutical industry, commercial operations
Ability to learn quickly, be organized and detail orientedRequirement 1
Thrive
What you can expect of us
As we work to develop treatments that take care of others, we also work to care for our teammates’ professional and personal growth and well-being.
Amgen offers a Total Rewards Plan comprising health and welfare plans for staff and eligible dependents, financial plans with opportunities to save towards retirement or other goals, work/life balance, and career development opportunities including:
Comprehensive employee benefits package, including a Retirement and Savings Plan with generous company contributions, group medical, dental and vision coverage, life and disability insurance, and flexible spending accounts.
A discretionary annual bonus program, or for field sales representatives, a sales-based incentive plan
Stock-based long-term incentives
Award-winning time-off plans and bi-annual company-wide shutdowns
Flexible work models, including remote work arrangements, where possible
Apply now
for a career that defies imagination
Objects in your future are closer than they appear. Join us.
careers.amgen.com
Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Join Us

If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.

Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancers, kidney disease, rheumatoid arthritis and other serious illnesses.

As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.

Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation."
1008922543968,Glassdoor,,,,
1008922406732,Glassdoor,$82K,$125K,http://www.avaloncommunities.com/,"Overview

AvalonBay Communities, Inc., an equity REIT, has a long-term track record of developing, redeveloping, acquiring and managing distinctive apartment homes in some of the best U.S. markets, and delivering outsized, risk-adjusted returns to shareholders. With equal parts experience and vision, we’ve established a leadership position rooted in our purpose of creating a better way to live and that is always focused on building value for the long term.
Creating a better way to live is the purpose that binds AvalonBay associates. We take that purpose seriously and expect you will as well. By focusing on collaboration, innovation, and taking ownership of our choices and actions, we act in ways that focus on creating value for our customers, investors and associates. Your positive, professional, and consistent personal interactions make AvalonBay a great place to work.

The Role

At AvalonBay we are building the industry’s most advanced Data Analytics capability. Join a green-field opportunity to take responsibility for developing Data Lakehouse in AWS at one of the largest REITs in the country. You will need strong data engineering capability particularly with Python, SQL, AWS tools including Glue, Lambda and Apache Spark. The role includes:
Developing a comprehensive Data Acquisition solution and meta-data for our Data Lakehouse to support Business Intelligence and Data Science solutions.
Working closely with our Digital Development team to support Customer Experience Applications development.
Working closely with our Data Science team to implement machine learning, forecasting and simulation models.
Delivering relational solutions in Snowflake to support Business Intelligence.
Implementing Data Governance best practices
Implementing automated quality assurance best practices

You Have...

Qualifications required:
A Bachelor’s degree in Computer Science, or other technical field, and 5 years experience developing data pipelines in AWS.
Deep knowledge of Python, SQL, Glue, Lambda and Apache Spark.
Experience with Infrastructure as Code (IaC) tools such as AWS CloudFormation or AWS CDK preferred.
Understanding of data warehousing methodologies and data lake concepts and experience with Snowflake a strong plus.
Experience developing ETL processes and leveraging tools such as Talend.
The ability to explain complex technical material to non-technical audiences.

How AvalonBay Supports You

We know that our teams are the beating heart of our success and we’re committed to showing our appreciation.
We offer:
Comprehensive benefits – health, dental & vision, 401(k) with company match, paid vacation and holidays, tuition reimbursement, an employee stock purchase plan and more!
Growth based on achievement and promotion from within.
Associate recognition (a company-wide recognition program that celebrates associate efforts and successes in contributing to the overall success of the organization – including destination awards, ‘AvalonBay’s Very Best’ recognition program and others!).
A 20% discount on our incredible apartment homes.
A culture built on purpose and our core values - A Commitment to Integrity, A Spirit of Caring, and A Focus on Continuous Improvement.

Additional Info

AvalonBay is proud to be an equal opportunity employer and is committed to an inclusive and diverse work environment free of discrimination and harassment. We believe that in order to achieve our purpose of creating a better way to live, we must recruit, develop and retain associates with a wide range of backgrounds, experiences and perspectives and create an environment that encourages all voices to be heard, understood and appreciated. With this we know we can do great things.
AvalonBay makes employment decisions without regard to a person’s race, ethnicity, color, religion, sex, national origin, sexual orientation, gender identity, pregnancy (including childbirth, lactation or related medical conditions), age, physical or mental disability, genetic information (including characteristics or testing), citizenship status, military or veteran status, or any other status protected by the law.
AvalonBay will consider for employment qualified applicants with criminal histories in a manner consistent with requirements under the law.
#LI-Hybrid
For California residents, if you elect to apply to AvalonBay you accept the AvalonBay California Personnel Privacy Notice"
1008922326506,Glassdoor,,,http://www.lvmh.com/,"Company Description

LVMH Beauty activities benefit from exceptional dynamism that relies on both the longevity and development of key lines, and on the boldness of new creations.
All are driven by the same values: a quest for excellence, creativity, innovation, and perfect mastery of their image.
The brands cultivate what makes them unique and is guaranteed to make them stand out in a highly competitive global market. The success of the Beauty division depends on finding the right balance between major historic Houses such as Parfums Christian Dior, Parfums Givenchy, Acqua di Parma, Guerlain, and newer brands with strong potential like Kenzo Parfums, Fresh, and Make Up For Ever.
LVMH Beauty invites you today to join its North America teams.
LVMH Beauty is part of the LVMH Group.
The position is with LVMH Beauty Tech within the regional Americas team managing the Data platform and applications
LVMH Beauty Tech regional team is split between the North America LVMH Beauty Shared Service Center, the Mexico LVMH Beauty Shared Service Center and its San Francisco offices, servicing all major LVMH Beauty Brands for the region: Acqua di Parma, Benefit Cosmetics, Fresh, Guerlain, Kendo, Kenzo, Maison Francis Kurkdjian, MAKE UP FOR EVER, Parfums Christian Dior, Parfums Givenchy and Stella.

Job Description

Within the Data team, the role will be to participate in the design and the development of the Data platform (based on Google Cloud Platform and Dataiku).
Provide business teams with standardized, reliable, up-to-date and actionable data.
Work in close collaboration with other members of the WW Data team (Data tech lead, data engineers, data scientists) and other Beauty Tech teams (especially CRM, retail and e-commerce) to build a reliable, scalable and secure data platform.
Work on the entire data production chain by implementing data ingestion pipelines (from multiple sources and in different formats), storage, transformation ... then their provision: datamarts, reports, datasets to feed models scoring (data science), API, ... mainly using Dataiku and Google Big query
Ensure that the integration pipelines are designed in a manner consistent with the overall data framework in collaboration with the data tech lead and according to best practices.
Be part of a continuous improvement approach by optimizing and reusing existing assets.
Take part in data integration processing aspects of data quality controls, monitoring, alerting and technical documentation, as well as data management (data models and mapping, data documentation, repositories, description of the transformations applied, etc.)
Acquire a good understanding and analysis of business challenges and be able to translate the needs into the design of concrete technical solutions and gradually extend the functionalities and scope of our data platform based on Google cloud platform and Dataiku.
Provide reliable estimates of workloads and planning according to the level of complexity and other activities to allow a good coordination of the activities of the team.
Perform unit development tests and support business users in their tests before final validation.
Contribute to the design and management of the data model, as well as to the orientations in terms of the architecture of our data platform (repositories, APIs, etc.)
Set up pipeline monitoring and monitoring of the data platform and APIs (from a functional point of view and data quality)
Analyze incidents, points of weakness and support requests related to the use of the data platform or APIs
Provide timely and accurate support to the business teams on issues
Propose improvements to optimize the data platform (optimization of existing processes, data restructuring, factorization, etc.)
Reports to the Data Domain Director based in East Brunswick, NJ

Qualifications

Key competencies:
Mastery of the data stack components in Google Cloud Platform (certifications appreciated) including but not limited to: Google Big Query (nested fields, partitioning, merge SQL, authorized views, RLS, …), Cloud storage, Cloud functions, Cloud composer, Google Firestore, Google data catalog.
Proficiency of Dataiku (on Google big query): development of dataiku flows, implementation of scenarios, scheduling, management of versioning, releases into production, administration etc.
Mastery of complex SQL queries
Good knowledge of Python is a plus
Development practices with data exchange architectures: webservice, API, streaming. Salesforce MuleSoft a plus.
Development in an agile team and the tools used in CI / CD (Azure devops, Jira, Confluence)
Knowledge of Microsoft Power BI, data catalog tool, data quality, data management
Knowledge of Terraform and the administration of Google Cloud Platform appreciated (rights management, API activation, network settings, etc.)
Personal skills:
Autonomous and proactive
Perseverance
Curious and a desire to learn
Rigorous, organized and attentive to detail
Team spirit and knows how to work collectively in multidisciplinary teams
Problem solver
Very good communication, in particular the capacity of synthesis and popularization to make oneself understood simply
Solution designer, knows how to argue and make recommendations when several technical options are possible
Proactive team player
Profile:
Bachelor’s degree in Management, Computer Science or related field
Bi-lingual English/French is a plus
Minimum of 3 years’ experience in IT development roles such as data integration on Google Cloud & Dataiku

Additional Information

Normal and Main Office Environment: LVMH Beauty New Jersey or San Francisco office
Occasional travels to New York, San Francisco, Canada, Miami or South America
LVMH Inc. uses the published salary range as a guideline to provide our employees with market competitive pay while allowing for flexibility to recognize and reward various levels of expertise, performance and tenure.
While the published salary range is a good faith reflection of the targeted salary level for the position, LVMH Inc. reserves the right to pay outside of the published salary range of $120,000.00 - $130,916.00.
This job description is intended to cover the core accountabilities of the position and is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities, and activities may change, or new ones may be assigned at any time with or without notice.
All your information will be kept confidential according to EEO guidelines."
1008917362577,Glassdoor,,,http://www.nscglobal.com/,"Job Title: Data Center - Smart Hands Engineer
Location: Waukegan, Illinois 60085
Duration: Fulltime/Permanent
Job Description:
On General network failure with Back Office support infrastructure then Hands and Eyes resource will be guided by the BO teams to find a resolution in line with the account TDA
Responsibilities:
Daily backup Tape change in LR data centre (Approx 40 Servers)
Weekly Tape change at Weekend in LR data centre (on Saturday as per rota)
Yearly Tape schedule for Abbotts to be created
ITSM change, stage, and call management to be managed for the Hands & Eyes support group in ITSM.
Daily Restore requests when raised to be managed with the Back Office (BO) team. Tape mounting box recalls, and management of tape boxes
Assist with Server room Audits
Take direction from Wintel and backup teams on hardware issues
Escort 3rd party vendors in to LR data centre as arranged by BO teams.
Ensure that work undertaken is managed via the ITSM management system
Effective communication with both Service Delivery Management Team and the client as required.
To perform ITSM stages (relevant to Hands & Eyes role) in line with the clients DR procedure at Greenwich DC
Qualifications:
Excellent written and verbal communication skills, comfortable taking a lead role in client communication.
Familiar with: Incident, Problem and Change Management,
Demonstrable organizational, analytical and methodical problem solving abilities, prioritizing and escalating when required
Experience of working within Data Centres
Escalation of potential serious or business impacting issues where necessary
Proven ability to ‘own’ issues and apply initiatives to ensure all delegated tasks are followed through to conclusion
Expected to take part in an weekly tape change rota, work overtime as and when required and may need to visit other 3rd party associated sites
nscglobal provides global network implementation and support solutions to world-class organizations, delivering cost savings and operational simplicity. Our goal is to partner with world-class enterprises, helping them become more agile, create commercial advantage and build quality through design, deployment, support and management of their global IT communications. nscglobal are a US & European CISCO Technology GOLD PARTNER with a corporate headquarters in London, UK and a US headquarters in New York, NY. Please review our website at www.nscglobal.comfor more information on our organization.
Title: Data Center - Smart Hands Engineer
Length: Full Time/Permanent
Location: Waukegan, Illinois 60085
PLEASE NOTE– WE ARE NOT AN AGENCY BUT THE ACTUAL EMPLOYER.
I would love to discuss this opportunity in greater detail and will make myself available at your convenience – let me know what works best for you.
Thanks in advance and I look forward to hearing from you!
Job Type: Full-time
Pay: $28.00 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Waukegan, IL 60085: Reliably commute or planning to relocate before starting work (Required)
Experience:
Computer networking: 1 year (Preferred)
LAN: 1 year (Preferred)
Security clearance:
Confidential (Preferred)
Work Location: In person"
1008918504891,Glassdoor,,,https://www.healthesystems.com/,"Healthesystems offers workplace flexibility with our Work-From-Home model, and a competitive compensation and benefits package including healthcare coverage, PTO, paid holidays, 401(k), company-provided life insurance/disability coverage, wellness options, and more.
Note: we are unable to hire in every state
Summary: Responsible for the analysis, design, documentation, development, unit testing, and support of Data Integration and database objects development for software applications. Provides support and guidance regarding Data Integration and T-SQL best practices and development standards. Promotes approved agile methodologies, leading the design and development efforts for the agile team. Actively coaches, guides, and mentors team members in providing valuable solutions to our customer.
Key Responsibilities: ""To simplify complexities for each customer.""
Collaborates with stakeholders and development team members to achieve business results.
Work closely with other engineers to integrate databases with other applications.
Leads the design, development, and implementation of database applications and solutions for managing and integrating data between operational systems, data repositories, and reporting and analytical applications. This includes but is not limited to ETL, stored procedures, views, and functions.
Recommends and provide guidance regarding Data Integration and database development, T-SQL best practices, and standards to the development team members as needed.
Create and propose technical design documentation which includes current and future functionality, database objects affected, specifications, and flows/diagrams to detail the proposed database and/or Data Integration implementation.
Has a deep understanding of the business processes and the technology platform that enables it.
Translates stakeholder's requirements into common language that can be adopted for the use with Behavior Driven Development (BDD) or Test Driven Development (TDD).
Participates in industry and other professional networks to ensure awareness of industry standards, trends and best practices in order to strengthen organizational and technical knowledge.
Provides support for investigating and troubleshooting production issues.
Promotes the establishment of group standards and processes. Participates in the Communities of Practice.
Works continually on improving performance of source code using industry standard methodologies.
Helps drive technology direction and choices of technologies by making recommendations based on experience and research.

Qualifications/Education/Certifications:
Bachelor's degree from four-year college or university (in Information Technology or Computer Science preferred), plus five to eight years related experience and/or training; or equivalent combination of education and experience.
Knowledge, Skills and Abilities:
Prefer experience in Healthcare, PBM and/or ABM, workers' compensation and/or insurance industry.
Required experience:
5+ years SQL Server 2008/2014
5+ years Data Integration technologies and principles
Advanced knowledge of T-SQL including complex SQL queries (ex: using various joins and sub-queries) and best practices
Advanced knowledge of index design and T-SQL performance tuning techniques
Advanced experience integrating data from structured and unstructured formats: flat files, XML, EDI, JSON, EXCEL
Advanced knowledge and experience in online transactional (OLTP) processing and analytical processing (OLAP) databases and schemas
Advanced knowledge of Data Warehousing methodologies and concepts
Experience with TDD / BDD
The following knowledge is not required, but is preferred:
Experience with BI Tools is a plus
Basic understanding of object oriented programming
Experience in distributed architectures such as Microservices, SOA, and RESTful APIs
Continuous Integration
Cucumber, Gherkin
Jira
Agile Competency Requirements:
Requires an understanding of the application of Agile development methodology.
Must be comfortable with change, close collaboration, and have conflict resolution skills.
Knowledge of or willingness to learn Agile / DevOps values.
Takes initiative and are passionate about what they do.
Adaption, Ability & Desire to Learn, Team Oriented - tolerance & helpful, and Quality Focus
Physical Demands/Working Conditions:
Duties are performed primarily in a home office setting utilizing computer equipment. Travel to attend meetings and visit locations throughout the country may be required. While performing the duties of this job, the employee is regularly required to sit and talk or hear. The employee is frequently required to use hands. The employee is occasionally required to stand and walk.*** Job descriptions will be reviewed and are subject to changes of business necessity. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Pay is based on several factors including but not limited to education, work experience, certifications, geographical cost of labor, etc. In addition to base pay, Healthesystems offers a comprehensive benefits package including, health, dental, vision, disability and life insurance, wellness resources, recognition programs, 401k contribution, and PTO & Holiday pay (all subject to eligibility requirements). Applicable statutory benefits also provided. https://healthesystems.com/careers/
Anticipated Starting Pay Range
$98,100—$135,000 USD
To facilitate working from home, and as a requirement for this role, candidates must provide their own reliable, high speed internet access with sufficient bandwidth to execute all job functions. Company laptop will be provided."
1008920103250,Glassdoor,,,http://www.plaxonic.com/,"Title: Senior Data Engineer
Location: Charlotte, NC/ Chicago, IL/ Denver, CO/ Iselin, NJ/ Lewisville, TX/ New York, NY(Onsite from day 1st)
Position: Contract (W2 only)
Interview: May be In Person/F2F
Data Engineer requirement covering ETL, AWS and API.
Summary
· Experience in Data Movement using code (Python, Spark) and ETL tools (Data Stage/ Talend/ AWS DMS)
· Experience with Real time & streaming platforms like Apache/Confluent Kafka or cloud native equivalent
· Understanding of AWS Data and Analytics eco-systems services like S3 including bucket policies & life-cycle policies, Glue, EMR, IAM, Security Groups, Lake Formation, Lambda functions, Cloud watch and event triggers
· Python or Java experience for Rest API development and consuming API endpoints to enable interaction and automation amongst tools/services
· Any GCP exposure is a plus
Job Type: Full-time
Salary: $75.00 - $90.00 per hour
Expected hours: 40 per week
Experience level:
11+ years
Schedule:
8 hour shift
Ability to commute/relocate:
Chicago, IL 60611: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica/ETL, Datastage/Talend: 10 years (Required)
SQL: 10 years (Preferred)
Data warehouse: 5 years (Preferred)
Apache, Confluent Kafka, Cloud Native: 8 years (Required)
AWS: 5 years (Required)
Work Location: In person"
1008923187692,Glassdoor,,,http://www.esource.com/,"Are you an experienced data engineer with a passion for data and innovation? Do you thrive on a cross-functional team of professionals?

E Source is a leading provider of software solutions and consulting services for utilities and their customers. We use data science and machine learning to help utilities optimize their operations and achieve their sustainability goals. We process large amounts of data from our clients and uncover insights and patterns that they didn’t see before.

Data engineering is a key function enabling a robust data science environment for our consulting services and as middleware in preparing our client’s data for processing within our software as a service (SaaS) solutions.

We are seeking a Senior Data engineer to join our Machine Learning Engineering team and help us design and build scalable, reliable, and secure data pipelines, infrastructure, and systems for our consulting services and software as a service solutions. The Senior Data Engineer will work with a cross-functional team of Machine Learning engineers, software engineers, data scientists, and data analysts to deliver data products and solutions for our clients while also contributing to our internal data practices.

Responsibilities:

Design, develop and maintain data pipelines, infrastructure, and systems to support data products and solutions using technologies such as AWS, Python, Databricks, Spark, and SQL databases like PostgreSQL.
Work with cross-functional teams to translate business problems into technical solutions and provide technical guidance and mentorship to junior data engineers.
Develop and implement data engineering strategies and best practices that align with business objectives and customer needs.
Monitor and troubleshoot data pipelines and systems to ensure data quality, integrity, and availability.
Conduct research on industry trends and best practices to improve data engineering capabilities and evaluate new data technologies and tools.
Build and maintain data lakes to support business intelligence needs.
Manage the software development lifecycle and DevOps aspects of the code.
Collaborate with data scientists and analysts to understand their data requirements and provide them with optimal data solutions.
Create new data validation methods and data analysis tools.

Requirements:

Bachelor's degree in computer science, information technology, or a related field.
4-7 years of experience in data engineering or a similar role.
Expert-level skills in Python, SQL databases such as PostgreSQL, and big data technologies such as Databricks and Spark.
Hands-on experience building cloud resident data pipelines in AWS.
Strong understanding of data governance, security, privacy, and retention policies and procedures.
Strong communication, collaboration, and problem-solving skills.
High proficiency using agile software tools like Jira and following mature DevOps practices using GIT, Docker, and CI servers like Jenkins.
Passion for data and innovation.

Preferred Qualifications:
Demonstrated capacity to work autonomously and proactively, with a proven track record of achieving results without constant supervision.
Experience with ETL optimization, designing, coding, and tuning big data processes in Databricks.
Sound knowledge of data lineage and data quality techniques.
Experience in working with data science and machine learning models and frameworks
Previous experience in the Energy or Utility industry in an analytic role.
MS Degree in management information systems, computer programming, software engineering, data science, or an equivalent STEM field.

A little about E Source

Since 1986, E Source has focused on partnering with utilities to help their customers save electricity. That novel approach defined the art of electric end-use efficiency—better known as energy efficiency. We’ve expanded that concept to include a broader perspective of sustainability for utilities that deliver electricity, natural gas, and water.

We work to enhance relationships with the people utilities serve, achieve the next generation of savings, and lead the carbon-reduction effort. We help utilities think differently, make data useful, and learn from the best strategies across the industry. Our people, our insights, and our network help our clients and give them the assurance that the programs they implement are the most effective.

Benefits

We offer excellent insurance packages, including medical, dental, and vision plans; company-paid life insurance; company-paid long- and short-term disability insurance; and medical and dependent-care flexible spending plans.
We provide a flexible time off (FTO) program; E Source employees can take as many paid days off per year as they need, with manager approval, while fulfilling their work obligations and ensuring proper coverage of their responsibilities.
We offer flexible schedules, flexible work locations, and a paid parental leave benefit.
We provide a 401(k) plan with a 3% employer match.

The budgeted salary for this position is $99,750 to $135,450 (includes base + annual bonus). Actual pay will be adjusted based on experience.

This person can work remote, a hybrid schedule, or from one of our physical office locations.

Applicants must be authorized to work for any employer in the US. We’re unable to sponsor or take over sponsorship of employment visas at this time.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

#LI-Remote

#LI-AP1"
1008918845174,Glassdoor,,,http://www.farmcrediteast.com/,"Be part of a team focused on the success of our customers, the success of our communities, and the success of each other. Farm Credit East is the leading provider of loans and farm advisory services to farm, forest product, fishing, and other agricultural business owners across the northeast. We are One Team Working Together with a focus on our five pillars: Outstanding Customer and Employee Experience, Quality Growth, Operational Excellence, Commitment to our Communities, and Protecting Customer Information.

Position Summary
The Data Engineer is responsible for cleaning, managing, and sharing data that guides business decisions. Using ETL tools you will gather data from a variety of sources, checking for anomalies, automating processes, and generally making it easier for business stakeholders to generate valuable insights. This position will collaborate with internal and external organization to capture requirements, design, create, document, manage, and fulfill requests for on-going and/or ad-hoc reports, dashboards, and scorecards.

Duties and Responsibilities
Work with product stakeholders to implement, maintain, and enhance data models and solutions used to define and measure quality of data domains.
Design data models to meet requirements.
Perform ETL (Extract, Transform, and Load) on data to meet stakeholder specifications.
Design and develop data access methods, datasets, views etc.
Develops data modeling and is responsible for data acquisition, access analysis, archive, recovery, load design and implementation.
Coordinates new data developments to ensure consistency with existing warehouse structure.
Collaborates with internal customers to capture requirements, design, create, document, manage and fulfill requests for on-going and/or ad-hoc reports, dashboards, and scorecards.
Assists with the development, implementation, and maintenance of front-end presentation (dashboards), automated report solutions and other BI solutions to support tactical and strategic reporting needs of the organization.
Assists in identification of data integrity problems and recommends solutions.
Work collaboratively with key stakeholders both internally and externally, including but not limited to Senior Management, Business Unit Leaders, Knowledge Exchange, and Farm Credit Financial Partners (FPI).

Job Qualifications/Requirements
Bachelor’s Degree in Computer Science, Business, Finance, or other related field from an accredited University.
Experience with MSFT SQL Server
Proficient in Python, PySpark, Spark SQL
Microsoft Azure (Data Bricks, Data Factory, Logic Apps, Functions, etc.)
2 plus years of experience in Finance related informatics, performance measurement, or analysis with strong relational database SQL skills.
1 + years of experience using Microsoft Azure product to perform ETL
Familiar with Databricks Unity catalog
Salary range: $74,000- $125,000 commensurate with experience

Farm Credit East is an Equal Opportunity Employer. As an Equal Opportunity Employer, we do not discriminate on the basis of race, color, religion, national origin, sex, sexual orientation, gender identity or expression, age, marital status, parental status, political affiliation, disability status, protected veteran status, genetic information or any other status protected by federal, state or local law. It is our goal to make employment decisions that further the principle of equal employment opportunity by utilizing objective standards based upon an individual's qualifications for a specific job opening. In compliance with the Americans with Disabilities Act (“ADA”), if you have a disability and would like a reasonable accommodation in order to apply for a position with Farm Credit East, please call 1-800-562-2235 or e-mail FarmCreditCareers@farmcrediteast.com ."
1008921149229,Glassdoor,,,http://www.pfp.org/,"For People is a team of skilled technologists improving government digital services for disadvantaged and vulnerable populations. We embed directly in government agencies to modernize software, systems, and platforms so that they better serve people.
Your Impact
We are a dedicated team focused on creating and managing an extensive Medicare data warehouse at the Centers for Medicare & Medicaid Services (CMS) to serve Medicare beneficiaries' demographic, enrollment, and claims data in a FHIR (Fast Healthcare Interoperability Resources) format. We are responsible for providing data to several Medicare APIs so that those systems can seamlessly exchange data between various healthcare providers, insurers, and patients. You will directly impact the quality of healthcare that over 65 million Medicare enrollees nationwide receive.
Our Culture
For People is a team of humans. We place a significant amount of emphasis on positive work-life balance, setting healthy expectations, and making sure our loved ones are taken care of first. That means picking a child up from school during the day or going for a mid-day walk is okay!
This position is 100% remote. Our entire team is remote across the United States, from the West Coast to the East Coast. There will never be a return-to-office, as we have none!
This position's published base salary range is between $125,000 and $160,000 annually, plus generous benefits (e.g., For People pays 100% of Gold-tier employee health insurance premiums) and annual company profit sharing.
Your Opportunities
Lead the implementation of FHIR (Fast Healthcare Interoperability Resources) standards within the data warehouse, ensuring accuracy and efficient data exchange across the ecosystem of partner APIs.
Ingest healthcare data from source systems into FHIR resources and profiles through developing ETL (Extract, Transform, Load) processes, checking for data quality and integrity.
Create and maintain data mapping specifications to transform non-FHIR data formats into FHIR-compliant data.
Design and maintain the data warehouse's FHIR-based data model to meet the needs of downstream API systems.
Implement security measures and access controls to protect sensitive healthcare data and comply with healthcare data privacy regulations, such as HIPAA.
Maintain comprehensive documentation of FHIR implementations, data transformation processes, and data flows.
Stay informed about industry best practices and evolving FHIR standards.
You Bring
A humble and caring attitude
In-depth knowledge and experience with FHIR standards and resource types.
Expert-level Java programming abilities, alongside some familiarity with Python and Bash scripts.
Proficiency in designing and implementing data ingestion and transformation processes.
Strong database design and data modeling skills, with experience creating and maintaining data models in a healthcare context.
A systematic approach to identifying and resolving issues related to FHIR data integration, data quality, and performance.
Demonstrated commitment to staying updated on industry best practices, evolving FHIR standards, and opportunities for process improvement.
If you're passionate about healthcare technology and ready to positively impact the quality of healthcare for millions of Medicare enrollees nationwide, we encourage you to apply. Join us in revolutionizing healthcare data accessibility.
Some fine print. You will be working on a United States government platform, and they have a few basic requirements for contractors like ourselves. You must perform all work physically within the United States at all times. In addition, you must be a United States citizen and be able to pass a government-performed public trust background check.
For People is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, and/or veteran status.
1D2WJ7jBEl"
1008919639397,Glassdoor,$86K,$119K,http://www.eclipsemining.com/,"This is a full-time position to be worked out of our Tucson, Arizona office.

In this position you will be responsible for developing, validating, and implementing various data science models, such as regression models, classification models, clustering models, and neural networks. The right candidate will have a strong grounding in statistics and mathematics enabling the development of robust and accurate models.

Responsibilities & Requirements
Statistical and Mathematical Proficiency:
Strong grounding in statistics, mathematics, and algorithms, enabling the development of robust and accurate models.
Understanding of probability, inference, and optimization techniques.
Model Development and Validation:
Proficiency in developing, validating, and implementing various data science models, such as regression models, classification models, clustering models, and neural networks.
Ability to assess model performance using appropriate metrics and validation techniques.
Machine Learning and Advanced Analytics:
Expertise in applying machine learning techniques and algorithms to build predictive, prescriptive, and descriptive models.
Knowledge of advanced analytical techniques such as text analytics, time series analysis, and anomaly detection.
Programming and Technical Skills:
Familiarity with machine learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.
Data Management and Pre-processing:
Ability to acquire, clean, transform, and manage data from various sources.
Proficiency in handling structured and unstructured data and experience with SQL and NoSQL databases.
Domain Knowledge and Business Acumen:
Understanding of the specific domain or industry to identify relevant features, variables, and potential biases in the data.
Ability to translate business problems into analytical questions and communicate findings effectively to stakeholders.
Computational and Algorithmic Thinking:
Strong computational thinking to develop efficient algorithms and solve complex problems.
Capability to optimize algorithms and models for performance and scalability.
Data Visualization and Communication:
Skills in producing intuitive and informative data visualizations to communicate findings effectively.
Ability to explain complex models and results to non-technical stakeholders, bridging the gap between technical and business understanding.
Research and Continuous Learning:
Commitment to staying abreast of the latest developments in data science, machine learning, and related fields.
Eagerness to learn new techniques, tools, and methodologies and adapt to evolving requirements and technologies.
Collaboration and Interpersonal Skills:
Ability to collaborate with cross-functional teams, including data engineers, product managers, and domain experts.
Strong interpersonal skills to work effectively within diverse teams and manage relationships with stakeholders.
Problem Solving and Critical Thinking:
Exceptional problem-solving skills to devise effective solutions to complex challenges.
Critical thinking to evaluate assumptions, methodologies, and results critically.
Attention to Detail and Quality Focus:
Meticulous attention to detail to ensure the accuracy and quality of work.
Focus on delivering high-quality, reliable, and reproducible results.

Other Requirements
Degree in STEM, computer science or another relevant technical field
5+ years of full-time experience directly related to data science modeling"
1008918720364,Glassdoor,,,http://www.everlakelife.com/,"Principal Data Engineer
Who We Are
Everlake, a leading life insurance company headquartered in Northbrook IL with offices in Chicago IL and Lincoln NE, is conducting a search for a Principal Data Engineer in Information Technology to join our growing team. If you have a passion for business, value working in a dynamic team environment and are ready to roll up your sleeves to help us achieve best in class results, then this may be the role for you. At Everlake, you will find the dynamics of a small entrepreneurial organization and the strength of a big corporation rolled into one. We think big and evolve quickly, backed by a collaborative mindset and a solid financial foundation.
Position Summary
At Everlake our technology vision is to transform our best-in-industry business capabilities into a scalable platform, one that is well-integrated into an extended ecosystem, making us the go-to partner for scale and growth in the life insurance and annuities industry. Democratizing data and analytics are core to achieving that vision. We are looking to add a Data Engineer to an established and collaborative team to build out a modern data solution that will allow us to be a leader in the Life and Annuity Insurance space.

We are looking for someone with a strong background in data and analytics who has a track record of successfully designing and building multiple databases, supporting migrations to cloud, and modernizing code and processes. This candidate would have experience with relational, data warehouse, data integration, data lake, and data vault design and development. They will operate in an agile model to deliver new data structures, technical improvements, business enhancements and business features. This role will report to the Head of Data Engineering, ensuring that we continue to build the best solutions, engage our business partners, and promote our data strategy.
The successful candidate must be an approachable and influential individual who gains trust and confidence quickly through consensus building and who can operate effectively within a dynamic and evolving organization. The successful candidate must be capable of seizing opportunities for continuous improvement but also driving adoption of organizational strategic initiatives. This is an individual contributor role.
Qualifications and Skills
Database:
Expert in Relational Database (RDBMS), Data Warehouse (Kimball/Inmon), Data Lake, and Data Vault design.
Expert in T-SQL/SQL languages or experience with other programing languages with desire to learn.
Expert in Snowflake, Microsoft SQL Server, Azure Databricks, or equivalent data platforms.
Strong understanding of Sigma, PowerBI, or equivalent reporting platforms.
Strong understanding of database performance and query optimization.
Experience with data validation and data quality.
Experience with data test scripting and processes.
Experience with data ops.

Integration:
Expert in ETL/ELT design and process flow.
Expert with Integration Tools like Workato, Informatica, or equivalent Integration Tools.
Strong understanding of SFTP/FTP, Event Messaging, Data Streaming, Data Sharing, or equivalent data ingestion technology.
Experience with REST based APIs and knowledge of HTTP and SOAP Protocols.
Experience with scheduling and managing jobs.
Experience with Encryption and Decryption methods.

Cloud:
Experience with Azure, AWS, GCP platforms or equivalent experience.
Understanding of architecture best practices.
Understanding of security best practices.

Additional Qualifications:
Be a fast learner and work well in a team situation, be flexible and adaptable to deal with a dynamic environment.
Execution and goal-oriented, this individual must be collaborative while possessing the drive to achieve individual results.
Be familiar with AI and how it interacts with a Data Organization.
Good written and oral communication skills.
Prior experience working in the life insurance industry/sector is preferred.
Knowledge about insurance process, and insurance products is a plus.
Regulatory Compliance knowledge about SOX, HIPAA, PCI.
Knowledgeable about setting up and using CI/CD pipelines/DevOps Tools to deploy and release code.
Working knowledge of ITSM practices (Incident, Change, Problem, Request – Management).
Strong understanding of project management methodologies.
Benefits:
Medical, dental and vision benefits
401-k plan
Incentive Program
Flexible paid time off plan
Remote / Hybrid work environment
Paid holidays
Tuition assistance"
1008922703522,Glassdoor,$92K,$130K,,
1008920494778,Glassdoor,,,http://www.gevo.com/,"About the role:
The team at Gevo works with experts in software engineering and data science. sustainability, agronomy, carbon accounting, and data science to help farmers create new value for sustainable practices. We are looking for a team member with excellent geospatial programming, analytics, and data engineering skills for the position of Geospatial Agronomist, Data Engineer. To be successful in this role you will:
Lead the overall geospatial data management program
Design scalable processes and programs to help acquire, organize, analyze, and display layered and temporal geospatial data sets.
Be the interface with both growers and external partners to lead collection and transfer of field and crop management boundaries files and other shapefiles from the farm into Verity Tracking.
Conduct manual (and developing automated processes for the) clean-up, corrections, and adjustments of geometries as well as attributional data, to fit into the platforms overall data flow.
Review, compare, validate, and normalize naming and acreage discrepancies between in-platform maps, USDA shapefiles, and third-party shapefiles.
Ensure maps are of acceptable quality and format with the appropriate tract, field, and farm boundaries demarcated.
Manage geospatial data associated with projects related to remote sensing, including data acquisition, processing, analysis, and storytelling with data.
Integrating remote sensing data with GIS databases and other geospatial information to provide an integrated and comprehensive understanding of the area(s) of interest.
Work with the data science and sustainability teams to analyze and interpret remote sensing data. This includes identifying features, objects, characteristics, and patterns within the imagery, such as land cover classification, vegetation indices, change detection, and anomaly detection.
Resolve problems by assisting, coaching, and training dealers/distributors on technical problem investigation and solution implementation.
Present and promote data management best practices to retailers, agronomy partners, and farmers.
Collaborate with the data engineering and data science teams to build automated geospatial workflows.
Identification of geospatial trends and insights to solve key tactical and strategic business problems
Write clean, testable, and modularized code
Work with key stakeholders to identify opportunities to enhance the flow, analysis, and presentation of multiple different geospatial data sets into and across the company
Transparently communicate priorities, obstacles, and progress on a regular basis to the Product, Sustainability, and Marketing teams.
Comfortably lead technical geospatial operations while following agile principles
Who you are:

Degree or equivalent experience in a quantitative field such as data science, data analytics, geospatial engineering, or computer science; with applied experience in technical geospatial data implementation (programming and visualization)
Expert in common geospatial platforms and programming languages such as Python and proficient with data management systems (e.g. ArcGis, GEOJSON etc.)
Experience with databases / SQL dialects is preferred
Experience in agriculture sales and/or business development and/or crop production preferred.
Comfortable in data validation, verification, and quality assurance methods for geospatial data - strong analytical skills and an eye for detail are crucial for fulfilling your duties.
Logic-driven critical thinker committed to accuracy, precision, and increasing understanding though geospatial data visualization.
Strong ability to manage projects, ask the right questions, and propose product solutions.
Passionate about environmental sustainability with domain knowledge in agricultural practices, industrial processes, and data.
Experienced in building trusted business relationships.
Customer-oriented, with a demonstrated ability to respect and earn the respect of farmers and retail distribution partners
Strong written and verbal communicator
Enjoy attending farm shows to promote the use of products and services
Proficient at managing time, priorities, and expenses.
Self-starter, reliable, and able to work independently.
Computer Skills: To perform this job successfully, an individual should be proficient in Google Suite applications (and similar office suites).
Who We Are
We are People First
We are Mission-Focused
We are Agile
We are Innovators
What Gevo Offers You
Free health, dental, vision, life and disability insurance for employee and family
21 days of paid time off plus 10 paid holidays
401k contribution plan
Annual incentive plan, based on Company performance
Paid community service time
Dog friendly office
Be part of a smart, high performing, passionate team
Work-from-home stipend, if remote
Commitment to Diversity and Inclusion

Gevo, Inc. is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws."
1008923081239,Glassdoor,,,,"As a Senior Data Engineer, you will focus on designing and developing state-of-the-art data engineering solutions. You will collaborate with multi-functional teams to analyze data requirements, design pipelines, and implement integration processes. Your expertise in data engineering, big data technologies, and data management will contribute to the effective storage, processing, and utilization of large-scale data sets. In partnership with enterprise data platform teams, you will focus on advancing connected data vision and expanding and optimizing data architecture and pipelines.
Responsibilities
Create and maintain optimal data pipeline architecture to a ssemble large, complex data sets that meet functional / non-functional business requirements .
Identify , design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Work with stakeholders to optimize the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using ‘big data’ technologies.
Work with stakeholders including the Product, Data and Engineering teams to assist with data-related technical issues and support their data infrastructure needs.
Adhere to and ensure engineering best practices using modern SDLC that enables CI/CD and favors automation, auditability, automated testing, infrastructure, and policy as code.
Ability to collaborate effectively with other architects and engineers delivering end to end, high-performing, highly reliable , scalable, and operable solutions.
Required Qualifications
Bachelor’s degree in Computer Science , Engineering, or a related technical field; or equivalent experience.
5 + years of experience delivering data engineering applications and services using one or more programming languages Scala , Python, Java
Experience in building and optimizing ‘big data’ data architecture , modeling , data formats and pipelines .
Experience in big data technologies ( Databricks , Spark, Data Lake , Delta Lake etc . )
Experience in any one of the stream-processing systems ( Kafka, Storm, Spark-Streaming, etc.
Understanding of modern software development including version control, unit testing, and continuous integration and deployment.
Strong communication skills, with proven ability to present complex ideas and to document concisely.
Preferred Qualifications
Working knowledge of Cloud providers and services such as Amazon AWS or Microsoft Azure.
Experience with relational SQL and NoSQL databases, including MongoDB and ElasticSearch .
Knowledge of healthcare data standards such as HL7, FHIR, EDI X12.
Knowledge of the healthcare revenue cycle, EMRs , practice management systems.
The US base pay range for this position is $63,140.06 - $143,517.00. Individual pay is determined by role, level, location, job-related skills, experience, and relevant education or training.
Learn more about Benefits at R1
Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests.

Our associates are given valuable opportunities to contribute, to innovate and create meaningful work that makes an impact in the communities we serve around the world. We also offer a culture of excellence that drives customer success and improves patient care. We believe in giving back to the community and offer a competitive benefits package including:
Comprehensive Medical, Dental, Vision & RX Coverage
Paid Time Off, Volunteer Time & Holidays
401K with Company Match
Company-Paid Life Insurance, Short-Term Disability & Long-Term Disability
Tuition Reimbursement
Parental Leave
R1 RCM Inc. (“the Company”) is dedicated to the fundamentals of equal employment opportunity. The Company’s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person’s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.
If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.
CA PRIVACY NOTICE: California resident job applicants can learn more about their privacy rights California Consent"
1008919848812,Glassdoor,,,,"Experience : 6 - 10 Yrs
Location : Pune (Aundh)
Position : Senior / Lead Big Data Engineer
To be successful in this role, you should possess :
Collaborate closely with Product Management and Engineering leadership to devise and build the right solution.
Participate in Design discussions and brainstorming sessions to select, integrate, and maintain Big Data tools and frameworks required to solve Big Data problems at scale.
Design and implement systems to cleanse, process, and analyze large data sets using distributed processing tools like Akka and Spark.
Understanding and critically reviewing existing data pipelines, and coming up with ideas in collaboration with Technical Leaders and Architects to improve upon current bottlenecks
Take initiatives and show the drive to pick up new stuff proactively, and work as a Senior Individual contributor on the multiple products and features we have.
7+ years of experience in developing highly scalable Big Data pipelines.
In-depth understanding of the Big Data ecosystem including processing frameworks like Spark, Akka, Storm, and Hadoop, and the file types they deal with.
Experience with ETL and Data pipeline tools like Apache NiFi, Airflow etc.
Excellent coding skills in Java or Scala, including the understanding to apply appropriate Design Patterns when required.
Experience with Git and build tools like Gradle/Maven/SBT.
Strong understanding of object-oriented design, data structures, algorithms, profiling, and optimization.
Have elegant, readable, maintainable, and extensible code style.
You are someone who would easily be able to :
Work closely with the US and India engineering teams to help build the Java/Scala based data pipelines.
Lead the India engineering team in technical excellence and ownership of critical modules; own the development of new modules and features.
Troubleshoot live production server issues.
Handle client coordination and be able to work as a part of a team, be able to contribute independently and drive the team to exceptional contributions with minimal team supervision.
Follow Agile methodology, JIRA for work planning, issue management/tracking.
Additional Project/Soft Skills :
Should be able to work independently with India & US based team members.
Strong verbal and written communication with ability to articulate problems and solutions over phone and emails.
Strong sense of urgency, with a passion for accuracy and timeliness.
Ability to work calmly in high pressure situations and manage multiple projects/tasks.
Ability to work independently and possess superior skills in issue resolution.
Should have the passion to learn and implement, analyze, and troubleshoot issues.
Job Type: Full-time
Salary: $2,500,000.00 - $3,000,000.00 per year
Benefits:
Flexible schedule
Health insurance
Experience level:
10 years
6 years
Schedule:
Day shift
Monday to Friday
Experience:
Scala: 4 years (Required)
Spark: 4 years (Preferred)
Apache Hive: 4 years (Preferred)
Work Location: Remote"
1008922183231,Glassdoor,$100K,$142K,,
1008923091974,Glassdoor,$74K,$104K,http://www.lucayantechnology.com/,"Description:
Required skills:
Data Engineering – They need to be stronger.
Azure – high need – should have experience here.
Kubernetes – have been very stringent with here.
Machine Learning.
Python – must have.
Spark - also required.
Jupterhub/ mlflow/ databricks/ kubeflow – Have been deployed and worked on any of this tool.

Secondary Skills - Nice to Haves:
HELM
Argo Workflow

Job Description:
The Engineer is responsible for developing, implementing, and maintaining technical software applications and provides a combination of technical and business leadership while being the primary trusted and capable owner of one or more high priority, high visibility, complex initiatives.
This Engineer will typically lead and coach a small number of team members and provide guidance to team members and multiple.
You will design, develop, test, deploy, maintain, and enhance Machine Learning Pipelines using K8s/AKS based Argo Workflow Orchestration solutions.
Participate and contribute to design reviews with platform engineering team to decide the design, technologies, project priorities, deadlines, and deliverables.
You will work closely with Data Lake and Data Science team to understand their data structure and machine learning algorithms.
Understanding of ETL pipelines, and ingress / egress methodologies and design patterns
Implement real time argo workflow pipelines, integrate pipelines with machine learning models, and translate data and model results into business stakeholders Data Lake
Develop distributed Machine Learning Pipeline for training & inferencing using Argo, Spark & AKS
Build highly scalable backend REST APIs to collect data from Data Lake and other use-cases / scenarios.
Deploy Application in Azure Kubernetes Service using GitLab CICD, Jenkins, Docker, Kubectl, Helm and Mainfest
Experience in branching, tagging, and maintaining the versions across the different environments in GitLab.
Review code developed by other developers and provided feedback to ensure best practices (e.g., checking code in, accuracy, testability, and efficiency)
Debug/track/resolve by analyzing the sources of issues and the impact on application, network, or service operations and quality.
Functional, benchmark & performance testing and tuning for the built workflows.
Assess, design & optimize the resources capacities (e.g. Memory, GPU etc.) for ML based resource intensive workloads.
Education: Bachelors Degree"
1008919892540,Glassdoor,,,http://www.patientpay.com/,"DESCRIPTION
PatientPay is seeking to hire a Senior Data Engineer, in a newly added position, to join its rapidly growing business. By leveraging modern cloud-based technologies, PatientPay offers unmatched user experience and results for its customers. In this role, you will be part of an Agile/Scrum team that is responsible for designing, building, and shipping commercial software at scale. This includes designing, documenting, coding, and testing complex solutions that exceed user expectations.
RESPONSIBILITIES
Apply data engineering principles to analyze, problem solve and design solutions.
Analyze and organize raw data
Align data architectures with business requirements
Develop data systems and pipelines
Explore and implement ways to enhance data quality, efficiency and reliability.
Create technical specifications.
Produce efficient and high-quality code that endures at scale.
Maintain and improve existing codebases and peer review code changes.
Analyze existing systems and drive improvements.
Monitor system health and perform predictive and proactive maintenance.
Investigate and implement new technologies where relevant.
SKILLS AND QUALIFICATIONS
Bachelor’s or higher degree in Computer Science or related field.
Previous experience as a Data Engineer or similar role.
Technical expertise with data models, data mining and segmentation techniques.
Knowledge of programming languages such as Java and Python.
Proficient in AWS Aurora/MySQL, S3 and SQL.
Hands-on experience working in an AWS environment with Apache Airflow, Aurora, S3, MongoDB, Jira, Confluence and DataDog.
Experience with Scrum/Agile development methodologies.
Proficient in troubleshooting data issues and debugging large codebases.
Strong communication skills with an ability to work collaboratively.
Analytical and logical thinking with strong problem-solving skills.
Takes pride and ownership of their code and deliverables.
Strong ability to understand all of the moving parts of complex systems and troubleshoot issues efficiently.
PREFERRED QUALIFICATIONS
Experience with AWS cloud technologies and Jenkins.
Experience in FinTech and payment processing.
Thrives in a company culture with a “do whatever it takes” attitude.
PatientPay, an equal opportunity employer, offers a competitive salary and benefits package. Employee benefits include:
$1000/month towards medical, dental and vision benefits
Equity program
Life Insurance
Health Plans with HSA/FSA accounts
Short and Long-term disability
Three weeks PTO upon hiring
Ten company holidays and two floating holidays per year
401K matching at 4%
Employee assistance programs
Hybrid and remote working opportunities
Casual dress
To apply, please email your cover letter and resume to careers@patientpay.com"
1008922619854,Glassdoor,$78K,$121K,http://www.orbisoperations.com/,"We are seeking an innovative Data Engineer with a TS/SCI and polygraph clearance. They will be responsible for interfacing with upstream and downstream data providers and consumers and will advise (and potentially help implement) on architectures to make the data useful and accessible. The Consultant will support a variety of efforts not restricted to a singular geographic region or language (existing natural language processes operate on 8 languages from across the globe, and more will likely be required). On this project, you’ll have the opportunity to demonstrate your intellectual agility by aiding development of key performance insights and identifying dataflows and techniques to measure their success, and will work closely with stakeholders to ensure that data science processes are aligned with mission objectives. This project features the opportunity to interact with a wide range of key stakeholders, including those at senior levels, and has the potential for travel. This is an exciting opportunity for an intellectually curious, energetic data scientist looking for more ""hands-on"" experience to work on a project with real impact helping our client develop ways to understand and improve performance of activities that support delivery of the mission.
Key Responsibilities
Duties/Responsibilities
Assist with stakeholder education on quantitative capabilities, helping them to understand strengths and weaknesses of different approaches and what problems are suitable and unsuitable for data science
Identify what data is already available and determine what mission-oriented questions we can answer using that data.
Extract insights from bulk semi-structured data using data analysis techniques.
Consult with internal and external stakeholders on the development, prioritization and implementation of process improvement and impact evaluations tasks.
Develop and implement practical strategies for measuring performance of models and processes, to include development of performance measures, design of actionable methods for collecting and analyzing performance metrics, and implementation of capture and analysis strategies with refinement as needed.
Analyze both quantitative and qualitative information to provide customers with comprehensive insights into organizational strengths and opportunities for growth.
Prepare engaging presentations of analysis through data visualization and analytic narratives
Brief senior-level customers on research plans, activities, findings and recommendations.
Supervisory Responsibilities
This position has no supervisory responsibilities
Skills, Knowledge and Expertise
Education and Experience
A Bachelor’s degree is required for this position
Minimum of 5 years' experience in a consulting role in the IC
Master’s degree in business, social science, or behavioral science preferred but not required for this position
Required Skills/Abilities
U.S. Citizenship
Active TS/SCI clearance with Polygraph
ETL
Ability to perform extract, transform, load (ETL) development for data pipelines
Ability to integrate and update lab-to-factory services into data pipeline
Ability to integrate and update workflow orchestration
Parsing
Ability to perform API Service Development
General
Working knowledge of ELK Stack (elastic search, logstash, and kibana) - ingestion, management, and access control
Python
Bash Scripting - ad-hoc processing, cron jobs, etc.
Experience working on cloud environments
Physical Requirements
Prolonged periods of sitting at a desk and working on a computer.
Routine video conference and/or in-person meetings.
Ability to attend planned meetings within the Washington Metro Area region.

Location
McLean, VA"
1008922147195,Glassdoor,$100K,$134K,http://www.myrocketcareer.com/,"Rocket Mortgage, backed by Rocket Companies®, means more opportunities for you to carve your own career path forward. From our desire to revolutionize the way people get mortgages to addressing challenges big or small with outside-the-box solutions, we’re not your typical employer. We’ll provide you with everything you need to make sure you’re successful here.

Apply today to join a team that offers career growth, amazing benefits and the chance to work with leading industry professionals.

Minimum Qualifications
Bachelor's degree in computer science, information technology, or a related field or equivalent experience

Preferred Qualifications
3 years of experience working with database tools
3 years of programming experience using Python
3 years of experience working with SQL server integration services or ETL tools
3 years of experience working with AWS
3 years of experience working with data integration tools
Proficiency in the Microsoft Office suite
Experience working with ETL tools
Knowledge of data integration tools
Knowledge of software programming languages, such as Python
Job Summary
As a Senior Data Engineer, you'll work with database engineers to design, develop and maintain the infrastructure of data within the data warehouse, including setting the ETL (extract, transform, load) processes, bringing in new data sources, modifying existing data sources, making sure data is clean, complete and consumable, as well as designing data models within the data warehouse. You'll work as part of one or more project teams and will be responsible for designing and building mechanisms to move, integrate, cleanse and publish large volume datasets. This is a developer role with a specialty in data and requires deep knowledge of a variety of programming languages and design patterns.

Responsibilities
Design and support the new and evolving sources of data being brought into the data warehouse
Work closely with data architects and follow best practices for data management consumption
Work closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platform
Assist with application layer and metadata design
Assist with the design and create automated applications and reporting solutions
Work closely with front-end developers to ensure data is being brought in and data integrity is being maintained
Monitor and troubleshoot performance issues on the data warehouse servers
Research and promote new tools and techniques to shape the future of the data environment
Mentor and train other data engineers
Benefits and Perks
Our team members fuel our strategy, innovation and growth, so we ensure the health and well-being of not just you, but your family, too! We go above and beyond to give you the support you need on an individual level and offer all sorts of ways to help you live your best life. We are proud to offer eligible team members perks and health benefits that will help you have peace of mind. Simply put: We’ve got your back. Check out our full list of Benefits and Perks.
Who We Are
Rocket Companies® is a Detroit-based company made up of businesses that provide simple, fast and trusted digital solutions for complex transactions. The name comes from our flagship business, now known as Rocket Mortgage®, which was founded in 1985. Today, we’re a publicly traded company involved in many different industries, including mortgages, fintech, real estate and more. We’re insistently different in how we look at the world and are committed to an inclusive workplace where every voice is heard. We’re passionate about the work we do, and it shows. We’ve been ranked #1 for Fortune’s Best Large Workplaces in Financial Services and Insurance List in 2022, named #5 on People Magazine’s Companies That Care List in 2022 and recognized as #7 on Fortune’s list of the 100 Best Companies to Work For in 2022.
Disclaimer
This is an outline of the primary responsibilities of this position. As with everything in life, things change. The tasks and responsibilities can be changed, added to, removed, amended, deleted and modified at any time by the leadership group.
We are proud equal opportunity employers and committed to providing an inclusive environment based on mutual respect for all candidates and team members. Employment decisions, including hiring decisions, are not based on race, color, religion, national origin, sex, physical or mental disability, sexual orientation, gender identity or expression, age, military or veteran status or any other characteristic protected by state or federal law. We also provide reasonable accommodation to qualified individuals with disabilities in accordance with state and federal law."
1008921710687,Glassdoor,$68K,$105K,https://mycareer.verizon.com/,"When you join Verizon
Verizon is one of the world’s leading providers of technology and communications services, transforming the way we connect around the world. We’re a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together—lifting up our communities and striving to make an impact to move the world forward. If you’re fueled by purpose, and powered by persistence, explore a career with us. Here, you’ll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.
What you’ll be doing...
This role is part of the Artificial and Intelligence (AI&D) organization which focuses on delivering the power of data and AI to drive our marketplace leadership through innovative solutions that create value for our customers, shareholders, V teamers and society, responsibly. At Verizon, we are on a multi-year journey to industrialize our data practices and AI capabilities. Very simply, this means that AI and data will fuel all decisions and business processes across the company.
Understanding code development that is compliant and meets high standards/quality, delivers desired functionality using cutting edge technology.
Programming a component, developing feature or frameworks
Working independently and contributing to the immediate team and cross functional teams.
Contributing to design discussions.
Taking ownership of delegated tasks and helping other team members.
Demonstrating the initiative to explore alternate technology and approaches to solving problems.
Following the agile based approach to deliver the data products.
What we’re looking for...
We're looking for a Junior Data Engineer with a good fundamental understanding of Google Cloud Platform, data ingesting and data curation concept. Depending upon the need of the product, we're looking for someone to help us build either in GCP platform, On-prem Hadoop or Teradata.
You’ll need to have:
Bachelor's degree or one or more years of work experience.
Good understanding of data warehousing, data lakes and big data platforms.
Strong leadership, communication, persuasion and teamwork skills.
Empathy and a positive attitude.
Even better if you have one or more of the following:
Bachelors/Masters degree in Computer Science, Information Science, Engineering or other related field with 1 or more years of relevant work experience.
One or more years of programming experience in GCP Data Proc, Cloud Shell SDK, Cloud Composer, GCS, Cloud Functions & Big Query.
One or more years of experience in designing and deployment of Hadoop cluster and different big data analytical tools including HDFS, PIG, Hive, Sqoop, Spark, Oozie.
Hands on experience in designing and building data pipelines in Nifi/Airflow/Apache Beam in GCP (Data Proc and Big Query) for ETL related jobs.
Knowledge in Google data catalog and other Google Cloud APIs for monitoring, querying and billing related analysis for Big Query usage.
Experience working with at least 1 NoSQL Databases (HBase, Cassandra, Couchbase) and 1 relational database (Oracle, MySql, Teradata).
If Verizon and this role sound like a fit for you, we encourage you to apply even if you don’t meet every “even better” qualification listed above.
This role is eligible to be considered for the Department of Defense SkillBridge Program.
Where you’ll be working
In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.
Scheduled Weekly Hours
40
Equal Employment Opportunity
We’re proud to be an equal opportunity employer - and celebrate our employees’ differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more."
1008922897858,Glassdoor,,,,"Bamboo Health is a leader in cloud-based care coordination software and analytics solutions focused on patients with complex needs, including those suffering from physical health and mental health issues and substance use disorders. We are driven by our mission of enabling better care for patients across the continuum. Our software solutions help healthcare professionals collaborate on shared patients across the spectrum of care. Join us in improving healthcare for all!
Summary:
We are actively hiring a full-time Sr. Data Integration Engineer to focus on supporting and extending our data platform. Bamboo Health receives HL7 data from hospitals, EHRs and HIEs around the country and this role will be responsible for integrating new HL7 EHR senders to the data pipeline using in-house tools, scripts, and custom applications. The ideal candidate will work well in a team, have a data-first mentality, and thrive in customer-facing projects.
What You Will Do:
Partner with Operations to ensure on-boarding HL7 integrations meet target deadlines through task resolution in a timely and organized manner
Partner with broader Platform Engineering team on cross-functional initiatives focused on infrastructure scalability and stability.
Partner with Software Engineers focused on improving our data pipeline
Design and execute HL7 test plans for on-boarding new integrations
Build a standard integration process to receive data and post events to new EHR systems
Work with ADT senders to resolve customer issues and maintain high quality interfaces
On-board and track standard HL7 integrations
Triage customer issues related to HL7 integrations

What Success Looks Like…
In 3 months…
Execute:
Develop solid understanding of Bamboo Health onboarding process for Technical Implementation Services
Contribute to HL7 data validation, mapping, and testing processes
Develop an understanding of our HL7 data pipeline
Build relationships across the broader Product Platform organization

In 6 months…Manage:
Work with our Product, Operations and Network Operations Center teams to drive streamlined data processing and continuous improvement initiatives.
Contribute to the development and reporting of data quality metrics

In 12 months…Scale:
Develop a comprehensive knowledge of our data ingestion architecture
Manage complex customer integrations with a heavy focus on service and quality outcomes

What You Need:
5+ years professional experience in or around software development
Experience in or around the Healthcare domain
Experience in at least one modern language such as Java, Python, JavaScript
Proficient in SQL
Willingness to learn healthcare data exchange formats
Ability to self-start project tasks and communicate progress clearly
Ability to work autonomously on multiple concurrent projects and prioritize appropriately
Experience organizing and delivering on several lines of work with clear communication on progress
Desire to work in a fast-paced collaborative environment
A work environment that is conducive to high quality virtual interactions. This includes but is not limited to being able to work from a quiet space with minimal interruptions or distractions, and a strong internet connection.

Helpful/Preferred Experience:
Healthcare data integration tools (Mirth preferred)
Cloud-native AWS solutions
SDLC – Git, pull requests
Docker & Kubernetes
Atlassian product suite
SumoLogic, Prometheus/Grafana, or equivalent

What You Get:
Join one of the most innovative healthcare technology companies in the country.
Have the autonomy to build something with an enthusiastically supportive team.
Learn from working at the highest levels and on the most strategic priorities of the company, including from world class investors and advisors.
Receive competitive compensation, including equity, with health, dental, vision and other benefits.

Bamboo Health is proud to be an Equal Employment Opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
#LI-Remote"
1008920871149,Glassdoor,$83K,$122K,,
1008923069772,Glassdoor,,,,"Description:
The Amivero Team
Amivero’s team of IT professionals delivers digital services that elevate the federal government, whether national security or improved government services. Our human-centered, data-driven approach is focused on truly understanding the environment and the challenge, and reimagining with our customer how outcomes can be achieved.
Our team of technologists leverage modern, agile methods to design and develop equitable, accessible, and innovative data and software services that impact hundreds of millions of people.
As a member of the Amivero team you will use your empathy for a customer’s situation, your passion for service, your energy for solutioning, and your bias towards action to bring modernization to very important, mission-critical, and public service government IT systems.
Special Requirements
US Citizenship required to obtain DHS Public Trust. Must be able to obtain the DHS Public Trust
Bachelors + 6 years of relevant experience.
Must have Python and Airflow experience.
The Gist…
Our Data Engineer will work as a part of a team responsible for developing enterprise grade data platforms, services, and pipelines. You will use your passion for data, background in problem solving and customer engagement to advance the build of this enterprise environment.
What Your Day Might Include…
Migrate environments with performance and reliability.
Assess and understand the ETL jobs, workflows, BI tools, and reports.
Work with stakeholders to gather and understand requirements
Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products.
Craft database / data warehouse solutions in cloud (Preferably AWS. Alternatively Azure, GCP).
Support an Agile software development lifecycle.
Manipulate, process and extract values from large, disconnected datasets.
Manipulate structured and unstructured data for analysis.
Construct complex queries to analyze results using databases or in a data processing development environment.
Aggregate results and/or compile information for reporting from multiple datasets.
Support project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models.
Requirements:
You'll Bring These Qualifications...
6+ years industry experience coding commercial software and a passion for solving complex problems.
6+ years direct experience in Data Engineering with experience in tools such as:
Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and Cassandra.
Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
AWS cloud services: EC2, EMR, RDS, Redshift (or Azure equivalents)
Data streaming systems: Storm, Spark-Streaming, etc.
Search tools: Solr, Lucene, Elasticsearch
Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Expertise in Python
Must have worked in an AWS environment.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Should have experience in airflow.
Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.

EOE/M/F/VET/DISABLED
All qualified applicants will receive consideration without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Amivero complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities."
1008921157818,Glassdoor,$93K,$134K,http://www.linquest.com/,"Position Summary
LinQuest is looking for an energetic and innovative Data Engineer/Scientist to assist in addressing gaps and discrepancies in sustainment-management reporting through the synchronization of multiple stakeholder requirements and the processing of sustainment data to develop and display operational readiness metrics. As a member of a team, the Data Engineer will streamline a current scheduling tool to improve user experience through the application of cascading filtering, refining user roles, and scheduling confidence ratings. As a Data Engineer the candidate will be adept at loading and joining data tables, integrating data from diverse static and automatic data sources, writing functions, and configuring charts and data grids. Candidates must be comfortable working with a wide range of stakeholders and functional teams that work across multiple time zones and have a passion for discovering solutions hidden in large data sets. Candidates will have the opportunity to work with unstructured and structured data, develop databases, build data pipelines, and find innovative solutions to complex data problems.
Key Responsibilities:
Loading and joining data tables, writing functions, and configuring charts and data grids
Publish charting for automated data feeds of effectiveness metrics
Provide the ability to display metrics generated from automated data sources
Research state-of-the-art data mining methods and innovative statistical models
Identify relevant data sources and sets to mine for client business needs and collect large structured and unstructured datasets and variables
Process, cleanse, and verify the integrity of data used for analysis
Clearly document and present methodology, assumptions, and findings to stakeholders

Required Skills and Experience:
Bachelor’s degree in Computer Science, Data Analytics, Software Development, Information Technology, or related discipline
3-5 years of experience in data engineering
Experience processing data in Advana
Manipulating data with SQL and Python
Developing data pipelines to support analytics
Documenting and communicating results of analysis
Experience manipulating data from spreadsheets (i.e. MS Excel)
Experience with Business Intelligence (BI) Tools (Power BI, Tableau, Qlik etc.)
Strong analytical and problem-solving skills with hands on experience driving analytic insights
Ability and motivation to self-teach in order to stay current with leading best practices in analytics
Expected to deliver in a fast-paced, team-oriented work environment
Must thrive in satisfying analytic requirements from diverse user base
Must have the knowledge and communication skills to articulate trade-offs between analytic techniques, recommend a course of action to clients, and provide effective updates on project outcome uncertainty to leadership
US citizenship and the ability to obtain a DoD Secret security clearance are required

Preferred Skills and Experience:
Text mining and unstructured data analysis techniques
Machine Learning techniques
Language/Scripting skills: Python, Databricks Spark Compute
Tools: Qlik
Extract, Transform, Load (ETL) experience
Predictive and prescriptive analysis
Optimization experience
A current/active DoD security clearance

Why LinQuest?
LinQuest Corporation has a stellar 40-year track record of providing end-to-end system-of-systems (SoS) architecture definition, engineering design, integration and test, and operations expertise to enable full lifecycle development and deployment of pre-eminent Space, Air, Land, Sea, Ground, and Cyberspace game-changing capabilities across US DOD and IC Customers’ portfolios. Unique combination of in-depth domain knowledge, lessons learned-honed best practices, and mission-specific applications of principles, tools, and techniques of Digital Engineering (DE), DE Ecosystem (DEE), and Model-Based Systems Engineering (MBSE) set LinQuest apart from the competition to consistently deliver stellar high-value results for our customers. LinQuest’s corporate vision and values place the employee at the center of utmost customer satisfaction, strategic business growth, and tactical execution excellence. Our employees’ creative and inspirational drive, sense of fulfillment of personal and professional growth, and tightknit camaraderie within and across lines of business are essential in gaining and maintaining exceptional LinQuest corporate-wide results of new business awards and renewed contracts.
Benefits:
LinQuest offers comprehensive and competitive benefit offerings to our team members to include medical, dental, vision, retirement, paid time off, tuition reimbursement, company paid life insurance, and more! For additional information please visit: https://www.linquest.com/careers/our-benefits
Education
Required
Bachelors or better
Licenses & Certifications
Required
Ability to Obtain
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
1008922668470,Glassdoor,,,https://www.viam.com/,"Viam is a software platform that makes it easy to turn great ideas into production-ready smart machines & robots at scale. Viam works with any hardware and has modern architecture, easy developer APIs, cloud connectivity and tools, and enterprise-grade security to give even the leanest teams the power to launch and manage their smart machine businesses.

Viam makes building, deploying, and monitoring smart machines a more flexible, affordable, and user-friendly experience, allowing developers to do more with smart machines while getting them to market faster. By making smart machines more accessible, Viam is attracting talent and investment to the industry so that more people start building automated products and services that improve our quality of life.
Senior Software Engineer, Data/Machine Learning (Fullstack)
We are seeking a Senior Software Engineer to join our New York based Data/ML team. The Data/ML team tackles interesting problems that span a wide range of technical challenges in machine learning, data storage, database optimization, cloud storage, API design, UI/UX, and more.
You will have the opportunity to create solutions that can make it seamless for a user to use a smart machine, get data from that smart machine, and use that data to do something really interesting. Since data is so fundamental to all types of smart machines and use cases, we collaborate with folks from different engineering teams, like SLAM or Computer Vision, to get the data from their components/services into Viam.
The current tech stack consists of Golang (backend), Python/TensorFlow (machine learning), TypeScript, Vue, Svelte, HTML (frontend).
In this role, you will:
Work across the stack to create scalable solutions that allow our users to manage the lifecycle of data from smart machines.
Design and implement data storage and processing systems.
Collaborate with many other teams to integrate their newest features into our web app frontend and backend.
We're looking for someone who:
Has an affinity for sophisticated problems, and loves solving them with practical solutions.
Believes in high-quality, tested, and well-documented code.
Is excited to discuss and implement best practices and design patterns for data viewing and analysis.
Has experience in data storage and cloud infrastructure.
Wants to work with physical hardware, but doesn't necessarily have experience doing so.
Has software engineering experience using languages, such as C/C++, Golang, Java, Python, JavaScript, TypeScript.
Benefits:
100% covered medical/dental/vision insurance plans
Competitive salary & equity packages (see below)
Reproductive Health Benefits including Fertility Benefits and Abortion Access Travel Benefits
25 days paid vacation and generous holiday observances
One Medical Membership
Citi Bike memberships
Commuter benefits
Monthly wellness stipend to be used for a variety of fitness-related items like gym memberships, fitness classes, fitness equipment, apparel, and more
Free lunch everyday that you're in the office
Paid parental leave
The starting salary for this role is between $157,000 - $213,000/year. Your exact offer will vary based on a number of factors including experience level, skillset, market location, and balancing internal equity relative to peers at the company. We recognize that the person we hire may be less experienced, or more senior, than this job description as posted. In these situations, the updated salary range will be communicated with you as a candidate. In addition to cash compensation, Viam offers a comprehensive Total Rewards package that includes equity grants, health benefits, and more."
1008921776642,Glassdoor,,,,"Job Description

Job Title:
Data Governance Engineer

Company Description
Varonis is the leader in unstructured and semi-structured data governance software. Based on patented technology and a highly accurate analytics engine, Varonis solutions give organizations total visibility and control over their data, ensuring that only the right users have access to the right data at all times from all devices, all use is monitored, and abuse is flagged. Varonis makes digital collaboration secure, effortless and efficient so that people can create and share content easily with whom they must, and organizations can be confident their content is protected and managed efficiently. Voted one of the ""Fast 50 Reader Favorites"" on FastCompany.com, and winner of the SC Magazine Innovation, Product or Service of the Year, and Best Network Security Awards, Varonis has more than 4,500 installations worldwide and is headquartered in New York, with regional offices in Europe, Asia and Latin America.

Job Description
We are in search of a talented Data Governance Engineer to help continue our outstanding growth.

Responsibilities
Be a lead engineer on projects centered around securing access to customer’s data.
Translate technical approach into non-IT language.
Be able to find IT solution for business problem.
Interact with external customers on daily basis by phone and WebEx.
Work with both IT and business staff on customer side.
Gather and analyze information about a customer’s environment.
Attend meetings on site during the project initiation.
Develop documentation as needed.
Provide demonstration and training on software as needed.
10% travel to customer locations (Domestic and International).

Requirements
Undergraduate Degree.
Experience working with external customers is highly desired.
Experience with managing permissions on Windows folders is highly desired.
3+ years of related experience.
Microsoft Environments (AD, Windows Servers).
Understanding of NTFS and Share Permissions.
Storage Devices (NetApp, EMC).
Excellent interpersonal skills.
Outstanding customer service skills.
“Please the customer” mentality.
Sense of Humor.

We invite you to check out our Instagram Page to gain further insight into the Varonis culture!
@VaronisLife

Varonis is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, and other legally protected characteristics."
1008917688653,Glassdoor,,,,
1008922400605,Glassdoor,,,http://www.rackspace.com/,"Job Summary: Responsible for maintaining the operation and maintenance of all electrical, mechanical, life safety and monitoring equipment within the Data Center/Facility. This equipment supports mission-critical servers and is expected to maintain 100% customer up-time.
Responsibilities include maintaining facility appearance and integrity.
Work Location: You’ll work onsite at our state of art Data Center located in Kansas City, MO.
Key Responsibilities:
Oversee potentially medium impacting projects and coordinate the use of resources, project execution, & communication.
Identify infrastructure risks and performance gaps.
Troubleshoot electrical and mechanical data center infrastructure.
Assist in facilitating Root Cause Analysis (RCAs) to ensure the recurrence of issues or incidents are eliminated.
Execute and assist in developing and documenting step-by-step methods of procedure (MOPs) for critical maintenances.
Execute and assist in the development of step-by-step Standard Operating Procedures (SOPs) and Emergency Operating Procedures (EOPs) to drive the consistency of operation and quickly respond to incidents to return equipment to operation.
Supervise and manage scheduled maintenance of electrical, mechanical, life safety and monitoring equipment.
Oversee the monitoring equipment and other critical systems.
Assist in effectively leading Incident Management efforts in the event of system degradation/failures communicating the status to all levels and resolving the issue in a timely fashion.
Maintain meticulous 5S and housekeeping practices.
Qualifications:
2 years+ experience with the electrical, mechanical, life safety and monitoring equipment maintenance within data center or other critical environments.
High school diploma or equivalent required.
Advanced knowledge of HVAC, HV and LV switch boards, Transformers, Chillers, BMS (Trend), Fire Alarms, Sprinkler systems, UPS, Lead acid batteries, Generators, PDUs, and RPPs.
Knowledge of Health and Safety at work acts, i.e. method statements, risk assessments.
Knowledge of Building Automation and Power Management Systems.
About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.
Job Type: Full-time
Pay: $28.55 - $38.07 per hour
Benefits:
401(k)
401(k) matching
Dental insurance
Employee discount
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Referral program
Relocation assistance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Supplemental pay types:
Bonus opportunities
Work Location: In person"
1008923122044,Glassdoor,$94K,$126K,http://www.trimarkusa.com/,"TriMark USA is the country’s largest provider of design services, equipment, and supplies to the foodservice industry. We proudly serve our customers by providing design services, commercial equipment, and foodservice supplies across a wide range of industries and business sectors. Headquartered in Massachusetts, with a history dating back to 1896, we have locations across the country that offer foodservice operators an unparalleled level of service by combining our unique design capabilities and our expert market knowledge with the purchasing strength, delivery, installation, and after-sales service capabilities of a national company. Our employees are focused on creating customized solutions for our clients to ensure they achieve their culinary goals while upholding our I.C.A.R.E. values: Integrity, Customer Service, Accountability, Respect, and Excellence. For more information, please visit: www.trimarkusa.com

Why you’ll love it here!
+ Benefits include Medical, Dental, Vision, Tuition Reimbursement, Pet, and Legal Insurance.

POSITION SUMMARY:
The Senior Data Engineer reports to the Vice President of Data Analytics.
Located in Mansfield, Ma.
Full-Time
Hybrid
ESSENTIAL FUNCTIONS & RESPONSIBILITIES:
Design, build, and deploy business intelligence solutions with Microsoft's BI stack and other BI tools.
Perform ETL development utilizing SQL queries, stored procedures, functions, views, SSIS packages and other tools as necessary to meet all customer requirements.
Plan, design, develop and implement robust ETL processes between internal systems and to external systems.
Develop integrations and support a large enterprise data warehouse integrated to several disparate database platforms.
Build reporting solutions for diverse business functions utilizing various reporting tools such as Microsoft SSRS, Tableau and Power BI.
Develop an in-depth understanding of our data environment and leverage knowledge to build robust, user-friendly reports and visualizations by utilizing diverse reporting tools.
Primarily work within MS-SQL, but access Oracle, DB2 and other database platforms, as well as import/export to a variety of file formats.
Job duties will include all phases of the SDLC process for database development, including problem definition, requirements gathering, design, build, test, implement and ongoing support. Follow design and development standards and guidelines as defined by the IT development team.
Assist in the designing, planning, and implementation of disaster recovery policies and procedures. Work with business analysts and application development staff to develop and enforce database architectures, coding standards and quality assurance policies and procedures.
Proactively contribute, offer recommendations, and identify risks and solutions associated with proposed or existing database solutions and strategies.
Work cooperatively with business analysts to define business needs, translating those needs into system requirements and clearly defining the scope of the solution.
Consult and coordinate with business analysts and other programmers to design and develop automated business systems.
Understand the data elements, database structures, and data flows within an enterprise system. Assist with new software/hardware implementation including initial training, follow-up support, and on-going continuous application improvement.
Track and document changes to functional and business specifications. Create or assist others in the writing of user documentation, instructions, and procedures.
Monitor and document post-implementation problems and revision requests.
QUALIFICATIONS & EXPERIENCE:
Requires a Master's degree in Computer Science, Information Systems, Business Analytics, or a related field plus 2 years of experience with SSRS reports developing Business Intelligence and Business Analytics reports, or equivalent Military or practical experience.
2 years of experience working with business requirements for projects, including designing and building reports.
2 years of experience creating dashboard-style reports with Tableau.
2 years of experience with Server Integration Services (SSIS), or other ETL protocols.
2 years of experience with Microsoft SQL. Ability to successfully pass a background check post offer acceptance.
The range provided represents the national average pay range for this position and is considered to be a general guideline. Pay for this position will reflect the candidate’s unique qualifications and may be higher or lower than the range provided based on employee geographic location. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other local, state, and federal law.

In addition to base salary, this role will be eligible for participation in TriMark’s’ benefits programs, including medical, dental, vision, 401K (with employer match), etc. Leadership positions may also qualify for participation in bonus programs commensurate with role and scope of responsibility.

TriMark’s commitment to diversity, equity, and inclusion is a purposeful mission of strengthening our organization and those we serve by uniting the unique differences of our employees. This mission is instilled in who we are as a company. We are committed to promoting diversity, equity and inclusion through sharing, education, and experiences. We are greater together through unity in diversity.

TriMark USA provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to accommodations@trimarkusa.com."
1008923151014,Glassdoor,,,https://scigon.com/,"Skills:
Extensive experience as a Data Engineer or similar role, with a focus on Scala, Java, and Python programming languages.
Proven expertise in Apache Spark, HBase, and Hive, with the ability to process and manipulate large datasets effectively.
Familiarity with AWS services (e.g., EMR, S3, Redshift) is a plus.
Experience with data migration from on-premises to cloud environments is desirable.
A bachelor's degree in Computer Science, Data Science, or a related field (a master's degree is a plus).
Strong problem-solving skills and attention to detail.
Excellent communication and teamwork abilities.
Responsibilities:
Develop Data Processing Solutions: Leverage your expertise in Scala (60%), Java, and Python to design, develop, and maintain data processing solutions that operate at scale, ensuring the efficiency, reliability, and performance of data workflows.
Big Data Mastery: Utilize your in-depth knowledge of Big Data technologies, including Apache Spark, HBase, and Hive, to process and manipulate large datasets efficiently.
Cloud Expertise: If you have experience with AWS, contribute to the migration of data processing systems from on-premises to the cloud, ensuring seamless and secure operations.
Data Migration: Collaborate on data migration initiatives, playing a pivotal role in transitioning data processing and handling systems to modern cloud-based platforms.
Data Handling: Employ best practices in data handling, ensuring the integrity, security, and accessibility of data assets while complying with relevant regulations.
Job Type: Contract
Pay: $58.00 - $68.00 per hour
Experience level:
5 years
6 years
Schedule:
Monday to Friday
Education:
Bachelor's (Preferred)
Experience:
Data warehouse: 4 years (Preferred)
Data Ingestion and ETL development: 4 years (Preferred)
Engineering in a Cloud-based infrastructure: 4 years (Preferred)
Python: 3 years (Required)
database management, modeling, and data warehouse operations: 3 years (Preferred)
AWS Cloud Services: 3 years (Preferred)
big data processing and concepts multiple datasources: 3 years (Preferred)
ETL tools like Talend Open Studio, Pentaho or similar: 3 years (Preferred)
industry: 5 years (Preferred)
Scala, Java: 3 years (Required)
Apache Spark, HBase, and Hive: 3 years (Preferred)
Data Engineering: 5 years (Preferred)
Work Location: Remote"
1008918497838,Glassdoor,$77K,$106K,http://www.hcahealthcare.com/,"Introduction
Are you looking for a work environment where diversity and inclusion thrive? Submit your application for our Associate Systems Engineer opening with HCA Healthcare today and find out what it truly means to be a part of the HCA Healthcare team.
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.
We are seeking an Associate Systems Engineer for our team to ensure that we continue to provide all patients with high quality, efficient care. Did you get into our industry for these reasons? We are an amazing team that works hard to support each other and are seeking a phenomenal addition like you who feels patient care is as meaningful as we do. We want you to apply!
Job Summary and Qualifications
**Please note this is a night time schedule 6 pm to 6 am shift; 3 days on 2 days off; broken schedule
JOB SUMMARY
Provide technical skills that cover a broad range of data center disciplines. Responsible for installation, maintenance, upgrades, and repairs of data center infrastructure.
Must have fundamental troubleshooting skills and basic knowledge of Data Center practices. Must have a rudimentary understanding of Data Center security including HIPAA and SOX.
GENERAL RESPONSIBILITIES
To perform the job successfully, the individual should be able to demonstrate the following skills and competencies:
Fundamental working knowledge of hardware platforms – HP ProLiant, Cisco UCS, Dell PowerEdge, IBM P-Series, Cisco Network/SAN switches and routers.
Fundamental working knowledge of server hardware components – Processors, Memory, Disk Drives, RAID controllers, I/O Cards, Mainboards.
Fundamental working knowledge of Firmware, RAID configurations, Integrated Lights Out, hardware logs.
Good working knowledge of copper and fiber optic infrastructure – Cat6, Twinax, Single-mode fiber, multi-mode fiber, rollover, serial. Fundamental understanding of TIA 942 standard.
Working knowledge of Operating systems - Windows OS, Unix / Linux, VMWare ESX
Working knowledge of networking topologies and network protocols including LAN/WAN technologies, TCP/IP, Switches and routers.
Limited 24x7 on call troubleshooting and repair – Must be able to meet established TTR and SLA’s.
Asset Management – Manage inventory of all assets and components in the data center. Update and report on assets to ensure compliance.
Project Management - Manages assigned projects with minimal supervision. Communicates changes and progress; Completes projects on time and within budget.
Leadership - Exhibits confidence in self and others; Inspires and motivates others to perform well; effectively influences actions and opinions of others; Provides vision and inspiration to peers and subordinates. Provides training and mentoring to junior level employees as required.
Requires minimal supervision and fill in for Hardware Engineer as needed.
Customer Service – Responds promptly to customer needs; Responds to requests for service and assistance; meets commitments.
Oral Communications – Speaks clearly and persuasively in positive or negative situations. Written communications – Writes clearly and informatively; Able to read and interpret written information and technical documents/maps. Leadership Skills - Carries out responsibilities in accordance with the organization's policies and applicable laws.
Ethics – Upholds and enforces organizational values and Data Center specific Standards.
Other duties as assigned.
TECHNICAL EXPERIENCE
Hardware: HP Proliant, Cisco UCS, Cisco Nexus, IBM P-Series, Nutanix
Operating Systems: Current Window OS, AIX / Linux, VMWare ESX
Applications/Software/Tools: Microsoft Office, Fluke, Remedy, Fieldview, Nlyte
Networking: LAN/WAN, DHCP, TCP/IP
Certifications: ITIL, Server +
SPECIAL QUALIFICATIONS
Must have good communications skills (verbal and written)
Must be able to work effectively in a high pressure and demanding environment
Must be self-motivated and highly productive with minimal supervision
Must be process driven with strong attention to detail
Must possess fundamental technical skills with proven resultsHCA Healthcare has been recognized as one of the Worldâ€™s Most Ethical CompaniesÂ® by the Ethisphere Institute more than ten times. Â In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Across HCA Healthcare’s more than 2,000 sites of care, our nurses and colleagues have a positive impact on patients, communities and healthcare.
Together, we uplift and elevate our purpose to give people a healthier tomorrow.""- Jane Englebright, PhD, RN CENP, FAAN
Senior Vice President and Chief Nursing Executive
If you find this opportunity compelling, we encourage you to apply for our Associate Systems Engineer opening. We promptly review all applications. Highly qualified candidates will be directly contacted by a member of our team. We are interviewing apply today!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
1008920231624,Glassdoor,,,,
1008923108250,Glassdoor,$71K,$110K,http://www.corevitas.com/,"POSITION SUMMARY:
The Data Engineer will be responsible for designing and developing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure that optimal data delivery architecture is consistent throughout projects. The successful candidate will be self-motivated and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
This is an important, visible, roll-up-your-sleeves position that enables our biostatisticians, pharmacovigilance experts and epidemiologists to gain insights and critical knowledge, enabling them to make better decisions faster.
PRINCIPLE DUTIES AND RESPONSIBILITIES:
Work together with the Director, Data Engineering and the software development team to realize the data architecture and data processing pipelines on AWS.
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our life sciences offerings.
Promote data best-practices across the organization and help build a “culture of data”.
MINIMUM QUALIFICATIONS:
Skills/Knowledge:
Must have Strong SQL Server Database development, maintenance experience.
Must have working knowledge SSRS reporting.
Must have proficiency with SQL Server functions and stored procedures.
Must be able to debug, profile, tune SQL queries, functions and stored procedures.
NoSQL Database experience is a big plus.
Proficiency in at least one high-level programming language, e.g., Python or Java.
Demonstrated experience developing data pipelines/ETL/ELT processes.
Excellent communication and organizational skills.
Also, Cloud platform experience that include:
AWS data storage and retrieval experience highly preferred
AWS data services, e.g., AWS Glue
AWS data processing and analytics services
Big Plus:
Familiarity working with sensitive data and with CFR Part 11, HIPAA, GDPR compliance.
Working knowledge of clinical and pharma data
Working knowledge of Clinical Data Standards such as CDISC
Experience:
5+ yeas overall experience, at least 3 in data management and/or data-centric software development. Life sciences background preferred.
Experience in writing production-level SQL and working with various databases and reporting systems.
Education/training:
BS/MS degree in Computer Science, Computer Engineering, or other technical discipline.
SPECIAL REQUIREMENTS:
Fully Remote, though some Travel may be required for this role
This description is not intended to be a complete statement of the job, but rather to act as a guide
About CorEvitas
CorEvitas, now part of Thermo Fisher Scientific, is a science-led, real-world data intelligence company. Using syndicated registry data and analytic services to understand the post-approval comparative effectiveness and safety of approved therapies, CorEvitas provides biopharmaceutical companies with objective data and clinical insights to demonstrate the value of their products to clinicians, patients, payers, and regulators. The company operates nine major autoimmune and inflammatory registries across the U.S., Canada, and Japan, collecting data from over 400 participating investigator sites, including collection of biosamples linked to the deep clinical data. CorEvitas recently expanded its services to include Pregnancy Registries, through the acquisition of Pregistry. CorEvitas also conducts client-sponsored registries through its Patient Powered Registries business, employing a transformative patient-focused registry model to support research needs for patient-centered outcomes across all therapeutic areas. The company’s regulatory-grade registry data is complemented by its Patient Experience business, supporting evidence-based patient engagement initiatives across the product lifecycle, as well as its Specialty EMR Data business and retinal data set. CorEvitas is headquartered in Waltham, MA and is a portfolio company of Audax Private Equity. www.corevitas.com
CorEvitas is proud to provide equal employment opportunities to all qualified individuals without regard to race, color, religion, sex, gender identity, sexual orientation, pregnancy, age, national origin, physical or mental disability, military or veteran status, genetic information, or any other protected classification. Minorities, women, LGBTQ candidates, Veterans, and individuals with disabilities are encouraged to apply.
CorEvitas participate with E-Verify"
1008923497591,Glassdoor,$115K,$157K,http://www.salesforce.com/,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
The Data and Analytics Organization (DnA) is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights. As a steadfast partner, we shape a data ecosystem that fuels innovation. Our commitment to integrity and accessibility propels informed decision-making, propelling Salesforce to new heights of excellence.

Interesting Articles about some of our work and our culture:
https://www.salesforce.com/blog/what-does-salesforce-do/
https://www.salesforce.com/company/equality/
https://www.salesforce.com/resources/data

Team Overview

Data Strategy and Management Engineering team brings Data to life, partnering with data producers and platform engineers to empower data consumers (data scientists, data analysts and visualization engineers) who consume data for business analytics and AI augmented solutions. We do this by delivering trusted data, in an agile way and make it accessible for a variety of use cases. We pride ourselves in being data curious (one who has an intrinsic need to understand a data point). We architect, automate, and scale our data curation frameworks, services, and processes to rapidly integrate disconnected and disparate raw data into a business-relevant asset and work towards one common theme - Customer Success.

Role Description:
Design, build, and maintain scalable and efficient data pipelines and ETL processes to support data-driven decision-making.
Implement data validation and monitoring processes to ensure data quality and integrity throughout the data lifecycle.
Have opinionated views on how data will be collected, stored, consumed & managed.
Ensure compliance with governing standards, data quality & protection principles.
Optimize data storage and retrieval mechanisms to enhance performance and cost-effectiveness, making data readily accessible for analytics.
Participate in code reviews and contribute to the development of coding standards and best practices to ensure high-quality data engineering solutions.

If You Are,
Experienced Data Engineer: Demonstrated experience in data engineering roles with a strong foundation in data pipeline development.
Experienced Professional:
Proficient in big data technologies like Hadoop, Spark, Presto, Hive, Snowflake etc...
Strong coding skills in Python/Java/Scala or equivalent
Understanding of scalability and reliability concerns for data-intensive applications
Data Engineering Enthusiast: Passion for data engineering and a desire to grow in this field.
Collaborative & Communicative: Effective communication skills and the ability to work well within a team.
Data Advocate: Strong commitment to data quality, security, and compliance.
Preferred: Familiarity with cloud-based data platforms (e.g., AWS, GCP, Azure).

Minimum Requirements (Senior Data Engineer):
Bachelor’s or Master's degree in Computer Science, Information Technology, or related field.
6+ years of experience in data engineering and related roles.
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce .
Salesforce welcomes all."
1008920913530,Glassdoor,,,http://jobs.cvshealth.com/,"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
Join our fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability and performance of CVS Health’s IT operations. As a data engineer, you will be responsible for developing and maintaining the data pipelines, databases and systems required for efficient data processing, storage and retrieval. You will collaborate with data scientists, developers and other stakeholders to ensure in an agile team environment.
Key Responsibilities include:
Data pipeline development: Design, implemented and manage data pipelines for extracting, transforming and loading data from various sources into data lakes for processing, analytics, and correlation.
Data modeling: Create and maintain data models ensuring data quality, scalability and efficiency
Develop and automate processes to clean, transform and prepare data for analytics, ensuring data accuracy and consistency
Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data
Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently
Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation
Create/maintain documentation for data processes, data flows and system configurations
Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness
Characteristics of this role:
Team Player: Willing to teach, share knowledge, and work with others to make the team successful.
Communication: Exceptional verbal, written, organizational, presentation, and communication skills.
Creativity: Ability to take written and verbal requirements and come up with other innovative ideas.
Attention to detail: Systematically and accurately research future solutions and current problems.
Strong work ethic: The innate drive to do work extremely well.
Passion: A drive to deliver better products and services than expected to customers.

Required Qualifications
2+ years of programming experience in languages such as Python, Java, SQL
2+ years of experience with ETL tools and database management (relational, non-relational)
2+ years of experience in data modeling techniques and tools to design efficient scalable data structures
Skills in data quality assessment, data cleansing and data validation

Preferred Qualifications
Knowledge of big data technologies and cloud platforms
Experience with technologies like PySpark, Databricks, Azure Synapse.

Education
Bachelor’s degree in Computer Science, Information Technology or related filed, or equivalent working experience
Pay Range
The typical pay range for this role is:
$94,500.00 - $196,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution."
1008923451275,Glassdoor,,,http://www.ocvibe.com/,"A great experience starts with you!
Join our team to help create and develop the future of live entertainment and sports in Orange County!
Once you've had a chance to explore our current open positions, apply to the ones you feel best suit you, as an applicant, you can always see your application status in your profile.
Job Title:
Data Engineer
Pay Details:
The annual base salary range for this position in California is $109,550 to $133,895 per year. The starting pay for the successful candidate depends on various job-related factors, including but not limited to the candidate’s geographic location, job-related knowledge, skills, experience, education/training, internal value, peer equity, external market demands, and organizational considerations.
Company:
ocV!BE Sports & Entertainment, LLC
Location(s):
ACC
ocV!BE, a premier mixed-use community and live entertainment district, is coming to Anaheim in 2026! This $4+ billion, 100-acre, mixed-use community will surround its anchor, Honda Center, with new live entertainment venues, dining and retail offerings, and public amenities. From intimate clubs to a new 6K-capacity concert venue, ocV!BE will provide a full range of entertainment, activating the District daily for the enjoyment of its guests.
ocV!BE’s District Insights Group (DIG) is a holistic data practice that initiates and conducts activities across existing business units (primarily the Anaheim Ducks and Honda Center). Overtime, the DIG’s scope will expand to encompass all phases of the ocV!BE district, building upon learnings, platforms, standards, and practices developed between now, the ocV!BE’ District Phase 1 opening and beyond. The DIG represents hybrid expertise between both Business Intelligence (BI) and Consumer Intelligence (CI) practices. DIG’s team will evolve to represent fully dedicated resources for both BI and CI while remaining organized within the single, holistic Insights practice inclusive of data enrichment and predictive analytics enabled by Machine Learning and Generative AI.
The Data Engineer will be responsible for designing and delivering data platform solutions to support all aspects of data analytics practice and software engineering projects. Responsible for participating in the core data engineering work associated with the design and implementation of Data Strategy, Information Architecture and Governance projects to ensure the security, integrity, and availability of information with appropriate technical documentation and QA activities. Conduct data modeling and associated research, development, deployment, monitoring, and ongoing maintenance to ensure efficient, stable, scalable, and highly secure cloud data infrastructures for the enablement of data-driven business decision making. Manage the data engineering requirements associated with third party technology integrations. Lead the implementation of all data engineering projects, designing and communicating/translating business requirements into data engineering solutions across departments and operating entities. Responsible for implementing data transformation pipelines and data ingestion points to collect data from external data sources according to specifications provided by technical and business leadership. Serve as the organization’s primary Database Administrator (DBA), providing associated support and oversight of the organization’s Database Administration priorities.
Responsibilities
Design and implement data engineering facets of Data Strategy, Information Architecture and Governance projects to ensure the security, integrity, and availability of information with appropriate technical documentation and QA activities in accordance with organizational systems, standards, specifications, and requirements
Lead the implementation of data engineering projects
Design and communicate data engineering solutions based on business requirements
Implement data transformation pipelines and data ingestion points to collect data from external data sources
Motivate and communicate data engineering considerations across multiple levels of the department, including non-technical, non-data savvy audience (ability to translate data engineering technical communication into highly relatable, non-technical terms)
Develop strategies, refine/evolve existing, and develop new, initiatives with your team to advance on an organizational and technical levels across the core focus areas of the DIG and the operations it supports
Provide a consistent/successful interface between Engineering Development and Product Management
Develop leadership skills within the organization and mentor other leaders
Development, measurement, and management of key metrics for group's performance
Drive high throughput and all connected key metrics on a strategic level
Standardize the development process where needed, allow local differences where advantageous
Perform other duties and projects as assigned

Requirements
Proven track record of designing and delivering data management solutions in complex cloud environments
Experience in setting up and maintaining/evolving data platforms in cloud environments such as AWS, Azure, GCP (Azure being a requirement)
Experience with Snowflake
Foundational understanding of Data & Analytics Architectures, definition of KPIs/metrics and insight requirements
Proficient in Python and system-level languages like Go, Rust, Java
Strong technical knowledge of distributed data processing frameworks such as Spark, Flink, Arrow and similar (PySpark being a requirement)
Knowledge of workflow tools such as Airflow, Kubeflow, Jira and similar
Proficient in SQL and Document DBs, and performance tuning of queries: ensuring solutions are both scalable and maintainable
Skills
Minimum of 5 years of experience as a Data Engineer and Database Administrator
Graduate degree in Computer Science, Mathematics, Engineering, or other STEM
Experience with enterprise-scale, multi-application (platform) systems
Experience with data and software engineering direction within the ML/AI space
Experience synthesizing data and creativity to deliver transformation business results
Excellent written and verbal communication skills
Understanding of, and interest in expanding expertise around, Large Language Models (MML)/ Generative AI and its emerging role in data, analytics, prediction and the future of broader insights platforms and practices
Able to understand business requirements and translate them into data engineering and related analytics projects that deliver solutions to business challenges and/or support capitalizing on business opportunities
Knowledge, Skills, and Experience
Education - Bachelors Degree
Certifications Required – NA
Experience Required – 5+ Years
JM2023
Our Commitment:
We are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, parental status, military service, medical condition or any protected category prohibited by local, state or federal laws. We are firm believers that diversity and inclusion among our team members are critical to our success, and we seek to recruit, develop, and retain the most talented people from a diverse candidate pool.
Thanks for your interest in becoming part of the team."
1008921169000,Glassdoor,$83K,$115K,https://mybluepeak.com/,"“We Push the Boundaries of Possibilities for our Communities.”
Overview of the Position Responsibilities: The Data Engineer II will manage our master data set, developing reports, and troubleshooting data issues as part of our Market Expansion team. To do well in this role you need a very fine eye for detail, experience as a data analyst, and a deep understanding of the popular data analysis tools and databases. If this sounds exciting, please read on.
Be part of our innovation- building and delivering a fiber-rich internet connection to people’s doorsteps.
What You Will Do:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Snowflake and AWS ‘big data’ technologies
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Work with data and analytics experts to strive for greater functionality in our data systems
Manage and design the reporting environment, including data sources, security, and metadata
Support the data warehouse in identifying and revising reporting requirements
Support initiatives for data integrity and normalization
Generate reports from single or multiple systems
Troubleshoot the reporting database environment and reports
Train end-users on new reports and dashboards
Provide technical expertise in data storage structures, data mining, and data cleansing
Create and maintain documentation including requirements, design, and user manuals
Identify opportunities to improve processes and strategies with technology solutions
Other related duties as assigned.
What You Will Need:
A bachelor’s degree in business or related field required
3 - 5 years in an analytical position required
Upon job offer, must be able to pass a background check and a drug test prior to employment
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management
A successful history of manipulating, processing, and extracting value from large, disconnected datasets
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores
Experience supporting and working with cross-functional teams in a dynamic environment
Ability to read code and support applications, reports, and processes.
A collaborative working style and strong attention to detail
Effective time management with the ability to work independently, manage multiple tasks, set priorities, and meet deadline
Consistent exercise of independent judgment and discretion in matters of significance
Strong analytical, written, verbal and presentation skills, including the ability to articulate ideas and suggestions clearly and effectively
MS Office Suite: Outlook, PowerPoint, Word, Excel, OneNote
Familiarity with data collection software and protocols
Knowledge in Technology such as Snowflake, Matillion, and ThoughtSpot are preferred
Prolonged periods of sitting at a desk and working on a computer
Regularly required to talk and hear
Frequently required to sit, stand, bend, reach, push, pull and walk
Required to use hands, handle objects and paperwork
Required to use close vision and be able to focus
Required to refrain from personal use of technology during working hours
Required to lift up to 5lbs at a given time
Why Work at Bluepeak?
Competitive Compensation + Annual Bonus Eligibility
Comprehensive Benefits Package, Including Medical, Dental, Vision, Life, and 401(k)
Generous Vacation and Paid Sick Time + Paid Holidays and Personal Days
Professional Development With an Emphasis on Internal Promotion
Employee Discounts on Bluepeak Services, Including Internet
Progressive and inclusive work culture in which our team has the flexibility, support, and resources to be successful in their careers!
About Us
We believe that the size of the city shouldn’t determine the quality of the technology. That’s why we are building for you: Faster, more reliable, and without the things that get in the way of great service—like red tape, hidden fees, and slow response times. And with up to 5 gigabits of speed for residential customers and 10 gigabits for businesses, we are whole new ballgame- from internet to TV, to connecting every device in your home, to powering your business, we’re not only providing the best fiber connections in your community, but we’re also meeting the growing needs for how you live.
Bluepeak provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
1008923420128,Glassdoor,$75K,$114K,http://www.parklandhealth.org/,"Interested in a career with both meaning and growth? Whether your abilities are in direct patient care or one of the many other areas of healthcare administration and support, everyone at Parkland works together to fulfill our mission: the health and well-being of individuals and communities entrusted to our care. By joining Parkland, you become part of a diverse healthcare legacy that’s served our community for more than 125 years. Put your skills to work with us, seek opportunities to learn and join a talented team where patient care is more than a job. It’s our passion.

Primary Purpose
The Parkland Community Health Plan’s (PCHP’s) Data Engineer is responsible for maintaining the data systems including business intelligence, ETL, and supporting backup strategies in order to provide PCHP with secure, dependable, and accurate data including data transfer, data integrity, and data storage responsibilities. The Data Engineer will collaborate with Database Administrators, server team, storage team, and other teams to plan maintenance activities and with PHCP’s analytics team for report or universe deployments. The Data Engineer will also be involved in dashboard and report development activities.

Minimum Specifications

Education
Bachelor’s degree in computer science, management information systems, information technology, statistics, mathematics, or related discipline.

Experience
Seven years of experience in maintaining business intelligence, data warehouse solutions, or ETL in a Run or Production environment.
Six years of experience troubleshooting ETL load related issues (SSIS or Data Solutions).
Six years of experience with ETL development and maintenance experience in a data warehouse environment.
Experience with systems engineering (hardware / software) capacity.
Experience with database or report portal tool administration is preferred.
Experience at a healthcare or managed care organization is preferred.

Equivalent Education and/or Experience
Five (5) years of experience with healthcare data management in a health plan or managed care organization may be considered in lieu of a degree.

Certification/Registration/Licensure
System Administration or Reporting Tool Administrative Certification is preferred. (i.e. Epic Cogito or Clarity, SAP Business Objects, Tibco Composite, Microsoft Certified Solutions Engineer (MCSE), Oracle Certified Professional (OCP), etc.)
PMP or other project management certificate or training is preferred.

Skills or Special Abilities
Proficiency with ETL tool Build or Run activities.
Ability to create reports and/or build virtual data environments.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Proficiency with Microsoft Office Excel, Word and Outlook is required; Access and PowerPoint are preferred.
Demonstrated critical thinking and troubleshooting skills accompanied by a high level of detail.
Demonstrated ability to plan and manage multiple processes and projects simultaneously.
High level of attention to detail.
Strong verbal and written communication skills.
Demonstrated ability to collaborate effectively and work as part of a team.
Independent worker and self-starter, having the ability to provide internal motivation and drive.
Proficiency with server or application patching, backups, scripting is preferred.
Understanding of SSIS and Apache NiFi is preferred.
Proficiency with Business Objects Administration is preferred.

Responsibilities
Implements and maintains high-value business intelligence environments.
Maintains the data systems including business intelligence, ETL, and supporting backup strategies.
Has a strong understanding of all the tools within the environment, regardless of vendor, and quickly and efficiently triages, troubleshoots, and restores services during outages or service degradation.
Responsible for being on-call for Business Intelligence and ETL cycles.
Works with the Database Analyst and storage teams to ensure proper backups are taken, test back-ups periodically, and ensures that the system can be restored in the time of a disaster.
Proactively identifies areas for improvement in our Business Intelligence environment.
Documents all routine processes and cross-trains other team members.
Improves function, speed, and accuracy of data distribution methods.
Develops automated reports and dashboards.

Job Accountabilities
Identifies ways to improve work processes and improve customer satisfaction. Makes recommendations to supervisor, implements, and monitors results as appropriate in support of the overall goals of PCHP.
Stays abreast of the latest developments, advancements, and trends in the field by attending seminars/workshops, reading professional journals, actively participating in professional organizations, and/or maintaining certification or licensure. Integrates knowledge gained into current work practices.
Maintains knowledge of applicable rules, regulations, policies, laws, and guidelines that impact the area. Develops effective internal controls designed to promote adherence with applicable laws, accreditation agency requirements, and customer requirements. Seeks advice and guidance as needed to ensure proper understanding.

Parkland Health and Hospital System prohibits discrimination based on age (40 or over), race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, genetic information, disability, national origin, marital status, political belief, or veteran status. As part of our commitment to our patients and employees’ wellness, Parkland Health is a tobacco and smoke-free campus."
1008922341599,Glassdoor,,,http://www.enigmalaw.co.uk/,"The Opportunity:
Join Enigma at a pivotal moment as we continue to provide valuable solutions for small businesses. We're seeking an experienced Data Product Engineer to join our team and help develop and build the iteration of small business data products . Your work will directly impact the accuracy of small business profiles, which influence decisions for companies that employ half the U.S. workforce!
The Role:
As a Data Product Engineer, you will design and develop data products that solve critical customer pain points. Your impact will be measured by your ability to deliver scalable, high-quality data products that customers love. To succeed in this role, you will bring together three distinct capabilities
Understand acute customer needs and extract common problem structures across customers
Analyze and extract value from data at scale
Build efficient, maintainable production-grade data pipelines
We are looking for someone who:
Operates with a bias for action and knows how to deliver value in the short, medium and long term
Loves talking to customers and works hard to solve their problems in a repeatable way
Adopts a principled, metrics-driven approach to difficult data problems and demonstrates excellence in their analytics and engineering craft
Operates transparently, collaboratively and with low ego—loves learning from others and having their ideas questioned and challenged
What Makes This Job Exciting:
Impact: Develop products that take an innovative data-first approach to solving high-value customer problems.
Technical Challenge: Tackle complex data and engineering problems while balancing customer impact, reliability, scalability, data quality, and an ambitious forward development plan.
Ownership: You'll work directly with customers. You and your teammates will design and build products based on your learnings .
Bonus Points If You:
Have experience building data products at scale.
Bring prior experience in Databricks or Spark
Have worked on data products in the marketing, kyb or credit underwriting space.
About Us:
At Enigma, we're building the single, most reliable source of data on businesses to power the future of financial services. By engineering better data from hundreds of public and third-party sources, we aim to tell the complete story of every business, so that companies of every size can access the financial services they need to grow and thrive. Our core values – generosity, curiosity, ingenuity, & drive – guide everything we do, from how we make our most important product decisions to how we work with and support one another on a daily basis. We're a team of curious, driven individuals with diverse backgrounds and skills, but we're all passionate about engineering deeper understanding through data—together. If this resonates, we would love to hear from you!
We are proud to be an equal opportunity workplace and an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.
Salary Range: $160,000-$210,000
A note on salary ranges: we pride ourselves on paying competitively for our size and industry. Salary is one piece of a total Enigma compensation package that includes additional benefits and opportunities. All of our compensation packages include equity because we believe 100% of Enigma employees should have the option to purchase ownership in the company and benefit from the value we're creating together"
1008921506969,Glassdoor,$121K,$155K,https://mstr.cd/407uWQT,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Software Engineer / Data Engineer - IDS1090
Ekata, a Mastercard company, is the global standard in identity verification, providing businesses worldwide the ability to link any digital transaction to the human behind it. Our Ekata Identity Engine, the first and only of its kind, uses complex machine learning to combine features derived from the billions of transactions within our proprietary network and the data from our graph to deliver industry leading risk assessment solutions.

We are looking for a Software Engineer who thrives on designing, coding, and maintaining large data processing systems, primarily in the Spark framework using Scala. Our ideal candidate will understand the challenges of working with data at scale and have a firm knowledge of algorithms and processing complexity.

Our team is a mix of software engineers and data analysts working to ensure our inputs, algorithms, and publishing artifacts are of the highest quality and efficiency. Our output is critical to the accuracy of our Risk Analysis APIs which power top e-commerce sites. Constant improvement and innovation is part of our process. Your ability to learn and grow will be recognized and rewarded.

As a Senior Software Engineer for the Graph and Tools Team, you will:
Develop big data processing systems using Scala, Apache Spark, Airflow and related technologies.
Increase the capabilities and efficiency of our data processing pipeline. Investigate problems when they occur and develop solutions.
Insist on highest coding standards, follow and create best practices for clean code, tests, and architecture.
Plan and document our development by delivering well-written engineering designs for review by the Product, Privacy, and Security teams.
Manage a sense of urgency and risks on project timelines and propose creative strategies for delivering constant business value.

Our ideal Software Engineer will have:
Bachelor's degree in Computer Science or equivalent experience
Strong data structures, algorithm design, and problem-solving skills
Aptitude to learn new languages and technologies as necessary
Ability to write well-organized, readable, and testable code that follows best practices
Experience with Scala, Java, or other strongly typed languages
Experience with functional programming
Good verbal and written communication skills
Experience using web service APIs
Familiarity with AWS services including EC2, S3, DynamoDB, and EMR

#IdentitiySolutions
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Pay Ranges
Seattle, Washington: $129,000 - $199,000 USD"
1008922758140,Glassdoor,,,http://www.positivepsyche.biz/,"Direct Hire
Flexible hybrid schedule
Annual bonus
Overview:
The Data Operations Engineer will create automated tests to ensure data meets quality standards and routinely work with our Product Development Team, handling requests and configuring connections to our predictive platform. The ideal Data Operations Engineer has a healthy drive to collaborate, gather feedback, and tackle challenges through testing and learning.
Duties:
Manage the end-to-end setup of our customers' data: from raw data sources to data ingestion pipelines and connections to our predictive platform
Analyze and validate customer data from ingestion to production
Monitor all data update processes and outputs to ensure quality and uptime
Collaborate with other members of the Data Analytics Program and with the Product Development Team to discuss new use cases or help identify and fix data issues
Develop and maintain proprietary technical documentation
Solve day-to-day customer data challenges
Strong proficiency in SQL for data analysis and manipulation
Experience with database design principles and query optimization techniques
Proficiency with Python for data processing tasks
Job Type: Full-time
Pay: $90,000.00 - $97,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Vision insurance
Compensation package:
Bonus opportunities
Experience level:
1 year
2 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Baltimore, MD 21211: Reliably commute or planning to relocate before starting work (Required)
Experience:
SQL: 1 year (Required)
Python: 1 year (Required)
Snowflake: 1 year (Preferred)
Sigma: 1 year (Preferred)
ETL: 1 year (Required)
Work Location: Hybrid remote in Baltimore, MD 21211"
1008920635431,Glassdoor,,,,"Tygart is currently seeking a Data/Software Engineer to support the data integration via applications or adaptors using XML data exchange specifications. The candidate will be part of a team, collaborating closely with the government staff and external criminal justice agencies, to enable data sharing and management, and establish connectivity with a national data repository. The ideal candidate will have practical experience in the areas of information sharing, Extensible Markup Language (XML), relational data bases, N-DEx IEPDs, Global Justice XML Data Model (GJXDM) and the (National Information Exchange Model) NEIM.
Responsibilities include:
Provide engineering support to facilitate inter-agency information sharing
Produce data integration applications or adaptors from various sources to the N-DEx XML data exchange specifications
Mapping data to Information Exchange Package Documentation (IEPD) standards, developing transformation code, validating and verifying data processes, and troubleshooting and making recommendations both to internal and external stakeholders
Process all new agency data and adapters and maintain existing agency data and adapters
Qualifications
The ideal candidate will have the following:
Active Secret security clearance
Bachelor's degree in Engineering, Information Technology, Computer Science, or related field.
Three (3) to five (5) years’ experience in software development, and management and support of information technology systems.
Two of more years’ experience in XML, relational data bases, and web services is desired.
Three (3) years’ Java development experience
Proficiency with Oracle databases and procedural Language/Structured Query Language (PL/SQL), Microsoft SQL server databases, subversion in XML and XML Schema Definition (XSD).
Proficiency in XML Stylesheet Language Transformations (XSLT) generation.
Experience in managing and troubleshooting secure file transfer protocols (SFTP) and web services for data submissions and user access.
Experience suing Python is a plus
Minimum three (3) years’ experience in the analysis and assessment of large data sets; managing and coordinating major parallel IT initiatives; and extracting data for analysis and consumption via appropriate form such as diagrams, reports, or tables.
Experience with the Logical Entity Exchange Specification (LEXS) Publication and Discovery (PD) and LEXS Search and Retrieve (SR), N-DEx IEPDs, GJXDM and NEIM is highly desire.
Must be able to well under pressure, and possess excellent oral and written communication skills, as well as excellent organizational skills.
Job Type: Full-time
Schedule:
8 hour shift
Security clearance:
Secret (Required)
Work Location: Remote"
1008923659764,Glassdoor,,,http://www.carlsmed.com/,"About Carlsmed
Our mission is to improve outcomes and decrease the cost of healthcare for spine surgery and beyond. The Carlsmed aprevo® personalized surgery platform is designed to improve the standard of care for spine surgery one patient at a time.

Position Description
As the Clinical Research Data Engineer, you will work on projects related to proprietary implants, instrumentation, and design automation systems to enable personalized surgery. The Clinical Research Data Engineer has a crucial role on the Medical Affairs team. This individual is responsible for the analysis and datafication of medical imaging to develop advanced algorithms that can inform continuous innovation in surgical planning software. This role also supports the Clinical Affairs, Engineering, Digital/Surgical and RA/QA teams with emphasis on the collection and analysis of imaging data from multiple sources.

This opportunity is not remote and requires an on-site presence. Please note that this position does not offer relocation assistance.

Responsibilities
Maintain radiographic alignment database, review data entries, issue queries and clean data as needed.
Develop and deploy monitoring/assessment techniques to ensure robustness and quality of raw and aggregated data.
Engage external experts for independent data assessments (e.g., core laboratory).
Evaluate and explore data from diverse sources to test hypotheses that correlate perioperative observations to radiographic outcomes.
Develop predictive models which will serve as a guiding light for improvement in surgical planning.
Utilize data mining and predictive analytics to advance personalized outcome predictions for individual patients.
Collaborate cross-functionally with Clinical Affairs, Engineering, Digital/Surgical and RA/QA to ensure alignment of project deliverables to address business needs.
Apply clinical data intelligence to develop, track, analyze and report on data management and performance metrics.
Support content development for conference abstracts, manuscripts, training, and marketing materials.

Qualifications
BS degree in a technical field, including Engineering, Life Sciences, Computer Sciences, Mathematics or related medical/scientific field; MS or graduate degree preferred.
Knowledge of medical imaging systems and medical image analysis highly desirable.
Experience with:
integrating and analyzing diverse data
study designs, data management, and analysis techniques
spine or orthopedics (highly desired)
machine learning and AI (highly desired)
Skills
Excellent verbal and written communication
Proficiency in Excel, Power BI, SQL, and Python, or equivalent statistical analysis tools.
Willingness to wear multiple hats when needed.

Equal Opportunity Employer
Carlsmed is an equal-opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. Carlsmed is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know.

Compensation
We are pleased to provide a competitive salary and benefits. Our benefits reflect our investment in the overall health and well-being of our employees and their families. including paying 100% of monthly healthcare, dental & vision insurance premiums, a 401(k) plan with employer matching and unlimited PTO. The expected pay range is: $105,000-130,000 annually. Compensation may vary based on related skills, experience, and relevant key attributes."
1008922825353,Glassdoor,,,,"Lovelytics is seeking a skilled consultant with experience delivering and leading strategic Databricks and data engineering client engagements.
This Senior Manager will oversee the success of a portfolio of projects and will play the role of an Engagement Manager on all team members’ projects. You’ll define project scopes, create project plans, and manage project kick-offs. The senior manager will also manage the performance, career growth, and resources for a team of 3-6 other consultants.
In addition to the leadership capabilities for this role, we are looking for someone who has experience solving complex client problems and providing solutions related to data warehousing, ETL development, data integrations, and data modeling (databricks and the 3 clouds).
Role Location: Open to remote candidates in the US (MD, DC, CA, IA, ID, IN, MA, NC, SC, TX, TN, GA, CO, NY, NJ, VA, FL, PA)
Primary Job Responsibilities:
Gather and understand requirements from clients to develop a creative and effective technical solution, including at times leading the technical aspect of sales/presales conversations.
Foster a collaborative work environment on your team, providing direct guidance, assignments, and overall performance and professional development for direct reports.
Ensure accurate project allocations, forecasting, and ensuring other administrative tasks are completed across the team.
Establish data governance frameworks, ensuring compliance across all engagements.
Continue to expand knowledge, and stay up to date on the newest technology, trends, and best practices.
Apply your skills with Databricks, using Python, and big data streaming to pioneer client technologies and data
Manage projects to ensure project milestones are reached within the given timeline and budget allocated
Support other team members on projects, which can oftentimes mean wearing many different hats
Integrate Databricks with 3rd-party applications to support customers' architectures
Troubleshoot complex data issues on the fly with prospects and clients
Our Ideal Candidate's Skills and Experiences:
B.S. in Computer Science or equivalent, MS preferred.
6+ years in data engineering working with cloud-based data analytics architectures and 3+ years of experience working directly with clients.
At least 1 year directly managing a team, providing feedback and career development.
Experience leading successful migration of complex data architecture from on-premises to cloud environments.
Extensive knowledge of data warehousing and data lake concepts and hands-on experience deploying pipelines using Databricks
Experience developing Machine Learning models or ML Ops processes a plus
Excellent communication skills are a MUST, all our employees are client-facing, and this role requires both written and verbal client management skills.
Experience designing architectures within a public cloud (AWS or Azure)
Hands-on experience with Big Data technologies, including Spark, Hadoop, Cassandra, and others
Ability to extract and transform data via Python, deep exposure and understanding of data warehousing, ETL pipelines, etc.
Overall understanding of analytics from analytic engineering to visualization tools
Databricks Data Engineer Professional and Databricks Machine Learning Professional certifications a plus
What We Promise You:
Exciting projects with great clients in varying departments and verticals across the world
The ability to work closely with experienced data engineers and quickly grow and expand your skillset
The ability to work closely with all sizes of companies, ranging from Fortune 100 to small local businesses
A workplace where you are encouraged to challenge the status quo and develop new technologies, methodologies, and processes
A diverse team consisting of data gurus, experience seekers, and entrepreneurial minds that are always pushing to be better

Lovelytics is an Equal Opportunity Employer. This means you don’t have to worry about whether your application process will be fair. We consider all applicants without regard to race, color, religion, age, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, veteran status, or disability. The salary for this position for candidates in the United States is $138,000-$185,000, however, salary determination is based on a number of different factors including but not limited to years of related experience, skills, and education.
ihaWo3AR3o"
1008919991423,Glassdoor,,,http://www.disney.com/,"We are seeking a Data Engineer who will partner with business, analytics and infrastructure teams to design and build datasets to facilitate measuring subscriber related metrics. Collaborating across disciplines, you will identify internal/external data sources to design table structure, define ETL strategy & automated Data Quality checks.

Responsibilities :
Partner with technical and non-technical colleagues to understand data and reporting requirements.
Work with engineering teams to collect required data from internal and external systems.
Design table structures and define ETL strategy to build performant Data solutions that are reliable and scalable in a fast growing data ecosystem.
Develop Data Quality checks and visualizations/dashboards
Develop and maintain ETL routines using ETL and orchestration tools such as Airflow.
Implement database deployments using tools like Liquibase
Perform ad hoc analysis as necessary.
Perform SQL and ETL tuning as necessary.
Develop and maintain Dashboards/reports using Looker
Basic Qualifications :
Bachelor’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience.
3+ years of relevant Professional experience.
3+ years of work experience implementing and reporting on business key performance indicators in data warehousing environments. Strong understanding of data modeling principles including Dimensional modeling, data normalization principles etc.
3+ years of experience using analytic SQL, working with traditional relational databases and/or distributed systems such as Snowflake or Redshift.
3+ Years of experience programming languages (e.g. Python, Pyspark) preferred.
3+ years of experience with workflow management tools (Airflow, Nifi)
Good understanding of SQL Engines and able to conduct advanced performance tuning
Familiarity with data exploration / data visualization tools like Tableau, Looker, Chartio, etc.
Ability to think strategically, analyze and interpret market and consumer information.
Strong communication skills – written and verbal presentations.
Excellent conceptual and analytical reasoning competencies.
Comfortable working in a fast-paced and highly collaborative environment.
Familiarity with Agile Scrum principles and ceremonies

The hiring range for this position in Santa Monica, CA is $102,500.00 to $137,500.00 per year and in Seattle, WA is $107,338.00 to $143,990.00 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered."
1008923161868,Glassdoor,,,http://www.travelers.com/,"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Data Analytics, Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$102,600.00 - $169,200.00
Target Openings
1
What Is the Opportunity?
Corporate Technology is seeking a Qlik Data Engineer to join our team to support Corporate Audit, Enterprise Risk and Cybersecurity customers. Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

Work arrangement is hybrid in a Travelers office.
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Knowledge in QlikView and Qlik Sense:
Development experience leveraging best practices and automation
Experience with platform administration (e.g. task reload management)
Understanding of DevSecOps
Understanding of data modeling and data transformation
Familiarity with pipeline automation (python), embedded analytics, self-service capabilities and Snowflake is a plus
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
."
1008922940352,Glassdoor,,,https://vuoriclothing.com/,"Company Description

Vuori is re-defining what athletic apparel looks like: built to move and sweat in but designed with a casual aesthetic to transition into everyday life. We draw inspiration from an active coastal California lifestyle; an integration of fitness, creative expression and life. Our high energy fast paced retail environment is reflected in the clothes we make. We aim to inspire others to take on all aspects of their lives with clarity, enthusiasm and purpose…while having a lot of fun along the way. We are proud to be an outlet for opportunity and for personal growth and success.

Job Description

Responsibilities include but are not limited to:
Data Pipeline Development:
Design, develop, and maintain scalable and efficient data pipelines.
Extract, transform, and load (ETL) data from various sources into our data warehouse.
Enable data quality and integrity throughout the ETL process.
Data Architecture:
Collaborate with cross functional tech leads and architects to design and optimize data models and database structures.
Implement best practices for end to end data pipe management on data lake.
Work on data warehousing solutions, such as Azure ADF, Snowflake etc.
Data Integration:
Integrate third-party data sources and APIs to enrich our datasets.
Enable processes for monitoring, exception management across end to end data pipe build to ensure integrity and reliability of data engineering solutions
Implement data connectors and data ingestion processes
Work on designing and defining new ways of data integrations while managing existing data integrations
Performance Optimization:
Monitor and optimize data pipelines and query performance.
Troubleshoot and resolve data-related issues in a timely manner.
Data Security and Compliance:
Ensure data security and compliance with relevant data protection regulations (e.g., GDPR, HIPAA).
Implement access controls and encryption mechanisms.
Collaboration:
Collaborate with analytics, product leads and business product owners to define and build best in class data ecosystem driving business analytic capabilities
Be part of agile operating model alongside analytics and business teams to drive collective data & analytics capabilities
Work alongside planning, master data and other teams looking for clean, connected data and provision datasets as API’s or onetime per need
Support data consumers by providing access to clean and well-organized datasets.
Documentation:
Maintain documentation for data pipelines, schemas, and data dictionaries.
Document end to end data pipes and ongoing enhancements to them
Create and update documentation on data engineering processes and standards.

Qualifications
Bachelor's degree in Computer Science, Information Technology, or a related field. Master's degree preferred.
5 years of experience as a Data Engineer or similar role.
Proficiency in data modeling, ETL development, and data warehousing.
Strong programming skills in languages like Python, Java, or Scala.
Experience with data pipeline orchestration tools
Knowledge of SQL and proficiency in working with relational and NoSQL databases.
Familiarity with cloud platforms (e.g., Azure, Snowflake) and associated data services.
Excellent problem-solving and communication skills.
Ability to work independently and as part of a cross-functional team.
Any specific certifications or additional qualifications preferred.
If you are a highly motivated and detail-oriented Data Engineer with a passion for working with data, we encourage you to apply and join our innovative team at Vuori. Help us drive data-driven decisions and make a meaningful impact in athletic performance apparel business.

Additional Information

Pay Range: $136,000-$160,000/yr
Benefits:
Health Insurance
Paid Time Off
Employee Discount
401(k)
All your information will be kept confidential according to EEO guidelines."
1008923468524,Glassdoor,,,,"Company Overview:
Voted Journal Sentinels Top Workplaces to work for 3 consecutive years! Join us at West Bend Mutual, where we have been voted top workplaces to work three consecutive years. At West Bend Mutual, we believe that our employees are our greatest asset. We hire talented individuals who are conscientious, dedicated, customer focused, and able to build lasting relationships. We create and maintain an environment where you feel a sense of belonging and appreciation. Your diversity of through, experience and knowledge are valued. Recognized as top workplace, we are committed to fostering a welcoming culture, offering you opportunities for meaningful work and professional growth. More than a workplace, we celebrate our success and take pride in serving our communities.
Job Summary:
West Bend Mutual's Data practice is seeking an experienced senior engineer to join their team! The ideal candidate will have experience with cloud-native data architecture, as well as coaching and mentoring junior engineers. We are a fast growing, relationships-based company who values employee engagement and culture. Future work initiatives include data engineering for warehousing and dataset curation, exposing new predictive analytics capabilities, enhancing risk pricing and ratemaking capabilities, and driving our company culture to embrace data-driven decision making.
Responsibilities & Qualifications:
The Senior Data Engineer provides technical leadership to an agile engineering team. We are looking for a flexible technical leader who is motivated to design, develop and test extensible data solutions, while mentoring junior team members. Ideal candidates possess experience with cloud-native data tooling, including programming languages such as SQL and Python, integration platforms such as Azure Data Factory and Snowpark, and data storage technology such as Snowflake, Microsoft SQL Server, and Azure Storage. All candidates should have experience with databases, data warehouses, and data lake concepts. Candidates should consider themselves to be high-level specialists who excel at solving complex issues and problems and should be skilled at adapting to new solutions in an ever-changing technical landscape.
At West Bend Mutual, we value leadership, teamwork, collaboration and incremental improvement. The ideal candidate should enjoy collaborating as part of a larger team. They will provide leadership, coaching and mentoring as part of our ongoing improvement efforts and participate as a technical leader.

*West Bend Mutual has office locations in Madison, West Bend, & Appleton. Flexible Hybrid schedule determined by manager based on candidates preferences and experience. Not open to fully remote candidates at this time*

Preferred Experience and Skills

Eight or more years of experience delivering data solutions
Advanced proficiency with solution design concepts in cloud-native data architectures
Advanced proficiency with SQL, Microsoft SQL Server, and SQL Stored Procedures
Experience with data modeling, data warehouse, and data lakehouse concepts
Experience with Snowflake, Azure Storage, and/or Microsoft SQL Server
Experience with Python, SnowSQL, Snowpark, Azure Data Factory, Azure Databricks, and/or Matillion
Experience with DevOps or DataOps concepts; including release engineering & observability frameworks
Can effectively communicate, influence, and challenge IT peers, architects and management
Sees a solution through to its full delivery – facilitates and leads the team, not just their individual code
Shares knowledge, mentors junior team members, advocates best practices
Experience in Property & Casualty Insurance, or Financial Services industry, is a plus
EEO:
West Bend provides equal employment opportunities to all associates and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, and promotion."
1008922875262,Glassdoor,,,http://www.workcog.com/,"Job Description:
Minimum 9+ years exp Mandatory
Mandatory Tech: We consider the following technologies as mandatory and should be familiar to the candidate:
GCP
Data Warehousing
GIT
Core Tech: Our ideal candidate should possess strong proficiency in the following technologies:
Airflow 2years
Python - 3 Years
SQL
Spark - 3 Years
ETL
Job Type: Contract
Pay: $55.00 - $85.00 per hour
Expected hours: 40 per week
Benefits:
Referral program
Compensation package:
Hourly pay
Experience level:
10 years
11+ years
9 years
Schedule:
8 hour shift
Experience:
Informatica: 5 years (Preferred)
SQL: 6 years (Preferred)
Data warehouse: 7 years (Preferred)
Work Location: Remote"
1008920878887,Glassdoor,$81K,$113K,http://www.comcastcareers.com/,"Comcast brings together the best in media and technology. We drive innovation to create the world's best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary
Providing day-to-day advanced level support of the data quality monitoring and alerts, SQL Reporting Services platforms, and Tableau administrative tasks. Performs root cause analysis and collaborates with data stakeholders to identify and understand factors that contribute to data quality issues and recommends data capture and operational process improvements based on findings, coordinates with the appropriate internal and external stakeholders in the correction of source data or creation of translation sources, where applicable. Uses structured Queries to gather, organize and analyze data from various databases, source systems or external systems to profile, monitor and evaluate data quality. Develops data quality key performance indicators and reporting to measure, monitor and evaluate data quality across the entire data stack.
Job Description
Core Responsibilities
Develops data structures and pipelines aligned to established standards and guidelines to organize, collect, standardize and transform data that helps generate insights and address reporting needs.
Focuses on ensuring data quality during ingest, processing as well as final load to the target tables.
Creates standard ingestion frameworks for structured and unstructured data as well as checking and reporting on the quality of the data being processed.
Creates standard methods for end users / downstream applications to consume data including but not limited to database views, extracts and Application Programming Interfaces.
Develops and maintains information systems (e.g., data warehouses, data lakes) including data access Application Programming Interfaces.
Participates in the implementation of solutions via data architecture, data engineering, or data manipulation on both on-prem platforms like Kubernetes and Teradata as well as Cloud platforms like Databricks.
Determines the appropriate storage platform across different on-prem (minIO and Teradata) and Cloud (AWS S3, Redshift) depending on the privacy, access and sensitivity requirements.
Understands the data lineage from source to the final semantic layer along with the transformation rules applied to enable faster troubleshooting and impact analysis during changes.
Collaborates with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality as well as process optimization.
Handles data migrations/conversions as data platforms evolve and new standards are defined.
Preemptively recognizes and resolves technical issues utilizing knowledge of policies and processes.
Understands the data sensitivity, customer data privacy rules and regulations and applies them consistently in all Information Lifecycle Management activities.
Identifies and reacts to system notification and log to ensure quality standards for databases and applications. Solves abstract problems beyond single development language or situation by reusing data file and flags already set.
Solves critical issues and shares knowledge such as trends, aggregate, quantity volume regarding specific data sources.
Consistent exercise of independent judgment and discretion in matters of significance.
Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.
Other duties and responsibilities as assigned.

Employees at all levels are expected to:
Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Disclaimer:This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is proud to be an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law.

Education
Bachelor's Degree
While possessing the stated degree is preferred, Comcast also may consider applicants who hold some combination of coursework and experience, or who have extensive related professional experience.
Relevant Work Experience
2-5 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details."
1008918798089,Glassdoor,$86K,$122K,http://www.kraftheinzcompany.com/,"General information
All posting locations: Chicago, Illinois, United States of America
Job Function: 16 - Digital
Date Published: 10-Oct-2023
Ref #: R-75631
Description & Requirements
3+ years of experience working in data engineering or architecture role.
Expertise in ELT and data analysis and experience with SQL and at least one programming language (Python/R preferred)
Experience developing and maintaining data warehouses in big data solutions e.g., Snowflake
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)
Experience with cloud service providers including AWS, Azure, or Google.
Database development experience using Hadoop, SPARK or Big Query and experience with a variety of relational, NoSQL, and cloud database technologies.
Experience with BI tools such as Alteryx, Tableau, Power BI, Looker.
Experience and/or knowledge of CI/CD (continuous integration and continuous deployment) practice using GitHub or Azure repos.
Conceptual knowledge of data and analytics, such as dimensional modeling, ELT, reporting tools, data governance, data warehousing, structured and unstructured data.
Familiarity with the Linux operating system
Familiarity with data engineering and workflow management frameworks such dbt.
Nice to have exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics.
An agile learner who brings strong problem-solving skills, and enjoys working as part of a technical, cross functional team to solve complex data problems.
Bachelor’s degree required; Computer Science, MIS, or Engineering preferred or equivalent experience.
Location(s)
Chicago/Aon Center
About Us
Kraft Heinz is a global food company with a delicious heritage. With iconic and emerging food and beverage brands around the world, we deliver the best taste, fun and quality to every meal table we touch. We’re on a mission to disrupt not only our own business, but the global food industry. A consumer obsession and unexpected partnerships fuel our progress as we drive innovation across every part of our company.
Around the world, our people are connected by a culture of ownership, agility and endless curiosity. We also believe in being good humans, who are working to improve our company, communities, and planet. We’re proud of where we’ve been – and even more thrilled about where we’re headed – as we nourish the world and lead the future of food.
Why Us
We grow our people to grow our business. We champion great people who bring ambition, curiosity, and high performance to the table as the guardians of our beloved and nostalgic brands. Good isn't good enough. We choose greatness every day by challenging the ordinary and making bold decisions. All while celebrating our wins - and our failures – as we work together to lead the future of food.
Challenging the status quo takes talent. We invest in your purpose and potential by developing skills and nurturing strengths that leave a legacy on our business and a lasting impact on your career. Because great people make great companies, and we’re growing something great here at Kraft Heinz.
Office Collaboration & Hybrid Work Environment
We believe our office environment fuels our collaboration, connection & community as an organization and allows our employees to grow toward greatness. We also believe providing a more flexible and agile model is essential in today’s workplace. A majority of our office-based employees will be able to work remotely for up to two days each week. Additionally, employees who are subject to this hybrid model will be eligible to work from anywhere for up to six weeks in a rolling 12-month period (in maximum two-week increments and according to benefits and tax guidelines). Some jobs may be required to be performed fully in office depending on the role’s responsibilities and requirements.
Kraft Heinz is an Equal Opportunity Employer that prohibits discrimination or harassment of any type. All qualified applicants are considered for employment without regard to race, color, national origin, age, sex, sexual orientation, gender, gender identity or expression, disability status, protected veteran status, or any other characteristic protected by law. Applicants who require an accommodation to participate in the job application or hiring process should contact NATAI@kraftheinz.com."
1008923511074,Glassdoor,,,https://blupeak.com/,"Overview:
The Azure Data Engineer will partner closely with our technology and business teams to enhance the existing data warehouse to provide reporting and insights to the business users. This position will be primarily technical, but will also involve some soft skills. The primary responsibilities of this role include development in the Azure data warehouse using SQL (Create Views and Stored Procedures), Azure Data Factory, Azure Databricks (Python), and Power BI (Desktop and Report Builder), amongst other tools. The Engineer will be expected to design, develop, and test solutions independently in an agile environment while working closely with and taking direction from the Data Warehouse Architect. The Azure Data Engineer will consult with personnel across the Credit Union and leverage knowledge of credit union or financial services industry to ensure successful development and execution of solutions. Through collaboration with business owners, this position will elicit functional requirements and translate these into technical requirements, which the Engineer will then implement in planned sprints. This position will also involve working with business users to assist them with user acceptance testing (UAT). This role may also involve the documentation of user procedures and the training of end-users.
Responsibilities:
Enhances and optimizes components of the data lake and data warehouse to support strategic and operational reporting and data analysis
Designs, develops, maintains, monitors, and supports scalable ETL solutions to deliver data from various source systems to the data lake, which may include both structured and unstructured data
Analyzes source data and builds appropriate data models to structure data to be used to fulfill current business requests, while being flexible enough to be leveraged for future needs
Analyzes data and identifies/resolves data integrity issues and data anomalies
Leverages data governance standards to ensure accuracy, timeliness, and completeness of data warehouse data
Documents data flows and processes; maintains documentation including data dictionary
Develops solutions to meet business reporting and analysis needs using SQL, Azure Databricks, Python, and Power BI
Ensures solutions are well designed, sufficiently documented, and easy to maintain and repurpose for future initiatives
Strong listener with analytical skills who can understand requests from business owners and recommend options for potential solutions based on knowledge of the credit union industry, business needs, and available data
Documents requirements with enough detail, clarity, and key artifacts for traceability in developing solutions that meet the business needs
Performs Quality Assurance (QA) Testing to validate/ensure technological feasibility of proposed solutions
Works with business teams to confirm sample data for testing that meets all key scenarios
Facilitates end-to-end UAT with business owners, which may include developing test cases, ensuring test case traceability to requirements, assisting users with test execution, validating and documenting results, resolving bugs, and providing status reports to project management.
Assesses impact to processes from new projects and initiatives that involve the data warehouse, negotiates modifications to optimize benefits and limit negative impacts, and aligns requirements to solutions
Performs data systems analysis of functions performed within the credit union with the intent of improving overall productivity and efficiency
Participates in (and may periodically be responsible for) creating project communications, training materials, and business procedures/documentation; may be asked to conduct user training on newly developed solutions
Delivers relevant technical and operational information to business stakeholders or other relevant parties.
Participates in production releases by coordinating with production management, performing verification, confirming business readiness, answering questions regarding expected functionality, and gathering user feedback post go-live
Performs other duties as assigned
Qualifications:
Experience in the financial services industry strongly preferred
Advanced knowledge of credit union operations/processes and procedures is desirable
Experience working with data warehouses and data lakes
Familiarity with Azure Cloud and related Azure tools
Very strong technical skills and experience developing in SQL, Python, Power BI
Experience with Agile software development frameworks
Familiarity with industry standard IT security practices is a plus
Experience in translating business requirements into technical requirements
Advanced skill applying innovative approaches to solving technical issues and negotiating with stakeholders to find acceptable solutions to business challenges
Thorough familiarity with problem analysis, determining root cause, scope, and scale of issues, and excellent level of problem-solving capabilities to establish reasonable solutions
Excellent communication - verbal and written
Proven presentation and facilitation skills when working with key stakeholders and management of all areas of the credit union
Ability to work independently, as well as with all levels within the credit union
Must be highly organized and capable of handling multiple tasks concurrently, able to redirect priorities based upon current workload, and flexibility to respond to changes of schedules, plans and priorities
Must be a fast and eager learner, adept at asking the right questions to understand business processes and needs, capable of synthesizing new information quickly, and able to become the subject-matter expert in a functional area
Proficiency with MS Office, DevOps, and experience with diagramming and collaboration tools
Analytical skills to translate needs of users and external entities into projects or tasks, which are practical and are well synthesized and integrated into the systems environment
Ability to translate use cases and requirements into test cases and conduct QA testing, while retaining traceability
Knowledge of UAT process and business analysis function
Ability to work on multiple concurrent projects in a team environment and build relationships with other teams
Experience with user guides and user training is a plus

EDUCATION and/or EXPERIENCE
Bachelor's Degree in computer science, information systems or analytical techniques preferred, or equivalent work experience (5 plus years in a similar role)
o 1 or more years of experience creating PowerBI dashboards and paginated reports required and
o 3 or more years of experience as an Azure Data Engineer preferred; experience must include working independently on projects that built or enhanced large and complex production data warehouses in a formal, process-oriented environment
o 5 or more years of experience using TSQL
Experience with data vault architecture preferred
Experience programming in Python Using Databricks preferred
Credit union, financial services, or banking industry experience strongly preferred
LANGUAGE SKILLS
Written and verbal communication skills, which support effective communication of information to groups of managers and clients. Ability to effectively present information and respond to questions from business line managers and staff. Excellent verbal and written communication skills required.
Ability to read, interpret, analyze and communicate with all levels of staff on a variety of topics, including but not limited to data structures, data warehouse solutions, and data outputs (dashboards and reports). Ability to create technical and process documentation.

TECHNOLOGY PROFICIENCY
To perform this job, the employee must possess applicable technology skills and demonstrated expertise.
The requirements for this job include proficiency in Azure Cloud components, SQL, Microsoft SQL Server Management Studio (SSMS), Azure Databricks, ETL processes including familiarity with Azure Data Factory, Python, and development of dashboards and reports in Power BI
Must also have the ability to efficiently use MS Word, Excel, PowerPoint and other Microsoft Office applications; Excel skills will include filtering, formatting, pivot tables, and formulas
Experience with diagramming tools, such as Visio or Lucidchart preferred
Ability to use project management and collaboration tools, such as Confluence, Monday.com, Jira, and DevOps
Solid understanding of the overall SDLC and Agile methodologies
CERTIFICATES, LICENSES, REGISTRATIONS
The following certifications are desirable:
Microsoft Certified: Azure Data Engineer Associate
Databricks Certified Data Engineer Associate
Data Vault Certification

OTHER QUALIFICATIONS
To perform this job, the employee must possess strong interpersonal skills, good phone and e-mail etiquette, a professional presentation, and a high degree of personal initiative. Must also possess strong creative skills and good writing skills.

Must be organized, self-disciplined and detail-oriented with the ability to manage and juggle multiple projects. Persistent and dependable, especially in meeting deadlines; able to manage multiple competing priorities. Must be able to work during regular business hours and occasional nights or weekends as needed to meet production deadlines.

BluPeak Credit Union is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law.

Employment may be contingent upon BluPeak Credit Union’s receipt of an acceptable and job-related background check, drug screen, credit check and vaccine verification, as applicable and permissible by law. BluPeak Credit Union is committed to the safety and wellbeing of our employees and their families; our members and visitors; and the community at large. In accordance with our duty to provide and maintain a workplace that is free of known hazards, we are requiring that employees must have received or be willing to receive the COVID-19 vaccine. BluPeak Credit Union continues to monitor the pandemic following CDC guidelines, federal state and local laws. Policies continue to be adjusted as new information emerges. BluPeak Credit Union is committed to working and provide reasonable accommodation to applicants with physical, mental disabilities and sincerely held religious beliefs. For more information, contact Human Resources.

PM17
Min: USD $97,789.60/Yr. Max: USD $146,684.40/Yr."
1008918926522,Glassdoor,$129K,$184K,https://www.airwallex.com/,"Airwallex is a global payments fintech company transforming the way businesses move and manage money globally. We have built a global financial infrastructure platform to help businesses transact, collect and pay across 130+ countries and 50+ currencies, without the constraints of the traditional global financial system. We've grown to 13 global locations and have raised over $900 million in funding. To support our ambitious growth plans, we’re looking for smart, collaborative and passionate people who are looking to make a genuine impact.

At Airwallex, you will work closely with a group of talented engineers with a passion for learning through solving the most challenging problems with cutting-edge technology. In this Data Engineering role, you need to have systemic thinking with data content architectural design and will be building a metrics layer to handle data at a massive scale. And you will be building robust data modeling to produce high-quality, consistent, structured data for running business applications and enabling less tech-savvy colleagues to do self-service analytics. In short, you will make Airwallex to be a truly data-driven organization. We are looking for talented senior Data Engineers excited about redefining what it means to do Data Engineering. However, we also recognize that each Data Engineer has a unique blend of skills. Whether your strength is in data modeling or data processing, we want to talk to you.

Responsibilities
Work in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret.
Develop and automate large-scale, high-performance distributed data processing systems (batch/ streaming) to drive Airwallex business growth and improve the product experience.
Evangelize high-quality software engineering practices toward building data infrastructure and pipelines at scale.
Lead data engineering projects to ensure pipelines were reliable, efficient, testable, and maintainable and were largely in charge of architecting solutions.
Design our data content models for optimal storage and retrieval and to meet critical product and business requirements.
Contribute to shared Data Engineering tooling standards to improve the productivity and quality of output for Data Engineers across the company.
Qualifications
5+ years of relevant experience as a data engineer.
Bachelor's or Master's degree in CS/CE/CIS (or equivalent experience) with knowledge of Kotlin / Java / Scala / Python / SQL. Knowledge of Spring Boot, Spark, Flink, Hadoop, BigQuery, and Snowflake is preferred.
Ability to take ownership of designing, building, and operating distributed systems and establishing overarching data architecture.
Strong working knowledge of Real-time/Batch processing systems.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.

At Airwallex you’ll have the ability to make an impact in a rapidly growing, global fintech. We organize regular team building events, encourage hybrid/flexible working, and we give our people the freedom to be creative.

Airwallex is proud to be an equal opportunity employer. We value diversity and anyone seeking employment at Airwallex is considered based on merit, qualifications, competence and talent. We don’t regard color, religion, race, national origin, sexual orientation, ancestry, citizenship, sex, marital or family status, disability, gender, or any other legally protected status. If you have a disability or special need that requires accommodation, please let us know. Airwallex does not accept unsolicited resumes from search firms/recruiters.

Airwallex will not pay any fees to search firms/recruiters if a candidate is submitted by a search firm/recruiter unless an agreement has been entered into with respect to specific open position(s). Search firms/recruiters submitting resumes to Airwallex on an unsolicited basis shall be deemed to accept this condition, regardless of any other provision to the contrary."
1008918461735,Glassdoor,,,,
1008921172894,Glassdoor,,,http://www.collectivei.com/,"Collective[i] is a leading research organization at the forefront of artificial intelligence development. We are on a mission to help our clients and community be more prosperous. Collective[i]’s first enterprise application is designed to enable revenue-facing organizations (eg, sales, client success, and marketing) to transform and adapt to modern buying.

We're in search of a Senior Data Engineer who finds satisfaction in constructing applications to manage operations on a global scale. In this role, you'll collaborate extensively with engineering, operations, and product teams to implement new applications onto our data framework, enhance existing outdated components, and conceive novel functionalities for our products. This opportunity calls for an individual enthusiastic about large-scale data technologies, adept at tackling intricate problems, skilled in teamwork, and possessing a mindset geared towards continual development.
Salary ranges can vary significantly based on a multitude of factors, reflecting the diverse and complex nature of today's job market. These factors encompass a wide range of elements, including industry, experience, education, geographic location, and even personal negotiation skills.
Who you are working for - About Collective[i]:

Collective[i] is a remote-first company on a mission to fuel global prosperity, helping companies around the world forecast, optimize and grow revenue. Our applications and network support highly productive, enlightened teams with everything they need to work smarter and win more.

We are a global team of committed scientists, developers, sales, finance, client success and marketing professionals who passionately believe that Collective[i]'s network and applications are dramatically transforming enterprises and improving the working lives of the people and companies we support.

We are recruiting for exceptional talent looking to join our team of A-players all committed to building a company that makes a difference. Our core values help shape our culture: We are curious. We are direct. We deliver. We succeed together. We strive for the extraordinary. If you enjoy a challenge, thrive in a fast paced environment and welcome the opportunity to work with amazing humans operating on the bleeding edge of innovation, Collective[i] is the place for you.

More about Collective[i]:

Collective[i] is passionate about using ML, RPA and other AI technologies along with a network to automate the myriad of tasks that distract sales professionals from selling and provide timely intelligence that helps to grow revenue. Our revenue optimization engine is one of the most transformative technologies to hit the enterprise since CRM. Founded and managed by the early teams behind LinkShare (purchased for $425m) and Overstock (NASDAQ:OSTK), Collective[i] is a private 100% remote company.

Recent press:
Forbes: The Revenue Operating System
ZDNet: Collective[i]: How the FAANG companies inspired a B2B sales solution

Information about the founders:
Tad Martin
Stephen Messer
Heidi Messer"
1008919582652,Glassdoor,,,,"REQUIRED QUALIFICATIONS, EXPERIENCE & SKILLS
5 years' experience consulting in Data or Dynamics business application domain
Expert experience with T-SQL language
Experience in creating Data Factory pipelines to orchestrate ingestion and transformation data for use in analytics and system integration
Experience with the Dynamics 365 data model
Experience using modern Azure data services such as Azure Synapse, Azure SQL Database, Azure Data Lake Storage Gen 2, Microsoft Fabric
Familiarity with security configuration and security policies, and best practices within Azure
Curious and tenacious when it comes to leveraging new Azure technology to deliver novel solutions for clients
ADDITIONAL QUALIFICATIONS & SKILLS
Azure Data Engineer Associate Certification preferred (DP-203)
Familiar with data lakehouse patterns and practices preferred
Bachelor’s Degree in Information Systems Management, Computer Science, or related field
Demonstrated ability to lead project workstream including interfacing in a client facing role
Familiar with Agile implementation methodology
Experience working with a multicultural and/or multilingual team across several time zones remotely"
1008923481938,Glassdoor,$93K,$130K,http://www.hcscenterprise.com/,"At HCSC, we consider our employees the cornerstone of our business and the foundation to our success. We enable employees to craft their career with curated development plans that set their learning path to a rewarding and fulfilling career.
Come join us and be part of a purpose driven company who is invested in your future!
Job Summary
This Position Is Responsible For Acting As A Concierge To The Divisional Analytics Teams (Dats). It Will Use Its Deep Knowledge And Understanding Of Business Needs To Help The Dats Define & Execute A Data Strategy. It Will Coordinate The Development & Delivery Of Data Assets And Serve As A Single Point Of Contact For Issues / Escalations To Business Stakeholders.
Required Job Qualifications:
Bachelor degree and 8 years of data and analytics experience OR 12 years of data and analytics experience
Experience in data processing environments
Experience with Teradata & Hadoop
Experience connecting business requirements to data mining objectives and measuring business benefit
Knowledge of statistical modeling/predictive modeling/machine learning/data mining/optimization and big data concepts
Analytical and quantitative problem-solving skills
Experience with Data Warehouse development and data consumption
Experience with Business Intelligence tools
Knowledge of Application development platforms / languages
Knowledge of DevOps / continuous deployment / integration process
Ability to understand market needs and to translate business vision into data asset development
Ability to execute strategic vision with tactical efficiency
Experience interacting with corporate leadership
Ability to manage demands from multiple stakeholders while optimizing resources

Preferred Job Qualifications:
Bachelor Degree in Computer Science, MIS or related field
Healthcare data experience
Are you being referred to one of our roles? If so, ask your connection at HCSC about our Employee Referral process!
HCSC Employment Statement:
HCSC is committed to diversity in the workplace and to providing equal opportunity and affirmative action to employees and applicants. We are an Equal Opportunity Employment / Affirmative Action employer dedicated to workforce diversity and a drug-free and smoke-free workplace. Drug screening and background investigation are required, as allowed by law. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status."
1008923193678,Glassdoor,$78K,$117K,https://www.neb.com/,"Employment at New England Biolabs (NEB) offers a challenging and creative work environment in a state-of-the-art research and production facility, with a team of exceptional scientists and professional staff. The NEB culture emphasizes personal and professional growth through creativity, teamwork, respect and responsibility, while maintaining a casual campus-like working environment. From our founding principles – placing the advancement of science and the stewardship of the environment as our highest priorities – to our unique corporate culture, NEB’s philosophy can be distilled down to three core values: passion, humility and being genuine.
We are hiring a Data Engineer to join our IT Architecture & Analytics team. Primary duties will be to design, develop and implement data solutions in the NEB ecosystem, which is comprised of internally, externally and cloud hosted data stores, tools, and business solutions. In the Architecture & Analytics team, we are regularly assessing, identifying technical debt, and modernizing our data architecture, which means the role requires an ability to adapt and learn new technologies when necessary to fulfill business requirements.

Primary Responsibilities:
Builds required infrastructure for optimal integration of data from our external partners, customers, and amongst our NEB applications.
Works with stakeholders to support data infrastructure and critical business processes orchestration.
Evaluates the performance of current data solutions; and designs and implements new cloud or hybrid data solutions.
Performs ETL, ELT, operations and administration of data and systems securely and in accordance with NEB security standards.
Creates scripts and program to automate Data Operations
Monitors data pipelines proactively and responds to production issues in a timely manner.
Assists in identification of best practice integration solutions and contribute to the decision-making on tooling and architecture.

Required Qualifications and Experience:
Bachelor’s degree and 5+ years of data engineering experience
Knowledge of Database systems including SQL Server, Databricks, Postgres
Highly Skilled in data analysis, data modeling, ETL and ELT
Expert in EDI, CXML, and SAP IDOCS for order processing in SAP
Highly proficient in SQL and experience with a variety of ETL tools and programming languages (e.g., Java, C#, Python)
Experience with large scale Salesforce, ERP, Data Warehouse and Data Lake environments
Experience with cloud-based technology (Azure, AWS)
A continuous improver and self-driven learner
Ability to work independently and contribute as a team player on coordinated efforts.
Must be willing to do some travel and off shift hours as required.
Effective written, oral, and interpersonal communication skills.
EEO Statement
New England Biolabs is committed to fostering a diverse and inclusive community; as an EEO/AA employer, New England Biolabs considers applicants for employment without regard to, and does not discriminate on the basis of, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. More in-depth details of EEO are available
here.
Information regarding New England Biolabs commitment to Diversity, Equity and Inclusion can be found
here.
New England Biolabs is a participating employer in the Employment Verification (
E-Verify
) program.

If you need an accommodation for any part of the employment process because of a medical condition or disability, please send an email to
hr@neb.com
or call 978-927-5054 to let us know the nature of your request."
1008923108577,Glassdoor,$98K,$145K,http://www.jadeglobal.com/,"ID: 6439 | 8-12 yrs | San Jose | careers
We are looking for a skilled Data Engineer with expertise in Salesforce and BigQuery to join our data team. The ideal candidate will be responsible for designing, developing, and maintaining data pipelines, ETL processes, and data integration solutions that leverage Salesforce and Google BigQuery. You will work closely with cross-functional teams to ensure the efficient flow of data, data transformation, and the availability of high-quality data for analytics and reporting.
Key Responsibilities:
Data Integration and ETL: Develop and maintain data integration solutions using Salesforce APIs and BigQuery for the extraction, transformation, and loading of data from various sources into a structured data warehouse.
Data Modeling: Create and optimize data models, data mappings, and data dictionaries to support ETL processes and ensure data integration aligns with business requirements.
ETL Pipeline Development: Design, build, and maintain ETL pipelines to move, transform, and load data from source systems into BigQuery, ensuring data consistency and accuracy.
Data Quality Assurance: Implement data quality checks, data validation, and error handling mechanisms to maintain the integrity of data during the ETL process.
Performance Optimization: Identify and resolve performance issues in ETL processes and data pipelines, working closely with database administrators to enhance data efficiency.
Collaboration: Collaborate with business analysts, data analysts, and stakeholders to understand data requirements and deliver solutions that meet business needs.
Documentation: Maintain comprehensive documentation of data pipelines, ETL processes, data models, and integration workflows, ensuring ease of understanding and future maintenance.
Monitoring and Support: Monitor data pipelines, diagnose and resolve issues, and provide support for production data integration systems.
Security and Compliance: Ensure data security and compliance with data governance policies, especially in the handling of sensitive Salesforce data.
Qualifications and Skills:
Bachelor's degree in Computer Science, Information Technology, or related field.
Proven experience as a Data Engineer with a focus on Salesforce and BigQuery.
Strong proficiency in Salesforce data integration, data modeling, and ETL development.
Expertise in Google BigQuery, SQL, and data warehousing concepts.
Problem-solving skills and attention to detail.
Excellent communication and teamwork abilities.
Ability to work independently and in a team.
Preferred Qualifications:
Salesforce certifications related to data and integration.
Google Cloud Platform (GCP) or BigQuery certification.
Familiarity with other data integration tools and cloud services.
Knowledge of business intelligence and reporting tools.
Experience with data governance and compliance practices."
1008921327720,Glassdoor,$102K,$139K,http://www.freewheel.tv/,"Comcast brings together the best in media and technology. We drive innovation to create the world's best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary
Job Description
DUTIES: Provide technical leadership to a team responsible for creating and maintaining large scale Big Data systems and Data Environments, used to ingest and process large data sets and provide actionable recommendations using data warehousing and business intelligence; design, develop, test, and maintain software that extracts, transforms, and loads large volumes of data; develop software systems in an Agile development environment and on AWS cloud-based platform using SQL, Golang, Python, Presto, Spark, Datadog, Terraform, Jenkins, Scala, Apache Hadoop, Spark, Snowflake, Databricks, and AWS Elastic MapReduce; deploy software on AWS using Terraform; develop Microservices API systems to support overall product development; store relational data in MySQL to support API and data processing applications; concurrently execute data processing software using multithreading; write code and scripts to extract MRM ad logs from FreeWheel Big Data platforms, and load MRM ad logs and campaign data; perform audience targeting; ingest audience, identity, and segment data; create dashboards and monitors on Datadog to ensure 24x7 availability of critical software deployments; build new software products and web frontend frameworks; analyze product specifications, write technical specs, create monitoring dashboards, develop test suites, design workflows, and setup database schemas and tables; interface with global engineering, operations, services, and business operations teams to execute proof of concepts and incorporate new requirements; improve system performance and ensure availability and scalability of services; provide production support for data processing systems running on AWS cloud and Snowflake; troubleshoot data processing problems running on distributed systems, and functional and performance issues on software modules; debug functional and performance issues on software modules running on Snowflake, Databricks, and Spark; and guide and mentor junior-level engineers. Position is eligible for 100% remote work.
REQUIREMENTS: Bachelor’s degree, or foreign equivalent, in Computer Science, Engineering, or related technical field, and five (5) years of experience developing software in an Agile development environment using SQL, Golang, and Python on AWS cloud-based platform; of which three (3) years of experience include using Presto, Spark, Datadog, Terraform, and Jenkins; and of which one (1) year of experience includes performing audience targeting; using Snowflake and Databricks; storing relational data in MySQL to support API and data processing applications; and debugging functional and performance issues on software modules running on Snowflake, Databricks, and Spark.
Disclaimer:
This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.
Comcast is proud to be an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law.

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details."
1008920866851,Glassdoor,$70K,$104K,http://oncologycarepartners.com/,"About Oncology Care Partners
Oncology Care Partners (OCP) is an innovative new platform of owned and affiliated oncology practices that is purpose-built for value-based care. We are dedicated to improving outcomes, delivering a better experience for patients, and making cancer care more affordable. With ambitious growth goals, OCP is attracting and developing team members who have a passion for transforming the current state of oncology care and placing the needs of patients above all.
Our company was formed in February 2022 by Valtruis (www.valtruis.com), a Welsh, Carson, Anderson & Stowe company that is solely focused on investing in and building companies advancing value-based care, in partnership with New Century Health (www.newcenturyhealth.com), an industry leader in oncology care management.
Learn more about our business at www.oncologycarepartners.com.
Ideal Candidate
Someone who is drawn to a culture that values critical thinking and innovative problem solving
A caring, passionate, driven, and self-motivated individual who is willing to challenge the status quo
Someone who participates in feedback loops and encourages engagement, inclusion, and diversity at all levels
Role Summary
The Data Engineer will serve a critical role in a growing organization, reporting initially to OCP’s Director of Data & Analytics. This person will be the lead engineering resource for OCP, bringing your expertise to help us deliver best-in-class oncology care to our patients.

Requirements
Responsibilities
Providing data engineering perspective to all relevant decisions, including but not limited to: vendor selection, vendor integration, tools and systems selection
Managing data pipeline from payors to Snowflake environment
Managing and implementing dbt solutions for data normalization and transformation
Partnering with the SVP of Digital Health to help design, implement and maintain infrastructure solutions to support patient engagement, patient portal experience and digital health
Key Competencies
Strong interpersonal and communication skills
Customer service and organizational awareness
Detail oriented with the ability to exercise independent judgement
Adaptable to change
Location
Remote, with opportunity to work out of OCP Nashville office

Qualifications
3+ years of hands-on experience developing data pipelines that demonstrate a strong understanding of data engineering principles and concepts
2+ years experience in Healthcare or Pharma, specifically with handling claims data: ingest, QA, pitfalls, and normalization
Ability to be the data engineering expert on the team: bring the data engineering perspective and communicate relevant concepts to stakeholders, including explaining technical concepts to a non-technical audience
Experience with managing data and normalization using dbt with a platform like Snowflake, following best practices in Cloud deployments. In-depth knowledge of SQL (any type) for data transformation, cleaning, etc.
Experience with DevOps tools, Git workflow and building CI/CD pipelines
Preferred
5+ years of hands on data engineering experience in Healthcare, working with both claims and clinical data: pipeline, ETL, QA, etc. in a cloud environment
Familiarity with implementing cloud solutions for data covered by HIPAA
Bachelor’s degree in Computer Science or relevant Engineering field or equivalent experience
Knowledge of best practices for schema design with applications/ implications for both data analytics and operations
Familiarity with implementing dbt or similar solution
Benefits
Benefits start day 1, No waiting period!"
1008920132445,Glassdoor,,,https://www.gatesfoundation.org/about/careers,"The Foundation
We are the largest nonprofit fighting poverty, disease, and inequity around the world. Founded on a simple premise: people everywhere, regardless of identity or circumstances, should have the chance to live healthy, productive lives. We believe our employees should reflect the rich diversity of the global populations we aim to serve. We provide an exceptional benefits package to employees and their families which include comprehensive medical, dental, and vision coverage with no premiums, generous paid time off, paid family leave, foundation-paid retirement contribution, regional holidays, and opportunities to engage in several employee communities. As a workplace, we’re committed to creating an environment for you to thrive both personally and professionally.
The Team
As part of the IT Enterprise Data Solutions (EDS) department, the Data Infrastructure team’s mission is to lead on data technology and utilization, enabling informed decision-making, knowledge management, and strategic insights across the Foundation. We are committed to providing a robust, secure, and scalable data platform that enables data-driven initiatives and cultivates collaboration. Working with our business operations and Foundation strategy program partners, the team supports the management of on-premises and cloud data infrastructure, data security and access controls and EDS technology stack and roadmaps.
Note: This job posting will close on October 24, end of day.
Your Role

You will be the primary domain expert on the team's cloud infrastructure! The role will develop and support needs of the Enterprise Data solution team to improve the quality and availability of information to drive better search, reporting, data sharing, data science and analytics capabilities. You will grow and optimize our data and data repository as well as optimize data flow and collection for multi-functional teams. As an authority on cloud data infrastructure builds and configuration, you enjoy optimizing data systems and building them from the ground up. You will work with a team consisting of business partners, business and data analysts, solution architects, data architects, data and infrastructure engineers, quality engineers and other technical roles in an Agile delivery environment.
What You’ll Do
Lead the setup and configuration of cloud-based infrastructure, primarily focusing on Azure. Design and implement scalable, efficient solutions that align with the foundation’s governed cloud strategy.
Lead data storage solutions, including data lakes, data warehouse, data marts and databases. Ensure data is stored securely, efficiently, and is easily accessible for analytics, data sharing and reporting.
Continuously monitor and optimize the performance of data infrastructure components. Identify bottlenecks and implement improvements to improve system efficiency.
Implement security standard processes to safeguard sensitive data. Ensure compliance with foundation information security policies, data privacy regulations and policies, such as GDPR or HIPAA.
Collaborate with data architects, business systems analysts, and customers to understand their infrastructure requirements and provide vital support.
Automate infrastructure provisioning and configuration using Infrastructure as Code tools like Terraform, enabling reproducibility and scalability.
Build and maintain comprehensive documentation for infrastructure configurations, processes, and standard methodologies.
Implement robust monitoring and alerting solutions to proactively identify and address infrastructure issues.
Participate in problem and Incident triage, investigate, and resolve infrastructure-related issues promptly.
Work on planning and forecasting to ensure that infrastructure resources are appropriately allocated to meet current and future data processing needs.
Stay up-to-date with emerging cloud technologies, standard processes, and industry trends to ensure the data infrastructure remains innovative and driven.
Participate in agile development practices, including sprint planning, backlog grooming, and design reviews.

Your Experience
Bachelor’s or master’s degree in computer science or a related field, or equivalent experience.
5+ years of experience in data infrastructure or related roles, with a focus on designing and maintaining data infrastructure.
Demonstrable experience and knowledge with the architecture, design and settings of Azure cloud data services.
Experience with automated infrastructure provisioning, using industry standard tools such as Terraform.
Experience in cloud governance practices via Azure Policy, Azure Arc, and monitoring/logging services.
Deep understanding of data security practices, access controls, encryption, and compliance.
Experience in implementing Continuous Integration and Continuous Deployment (CI/CD) solutions for data pipelines and databases, ensuring automated testing, deployment, and monitoring processes.
Demonstrable ability to quickly respond to incidents by assessing the situation, lead incident triage, solve issues, and providing immediate short-term solutions. Capable of formulating and implementing medium and long-term strategies to prevent similar incidents in the future.
Experience with Agile, Scrum, and Jira required.
Experience supporting and working with multi-functional teams in a dynamic environment.
Excellent leadership, communication, and collaboration skills.
A dedication to diversity, equality, and inclusion, confirmed through past experiences or initiatives.
Experience with data engineering, analytics tools, data modeling, and visualization platforms (e.g., Power BI) is a plus.
The typical salary range for this role is $101,100 to $188,100 USD. The exact offer will be determined by a variety of factors such as the candidate’s individual skills, qualifications, and experience relative to the requirements of the role.

Must be able to legally work in the country where this position is located without visa sponsorship.
Hiring Requirements
As part of our standard hiring process for new employees, employment will be contingent upon successful completion of a background check.
Candidate Accommodations
If you require assistance due to a disability in the application or recruitment process, please submit a request here.
Inclusion Statement
We are dedicated to the belief that all lives have equal value. We strive for a global and cultural workplace that supports ever greater diversity, equity, and inclusion — of voices, ideas, and approaches — and we support this diversity through all our employment practices.
All applicants and employees who are drawn to serve our mission will enjoy equality of opportunity and fair treatment without regard to race, color, age, religion, pregnancy, sex, sexual orientation, disability, gender identity, gender expression, national origin, genetic information, veteran status, marital status, and prior protected activity."
1008918774599,Glassdoor,,,http://www.abercrombie.com/,"Company Description

Job Description
The primary responsibility of the Senior Engineer, Global Data & Insights - Data Management is to build data pipelines, model and prepare data, perform complex data analysis to answer Business questions, build and automate data pipeline and quality framework to enable and promote self service data pipelines, assist in operationalizing the AI / ML Engineering solutions. This role is expected to lead and guide other team members and evangelize the design patterns as well as coding standards.
This role plays an active part in our Data Modernization project to migrate the from on-prem platforms such as IBM Netezza to cloud project
What Will You Be Doing?
Team up with the engineering teams and enterprise architecture (EA) to define standards, design patterns, accelerators, development practices, DevOps and CI/CD automation
Create and maintain the data ingestion, quality testing and audit framework
Conduct complex data analysis to answer the queries from Business Users or Technology team partners either directly from Analysts or stemmed from one of the Reporting tools suchs PowerBI, Tableau, OBIEE.
Build and automate the data ingestion, transformation and aggregation pipelines using Azure Data Factory, Databricks / Spark, Snowflake, Kafka as well as Enterprise Scheduler tools such as CA Workload automation or Control M
Setup and evangelize the metadata driven approach to data pipelines to promote self service
Setup and continuously improve the data quality and audit monitoring as well as alerting
Constantly evaluate the process automation options and collaborate with engineering as well as architecture to review the proposed design.
Demonstrate mastery of build and release engineering principles and methodologies including source control, branch management, build and smoke testing, archiving and retention practices
Adhere to and enhance and document the design principles, best practices by collaborating with Solution and in some cases Enterprise Architects
Participate in and support the Data Academy and Data Literacy program to train the Business Users and Technology teams on Data
Respond SLA driven production data quality or pipeline issues
Work in a fast-paced Agile/Scrum environment
Identify and assist with implementation of DevOps practices in support of fully automated deployments
Document the Data Flow Diagrams, Data Models, Technical Data Mapping and Production Support Information for Data Pipelines
Follow the Industry standard data security practices and evangelize the same across the team.
What Do You Need To Bring?
Bachelor’s degree in Computer Science or Engineering or Mathematics or related field and 5+ years of experience in various cloud technologies within a large-scale organization
Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, highly motivated, Team oriented
Experience designing and building complex data pipelines in an agile environment
Expertise on data analysis and wrangling using sql, python, databricks
Experience with modern cloud development and design concepts; software development lifecycle; multi-developer code versioning and conflict resolution; planning, design, and problem resolution enterprise data applications / solutions
Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms
5+ years of experience in an Enterprise Data Management or Data Engineering role
3+ of hands on experience in building metadata driven data pipelines using Azure Data Factory, Databricks / Spark for Cloud Datalake
5+ years hands on experience with using one or more of the following for data analysis and wrangling Databricks, Python / PySpark, Jupyter Notebooks
Expert level SQL knowledge on databases such as but not limited to Snowflake, Netezza, Oracle, Sql Server, MySQL, Teradata
3+ years of hands on experience on one or more of big data technologies such as Cloudera Hadoop, Pivotal, Vertica, MapR is a plus
Experience working in a multi developer environment and hands on experience in using either azure devops or gitlab
Preferably experienced in SLA driven Production Data Pipeline or Quality support
Experience or strong understanding of the traditional enterprise ETL platforms such as IBM Datastage, Informatica, Pentaho, Ab Initio etc.
Functional knowledge of some of the following technologies - Terraform, Azure CLI, PowerShell, Containerization (Kubernetes, Docker)
Functional knowledge of one or more Reporting tools such as PowerBI, Tableau, OBIEE
Team player with excellent communication skills, ability to communicate with the customer directly and able to explain the status of the deliverables in scrum calls
Ability to implement Agile methodologies and work in an Agile DevOps environment
Our Company
Abercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we’re here for our associates, customers and communities on the journey to being and becoming who they are – and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas.
Our Values
We lead with purpose and always put our people first, which is evidenced by our Great Place to Work™ Certification, as well as being a 2021 recipient of Fortune’s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We’re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities.
What You'll Get
As an Abercrombie & Fitch Co. (A&F Co.) associate, you’ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company’s culture and values, but most importantly – with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward:
Incentive Bonus Program
Paid Time Off and Work From Anywhere Flexibility
Paid Volunteer Day per Year, allowing you to give back to your community
Merchandise Discount
Medical, Dental and Vision Insurance Available
Life and Disability Insurance
Associate Assistance Program
Paid Parental and Adoption Leave
Access to Carrot to support your unique parenthood journey
Access to Headspace dedicated to creating healthier, happier lives from the inside out
401(K) Savings Plan with Company Match
Opportunities for Career Advancement, we believe in promoting from within
A Global Team of People Who'll Celebrate you for Being YOU

Additional Information

ABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER
Notice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $110,000 - $136,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future."
1008921326271,Glassdoor,,,https://www.ibm.com/,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes.
Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region’s best places to work multiple times, Octo is an employer of choice!
As a Data Engineer, you will work closely with architects, engineers, and integrators to assess customer requirements and to design and support our team to unlock insights from the massive amounts of data within the Veterans Affairs ecosystem. You will be tasked with overall onboarding, operationalizing, administration, and maintenance of key big data/data science/machine learning platforms like Databricks and other cutting-edge technologies.
Previous experience with Veterans Affairs and/or health/clinical data is a major plus.
Us...
We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client’s missions.
Program Mission...
This program supports Veterans Affairs' strategic mission of furthering efforts to modernize its data analytics platform and enhance accessibility to enterprise data and reporting tools.
Responsibilities...
Serves as a technical consultant to implement Analytics solutions and produce Data Domain ETL Scripts.
Uses PowerBI/dashboards to support problem identification and resolution.
Develops and maintains documentation on various operational and design aspects of the Platform. Assist in troubleshooting issues and resolving them.
Builds awareness, increases knowledge and drives adoption of modern technologies, sharing user and engineering benefits to gain buy-in.
Effectively communicates with and influences key stakeholders across the enterprise, at all levels of the organization.
Operates as a trusted advisor for technology, platform, or capability domain, helping to shape use cases and implementation in a unified manner.
Years of Experience: Must have at least 5 years of experience with Microsoft database and BI technologies, including at least 2-3 years of experience with Azure Data Lake Storage, Azure Data Factory, Azure SQL DW, Azure Synapse, Databricks, Spark, and/or Python
Education: Bachelor's degree in computer science or related area OR 8 years of additional experience will be considered in lieu of degree.
Location: Remote within the United States.
Clearance: Ability to obtain a Public Trust security clearance.

Required Technical and Professional Expertise
See below for experience and educational requirements.
Experience defining and implementing strategies for extracting, transforming, and loading data from multiple data sources into analytic data stores.
Knowledge of Cloud Data Analytics platforms
Experience programming in PowerShell, Python, SQL.
Experience with cloud data storage formats such as Parquet, Avro.
Experience with data transformation techniques.
Ability to test data integrity and develop tests and quality checks.
Experience preparing data for various types of data analysis: descriptive, diagnostic, predictive, prescriptive.
Performance analysis and tuning experience
Experience with Data Warehouse or Big Data solutions
Experience with ML models
Experience with data modeling and database design
Strong communication, interpersonal, and collaboration skills working in a team-oriented environment.

Preferred Technical and Professional Expertise
Experience supporting Department of Veterans Affairs (VA) and/or other federal organizations.
Advanced SQL, NoSQL query, and scripting. Experience with Python, Java.
Experience with Azure Data Lake Storage, Azure Data Factory, Azure SQL DW, Azure Synapse, Databricks, Spark, and/or Python
Experience with relational database systems (i.e., DB2, SQL Server) and non-relational databases such as (Azure SQL, Amazon RDBS, MongoDB, Hadoop tools).
Understanding of data design concepts (i.e., data modeling, data mapping, OLTP, and OLAP).
Experience modeling data, message, and service interoperability.
Azure PowerShell knowledge

About Business Unit
IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.

Your Life @ IBM
In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.
Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.
Are you ready to be an IBMer?

About IBM
IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement
IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:

Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
- Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs
Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year.

We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
1008922163828,Glassdoor,$86K,$124K,,
1008921209589,Glassdoor,$98K,$137K,,
1008919197461,Glassdoor,,,http://www.zscaler.com/,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company's cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances.
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler's purpose-built security platform puts a company's defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Position: Principal Data Engineer
Location: Remote within United States
Responsibilities/What You'll Do:
Architect, design, and build large-scale data operations at Zscaler with a focus on scalability, latency, efficiency, standardization, interoperability and fault-tolerance
Work closely with senior leadership, business analysts, & engineering team to strategize and implement data initiatives
Drive technical architecture to accelerate solutions designs. Comprehensive understanding of data integration models, master data management, enterprise data assets and products.
Explore, learn, & recommend new tools & technologies that help the data platform to stay up to date and operate in an efficient way.
Improve, and implement data engineering & analytics engineering best practices. Expert in CICD pipelines, able to mentor and guide others to adoption and use.
Collaborate with Data Engineering, Analytic engineering & BI teams and perform complex data analysis to design physical data models and mappings from business requirements.
Hands on in designing & developing key initiative data pipelines to integrate various applications using supported APIs & model the data in cloud data warehouse to support the reporting requirements.
Perform code reviews, manage code performance improvements, and teach standards for code maintainability.
Solve technical problems of the highest scope and complexity.
Propose ideas to improve the scale, performance, and capabilities of the Data Platform
Qualifications/Your Background:
12+ years of experience in data warehouse design & development
Proficiency in building data pipelines to integrate business applications (salesforce, Netsuite, Google Analytics etc) with Snowflake
Extensive experience in generating architecture recommendations with the ability to implement them
Strong hands-on experience in modern data stack tools like Matillion, DBT
Completely proficient in advanced SQL, Python/Snowpark/PySpark/Scala (any Object Oriented language Concepts), ML libraries.
Must have hands-on experience in Python to extract data from APIs, build data pipelines.
Solid understanding of advanced snowflake concepts like Streams, tasks, warehouse optimizations, SQL tuning/pruning, snowpark
Must have the knowledge of data visualization tools such as Tableau, and/or Power BI
Familiarity with data mesh style architecture
Experience in using data orchestration workflows using open-source tools Apache Airflow, Prefect is a plus
#LI-YC2
#LI-Remote
Zscaler’s salary ranges are benchmarked and are determined by role and level. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations and could be higher or lower based on a multitude of factors, including job-related skills, experience, and relevant education or training.
The base salary range listed for this full-time position excludes commission/ bonus/ equity (if applicable) + benefits.
Base Pay Range
$180,000—$200,000 USD
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support. If you need support, please contact us by sending an email to accommodations@zscaler.com. This email address is used specifically for accommodation requests only, and resumes, CV's, or questions other than accommodations will not be replied to or accepted."
1008918377629,Glassdoor,,,,
1008918496788,Glassdoor,$81K,$126K,http://www.roycetrading.com/,"Why Choose Royce Geo
We're not your typical government contracting company, nor do we want to be. At Royce Geo, we live for building durable and long-lasting relationships with our clients, providing exceptional service with a CAN'T QUIT / WON'T QUIT attitude. We are creating a culture of winning, optimism, FUN, and caring for the person next to you. If you want to work in a real team environment and share the wealth and satisfaction of providing real value to your customer, then this company may be just for you.
Royce Geo prides ourselves in our values-first approach. Our values of Accountability, Attitude, Communication, Innovation, and Leadership are integrated into how we approach problems, guide our interactions with others, and create the framework for our culture. We recognize and reward our team members that champion these attributes.
We offer a competitive benefit package that is designed to attract and retain exceptional talent. We take care of our team members from multiple facets including health, financial, and well-being programs:
Robust health plan including medical, dental, and vision
Health Savings Account with company contribution
Annual Paid Time Off and Paid Holidays
Paid Parental Leave
401k with generous company match
Training and Development Opportunities
Award Programs
Variety of Company Sponsored Events
Summary:
We are seeking an experienced Data Engineer to join our team. As a Data Engineer, you will be responsible for collecting data, interpretation of data for business analysis. Candidates for this position will be able to sift through data, apply statistics, compare data points, and create reports outlining business predictions. The data engineer will provide extensive technical expertise, help businesses make decisions and develop innovative solutions to complex problems. We want innovative problem solvers that are passionate about data and enjoy a challenge. This is a fully remote position.

Responsibilities:
Creates database models and components that meet product specification and development schedules for customer/customers
Participates in large system and subsystem planning
Designs data pipelines, data models, profiling/cleansing the data, and performance tuning.
Develops and maintains data pipelines, data workflows, ETL/ELT scripts or packages.
Prepares comprehensive test plans.
Collaborates and provides influence to team on project deliverables
Acts as a technical resource for lower-level engineers
Researches and integrates design strategies, product specifications, development schedules, and user expectations into product capabilities.
Develops technical designs and specifications for complex data pipelines/data flows for customer/customers.
Uses ETL tools or languages to build, test, and maintain product modules, components, and subsystems.
Creates quality deliverables for customers
Drives full life-cycle of services/solution delivery for project(s)
Oversees technical design, development, and implementation of large projects and/or major data pipelines/data flows and solutions for customer/customers.
Factors emerging technologies and product supportability into design and implementation.
Identifies data quality issues and potential remediations for consideration by PM and/or customer
Identifies data gaps and potential remediation or integration activity for consideration by PM and/or customer
Responsible for services/solution delivery and customer satisfaction of program(s)
Sets strategy and enforces quality assurance program for program and project deliverables
Provides leadership to team members on program and project deliverables
Serves as primary technical resource to development team.
May act as team leader in prioritizing group tasks, determining individual assignments, and reviewing work of lower-level data engineers or other team members.

Required Qualifications:
Active TS clearance is required
Bachelors degree in a relevant field
Minimum 8+ years of experience in the technical field and data solutions
Ability to understand requirements and map them into the existing data environment or create new structures needed
Background developing data solutions and can operate in a fast paced, highly collaborative environment
Experience with SQL, Python, PySpark, leading ETL technologies and approaches
Independent, creative, and determined
Strong SQL and data management experience
Experience with machine learning and statistical analysis
Experience with modern programming languages such as Python
Strong analytical skills with the ability to organize, analyze and prioritize
Experience or exposure to one or more: Redshift, Teradata, Snowflake
Familiarity with Metadata management tools like Immuta / Alation / Collibra is a plus

EEO Statement
Royce Geo. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability. Anyone requiring reasonable accommodations should email recruiting@roycegeo.com or call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days.
Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov)
Please review our current job openings and apply for the positions you believe may be a fit. If you are not an immediate fit, we will also keep your resume in our database for future opportunities."
1008920627656,Glassdoor,,,http://www.guardianlife.com/,"Guardian is seeking a Data Engineer to join the team responsible for establishing and maintaining an optimized, scalable data pipelines to provide access to high quality, consistent data in an easy and convenient manner to all authorized end users and applications of Guardian and its subsidiaries.
As a Data Engineer, you will play a vital role in our data infrastructure and analytics ecosystem. You will work closely with data architects and data scientists to build and maintain data pipelines, transform raw data into actionable insights, and contribute to the development of innovative data solutions. This is an excellent hands-on opportunity to experience the newest technologies and make a significant impact on our data-driven initiatives. The position will integrate new data sources from enterprise sources and external vendors using a variety of ingestion patterns including Structured Query Language (SQL) Ingestion, File, and Application Programming Interfaces (APIs)
You Are:
A self-starter, self-motivated teammate and have superb communication skills, enabling you to engage with all levels of collaborators who is fueled by collaboration, able to transform conceptual designs into reliable, scalable processes that meet or exceed customer needs.
An individual who works closely with IT and business leaders across the enterprise to drive and embed the Enterprise Data Strategy into ground-breaking roadmaps ensuring key principles of Data Governance, Data Management, Data Analytics and Architecture are implemented.
You Will:
Collaborate with multi-functional teams to understand data requirements and translate them into effective data pipelines.
Develop and maintain ETL processes using Python, PySpark, and SQL to extract, transform, and load data from various sources.
Apply Databricks for data processing, analysis, and optimization tasks.
Work with Syncsort to enhance data integration and data quality.
Assist in data modeling, schema design, and database optimization.
Monitor and solve data pipelines to ensure data accuracy, reliability, and performance.
Participate in code reviews, testing, and documentation efforts to maintain high-quality code and data documentation.
Stay updated on industry trends and standard methodologies in data engineering.
Establish and maintain the quality, supportability, and performance of all processes.
Continue to look for innovative and next generation solutions for solving data challenges.
Establish real time data pipelines using AWS services like SQS / SNS and Open-Search
You Have:
5+ Years of IT experience, with 5+ years of experience as a Data Architect, data engineer or other data professional
Expert Relational database concepts and experience across multiple database technologies (e.g., SQL, NoSQL, Oracle, Hadoop, Postgres) environments.
Expert Proficiency in data modeling tools
- preferably Erwin and strong Logical and Physical Data Modeling experience
Hands on experience in data engineering desired with extensive knowledge of SQL and PySpark, on Databricks Platform.
Hands on experience designing, building, and optimizing data pipelines, architecture for large scale data warehousing projects.
Experience with cloud data services such as Redshift, Relational database services (RDS), Snowflake and Databricks.
Knowledge of AWS Data services is a big plus
Demonstrated expertise with data sourcing, profiling, data mapping and data analysis.
Strong SQL, PL/SQL experience and skilled in creating and optimizing queries and data structures.
Knowledge of ETL concepts, preferably Informatica or Syncsort
Experience with one or more SQL-on-Hadoop technology (HIVE, Presto, Spark SQL) and Hadoop ecosystem.
Ability to design cloud and on Prem data solutions and provide guidance across storage, big data platform services, Hadoop ecosystem, vendor SaaS integrations, RDBMS and NoSQL databases is a plus.
Excellent written and verbal communication skills and creative problem-solving skills.
Ability to adapt to changing business priorities and experience with effectively communicating change across different levels in the organization.
Communication Skills: Articulate the vision and goals, both to the team members and other stakeholders.
Emotional Intelligence & Empathy: Motivate, inspire, and resolve conflicts with others while building a positive rapport with team members and partners.
Collaboration: Collaborate optimally with the Product Manager and your leadership and keep appraised with key updates and planning. Encourage partnership between team members to create a more dynamic and effective work environment.
Strong listeners and able to provide constructive feedback.
SAFE experience and the ability to work on a cross functional, self-organizing development teams is a plus.
Significant experience working with both customers and management across business and IT
Location & Travel:
Hybrid remote - 2 Days a week at our Bethlehem, PA office with work from home flexibility.
Up to 10% travel within the NY/NJ/PA locations
Salary Range
$74,560.00 - $122,485.00
The salary range reflected above is a good faith estimate of base pay for the primary location of the position. The salary for this position ultimately will be determined based on the education, experience, knowledge, and abilities of the successful candidate. In addition to salary, this role may also be eligible for annual, sales, or other incentive compensation.
Our Promise
At Guardian, you’ll have the support and flexibility to achieve your professional and personal goals. Through skill-building, leadership development and philanthropic opportunities, we provide opportunities to build communities and grow your career, surrounded by diverse colleagues with high ethical standards.
Inspire Well-Being
As part of Guardian’s Purpose – to inspire well-being – we are committed to offering contemporary, supportive, flexible, and inclusive benefits and resources to our colleagues.
Health Care
Choice of [high deductible/copay] medical plans* with prescription drugs, including coverage for fertility and transgender inclusive benefits
Dental plan
Vision plan
Health care accounts – flexible spending, health reimbursement, and health savings accounts
Critical illness insurance
Life and Disability Insurance
Company-paid Life and Disability insurance plus voluntary supplemental coverage
Accident insurance
Retirement and Financial
401(k) retirement plan with a company match, plus an annual age/service-based Company contribution and an annual profit-sharing contribution, if applicable
Complimentary 1:1 financial guidance with a licensed Fidelity representative
Time Off and Remote Work
Flexible work arrangements (part in-person/part remote)
Unlimited paid time off for most roles plus time off for volunteering, jury duty, voting, and bereavement
Personal holidays for colleagues to use in recognition of religious, cultural, or civic days
Paid parental leave and paid family and medical leave policies
Emotional Well-being and Work-Life
Emotional well-being, mental health, and work/life resources powered by Spring Health
Wellness programs, including fitness program and equipment reimbursement
Child, adult, and elder back-up care support through Bright Horizons
Adoption assistance
College planning
Tuition reimbursement
Student loan assistance
Commuter benefits in select metropolitan areas
Justice, Equity, Diversity & Inclusion (J.E.D.I.)
Employee Resource Groups that advocate for inclusion and diversity
J.E.D.I. certification and training programs
Matching gifts/volunteering
Benefits apply to full-time eligible employees. Interns are not eligible for most Company benefits.
Equal Employment Opportunity
Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law.
Accommodations
Guardian is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. Guardian also provides reasonable accommodations to qualified job applicants (and employees) to accommodate the individual's known limitations related to pregnancy, childbirth, or related medical conditions, unless doing so would create an undue hardship. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact
applicant_accommodation@glic.com
."
1008922101412,Glassdoor,$51K,$73K,http://www.peloton.com/,"Implementation Specialist, Production Data Lifecycle Solutions
Peloton Computer Enterprises Inc. (https://www.peloton.com/)

Peloton is looking to grow our Production Data Lifecycle Solutions team with the addition of Implementation Specialists within our Houston, TX office. The ideal candidates are Petroleum Engineers with at least 2-3 years' relevant experience and a passion for data.

Reports To: US Services Manager, Production Data Lifecycle Solutions

Supervisory responsibilities:
None

Principal Duties and Responsibilities:
Liaise with clients to determine current and future Peloton application requirements and implement the Production Data Lifecycle solution with these requirements in mind.
Develop project plans and coordinate technical implementations and rollout of Peloton applications at client sites.
Work with clients to deliver Peloton specific, customized application training (including train the trainer programs) to be delivered throughout the organization.
Serve as technical resource of escalated technical issues for clients (liaise with Development team if necessary).
Deliver technical excellence presentations at staff meetings / gatherings to transfer knowledge throughout the organization.

Qualifications:
Bachelor of Science in Engineering
Entry to mid-level experience in oil and gas operations with a focus on production accounting systems is a plus
Good understanding of network flow schematics and production allocation
Working knowledge around regulatory filing requirements for production volumes is a plus
Ability to communicate effectively with client and Peloton development team
Ability to manage balance between client business needs and Peloton development capabilities
Excellent oral and written communication skills
Strong problem-solving skills
Proficient in Windows, Microsoft Office and general IT / software installation processes
Understanding of database / reporting technology
Prior knowledge of Peloton applications or competitive products like P2's ProCount, Schlumberger’s Avocet Capture or Landmark’s TOW is a strong plus
Occasional travel will be required to client locations (up to 30% of the time)

As part of our team you’ll enjoy:
Exceptional benefits package
Vacation & Paid Time Off
Retirement benefit with employer contribution

About Peloton
The Peloton Platform energizes the oil and gas digital transformation through mobility, automation and data integration by providing fully integrated well data lifecycle, production data lifecycle and land data management solutions. Today, over 600 oil and gas clients worldwide rely on Peloton technology to equip their stakeholders with the tools and information necessary to manage, simplify and optimize their operations. For more information, visit www.peloton.com.

By submitting your job application, your confirm that you agree to the storing and processing of your personal data by Peloton as described in our Privacy Policy."
1008918489720,Glassdoor,,,https://www.insight.com/en_US/home.html,"Senior Data Engineer

Insight’s diverse, full-time team of experts combine innovative thinking with breakthrough-technologies to progress further, faster. Our Digital Innovation team is seeking a passionate Data Engineer to join our team in leveraging modern technology to tackle complex challenges and help our clients be the disrupters, not the disrupted.

On our team, you’ll work with smart, driven teammates and client stakeholders on high impact projects leveraging cutting-edge technology to solve meaningful business problems. At Insight, diversity and inclusion is critical to our success in designing, building, and implementing next-generation solutions. Our teammates bring unique life experiences, viewpoints and backgrounds that makes our team stronger. As a full-time, permanent team member with a competitive benefits plan, you’ll be inspired to grow in a supportive environment where you can be creative and stay on the forefront of technology.

What You’ll Do
Design and develop cutting-edge enterprise data solutions in a fast-paced environment
Lead discussions with clients and recommend technical solutions for business cases
Design and code modern solutions to tough data challenges leveraging the cloud
Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externally
Prioritize, self-direct and execute at velocity
Aggressively grow your skillset and expertise to meet emerging needs

What We Look For
Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity
1+ year of experience in some of the following:
Cloud: Azure SQL Database, Azure SQL Data Warehouse and Azure Data Factory
Azure Big Data Technologies: Azure Data Lake and Azure Data Lake Analytics
Big Data Technologies: Databricks, Spark, Hadoop or HDInsight, Hive, Pig, Python, Oozie
Predictive Analytics: R, Python, Azure Machine Learning
Scripting: PowerShell, Azure Automation
Development Languages: .NET, Java or Scala
3+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:
SQL Server
Analysis Services (SSAS) and DAX
Reporting Tools: Power BI, Tableau, Qlik, SSRS
Integration Services (SSIS)
Strong analytical and reasoning skills that result in clear technical execution
Skill at translating requirements into clean, efficient, quality code
Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team
Alignment with our values of hunger, heart, and harmony

What can Insight offer?
You’ll join a team of proven professionals who are curious and encouraging, ensuring you continue developing your skills while working consistently to deliver value to our clients. You’ll collaborate with teammates across our areas of expertise, including Cloud Enablement, DevOps, Data & AI, Modern Applications, Digital Strategy, IoT & Smart Edge, and Transformation Services. We’ll invest in your professional development and provide a clear path for career advancement. You’ll also receive great benefits like flexible vacation, 401k matching, and a quarterly bonus program.

Ready to join? Discover more at insight.com…or just APPLY!

About Insight
Insight Enterprises Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of Digital Innovation, Cloud + Data Center Transformation, Connected Workforce, and Supply Chain Optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our teammates help clients innovate and optimize their operations to run business smarter.
Fortune 100 Best Workplaces for Diversity
Fortune Top 50 Best Workplaces in Technology
Winner of several “Best Places to Work” awards
Fast Company recognizes Insight in World Changing Ideas Awards for social good
30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019

Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.

The position (or opportunity) described above provides a summary of some the job duties required and what it would be like to work at Insight.

Compensation: $100-110k Base Salary + Bonus"
1008918337910,Glassdoor,$83K,$122K,http://www.icubecsi.com/,"Life at ICUBE CSI
Are you interested in working with a startup in cutting edge Technology space ?
Are you excited about Artificial Intelligence, Machine Learning, Data Analytics ?
Come join our ICUBE CSI team! Our team comes from all over the world with backgrounds in different types of industries. We are building a close knit team and meaningful culture.
Our benefits: We’re happy when you’re happy. To make this happen, we offer competitive compensation, big-company benefits and a startup culture with vibrant energy and cool perks of a startup.
Health care (medical and dental)
401k/Retirement Benefits
Life/LTD Insurance
Flexible schedules
Paid time off
Training & development
Fun, diverse and intellectually eager coworkers
Team happy hours and retreats
Workplace perks such as food/coffee
We are building innovation around Data Analytics, Data Management using open source technologies. Our company thrives on selling big data analytics solutions. Our in-house advanced big data analytics team comes with backing of its leadership team with 100+ combined years of experience in data engineering, data processing, infrastructure designs, machine learning and visualization. We are an equal opportunity employer.
Everyone can push forward in good times and when all is going perfectly as planned. But when it doesn’t go perfectly, you’re ready to attack problems head on. Business isn’t always easy, but you’re known for being there through thick and thin.

Responsibilities:
Design, Develop and Implement Big data engineering projects in Hadoop ecosystem.
Engineer solutions with Cloudera, MapR or HDP for both batch & streaming data with high quality and with a sense of urgency.
Develop application and custom integration solutions using spark streaming and Hive.
Understand specifications, plan, design and develop software solutions, adhering to process – either individually or collectively within a project team
Work in state-of-the art programming languages and utilize object-oriented approaches in designing, coding, testing and debugging programs.
Work with support teams in resolving operational & performance issues
Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities
Integrate data from multiple data sources, Implementing ETL process using APACHE NIFI
Monitoring performance and advising any necessary infrastructure changes
Management of Hadoop cluster, with all included services such as Hive, HBase, mapReduce and Sqoop
Cleaning data as per business requirements using streaming API’s or user defined functions.
Build distributed, reliable and scalable data pipelines to ingest and process data in real-time, defining Hadoop Job Flows.
Managing Hadoop jobs using scheduler.
Apply different HDFS formats and structure like Parquet, Avro, etc. to speed up analytics.
Work with various hadoop ecosystem tools like Hive, pig, Hbase , spark etc.
Reviewing and managing Hadoop log files.
Assess the quality of datasets for a hadoop data lake.
Fine tune Hadoop applications for high performance and throughput.
Troubleshoot and debug any Hadoop ecosystem run time issues.
Being a part of a POC effort to help build new Hadoop clusters
Education:
Bachelor’s Degree or higher in Computer Science, Information Systems or related engineering disciplines
General Knowledge, Skills & Abilities
Be a good detail-oriented data engineer
Systematic and organizational skills important.
Willing to commit for completing deliverable on time.
Preferred Qualifications:
Must have experience with Spark, Hive, Scala or py spark.
Preferred experience in one of the following technologies: Nifi, Kafka, or any other streaming technologies.
3+ years experience in data engineering building ETL pipelines using JAVA or Python or Scala
Should be good at Pig, HIVE scripting.
Solid understanding of HDFS is important.
Work experience within a Data Warehousing/Business Intelligence/Data analytics group, and have hand’s-on experience with Hadoop
Create tables/views in Hive or other relevant scripting language
Have experience with Agile development methodologies
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB.
Experience Architecting Solutions Utilizing any of the following:
JAVA or Python or Scala programming languages
Nifi, Kafka-topics, or any other streaming technologies
Parquet/Avro/ORC/XML/JSON/ORC/CSV/TXT formats
Location: Jacksonville, FL
Send your resumes to careers@ICUBE CSI.com"
1008921129938,Glassdoor,,,,"As the Data Platform Engineer, you will use your significant experience in Microsoft Azure to design and set up projects that combine information from various sources to enable analysis and decision-making as well as play a key role in implementing scalable and secure solutions that meet specific business requirements. Candidates must be able to work EST and travel to the DC area monthly to bimonthly.
Skills:
Develop Python code to ingest and transform Excel data, perform calculations, and check data quality.
Troubleshoot and resolve issues related to ingesting and preparing data for visualization.
Develop, test, and maintain production-level data pipelines running on a laptop and in the cloud.
Support code refactoring to improve pipeline efficiency.
Maintain data analytics (NLP, text classification, time series & forecast models).
Plan and deliver data warehouse and storage.
Design and run data services for individual projects.
Design, develop, adapt, and maintain data warehouse architecture and relational databases to support data mining.
Customize storage and extraction, meta-data, and information repositories.
Create and use effective metrics and monitoring processes.
Monitor key performance indicators to determine where current data operations can be improved.
Create the building blocks for transforming enterprise data solutions.
Design and build modern data pipelines, data streams, and data service APIs.
Create/maintain report forms and formats, information dashboards, data generators, scanned reports, and other information portals and resources.
Excellent written and verbal communication skills in English.
Qualifications:
Minimum 5 years of work experience.
BS in Computer Science, Applied Mathematics, Statistics, or Machine Learning (or +3 years).
3 years of experience as an Azure or AWS Data Engineer in technology consulting.
3 years of experience performing data engineering, warehousing, publishing and visualization throughout the full data lifecycle.
1 year of experience defining ETA architecture and ETL process design.
2 years of experience performing end-to-end implementation of data warehousing analytics solutions built on MS or Azure platforms.
2 years of experience with Python, Databricks, Azure Synapse, SQL Server, Azure Data Lake, and/or Azure Data Factory (ADF).


About Harvard Partners, LLP, Trusted Advisors to IT:

Harvard Partners is a management consulting firm focused on helping companies more effectively leverage their IT investment. We engage with the C-Suite and Technology Team to help them better understand their IT infrastructure and process in order to align the technology strategy and organization to reach the firm’s strategic business goals.Some of our practices include:• Program/Project Management and ""PMO as a Service""• IT Assessments• Business Continuity/Disaster Recovery• Optimized Infrastructure• Concierge Managed Services• Data Center Strategy, Transformation, and Migration• Cloud Management Programs• Security Assessments and Remediation• Staffing, technical & tacticalWorking with the client’s staff, vendors, and consultants, we deliver supportive and collaborative engagements where direct dialog, simplified reporting, productive meetings, and clear responsibility and accountability encourage active participation resulting in consensus-based business outcomes."
1008918696975,Glassdoor,$81K,$121K,http://www.cookchildrens.org/,"Location:
Rosedale Office Building
Department:
IS Epic
Shift:
First Shift (United States of America)
Standard Weekly Hours:
40
Summary:
The Data Engineer Senior is an experienced data professional who analyzes, architects and engineers data pipelines and data integration activities to power data products and support the overall Knowledge Management and Data Operations mission at Cook Children’s.
This role is responsible for data engineering activities including data pipeline design, data ingestion, data integration, data cleansing, data mapping, data store architecture, data transformation, tuning, testing, and data quality. This role actively drives the expansion of the Cook data platform through data flow development, workload management, data architecture/structures/schemas, orchestration and metadata/lineage. The Data Engineer Senior partners with Business Intelligence developers and analysts to design robust, scalable data pipelines and data architectures that power reports, dashboards, integrations and advanced analytics products/capabilities while enabling rapid experimentation. This positon interfaces with business customers and bridges the gap between business and technology solutions throughout the data product lifecycle to ensure that technical solutions meet the needs of the business.
The Data Engineer Senior has strong expertise with SQL, data modeling (relational and/or data warehouse context), and ETL/ELT development. They have familiarity with modern cloud-based data platforms (data lake, data warehouse), cloud data integration technologies, business intelligence tools (Power BI, Tableau, etc.), and at least one modern programming language (Python, Scala, Java, etc). They have demonstrated experience aligning data architectures with business requirements and building data pipelines that interface well with on premise systems/applications as well as modern data sources (APIs, web data sources, real-time/streaming, unstructured data, etc.). They have excellent analytical skills and have demonstrated success in succinctly conveying complex data concepts for storytelling and to influence decision making.
The Data Engineer Senior is seen as an experienced leader and mentors less experienced data engineers, effectively sharing knowledge and best practices.
Qualifications:
High school diploma or GED required.
Bachelor’s degree in Computer Science, Engineering, Management Information Systems (MIS), Business or related/relevant degree AND minimum of 5 years of experience as a Data Engineer, Database Developer, BI Developer, Software Engineer, Programmer, Technical or Systems Analysts, and/or Database Administrator preferred.
OR - Minimum of 7 years of experience as a Data Engineer, Database Developer, BI Developer, Software Engineer, Programmer, Technical or Systems Analysts, and/or Database Administrator required.
Minimum of 5 years of experience in Information Technology required.
Minimum of 2 years of experience in a Health Care environment preferred. Knowledge and Experience
Demonstrated strength in SQL coding, data integration, data modeling, data pipeline and ETL/ELT design and development.
Data lake and data warehouse experience including: end to end data warehousing methodology, relational and dimensional design/modeling, architecture, implementation, security, and support/maintenance
Coding proficiency in at least one modern programing language (Python, Scala, Java, Spark, etc.) preferred.
Strong experience with modern data ingestion and transformation technologies such as Fivetran, Stitch, dbt, etc as well as traditional data integration/management tools such as SSIS, Informatica, etc.
Experience with cloud data lake/data warehouse technologies such as Snowflake, Azure Synapse, AWS Redshift, etc. preferred.
Demonstrated experience identifying opportunities to simplify and automate tasks while building reusable components across multiple use cases.
Experience with Agile, DataOps delivery methodologies
Comfortable with ambiguity, experimentation and rapid iteration.
Proven experience with business and technical requirements elicitation, analysis and verification.
Experience working with structured, semi-structured and unstructured data preferred.
Experience working with healthcare specific applications and data systems (Electronic Health Record, imaging systems, pharmacy systems, etc.), business systems (ERP, CRM, etc.) and digital platforms preferred.
Licensure/Certification:
Epic certification(s) a plus, and may be required upon hire or within six months of hire date based on the primary responsibilities/focus of the role.
Preferred Epic certification(s) include Cogito Systems Administration, Caboodle-Clarity Development, Caboodle Development, Clarity Data Model, Clinical Data Model, Revenue Cycle Data Model, Access Data model, and/or Caboodle Data Model.
Snowflake and/or Microsoft certification(s) a plus
About Us:
Cook Children's Health Care System
Cook Children's Health Care System offers a unique approach to caring for children because we are one of the country's leading integrated pediatric health care delivery organizations. Patients benefit from the integrated system because it allows Cook Children's to use all of its resources to treat a patient and allows for easy communication between the various companies by physicians with a focus on caring for children and adolescents.
Cook Children's is an EOE/AA, Minority/Female/Disability/Veteran employer."
1008923091302,Glassdoor,$76K,$111K,http://www.ornl.gov/,"Requisition Id 11602

Our Organization:
As a U.S. Department of Energy (DOE) Office of Science national laboratory, ORNL has an extraordinary 80-year history of solving the nation’s biggest problems. We have a dedicated and creative staff of over 6,000 people! Our vision for diversity, equity, inclusion, and accessibility (DEIA) is to cultivate an environment and practices that foster diversity in ideas and in the people across the organization, as well as to ensure ORNL is recognized as a workplace of choice. These elements are critical for enabling the execution of ORNL’s broader mission to accelerate scientific discoveries and their translation into energy, environment, and security solutions for the nation.

ORNL is home to Frontier, the world’s fastest and first exascale supercomputer—providing an open science environment to develop solutions that touch us all. With direct access to Frontier, we can simulate and engineer solutions that only exascale computing can enable.

The Analytics and AI Methods at Scale Group (AAIMS) at the Oak Ridge National Laboratory is seeking qualified and driven applicants for a Machine Learning Data Engineer position for the broad area of AI for science projects. The research and development activities include but not limited to: scientific data collection, transformation, feature engineering, large-scale natural language modeling and understanding etc. In this role, you will have the opportunity to work on some of the most challenging and impactful research and development, and collaborate with both computer scientists and domain scientists to build end-to-end data and ML pipeline/services to facilitate and expedite the ML-assisted scientific discovery process.

As a Machine Learning Data Engineer, you should be comfortable around Linux, SQL, Python, containers, Pandas, Spark, and source control in a highly collaborative environment.

Major Duties and Responsibilities:
Mobilizing and leading data analysis activities on projects with a focus on common deliverables, goals and timelines, including data preparation, transformation, feature engineering etc. in collaboration with scientists and engineers.
Research and evaluate emerging technologies and approaches from the broader ML community.
Evaluate and deploy scalable AI frameworks, tools, and execute them on high-performance computing (HPC) resources, in close collaboration with research staff and computing technical staff.
Troubleshoot data analysis issues, including implementation issues, hyperparameter choices, and modeling decisions.
Quickly and clearly summarize analyses, following best practices in documentation, data visualization, and provenance tracking for reproducibility.
Assist in preparation of manuscripts and dissemination of research results in publications and conferences.
Develop high-quality Python code following best practices in the community; manage code and data through version control systems and community hub such as HuggingFace.

Basic Qualifications:
B.S. and 2+ years of relevant experience or an M.S. and 1+ year of relevant experience.
Degree concentration should be in Computer Science/Engineering or closely related field.
Experience with Python for data science.
Experience with PyTorch and/or Tensorflow.

Preferred Qualifications:
Understanding of supervised and unsupervised learning, reinforcement learning, and deep learning.
Experience of CUDA programming.
Experience of MPI programming, and collective communication primitives.
Applied research experience in at least one machine learning discipline such as natural language processing, image processing and classification or related areas.
Excellent communication skills for conveying technical material to both scientists and non-scientists in both written and oral presentations.
Self-disciplined work ethic and eagerness to tackle challenging research problems.
Ability to communicate and work on diverse and interdisciplinary teams.

Benefits at ORNL:
ORNL offers competitive pay and benefits programs to attract and retain talented people. The laboratory offers many employee benefits, including medical and retirement plans and flexible work hours, to help you and your family live happy and healthy. Employee amenities such as on-site fitness, banking, and cafeteria facilities are also provided for convenience.

In addition, we offer a flexible work environment that supports both the organization and the employee. A hybrid/onsite working arrangement may be available with this position.
Other benefits include: Prescription Drug Plan, Dental Plan, Vision Plan, 401(k) Retirement Plan, Contributory Pension Plan, Life Insurance, Disability Benefits, Generous Vacation and Holidays, Parental Leave, Legal Insurance with Identity Theft Protection, Employee Assistance Plan, Flexible
If you have difficulty using the online application system or need an accommodation to apply due to a disability, please email: ORNLRecruiting@ornl.gov or call 1.866.963.9545.

#LI-KC1

This position will remain open for a minimum of 5 days after which it will close when a qualified candidate is identified and/or hired.
We accept Word (.doc, .docx), Adobe (unsecured .pdf), Rich Text Format (.rtf), and HTML (.htm, .html) up to 5MB in size. Resumes from third party vendors will not be accepted; these resumes will be deleted and the candidates submitted will not be considered for employment.

If you have trouble applying for a position, please email ORNLRecruiting@ornl.gov.

ORNL is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. UT-Battelle is an E-Verify employer."
1008918619296,Glassdoor,$92K,$141K,http://www.manteksolutions.com/,"Job Summary:
Under the direction of Director – Data Engineer, the Senior Data Engineer works closely with business leaders, managers, staff and vendor to accurately gather and interpret requirements, specifications. Develop technical specifications and recommend, design, develop, test, implement, and support innovative and optimal data solutions. Serves as a coach and mentor to Data engineering team
Skills and Abilities:
1. Be able to consult on complex data engineering efforts and lead project teams through the solution design process
2. Be able to teach and mentor to less-experience technical team members.
3. Ability to compliance with standards and procedures such as standard of communication, work management, change management, version control, implementation and/or consistency of coding. Recognizes code, process and/or standard inefficiencies and suggests new standards and opportunities for improvement.
4. Ability to build and integrate a data-driven intelligent solution into our business processes. Manage the innovation development processes, and be responsible for driving the data architecture for the company's products and IT processes.
5. Ability to research, evaluate and formally recommend third party software and technology package
6. Keep big picture concepts in mind when designing solutions; fully understand business needs
7. Strong experience on database technologies, data warehouse, data validation, data quality, metadata management and data governance
8. Providing proactive technical oversight and advice to application architecture and development teams fostering re-use, design for scale, stability, and operational efficiency of data/analytical solutions
9. Knowledge of and experienced in rolling out best practices in all facets of DW architecture, data flow strategy, data modeling, metadata and master data management.
10. Ability to interact and develop relationships with all levels of personnel and management.
Physical Requirements:
1. Ability to sit, stand, lift (up to 20 lbs), bend, and walk, as required, for carrying out the duties of position
2. May require travel to sites/program and special functions Environmental Conditions Critical to Performance:
1. Work is based in an office environment, climate controlled through central air conditioning
2. May be required to attend off site meetings and other related functions"
1008923514633,Glassdoor,$84K,$112K,http://www.steampunk.com/,"Overview:
In today’s rapidly evolving technology landscape, an organization’s data has never been a more important aspect in achieving mission and business goals. Our data exploitation experts work with our clients to support their mission and business goals by creating and executing a comprehensive data strategy using the best technology and techniques, given the challenge.

At Steampunk, our goal is to build and execute a data strategy for our clients to coordinate data collection and generation, to align the organization and its data assets in support of the mission, and ultimately to realize mission goals with the strongest effectiveness possible.

For our clients, data is a strategic asset. They are looking to become a facts-based, data-driven, customer-focused organization. To help realize this goal, they are leveraging visual analytics platforms to analyze, visualize, and share information. At Steampunk you will design and develop solutions to high-impact, complex data problems, working with the best and data practitioners around. Our data exploitation approach is tightly integrated with Human-Centered Design and DevSecOps.
Contributions:
Steampunk wants you to join our awesome team as a Senior Data Visualization Engineer. In this role you'll be working with a large team of Steampunk and clients to identify data sources, tools, and mission challenges that can all be brought together to create decision-supporting insights and information. Your main goal in this work is to use the data that we have as a team and client base to provide meaningful information and representations of data to enable our client to make better and quicker decisions. We are looking for more than just a ""Senior Data Visualization Engineer"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.

Will be a Subject Matter Expert supporting a major federal agency and will be responsible for creating visually appealing and operationally impactful dashboards and reports. This impactful work will translate our client's data into actionable insights
Use expert knowledge of data visualization tools to deliver information that allows client users to quickly understand data, ask better questions, and take action
Design, develop, and deliver analytics solutions with consideration for functionality, data, security, integration, infrastructure, and performance
Collaborate with clients and stakeholders
Help define enterprise data and technology needs to support business intelligence and analytics
Facilitate meetings with diverse and sometimes conflicting points of view
Support an Agile software development lifecycle
You will contribute to the growth of our Data Exploitation Practice!
Qualifications:
US Citizen Only
Ability to hold a position of public trust with the US government.
8+ years experience with a Bachelor's Dergee or 6+ years of experience with a Master's Degree
5+ years of experience in designing, developing, and configuring data visualizations for different types of users
5+ years of experience primarily using QLIK but potentially other s like Tableau and Power BI to create and develop robust reporting applications
5+ years of experience with data management disciplines including data governance, data architecture, data modeling, data integration, and data quality
Ability to lead or participate in business sessions to identify and document analytic use cases
Ability to be a self-starter, take ownership of opportunities, work independently, and manage simultaneous projects
Excellent written and verbal communications skills with the ability to explain advanced concepts to audiences of varying levels using simple terms
About steampunk:
Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program."
1008924013121,Glassdoor,,,http://www.amazon.jobs/,"5+ years of data engineering experience
Experience with data modeling, warehousing and building ETL pipelines
Experience with SQL
Experience in Big data engineering including EMR/Spark/HUDI & Scala & Airflow
The Accounting BI team supports the global Accounting organization with process automation/improvements, developing automated reporting solutions/tools, and improving the ability of the accounting organization to process, analyze, access and consume accurate and timely financial data. The team supports the global accounting organization and partners closely with all technical roles across the org and various businesses and industries Amazon operates in.

The ideal candidate thrives in a fast-paced environment, relishes working with ambiguity, big data, and enjoys the challenges of highly complex business context. This role requires an individual with excellent analytical abilities, deep knowledge of business intelligence solutions, and the ability to quickly learn, adapt and work with a variety of technologies.

Responsibilities of this position include:
Working with stakeholders and other engineering teams to identify and scope the right data architecture and technology to be used to facilitate analysis of most common Amazon customer behavioral questions.
Partnering with partner engineering teams to enhance data infrastructure, data availability, and broad access to customer insights made available through BI tools across the organization.
Design, build and implement the right ETL processes using AWS and similar technologies.
Implement anomaly detection systems to have a proactive approach to any potential data quality issues, using industry standard frameworks.
Enable large scale analytics using EMR and other big data technologies
Establishing and implementing technology best practices that should be followed across the organization.
Work on proof of concepts for adoption of new technology and tools
We are open to hiring candidates to work out of one of the following locations:

Arlington, VA, USA | Seattle, WA, USA

Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $105,700/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site."
1008918724920,Glassdoor,$67K,$91K,http://www.sncorp.com/,"Are you ready to apply your technical creativity? Dream, Innovate, Inspire and Empower the next generation to transform humanity through technology and imagination! As a Data Engineer I you'll design, develop, document, test, and debug new and existing cloud-based data pipelines and transformations. You will participate in design meetings and consult with business clients to develop processes and structures that ingest data from multiple sources into our cloud-based Enterprise Data Warehouse (EDW). Within the EDW, you will use a variety of tools to implement data integration, master data management, data lifecycle management, data security, data quality management, metadata management, and reporting and analytics. Additionally, you will perform defect corrections (analysis, design, code).
The Mission Solutions and Technologies (MST) business area provides affordable, turn-key command/control, communications, integrated ISR, force protection and security solutions worldwide. The MST team has a long legacy of supporting the Department of Defense, Department of Homeland Security, commercial and international customers with years of experience in platform operations, engineering and full lifecycle management across domains – air, land, sea, space and cyber. Learn more about MST

Must-haves:
Bachelor's Degree in a related field with at least 0-2 or more years of relevant experience
Higher education may substitute for relevant experience
Relevant experience may be considered in lieu of required education
Working SQL knowledge and experience working with relational databases
Experience with cloud-based data platforms such as AWS, Azure
Preferred:
Experience building data pipelines, architectures and data sets
Experience performing root cause analysis on data to answer specific business questions or issues
Experience with AWS cloud services: S3, EC2, RDS, Redshift, Glue, Lambda, Step Functions, Athena, CloudWatch, ECS, IAM
Experience with AWS security: best practices, AWS KMS, AWS Secrets Manager
Experience with object-oriented scripting languages and frameworks: Python (BOTO3), PySpark, Java, etc
Source system integration patterns (SQL, APIs)
Operational responsibilities (schedules, monitoring, logging, alerting, error handling, etc.)
Master Data Management (MDM) Solution experience
DevOps experience
At Sierra Nevada Corporation (SNC) we deliver customer-focused technology and best-of-breed integrations in the aerospace and defense sectors. SNC has been honored as one of the most innovative U.S. companies in space, a Tier One Superior Supplier for the U.S. Air Force, and as one of America’s fastest-growing companies. Learn more about SNC
#LI-HYBRID #LI-REMOTE
SNC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with 150% match up to 6%, life insurance, 3 weeks paid time off, tuition reimbursement, and more.
IMPORTANT NOTICE:
This position requires the ability to obtain and maintain a Secret U.S. Security Clearance. U.S. Citizenship status is required as this position needs an active U.S. Security Clearance for employment. Non-U.S. citizens may not be eligible to obtain a security clearance. The Department of Defense Consolidated Adjudications Facility (DoD CAF), a federal government agency, handles the adjudicative aspects of the security clearance eligibility process for industry applicants. Adjudicative factors which affect the outcome of the eligibility determination include, but are not limited to, allegiance to the U.S., foreign influence, foreign preference, criminal conduct, security violations and illegal drug use.
Learn more about the background check process for Security Clearances.
At Sierra Nevada Corporation (SNC), our mission is to dream, innovate, inspire and empower the next generation to transform humanity through technology and imagination. As an Equal Opportunity Employer, we welcome our employees to bring their whole selves to their work. SNC is committed to fostering an inclusive, accepting, and diverse environment free of discrimination. Employment decisions are made without regarding to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran or other characteristics protected by law. Contributions to SNC come in many shapes and styles, and we believe diversity in our workforce fosters new and greater ways to dream, innovate, and inspire."
1008920812110,Glassdoor,$74K,$110K,http://www.tifin.com/,"WHO WE ARE:
TIFIN is a fintech platform backed by industry leaders including JP Morgan, Morningstar, Broadridge, Hamilton Lane, Franklin Templeton, Motive Partners and a who's who of the financial service industry. We are creating engaging wealth experiences to better financial lives through AI and investment intelligence powered personalization. We are working to change the world of wealth in ways that personalization has changed the world of movies, music and more but with the added responsibility of delivering better wealth outcomes.
We use design and behavioral thinking to enable engaging experiences through software and application programming interfaces (APIs). We use investment science and intelligence to build algorithmic engines inside the software and APIs to enable better investor outcomes.
In a world where every individual is unique, we match them to financial advice and investments with a recognition of their distinct needs and goals across our investment marketplace and our advice and planning divisions.
OUR VALUES: Go with your GUT
Grow at the Edge. We are driven by personal growth. We get out of our comfort zone and keep egos aside to find our genius zones. With self-awareness and integrity we strive to be the best we can possibly be. No excuses.
Understanding through Listening and Speaking the Truth. We value transparency. We communicate with radical candor, authenticity and precision to create a shared understanding. We challenge, but once a decision is made, commit fully.
I Win for Teamwin. We believe in staying within our genius zones to succeed and we take full ownership of our work. We inspire each other with our energy and attitude. We fly in formation to win together.
WHAT YOU'LL BE DOING:
A division of TIFIN, TIFIN.AI is dedicated to conceiving and developing TIFIN's second cohort of AI-powered fintech companies and ushering in a new phase of fintech innovation in wealth management. Use cases for these AI capabilities, primarily conversational AI assistants, include client portfolio insights for advisors, alternative investing, wealth management in the workplace, and insurance among others.
Leveraging our experience with the previous cohort, TIFIN.AI has refined a template for repeatable innovation that bolsters efficiency and leads to a shorter time to market for new innovations. That template includes building MVPs in 3 months with production-ready products in 6-12 months with real-time feedback from an ecosystem of industry professionals.
TIFIN. AI is seeking a Senior Data Engineer with experience working on an AI/ML-based product team. The ideal candidate has experience building data pipelines in AWS and is passionate about innovating in the fintech and AI space. The AI-based products center primarily around conversational AI assistants and personalization with applications across different themes and user groups. We are looking for a creative thinker who can be hands-on with early-stage projects building 0-1.
You must be a motivated and tenacious self-starter who is comfortable interpreting technology requirements, based on business requirements, and implementing them with maximum impact on the users. You will be expected to develop technology that minimizes technical debt while maximizing the customer experience. This is a high-impact role on a lean team that is results-and execution-oriented. We are a team of do-ers!
THE ROLE:
Participate in architectural, design, and product sessions and be a crucial part of the decision-making process on overall technology direction
Work closely with Product, Design, and other Devs to build customer-facing features
Integrate with a wide array of tools and services via API
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies like Redshift and Glue
Assemble, splice, and merge large, complex data sets that meet functional / non-functional business requirements
Develop event streaming architecture to load data into a Customer Data Platform
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Create datasets for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Work with stakeholders, including the Executive, Product, Data, and Design teams, to assist with data-related technical issues and support their data infrastructure needs
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions
Manage technical optimization for maximum speed and scalability
Help shape company and engineering culture as an early stage hire
WHO YOU ARE:
Degree in Computer Science, related field, or equivalent experience
3+ years of increasing responsibility in backend and data engineering roles
Real-world experience developing highly scalable solutions designed to democratize data to everyone in an organization
Strong coding skills in Python
Experience designing and building ETL pipelines
Expertise in various big data technologies, both open source and cloud native, AWS preferred (Kinesis, Athena, PySpark, Airflow)
Ability to work comprehensively with various databases (Postgres, SQL, MongoDB, Pinecone etc.)
Expertise in data model design with sensitivity to usage patterns and goals – schema, scalability, immutability, idempotency, etc.
Track record of choosing the proper transit, storage, and analytical technology to simplify and optimize the user experience
Ability to thrive in a highly demanding, entrepreneurial, and fast-paced environment
Highly flexible, good tolerance for ambiguity, and able to quickly adapt to changing priorities
A top performer with a proactive approach who has a ""doer"" & problem-solver mentality
An exceptional team player with strong communication skills
A local presence in Denver or Boulder is preferred
COMPENSATION AND BENEFITS PACKAGE:
For Colorado Applicants: The expected starting salary range for this position in Colorado is between $120,000 - $160,000. Applicable salary ranges may differ across markets. Actual pay will be determined based on experience and other job-related factors permitted by law. The position is also eligible for incentive compensation as well as client acquisition bonus program.
TIFIN offers a competitive benefits package that includes:
Performance linked variable compensation, including equity
Medical, dental, vision, life and disability insurance
Flexible Spending Account (FSA) and Health Savings Account (HSA)
401(k) Retirement Plan
Flexible PTO policy and Company-paid holidays
Parental Leave: 12 week paid maternity, 4 week paid paternity leave
Corporate Social Responsibility and volunteering opportunities
Access to our Chief Mindfulness Officer, including 1:1 personal coaching for executives and rising stars
Company sponsored events like Qi Gong, Lunch & Learns, Development Workshops, Dinners, Happy Hours, and more!
The ability to make a real impact in an incredibly fast-growing organization
A note on location. While we have team centers in New York City, San Francisco, Charlotte, and Mumbai, TIFIN is headquartered in Boulder, CO and our preference is to build the team here whenever possible, so relocation packages are available for any candidate willing to relocate to the Boulder area.
TIFIN is proud to be an equal opportunity workplace and values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status."
1008918440227,Glassdoor,$72K,$104K,http://cardamom.health/,"Remote
Your Role:
As part of the Delivery Team in Data Services at Cardamom, you will design and develop cloud-based data lakehouse, warehouse, and platform solutions to support the data, analysis, and reporting needs of our clients. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate disparate data from multiple sources.
As a Senior Snowflake Data Engineer at Cardamom, you will:
Provide outstanding customer service through listening to make sure customer needs are understood, building relationships with customers up to director level, and providing timely updates with the right level of detail to each audience
Build relationships and communicate engagement accomplishments, plan, and challenges to manager and director-level client counterparts
Develop ETL/ELT data pipelines to load data from various data sources to the staging database and apply complex business logic to populate normalized and denormalized data structures
Develop data pipelines to handle integration of disparate data types such as flat files, XML/JSON, API, unstructured data into Snowflake cloud services
Seek business and technical requirements from enterprise data architect and business stakeholders to accurately build required data pipelines, data definitions, and analytical data models
Build reusable components for a scalable data integration methodology such as error handling, logging, and recoverability
Review end-to-end pipelines for performance and cost efficiency of the overall data services
Travel occasionally dependent on client requirements (up to 10%)

Our ideal Senior Snowflake Data Engineer will have:
3+ years of required Snowflake experience
SnoPro Core or SnoPro Advanced required certification
Strong SQL skills for complex queries
Familiarity with the software development lifecycle
Proficiency in database development (OLTP and Data Warehouse/Dimensional)
ETL/ELT process experience
Competence in complex, distributed, and massively parallel systems
Excellent analytical and problem-solving abilities, including algorithm representation in software
Deep understanding of data structures and algorithms
Expertise in integrating and modeling healthcare data such as clinical, claims, genomics datasets

Bonus points for experience with the following:
Snowflake Cloud Data Warehouse ELT tools
ML frameworks and libraries including TensorFlow, Spark, PyTorch, and MLPACK
BI tools
Amazon Web Services, Microsoft Azure, or Google Cloud

What do we offer to ideal candidates?
To learn more about Cardamom's culture and the benefits and overall work experience we provide, visit our Careers page."
1008918314745,Glassdoor,$69K,$105K,http://www.polarsemi.com/,"The Database Engineer is a member of the IT Team at Polar Semiconductor LLC (PSL) and is essential to the development, implementation and maintenance of new database objects, data entity relationships and associated documentation.
Main responsibility will be to update and enforce/add data integrity constraints and relationship on Manufacturing databases. This position is also responsible to work with developers, business analysts and key business users to evaluate business data and determine the ideal data structures to store, retrieve and present data. Duties include but are not limited to supporting, designing, archiving, tuning and optimizing an internally developed Manufacturing Execution Systems (MES) Microsoft SQL database(s). Assists in data transformations used in integrating PSL’s MES to supporting systems.
Responsibilities:
Design and implement logical and physical data models and work closely with application developers to create and implement new features.
Design and support complex queries used to present meaningful reports to end users.
Create stored procedures, functions, views, tables and triggers using SQL, T-SQL.
Examine and identify database structural necessities by evaluating client operations, applications, and programming.
Monitor the system performance by performing regular tests, troubleshooting and integrating new features.
Recommend solutions to improve new and existing database systems (Nice to have)
Education and Work Experience Requirements:
Bachelor’s Degree in Computer Science, Information Systems
Equivalent experience of 3-5 years minimum in information technology with five years minimum of management experience.
Experience in a manufacturing environment supporting Manufacturing Systems (Preferred)
5+ years’ experience in Microsoft SQL Server database administration and ORACLE
Preferred Qualifications
Knowledge of data modeling techniques and creating normalized data models
Update existing database structures and objects to a standardized relational model.
Write performant SQL/TSQL and/or Oracle PL/SQL code that is easy to understand, analyze, and support.
Database design\management\modeling.
Improve data\database efficiency, reliability, and quality.
Test infrastructure design modifications to mitigate issues and errors
Identify, design, and implement process improvements, including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Work with stakeholders, assisting them with data-related technical issues.
Experience with SQL Server Reporting Services and Power BI
Design and maintain data entity diagrams.
Problem-solving and Communication skills
** Hybrid role requiring 3 days onsite and 2 days remote**
At Polar’s discretion, the education and experience prerequisites may be excepted where the candidate can demonstrate, to the satisfaction of Polar, an equivalent combination of education and experience specifically preparing the candidate for success in the position."
1008918809229,Glassdoor,$112K,$153K,https://www.everestre.com/,"Title:
Senior Data Engineer
Company:
Everest Global Services, Inc.
Job Category:
Technology
Job Description:
It’s an exciting time for Everest! As we continue on our journey, we see significant opportunity ahead of us to expand our reach, build diversity, and enhance our capabilities in critical markets.
Everest is a leading global reinsurance and insurance provider, operating for nearly 50 years through subsidiaries in the Bermuda, Canada, Europe, Singapore, US, and other territories. Our strengths include extensive product and distribution capabilities, a strong balance sheet, and an innovative culture. Throughout our history, Everest has maintained its discipline and focuses on creating long-term value through underwriting excellence and strong risk and capital management. But the most critical asset in this organization is our people.
At Everest, we are committed to the development of our people. We offer dynamic training & professional development to our employees. You will benefit from career development and learning opportunities that will let you set career goals and fulfill them, including:
Generous tuition/continuing education reimbursement
Mentoring opportunities
Flexible work arrangements
Talent development initiatives
Networking groups
Everest is a growth company with $13 Billion of Gross Written Premium offering Property, Casualty and specialty products among others, through its various operating subsidiaries located in key markets around the world. Everest has been a global leader in reinsurance with a broad footprint, deep client relationships, underwriting excellence, responsive service and customized solutions. Our insurance arm draws upon impressive global resources and financial strength to tailor each policy to meet the individual needs of our customers.
Our financial strength is evident in Financial Agency Ratings of: A+ A. M. Best, A+ S&P Global and A1
Moody’s Investor Service. We are a market leader for our broad diversified income streams, strong underlying underwriting performance with reduced volatility and strong cash flow. We take pride in being known in the industry as nimble, entrepreneurial and responsive.
Everest Re Group, Ltd. (“Everest”) is seeking a Senior Data Engineer to drive the execution of our Reserving Transformation projects. In this highly visible position, you will apply strong technical acumen and leadership in partnership with business counterparts to effectively define, plan and deliver technical solutions that support business outcomes in service to Everest's strategy. This is a player/coach role that will lead a group of teams and be a strong engineering leader across the organization.
Responsibilities include but not limited to:
Partner and work collaboratively with internal customers to understand strategic analytics and business needs and the associated enabling technology requirements.
Lead the technology activities to enable the delivery of meaningful, actionable, data-driven capability in alignment with business strategies
Develop and lead the execution of the Reserving Transformation strategies and roadmaps to optimize rapid delivery of information management capabilities, while aligning to established technology and architecture standards
Define and deliver the data & analytics architecture, tooling and capabilities needed to enable a modern cloud-based data environment and the best practices, governance, and controls to support the broad adoption and use across the enterprise
Drive the delivery of an exceptional customer/partner experience through ready access to data and intuitive self-service capabilities that ensures the security, integrity and quality of data while enabling the agility and performance of a scaled ecosystem.
Deliver enabling capability to support the rapid ingestion of new data and the timely deployment of advanced analytic models into production
Support the development of engineering capabilities that promotes sharing, inner sourcing and reuse of code, capabilities and methods in a cloud-first environment that leverages highly automated DevOps tools and capabilities
Manage the engagement / coordination across assigned delivery teams to ensure high quality project delivery within scope, timeframe, and budgets
Qualifications, Education & Experience:
Bachelor’s degree in computer science, engineering, or business experience in insurance or financial services
5+years in the data and analytics space with deep experience delivering enhanced analytic and data access capabilities
Team Lead experience
Scaled agile experience a plus
Experience working in a large multinational company is preferred
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of business intelligence practices
Knowledge, Skills & Competencies:
SQL
PowerBI
Python
Azure Data Factory
Data Modeling
Azure Data Brick
Our Culture
At Everest, our purpose is to provide the world with protection. We help clients and businesses thrive, fuel global economies, and create sustainable value for our colleagues, shareholders and the communities that we serve. We also pride ourselves on having a unique and inclusive culture which is driven by a unified set of values and behaviors. Click
here
to learn more about our culture.

Our Values are the guiding principles that inform our decisions, actions and behaviors. They are an expression of our culture and an integral part of how we work: Talent. Thoughtful assumption of risk. Execution. Efficiency. Humility. Leadership. Collaboration. Diversity, Equity and Inclusion.
Our Colleague Behaviors define how we operate and interact with each other no matter our location, level or function: Respect everyone. Pursue better. Lead by example. Own our outcomes. Win together.

All colleagues are held accountable to upholding and supporting our values and behaviors across the company. This includes day to day interactions with fellow colleagues, and the global communities we serve.
#LI-HYBRID
#LI-AS1

Type:
Regular
Time Type:
Full time
Primary Location:
Warren, NJ
Additional Locations:
Everest is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or creed, sex (including pregnancy), sexual orientation, gender identity or expression, national origin or ancestry, citizenship, genetics, physical or mental disability, age, marital status, civil union status, family or parental status, veteran status, or any other characteristic protected by law. As part of this commitment, Everest will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Everest Benefits at everestbenefits@everestglobal.com.
Everest U.S. Privacy Notice | Everest (everestglobal.com)"
1008922385319,Glassdoor,$98K,$133K,https://www.capgemini.com/,"Lead Data Engineer
Title: Lead Data Engineer
Location: Chicago, IL
Responsibilities

Participate in the agile development process
Develop functional and technical specifications from business requirements for the commercial platform
Ensure application quality and alignment to performance requirements
Help create project estimates and plans Represent engineering team in project meetings and solution discussions
Participate code review process
Work with team members to achieve business results in a fast paced and quickly changing environment
Pair up with data engineers to develop groundbreaking analytic applications using Big Data technologies like - Hadoop, NoSQL and In memory Data Grids
Mentor and influence up and down the chain of command
Required Skills
Bachelor's degree in a quantitative field such as Engineering Computer Science, Statistics, Econometrics and a minimum of 10 years of experience
Minimum 5 years experience working with and developing big data solutions
Hands on experience on writing shell scripts, complex SQL queries, Hadoop commands and Git
Ability to write abstracted reusable code components.
Programming experience in at least two of the following languages: Scala, Java or Python
Strong business acuity, critical thinking and creativity;
Experience with performance tuning
Experience in developing Hive, Sqoop, Spark, Kafka, HBase on Hadoop
Familiar with Ab Initio, Hortonworks, Zookeeper and Oozie is a plus
Willingness to learn new technologies quickly
Superior oral and written communication skills as well as the willingness to collaborate across teams of internal and external technical staff, including business analysts, software support, and operations staff
Strong discernment including a broad understanding of financial business processes and practices
Primary Skills: AWS, Kafka, PySpark, Spark, Hadoop, Shell Scripting, SQL
Life At Capgemini
Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:
Flexible work
Healthcare including dental, vision, mental health, and well-being programs
Financial well-being programs such as 401(k) and Employee Share Ownership Plan
Paid time off and paid holidays
Paid parental leave
Family building benefits like adoption assistance, surrogacy, and cryopreservation
Social well-being benefits like subsidized back-up child/elder care and tutoring
Mentoring, coaching and learning programs
Employee Resource Groups
Disaster Relief
About Capgemini
Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.
Get The Future You Want | www.capgemini.com
Disclaimer
Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law"
1008920877945,Glassdoor,$115K,$149K,http://www.fidelitycareers.com/,"Job Description:
Senior Database Cloud Engineer
The Role
Cloud and Platform Engineering (CAPE) is looking for a database/automation engineer to work in the Oracle squad. The role involves general maintenance task such as rehydration, upgrades, backup, recovery, and troubleshooting. Responsibilities also involve database security, monitoring and performance tuning of the database and application queries.
The Expertise
Bachelor or Master degree in Computer Science, Information Technology or Equivalent
8+ years of IT database experience
Requires in depth knowledge of Oracle RAC, Oracle Performance & Tuning and SQL Tuning.
Experience working on various Cloud Options (AWS/Azure).
Build, deliver, configure, and maintain Oracle databases on-premises and Cloud Infrastructure in AWS and Azure using industry standard deployment tools.
Standardize and implement Cloud user management, security, capacity, monitoring and configuring application tools
Experience with Aurora PostgreSQL, Cosmos DB, Cockroach DB and other cloud native database skills preferred in AWS or Azure.
Strong experience in production support and maintenance of high availability database systems with ability to manage large scale database projects.
Experience in Golden Gate replication on Oracle Real Application Clusters (RAC) & Exadata
Analytical skill in solving complex technology challenges including solid troubleshooting skills with advanced performance SQL tuning expertise.
Proven expertise in Realtime Application Testing, Oracle diagnostic tools.
Experience in configuring Monitoring tools like Data Dog, OEM and proactive detection.
Aurora PostgreSQL, Cosmos DB, Cockroach DB and other cloud native database skills preferred in AWS RDS and Azure.
The Skills You Bring
Your ability to learn and adapt to new technologies.
You have experience collaborating with multiple teams and stakeholders.
Your ability to work in fast paced, highly demanding environment.
Team
The CAPE Cloud Ops team is focused on delivering cloud solutions for Fidelity. The team is responsible for on-boarding new databases to the AWS and Azure cloud. Additionally, the team works with various business units within Fidelity to help solution and migrate existing on-premise database to the cloud.
Certifications:
Company Overview
Fidelity Investments is a privately held company with a mission to strengthen the financial well-being of our clients. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients' money.

Join Us
At Fidelity, you'll find endless opportunities to build a meaningful career that positively impacts peoples' lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees' Choice Award, we have been recognized by our employees as a Best Place to Work in 2023. And you don't need a finance background to succeed at Fidelity—we offer a range of opportunities for learning so you can build the career you've always imagined.
At Fidelity, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we’re calling “Dynamic Working”. Most associates will have a hybrid schedule with a requirement to work onsite at a Fidelity work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change.
We invite you to Find Your Fidelity at fidelitycareers.com.

Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.
Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team by sending an email to accommodations @fmr.com, or by calling 800-835-5099, prompt 2, option 3.
At Fidelity, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry. Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Fidelity offer will need to go through a background investigation and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, Fidelity will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine."
1008917476829,Glassdoor,,,,"We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, age, citizenship, color, religion, sex, marital status, national origin, disability status, gender identity or expression, protected veteran status, or any other characteristic protected by law.
Description
Now hiring Senior Data Science Engineer (Hybrid)

Where the Chemistry Happens

Join our team Production AI North & South America and provide BASF-wide data science solutions for multiple application areas within Production. You will cover the entire solution life cycle, that is, development, testing, deployment, and operations. As a Senior Data Science Engineer, you will be primarily responsible for supporting the BASF digitalization community in North and South America. You will work in partnership with Global Digital Services, AI expert communities and BASF Production AI teams.


As a Senior Data Science Engineer you create chemistry by…


Designing, implementing, testing and maintaining of cloud-based architectures and tools and in developing processes for data mining, analysis, and modeling.

Deciding which demands are to be prioritized to develop products that produce the most valuable outcome for the customer. Also, by defining a stepwise implantation plan that demonstrates the value achieved in each step.

Being responsible for how the budget dedicated to the product is spent to develop the product and increase value (e.g., innovation).

Being familiar with agile working methodologies and confident to contribute to the corresponding ceremonies.

Preparing and presenting formal communication content to senior leadership and technical steakholders including resolving any misalignments related to the team product portfolio.

Guiding less experienced data scientist in their projects and support them in the growth of their technical and personal skillsets.

Supporting the realization of the Production AI scope. You will ensure all solutions deployed are highly reliable and adhere to all applicable internal and external/governmental requirements.

Qualifications - BASF recognizes institutions of Higher Education which are accredited by the Council for Higher Education Accreditation or equivalent
Your formula for success…

Bachelor’s degree in computer science, (process) engineering or in a comparable field. Background in chemical process engineering, mathematics, statistics, or natural sciences
Field-proven experience with cloud native services (Microsoft Azure) are welcome
Experience with data mining, ML and AI in Python and related libraries


You @ BASF
At BASF you get more than just compensation, Medical & Dental. Our total offer includes a wide range of elements you need to be your best in every stage of your life. That’s what we call you@BASF. Our Periodic Table of Benefits includes some additional perks below for starters…

Flexible Work Arrangements whenever possible
Retirement Benefits
Maternity/Paternity Leave, Infertility & Adoption reimbursement
Mentoring & Development Programs
Employee Discounts
Pet insurance
Matching Donations to your favorite cause
Access to our BASF Wine Cellar
What are you waiting for? Click Apply now to BELONG@BASF!!
BASF takes security & data privacy very seriously. We will never request financial information of any kind via email, private text message or direct message on any social medial platform or job board. Furthermore, we will never send a candidate a check for equipment or request any type of payment during the job application process. If you have experienced any of the above, please contact myhr@basf.com to report fraud."
1008922347152,Glassdoor,$67K,$98K,https://www.jpmorganchase.com/,"JOB DESCRIPTION

Launch your career in Technology Operations and put your creative problem solving into action, delivering solutions that shape the future of global business. You'll work directly with clients to build strong customer relationships and problem-solve technical issues to make businesses more productive. Alongside a motivated team of fellow analysts, supervisors, and stakeholders, you'll develop innovative solutions to troubleshoot and resolve issues while accurately diagnosing problems and providing effective user support. Finally, your strong technology background will ensure that the security and standards of our commitment to excellence are met. And because professional development is a key component of our culture, you'll receive coaching, mentoring — and a host of other development opportunities — alongside your invaluable on-the-job experience.
This role requires a wide variety of strengths and capabilities, including:
Ability to identify problems and clearly communicate strategic solutions to clients
Desire to develop a working knowledge of change management, corporate IT audit processes, IT risk management, technical problem resolution, operations systems, and data sources knowledge
Strong initiative and desire to learn
Ability to effectively collaborate with team members and clients to achieve common goals
Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis
Working knowledge of Microsoft Office products
Strong analytical and problem resolution skills
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our Global Technology Infrastructure group is a team of innovators who love technology as much as you do. Together, you’ll use a disciplined, innovative and a business focused approach to develop a wide variety of high-quality products and solutions. You’ll work in a stable, resilient and secure operating environment where you—and the products you deliver—will thrive."
1008917539012,Glassdoor,,,,
1008917454154,Glassdoor,,,http://www.innovethealth.com/,"Job Summary
InnoVet Health, a small and growing business that provides health IT professional services to the Department of Veterans Affairs (VA) is looking for a talented and experienced Data Engineer with Healthcare IT experience who can turn analytics project requirements into automated data sets processing and modeling. The ideal candidate will support our customers with data ingestion, quality check, transformation and analytics processes applied to a variety of data sources (EHR, wearable devices, mobile apps, etc.). The position offers stimulating advanced data analysis activities, in a rich healthcare environment, interacting with senior staff. It is flexible, full-time and does not require relocating (work from home). The pay, benefits, and growth potential are competitive.
Responsibilities
Gather and manage business and technical requirements
Conduct systems and data analysis, and design, implement and maintain data integration processes
Develop automated data processes for extracting, assessing quality, cleansing, transforming, loading and structuring data sets for downstream processing by data analysts and scientists. This will include ETL pipelines to convert FHIR JSON data into relational database structures.
Develop and maintain data models and architecture that support efficient storage, retrieval, and analysis of healthcare data
Collaborate with data analysts and data scientists to ensure data flows efficiently and continuously to other databases and analytics tools
Stay up to date with emerging technologies and trends in data engineering and healthcare data management
Present and discuss results with IT and business stakeholders
Participate in company growth and other responsibilities, as assigned
Qualifications
Bachelor’s or master’s degree in computer science, data analytics or related field
5+ years of experience as a Data Engineer, preferably in the healthcare field.
Proficiency in ETL, database architecture, data warehousing, data modeling, data mining, and SQL queries (e.g., MS SQL BI Stack/SSIS)
Experience with healthcare standards (e.g., HL7, FHIR, SNOMED, ICD)
Hands-on experience with scripting languages, R, Python, in on-prem and/or cloud-based platforms (AWS, Azure, GCP)
Excellent problem-solving, collaboration and communication skills
Green card or US citizen required because government contract work
No 1099 or corp-to-corp or international outsourcing or staffing agencies
Job Type: Full-time
Pay: From $110,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Referral program
Vision insurance
Compensation package:
Bonus opportunities
Experience level:
5 years
Schedule:
8 hour shift
Day shift
Monday to Friday
Application Question(s):
What is the highest level of education you have completed? Please enter 0 for a high school diploma, 1 for a bachelor's degree, 2 for a master's degree, and 3 for a PhD.
This position requires US citizenship or permanent resident card. Please answer 2 if you are a US citizen, 1 if you have a permanent resident card, 0 if have neither.
This position requires that work be conducted within the U.S. Applicants MUST provide their U.S. State of Residence. All applications without a U.S. address will be excluded from consideration.
Experience:
Data warehouse: 2 years (Required)
healthcare data engineering: 2 years (Required)
Extract, Transform, Load (ELT): 2 years (Required)
data modeling: 2 years (Required)
Work Location: Remote"
1008920234929,Glassdoor,$73K,$111K,http://www.enabledata.com/,"Description
Enable Data Incorporated is currently seeking a skilled and experienced Data Engineer with expertise in Azure Databricks to join our dynamic team. As a leading provider of advanced application, data, and cloud engineering services, Enable Data has developed deep expertise across various industries. We work closely with our customers to leverage modern solutions and technologies to drive increased value across their business ecosystem.
As a Data Engineer with Azure Databricks, you will play a pivotal role in designing, developing, and implementing data solutions for our clients. You will be responsible for building scalable data pipelines, integrating with various data sources and platforms, and ensuring data quality and reliability. Working closely with cross-functional teams, you will contribute to the development of data strategies and architectures, as well as provide insights and recommendations to optimize data processes and improve overall data performance.
This is an exciting opportunity for a talented Data Engineer who is passionate about working with cutting-edge technologies and wants to contribute to the success of our clients. If you have strong analytical and problem-solving skills, a deep understanding of data engineering principles, and extensive experience with Azure Databricks, we would love to hear from you.

Responsibilities
Design, develop, and implement end-to-end data solutions using Azure Databricks and other relevant technologies.
Build and maintain scalable data pipelines to extract, transform, and load large volumes of data from various sources.
Collaborate with cross-functional teams to analyze data requirements and translate them into technical specifications.
Ensure data quality and integrity by implementing data validation and cleansing processes.
Optimize data processing and storage for improved performance and efficiency.
Conduct data profiling, analysis, and modeling to identify opportunities for data-driven insights and recommendations.
Monitor and troubleshoot data pipelines and processes to ensure continuous data flow and availability.

Requirements
Bachelor's degree in Computer Science, Data Science, or a related field.
Strong experience with Azure Databricks and other Azure services, such as Azure Data Factory and Azure SQL Database.
Proficient in programming languages such as Python, Scala, or SQL.
Solid understanding of data engineering principles, including data modeling, data integration, and data architecture.
Experience working with big data platforms, such as Hadoop or Spark.
Familiarity with data warehousing concepts and technologies.
Knowledge of cloud data storage and retrieval techniques.
Excellent problem-solving and analytical skills.
Strong communication and collaboration abilities.
Ability to work in a fast-paced, deadline-driven environment.
Experience with Agile methodologies is a plus.
Relevant certifications in Azure Databricks or related technologies are a plus."
1008918316863,Glassdoor,$107K,$166K,http://www.caesars.com/careers,"The Director – Data Engineer position will develop new APIs and web-based products to consume and execute machine learning models. Primary focus will be to integrate data science models with Caesars Digital Product team and develop internal web-based consumption tool.
KEY JOB FUNCTIONS :
Efficiently collect, process and access data necessary for Data Science team
Build infrastructure and “pipelines” for handling data, using generalization and abstraction layers to improve efficiency and sustainability of data architecture
Design redundancies, automated monitoring and robust architecture to minimize data downtime
Working with distributed clusters of variety of servers
Collaborate with data scientists to productionalize machine learning models
Collaborate with digital product teams to align with product road maps and ensure API feeds are always working
Develop web-based tools to serve data science insights to internal stakeholders
EDUCATION and/or EXPERIENCE:
MS or PhD in quantitative field, preferred computer science
Graduation from a top-tier program or other evidence of high performance/potential preferred
Demonstrated experience in developing data solutions
Previous experience working in a cloud environment
2+ years relevant experience preferred
Real time data (ie Spark, Kafka) experience required
Web development, client and server side scripting (ie HTML, Javascript, PHP, Python Flask) experience required
Javascript libraries JQuery, Vue.js, chart.js preferred
Relational Database (ie SQL) experience required
Must possess very strong interpersonal, communication and consensus building skills; willing to work on developing and managing key relationships across the organization.
Must be able to work in a deadline-oriented environment, ensuring decisions and management communication is occurring in a timely fashion across all geographical areas of operations
Ability to uphold and demonstrate the highest level of integrity in all situations and recognize standards required by a regulated business"
1008918358221,Glassdoor,,,http://www.intonenetworks.com/,"Job Description: Senior Python Developer + Data Engineer (12+ yrs of experience) A global team of alternative investment managers passionate about delivering uncommon value to our investors and shareholders. With over 30 years of proven expertise across Private Equity, Credit and Real Estate, regions and industries, we're known for our integrated businesses, our strong investment performance, our value-oriented philosophy - and our people. We are seeking hands on Data Engineer consultants to build out the next generation data warehouse/mess for the organization. To solve the data availability and access issues of all data across the organization. Enabling a graph of connectivity between 100s of data sets. We need people that are enthusiastic about enabling internal and external clients by streamlining and facilitating easy access to their critical data that is well defined and has established transparent levels of quality. This engineer will leverage our data platforms to achieve this, while providing critical input to extend data platform capabilities. Familiarity with ETL and Cloud Platform data pipeline solutions is critical, as is REST API authoring for data access. Responsibilities • Member of the Business Date Engineering team, work to deliver Data Ingest/Enrich Pipelines, and Access APIs using common cloud technologies. • Work with consumers to understand the data requirements and deliver data contracts with well defined SLIs to track SLA agreements. • Harness modern application best practices with code quality, API test Coverages, Agile Development, DevOps, and Observability and support. • Maintain programming standards and ensure the usage of the pattern / template for API Proxy. • Conduct code reviews and automatic test coverage • Standardize the CI/CD setup for API management tools and automated deployment. • Utilize problem-solving skills to help your peers in the research and selection of tools, products, and frameworks (which is vital to support business initiatives) Skills Must have • Data Engineer highly proficient in Python development with 7+ years of ETL development experience with Azure cloud-based experience. • Can demonstrate the use of modular configurable reusable components, with logging, exception handling and rejection management. • Strong Python development skills (rest API, and also for connections, encryption-decryption, managing data and storaging data purposes) • Solid understanding of API and integration design principles and pattern experience with web technologies. • Design object-oriented, modularized, clean, and maintainable code and creating policies in Python. • Hands-on experience in designing and developing high-volume REST using API Protocols and Data Formats. • Experience with test-driven development and API testing automation. • Understanding of Data Warehouse Concepts such as Real-time Data Ingestion, Data Modeling, Dimensional Modeling, Denormalized Data structures, etc. • Good exposure to the Azure cloud platform, and knowledge of its key components e.g., Azure Blob Storage, Azure Data Factory, etc. • Clear understanding of Code testing, e.g., regression, performance & automated tests. • Implemented ETL solutions in Snowflake, with knowledge of DB components and its DR capabilities. • Exposed to scripting languages e.g., Shell scripts for data transfers, automated deployments, etc. • Managed automated deployments using Source code Control & DevOps tools. • Knowledge of Cloud Security features and their adoption in the Cloud environment and application development. • Bachelor's degree in IT Nice to have • Financial experience: Public and Alternatives Asset Management • Familiar in NoSQL\NewSQL databases • Working with Azure API and DB Platforms • Strong documentation capability and adherence to testing and release management standards • Design, development, modification, and testing of databases designed to support Data Warehousing and BI business teams • Familiarity with SDLC methodologies, and defect tracking (JIRA, Azure DevOps, ServiceNow, etc.) Soft Skills: • Candidate must have an analytical and logical thought process for developing project solutions • Strong interpersonal and communication skills; works well in a team environment • Ability to deliver under competing priorities and pressures. • Excellent organizational skills in the areas of code structuring & partitioning, commenting and documentation for team alignment and modifications Compensation for NY is 100000-300000 USD Gross per Year"
1008918095458,Glassdoor,,,,"Summary
Posted: Oct 9, 2023
Weekly Hours: 40
Role Number:200508772
Apple’s iPhone Hardware Engineering organization is looking for a highly motivated engineer with a real passion in both hardware and software. As a member of the iPhone modeling and algorithm team, you will work on opportunities to extend iPhone/iPad user experiences and improve battery life by studying data from the field, internal data sources and vendors. Are you ready for your next challenge? You will have the opportunity to influence the architectural roadmaps and high-level system specifications for the future iOS devices. This is an extraordinary cross-disciplinary opportunity and it requires intensive team collaboration effort coupled with proven system-engineering background.
Key Qualifications
Data analysis and automation - Significant expert at processing large volume of data, analysis, visualization analytics.
A deep understanding of probability, statistics, algorithms and mathematics.
Practical modern machine learning experiences in regression, classification and clustering.
Strong software skills (Matlab, C/C++, R, Python).
Excellent communication, persuasion and negotiation skills.
Proven self motivation and ability to work independently.
Understanding of control theory and how it relates to modeling Li-on batteries is a plus.
Understanding embedded system architecture is a plus.
Deep knowledge in key system-engineering architectural and implementation tradeoffs is a plus.
Description
We are looking for an engineer capable of handling challenges from “cradle to grave”. We love self-motivated teammates who are committed to continually innovate. Bring your passion and dedication and you will discover excitement and endless possibilities in the process of building our next-gen products in Apple. IN THIS ROLE, YOU WILL BE RESPONSIBLE FOR: - Support automated power data collection infrastructure for latest iPhone. - Build visualization tool for x-functional team to digest the power performance data - Perform data mining and data analysis across gigantic amount of data generated by multiple generation of iPhones - Leverage machine learning techniques to analyze the field data and provide the mentorship to the x-function teams for design decision making - Use case power analysis - Drive the future power-saving algorithms/techniques
Education & Experience
BS/MS/PHD EE Required
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program."
1008918399483,Glassdoor,,,http://www.blueskynj.com/,"We have an immediate need for a Senior Data Engineer with experience supporting Health Plan Financial Data Reporting. This permanent position is 100% remote and offers competitive compensation (that will depend on level of experience). Excellent benefits package.
Target Skills and Experience:
4+ years of SAS programming experience with extensive macro utilization. One or more SAS certifications desired.
Strong Data Engineering experience with proven track record in SAS usage of designing, developing, and maintaining data extract/transformation jobs, analytical reporting, and automated programming with reusable and SAS macro driven components
Strong experience as Data Analyst or Data Engineer within a Health Plan/Payor environment supporting Financial reporting.
Prior Clinical and Claims data reporting experience.
4+ years of SQL technical experience preferably with multiple Data Base Management systems. Strong understanding of indexed and efficient table joins.
3+ years of Tableau dashboard development experience.
Job Type: Full-time
Pay: $105,000.00 - $125,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Life insurance
Paid time off
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 4 years (Preferred)
Data Analytics/Data Engineering: 4 years (Preferred)
SAS programming: 4 years (Preferred)
Health Plan Financial Reporting: 3 years (Preferred)
SAS Macro utilization: 3 years (Preferred)
Work Location: Remote"
1008918095472,Glassdoor,,,,"Summary
Posted: Oct 9, 2023
Weekly Hours: 40
Role Number:200509365
Meaningful insights require a solid infrastructure that is able to scale with the large amount of data coming in. Our team is responsible for discovering such great insights from a sea of data, and our infrastructure needs innovative ideas to improve its performance and ease-of-use. Would you like to help understand the challenges of building and maintaining a large-scale analytics infrastructure? Are you excited about identifying areas for improvement and creating out-of-the-box solutions? If this describes you, we would love to hear from you!
Key Qualifications
Great programming skills in C, C++, Python or Java
Strong analytical thinking
Self-motivated and able to work independently
Excellent spoken and written communication skills
Description
We're looking for a motivated engineer with excellent programming, problem solving and communication skills. In this role, you will be responsible for effective provisioning, installation/configuration, operation, and maintenance of our team’s analytics infrastructure. You will enable continued innovation and progress within the infrastructure through research and development. You will help and support the execution, test and roll-out of solutions. To be successful in this role, you must have a solid software engineering background and be able to write production level code. As a member of this team, you will have the opportunity to solve challenging engineering problems across a broad range of Apple products.
Education & Experience
B.S., M.S. or Ph.D. in Computer Science, Electrical Engineering or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $110,200 and $198,100 annualized, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program."
1008918730648,Glassdoor,,,http://www.risk-strategies.com/,"Data Conversion Engineer
Location: United States
Requisition Number245807
We are seeking a skilled and meticulous Data Conversion Engineer to join our team. As a Data Conversion Engineer, you will be responsible for designing, implementing, and executing data conversion processes to ensure the smooth transition of data from legacy systems to modern platforms. Your expertise in data manipulation, transformation, and migration will be crucial in maintaining data integrity and enabling accurate and efficient data conversion. Your ability to collaborate with cross-functional teams and troubleshoot complex data issues will contribute to the success of our data conversion initiatives.

As a Data Conversion Engineer, you will play a crucial role in ensuring the successful conversion of data from legacy systems to modern platforms. Your contributions will enable our organization to leverage accurate and reliable data, improve operational efficiency, and make informed business decisions. Join our team and make a significant impact on our data management and conversion initiatives.

Primary Responsibilities and Duties:
Analyze legacy data systems and understand the data structure, relationships, and dependencies to design effective data conversion strategies.
Collaborate with stakeholders to define data conversion requirements, objectives, and success criteria.
Develop and implement data conversion plans, including data extraction, cleansing, mapping, transformation, and migration processes.
Perform data profiling and analysis to identify data quality issues, anomalies, and inconsistencies in the legacy data.
Write scripts, queries, or programs to extract, transform, and load (ETL) data from various sources into the target systems.
Ensure data integrity and accuracy during the conversion process by validating and reconciling data across multiple systems.
Collaborate with database administrators, software developers, and system administrators to ensure compatibility and smooth integration of converted data into the target systems.
Develop and maintain documentation related to data conversion processes, including data mapping, transformation rules, and validation procedures.
Monitor and troubleshoot data conversion issues, identify root causes, and implement corrective actions in a timely manner.
Conduct performance tuning and optimization of data conversion processes to enhance efficiency and minimize processing time.
Collaborate with testing teams to develop and execute data validation tests to ensure the accuracy and completeness of the converted data.
Stay updated with industry best practices, emerging technologies, and data management trends related to data conversion.

Requirements and Qualifications:
Relevant certifications or training in data management or ETL processes are desirable.
Proven experience as a Data Conversion Engineer or similar role, with a focus on data migration and transformation.
Proficiency in data manipulation, transformation, and migration using ETL tools, scripting languages, or programming languages (e.g., SQL, Python, R, etc.).
Strong understanding of database concepts, data structures, and data modeling principles.
Experience with data profiling, data quality assessment, and data cleansing techniques.
Familiarity with database management systems and knowledge of SQL for data extraction, manipulation, and analysis.
Knowledge of data integration methodologies and techniques, including data mapping and transformation rules.
Understanding of data governance, data security, and privacy considerations in data conversion processes.
Strong analytical and problem-solving skills to troubleshoot and resolve data conversion issues.
Excellent collaboration and communication skills to work effectively with cross-functional teams and stakeholders.
Detail-oriented mindset with a focus on data accuracy and integrity.
Ability to manage multiple priorities and meet project deadlines.

Risk Strategies is the 9th largest privately held US brokerage firm offering comprehensive risk management advice, insurance and reinsurance placement for property & casualty, employee benefits, private client services, as well as consulting services and financial & wealth solutions. With more than 30 specialty practices, Risk Strategies serves commercial companies, nonprofits, public entities, and individuals, and has access to all major insurance markets. Risk Strategies has over 100 offices and nearly 5,000 employees across the US and Canada.

Our industry recognition includes being named a Best Places to Work in Insurance for the past five years (2018-2022) and on the Inc. 5000 list as one of America’s Fastest Growing Private Companies. We are committed to being good stewards for our company, culture, and communities by having a strong focus on Environmental, Social, and Governance issues.

At Risk Strategies Company, base pay is one part of our total compensation package, which also includes a comprehensive suite of benefits, including medical, dental, vision, disability, life, and retirement savings, The total compensation for a position may also include other elements dependent on the position offered. The expected base pay range for this position is between $70,000.00 - $125,000.00. The actual base pay offered may vary depending on multiple individualized factors, including geographical location, education, job-related knowledge, skills, and experience.

#245807
Risk Strategies Company does not discriminate on the basis of race, sex, color, religion, age, national origin, marital status, disability, veteran status, genetic information, sexual orientation, gender identity or any other reason prohibited by law in provision of employment opportunities and benefits."
1008918344049,Glassdoor,,,,"Description:
Spyglass MTG (Microsoft Technology Group) is a Microsoft Gold Certified Partner. We hire people who are professional consultants in addition to being highly competent performers in their specific discipline. As a Consultant at Spyglass MTG you will be working on projects to develop Microsoft technology focused solutions for a variety of clients in industries such as Financial Services, Healthcare, Life Sciences, Manufacturing and Higher Education. Our office is located in Lincoln, RI, however our clients are typically located in the Greater Boston and New England area. You will be working in a team environment that consists of Spyglass and Client members.
We are seeking a highly skilled and experienced Lead Azure Data Engineer to our data engineering team and drive the design and implementation of data solutions on the Microsoft Azure platform. As the Lead Azure Data Engineer, you will play a pivotal role in architecting and developing end-to-end data solutions, providing technical guidance to the team, and collaborating with cross-functional stakeholders to deliver high-quality and scalable data solutions that support our organization's data-driven initiatives.
Responsibilities:
Data Architecture and Design: Lead the design and development of scalable, efficient, and reliable data architecture on the Microsoft Azure cloud platform. Work closely with data architects and business stakeholders to understand data requirements and translate them into well-defined data models and data pipelines.
Azure Data Services: Demonstrate expert-level knowledge of Microsoft Azure data services, including but not limited to Azure Data Factory, Azure Databricks, Azure Synapse Analytics (formerly Azure SQL Data Warehouse), Azure Cosmos DB, and Azure Data Lake Storage. Utilize these services to build robust and performant data solutions.
Team Leadership: Provide technical leadership and mentorship to the data engineering team. Foster a collaborative and innovative work environment, encouraging professional growth and skill development among team members. Lead by example and inspire the team to deliver high-quality solutions.
Data Integration and ETL: Oversee the development of data integration processes and efficient ETL (Extract, Transform, Load) workflows to ensure the seamless flow of data from diverse sources into data repositories. Implement data transformation and cleansing strategies to maintain data accuracy and consistency.
Performance Optimization: Optimize data pipelines, data storage, and queries for maximum performance and cost-efficiency on the Azure platform. Monitor and troubleshoot data-related issues, providing timely solutions to maintain data solution stability.
Data Governance and Security: Implement data governance policies and security measures to ensure data quality, security, and compliance with data regulations and industry standards.
Collaboration and Communication: Collaborate effectively with data scientists, data analysts, software engineers, and other stakeholders to understand data requirements and support data-driven decision-making processes. Communicate technical concepts and solutions clearly to both technical and non-technical audiences.
Continuous Improvement: Stay abreast of the latest advancements in Azure data services, data engineering best practices, and industry trends. Identify opportunities for process improvement, automation, and innovation to enhance data engineering capabilities.
Requirements:
Bachelor's degree in Computer Science, Engineering, or a related field. Master's degree is a plus.
Proven experience (typically 5+ years) as a Data Engineer, with a focus on building data solutions on the Azure cloud platform.
Extensive expertise in Microsoft Azure data services, particularly Azure Data Factory, Azure Databricks, Azure Synapse Analytics, Azure Cosmos DB, and Azure Data Lake Storage.
Strong programming skills in languages such as Python, SQL, or Scala for data processing and manipulation.
Solid understanding of data modeling, data warehousing, and ETL/ELT concepts.
Previous experience in leading and managing a data engineering team, with the ability to provide technical guidance and mentorship.
Knowledge of data governance, data security, and data compliance best practices.
Familiarity with Agile methodologies and working in an Agile development environment.
Excellent problem-solving skills and the ability to handle complex data-related challenges.
Outstanding communication, leadership, and teamwork skills.
Benefits:
Medical, Vision and Dental Plans
Life and Disability Insurance
Open PTO Policy
Holiday PTO
Paid training certification
Bonus plan
401k
Flexible working arrangements
& more
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, transgender status, national origin, citizenship, age, disability or protected veteran status."
1008920638314,Glassdoor,$93K,$135K,http://www.bankofamerica.com/,"Job Description:
Bank of America is looking for a Data Engineer II to join the Cybersecurity Cloud team in our Global Information Security group.
This job is responsible for developing and delivering data solutions to accomplish technology and business goals and initiatives. Key responsibilities include performing code design and delivery tasks associated with the integration, cleaning, transformation, and control of data in operational and analytical data systems. Job expectations may include managing teammates, working with stakeholders and Product and Software Engineering teams to aid with implementing data requirements, analyzing performance, and researching and troubleshooting data problems within system engineering domains.
Key Responsibilities:
Works across development teams to contribute to the story refinement and delivery of data requirements through the delivery life cycle
Leverages architecture components in solution development, codes solutions to integrate, clean, transform, and control data in operational and analytical data systems per acceptance criteria
Builds processes supporting data transformation, data structures, metadata, data quality controls, dependency, and workload management and defines and builds data pipelines and complex data sets to enable data-informed decision making, identifying and raising risks at all stages of the data engineering process
Develops and executes test plans to produce quantitative results, contributes to existing test suites including integration, regression, and performance, analyzes test reports, identifies test issues and errors, and triages underlying causes
Drives complex information technology projects to ensure on-time delivery and adheres to team delivery and release processes
Identifies, defines, and documents data engineering requirements, communicating required information for deployment, maintenance, support, and business functionality
Works with technology partners and a diverse set of stakeholders to identify and close gaps in data management standards adherence, negotiates paths forward, and helps identify and communicate solutions to complex data problems leveraging knowledge of information systems, techniques, and processes
Requirements:
8+ years of professional IT or Cybersecurity (preferred) experience
3+ years of experience with Cloud Technologies including Azure, AWS and/or GCP
5+ years as a Data Analyst, strong preference for Cloud Analytics
Enterprise Role Overview:
Responsible for developing and delivering data solutions to accomplish technology and business goals. Codes design and delivery tasks associated with the integration, cleaning, transformation and control of data in operational and analytics data systems. Works with stakeholders, Product Owners, and Software Engineers to aid in the implementation of data requirements, performance analysis, research and troubleshooting. Familiar with the data engineering practices of the bank. Contributes to story refinement/defining requirements. Participates in estimating work necessary to realize a story/requirement through the delivery lifecycle. Understands and utilizes basic architecture components in solution development. Codes solutions to integrate, clean, transform and control data in operational and/or analytics data systems per the defined acceptance criteria. Works across development teams to understand and aid in the delivery of data requirements Assembles large, complex data sets that meet functional / non-functional requirements. Builds processes supporting data transformation, data structures, metadata, data quality controls, dependency and workload management. Defines and builds data pipelines that enable faster, better, data-informed decision-making within the business. Contributes to existing test suites (integration, regression, performance), analyzes test reports, identifies any test issues/errors, and triages the underlying cause. Documents and communicates required information for deployment, maintenance, support, and business functionality. Adheres to team delivery/release process and cadence pertaining to code deployment and release Identifies gaps in data management standards adherence and works with appropriate partners to develop plans to close gaps. Individual contributor.
Shift:
1st shift (United States of America)
Hours Per Week:
40"
1008920178209,Glassdoor,,,http://www.bridgewcg.com/,"Position: 230141 - IT Infrastructure Engineer – Data Power
Location: Hybrid – Rosemead, CA
Responsibilities:
Design, build, test, and document DataPower services.
Works with application integration engineers, developers, and SMEs to ensure authentication/authorization services are configured in accordance with business requirements and enterprise security policies.
Deploy WSDL files and update configurations to meet evolving business needs.
Troubleshoots incidents in QA and production environments.
Meets with auditors to provide implementation details and compliance data.
Works with application and build teams to ensure successful upgrades of infrastructure components and application code.
Participates in incident and change management processes.
Creates and maintains run books and deployment documentation.
Possess intermediate or higher DataPower developer experience.
Experience with IBM DataPower firmware deployment, policy configuration, and application integration.
Experience with SOAP and/or REST-based Web services with emphasis on security, including the use of SSL/TLS, WS-Security, and federated identities.
Experience with XS40, XI50, XG45, or equivalent device models.
Experience with multiple DataPower services, including XML firewall, Crypto objects, Web Service Proxy, and Multi-Protocol Gateways.
Experience creating and deploying XSLT, XSDs, and WSDLs.
Experience with DataPower AAA (authentication, authorization, and auditing).
Experience with n-tier architecture and J2EE application deployment patterns.
Experience troubleshooting time-sensitive production issues.
Knowledge of PKI certificates and their use in secure environments, to include obtaining and installing PKI certificates, trust chaining, mutual authentication, and working with private CAs.
Knowledge of service-oriented architecture (SOA), B2B and cloud layers
Understanding of software development life cycle
Possess strong troubleshooting skills.
Able to consistently apply quality and security standards.
Able to work effectively with technical team members.
Assess and make recommendation for physical / logical designs
Create capacity analysis reports to determine health of virtual infrastructure
Create Disaster Recovery Plans and test execution
Performing project assignments and responsibilities
Perform analysis, provide recommendations, using knowledge and experience of infrastructure configuration and capability, application flows, and use of monitoring tools
Create, review, and modify operational processes and procedures
Working with business clients and IT partners to maximize infrastructure and application performance
Coordinating activities involving clients, IT teams, and Suppliers in the day-to-day operations and maintenance of our systems following change control processes
Monitor, support, and maintain a large, complex, and regulated compute infrastructure per predefined standards and guidelines, industry best practice, including install, configure, and update/patch HW and OS patches
Troubleshoot/support 1000+ Server compute infrastructure comprised of physical and virtual assets (servers, workstations, appliances, and application)
Monitor, support, and maintain a large, complex, and regulated compute infrastructure per predefined standards and guidelines, industry best practice, including install, configure, and update/patch HW and OS patches
Required:
Minimum 5+ years of experience in DataPower
Strong development skills in DataPower
Worked on XI52 device. Working knowledge on other devices like XB50/52 and XC10 are added as an advantage.
Must have experience in creating WSP, XFW, MPGW, FSH and Log targets.
Able to understand and work with AAA policy.
Should have worked with Certificates and Encryption.
Programming in XSLT, proficient in XML, sound knowledge on SOA, Webservices, SOAP, WSDL & REST.
Error Handling and troubleshooting in DataPower
DP Extension functions.
Should have knowledge in SoapUI and other testing tools for DataPower. Knowledge in SOATest is an added advantage.
A background in software lifecycle management and understanding of testing process.
Minimum of three (3) years of experience NERC regulated compute infrastructure
Minimum of three (3) years of experience compliance and audit activities
Excellent oral and written communication skills
Nice to have:
Minimum of five (5) years of experience maintaining and supporting enterprise hardware and Windows/Linux Operating systems (2012/2016/2019 Win7/Win10 and RHEL7/RHEL8/SLES12), software, and applications.
Minimum of five (5) years of experience in the field performing complex analysis, consulting, and providing recommendations.
Minimum of three (3) years of experience managing and maintaining VMWare infrastructure (ESXi hosts, vRealize Operations Manager and Virtual Center)
Minimum of three (3) years of experience maintaining and supporting enterprise class IT hardware
Minimum of three (3) years of experience using Infoblox. (IP Management, Zone Management, DNS Management)
Minimum of three (3) years of experience supporting Hyperconverged network (Dell EMC VxRail)
Minimum of three (3) years of experience supporting NetApp storage
Minimum of three (3) years of experience using Infoblox. (IP Management, Zone Management, DNS Management)
Minimum of three (3) years of experience supporting Microsoft Active Directory (User Management, Group Policy Management, PowerShell Scripting)
Job Type: Contract
Pay: $166,400.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Vision insurance
Schedule:
Monday to Friday
Ability to commute/relocate:
Rosemead, CA 91770: Reliably commute or planning to relocate before starting work (Required)
Experience:
compliance and audit activities: 3 years (Required)
creating and deploying XSLT, XSDs, and WSDLs: 5 years (Required)
design, build, test, and document DataPower services: 5 years (Required)
working on XI52 device: 5 years (Required)
creating WSP, XFW, MPGW, FSH and Log targets: 5 years (Required)
programming in XSLT, proficient in XML, knowledge on SOA: 5 years (Required)
error Handling and troubleshooting in DataPower: 5 years (Required)
NERC regulated compute infrastructure: 3 years (Required)
Work Location: Hybrid remote in Rosemead, CA 91770"
1008918374901,Glassdoor,$104K,$158K,https://www.emerson.com/en-us/careers,"If you are an associate or senior engineer looking for an opportunity to join a diverse, collaborative team, we have an opportunity for you! Based out of our Pittsburgh, PA office, our Projects team is seeking a self-motivated engineer to join the Enterprise Data Solutions (EDS) team.
Power & Water Solutions is an industry-leading controls automation company that provides applications in the renewable (solar, hydro, wind), fossil (natural gas and coal) power generation, and water treatment plant sectors. We focus on upgrading existing plant control systems with industry-leading automation controls and instrumentation to promote the sustainability and longevity of our North American power grid and wastewater infrastructure.
The Enterprise Data Solutions (EDS) team is expected to interface will all aspects of operations, partnering with developers to improve our products and procedures, working to ensure perfect execution, and providing exceptional service to our customers.
As an Enterprise Data Solution (EDS) Engineer, you will:
Perform installation of EDS servers and data feeders
Troubleshoot and diagnose EDS complications
Research, analyze, and recommend the implementation of software or hardware changes to rectify any EDS deficiencies or to enhance performance, when appropriate
Provide field service support for installed EDS systems, to resolve customer problems and questions
Seek opportunities to develop new tools that can optimize the installation of EDS
Engage with the EDS Development Team to seek opportunities to improve tools for EDS.
Create and maintain schedules with the understanding that several inputs/outputs may or may not be in your control
Capture technical equipment specifications from customer specification understanding of how best to implement a network configuration based on these inputs and Ovation standards
Ability to work and lead within a team. Possess the listening skills necessary to receive instruction and direction. Possess the leadership to pass those directives to other colleagues to achieve a satisfied customer and high-quality product
Maintain proficiency with current technologies
Who you are: You are passionate about making an impact and always act with integrity. You continuously push yourself to achieve new goals and are not afraid to question the status quo by proposing creative solutions to problems. You are very comfortable using computers and digital tools. You have a strong technical background but at the same time, you enjoy working with people and are an excellent teammate.
Required education, experience & skills:
Bachelor’s Degree in Computer, Electronics, Electrical, or Software Engineering, Computer Science, or a closely related field of study, or equivalent
Strong communication, computer, presentation, and interpersonal skills
Exceptional organization skills and ability to manage complex projects with multiple work phases
Willingness and ability to travel up to 50% within the US
Legal authorization to work in the United States - sponsorship will not be provided for this position
Preferred education, experience & skills:
Experience programming in Python, C, C++
Understating of Ovation networks and architecture
Cisco networking experience
Self-starter mentality with outstanding analytical, communication, and interpersonal skills.
Strong attention to detail and ability to prioritize tasks on an ongoing basis
Flexible Work Schedule – Remote Work Option
This role has the flexibility of a remote work option up to three days a week. Our teams work together to ensure our chosen work schedules enable our creativity and productivity as we serve the needs of our customers.

WHY EMERSON
Our Commitment to Our People
At Emerson, we are motivated by a spirit of collaboration that helps our diverse, multicultural teams across the world drive innovation that makes the world healthier, safer, smarter, and more sustainable. And we want you to join us in our bold aspiration.
We have built an engaged community of inquisitive, dedicated people who thrive knowing they are welcomed, trusted, celebrated, and empowered to solve the world’s most complex problems — for our customers, our communities, and the planet. You’ll contribute to this vital work while further developing your skills through our award-winning employee development programs. We are a proud corporate citizen in every city where we operate and are committed to our people, our communities, and the world at large. We take this responsibility seriously and strive to make a positive impact through every endeavor.
At Emerson, you’ll see firsthand that our people are at the center of everything we do. So, let’s go. Let’s think differently. Learn, collaborate, and grow. Seek opportunity. Push boundaries. Be empowered to make things better. Speed up to break through. Let’s go, together.
Work Authorization
Emerson will only employ those who are legally authorized to work in the United States. This is not a position for which sponsorship will be provided. Individuals with temporary visas such as E, F-1(including those with OPT or CPT) , H-1, H-2, L-1, B, J or TN, or who need sponsorship for work authorization now or in the future, are not eligible for hire.
Equal Opportunity Employer
Emerson is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, race, color, religion, national origin, age, marital status, political affiliation, sexual orientation, gender identity, genetic information, disability or protected veteran status. We are committed to providing a workplace free of any discrimination or harassment.
Accessibility Assistance or Accommodation
If you have a disability and are having difficulty accessing or using this website to apply for a position, please contact: idisability.administrator@emerson.com .

ABOUT EMERSON
Emerson is a global leader in automation technology and software. Through our deep domain expertise and legacy of flawless execution, Emerson helps customers in critical industries like life sciences, energy, power and renewables, chemical and advanced factory automation operate more sustainably while improving productivity, energy security and reliability.
With global operations and a comprehensive portfolio of software and technology, we are helping companies implement digital transformation to measurably improve their operations, conserve valuable resources and enhance their safety.
We offer equitable opportunities, celebrate diversity, and embrace challenges with confidence that, together, we can make an impact across a broad spectrum of countries and industries. Whether you’re an established professional looking for a career change, an undergraduate student exploring possibilities, or a recent graduate with an advanced degree, you’ll find your chance to make a difference with Emerson. Join our team – let’s go!
No calls or agencies please."
1008919884403,Glassdoor,,,,
1008923499778,Glassdoor,,,,"Overview:
Our data link test team is searching for new test engineer professionals that can help us design and execute test events. If you enjoy working in a fast-paced environment, learning new technology areas, this is the place for you. We provide a number of opportunities to learn ranging from on-the-job training with other team members to formal courses for unique technology areas.
We realize that no one will have all of these qualifications. We are looking for people that have experience with Link 16 and system testing. And have the drive and motivation to learn all other required areas.
This position provides support to the 96 Cyber Test Group, 46 Test Squadron, Data Link Test Flight at Eglin AFB as a member of an platform integration team responsible for planning, designing, and executing test events for tactical communications systems. This is NOT a telework or remote position; however, telework opportunities may be authorized as mission requirements allow.

LOCATION: Eglin AFB, FL
JOB STATUS: Full Time
TRAVEL: 25% CONUS / OCONUS TDYs

REQUIRED QUALIFICATIONS (Education, Certifications, Experience, Skills)
SECURITY CLEARANCE: Secret and be able to obtain and maintain a Top Secret clearance – US citizenship required
EDUCATION: BS Degree in a Computer Science, Computer Engineering, or a related technical field (i.e., CS, AE, ME, etc.)
CERTIFICATIONS: None
EXPERIENCE LEVEL: 3-10 years of applicable experience

OTHER QUALIFICATIONS/SKILLS:
US citizenship required
Active Top Secret clearance
Experience with tactical data link radios and terminals
Experience with computer network design concepts, configuration, and operation
Analytical skills and problem-solving skills
Excellent self-initiative and self-motivation with the ability to work under minimal supervision
Ability to work effectively in small and large team settings to solve complex problems
Capable of traveling to contractors' facilities, test sites, and other locations, both CONUS and OCONUS. Travel is on average is 25% of total time worked
Good organization, decision making, verbal and written communication skills
Proficiency in MS Office products to include Word, Excel and PowerPoint

PREFERRED SKILLS:
Relevant technical experience in the areas of software system and hardware integration testing
An understanding of DOD developmental test and evaluation processes
Knowledge of computer networking principles and configuration
Experience using interpreted languages (Python, Ruby, JavaScript, PHP, etc.)
Security+ certification

RESPONSIBILITIES:
Perform as a member of the Platform Integration Element test team
Interface directly with System Program Offices, users, test support organizations, and product development contractors
Plan, execute, and report on tests for Air Force advanced tactical communications programs to include Link 16, Situation Awareness Data Link (SADL) and emerging next generation tactical data links
Utilize Military Standards to evaluate system compliance
Proficient/familiar with various radios such as: MIDS-JTRS, SADL, PRC-117G, etc
Review customer requirements and participate in test planning meetings
Develop test plans and procedures, schedules, and execute tests within the constraints of customer requirements and produce timely test reports
Capable of performing as a team leader in directing and executing system testing
Author technical documents and briefings and conduct formal presentations
Travel to other locations as required to attend meetings and conduct tests

What we offer:
Competitive salaries
Continuing education assistance
Professional development allotment
Multiple healthcare benefits packages
401K with employer matching
Paid time off (PTO) along with a federally recognized holiday schedule

Who We Are
Oasis Systems is a premier provider of customer-driven, cost-effective, and quality Engineering Services; Enterprise Systems and Applications; Human Factors Engineering; Information Technology and Cyber Security; Professional Services; and Specialized Engineering Solutions to the Department of Defense, Federal Aviation Administration, Nuclear Regulatory Commission, and other Federal Agencies.

We strive to be an exciting and welcoming company that attracts, develops, motivates and retains the most talented, skilled and dedicated people in the industry; where they are encouraged to achieve personal excellence, purpose, and their full potential and career aspirations, while supporting mission-critical national security technologies and programs.

Oasis Systems is an Equal Employment Opportunity/Affirmative Action Employer. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
""Oasis Systems Cyber Division"""
1008918835764,Glassdoor,,,http://www.upclear.com/,"ABOUT UPCLEAR
UpClear delivers a SaaS revenue management platform that is used by some of the most recognizable consumer goods brands in the world. Our system supports Trade Promotion Management, Trade Promotion Optimization, Integrated Business Planning and Revenue Management.
We serve more than 80 brands in over 30 countries. Our growth is substantial and consistent; we have been on the Inc 5000 list of fastest growing private companies for eight years in a row.
UpClear's global headquarters is in New York City and we have satellite offices in London, Paris, and Hong Kong.

POSITION OVERVIEW
We are looking for a Senior Data Engineer to join our team and help us build and maintain our data infrastructure. The ideal candidate will have a strong understanding of data engineering principles and best practices, as well as experience with a variety of data technologies. They will also have experience with a variety of data tools and technologies, and be able to work independently and as part of a team.
Responsibilities
Design, Develop, Deploy and Maintain SQL Schema objects (Tables, Indexes, Stored Procedures etc).
Optimize and refactor data architecture solutions using technology other than SQL.
Optimize database performance and troubleshoot performance issues.
Integrate data from disparate sources into a single data warehouse.
Develop, maintain, and document data models and schemas.
Work with other engineers to design and implement data governance protocols and procedures.
Ensure high availability and accuracy of data across multiple geographical regions.
Perform code reviews and give senior guidance to other developers.
Ability to use database monitoring tools to identify performance bottlenecks.
Work directly with product leadership in building functional/technical specifications for customer requests.
Deep dive into complex data issues and provide detailed analysis and solutions to client representatives.

Requirements
Bachelor’s Degree in computer science or similar
5+ Years Experience with a Database Platform (e.g., SQL Server, Azure SQL)
Ability to perform DBA tasks and operations, preferably in cloud-based database solutions (e.g., Azure SQL).
Experience with optimizing data procedures and ETL pipelines.
Experience with a source control system (e.g., GIT)
Experience with Agile Development Processes.
Experience with designing, developing and analyzing complex T-SQL (e.g. Functions, Stored Procedures)
Experience and knowledge of CI/CD principles.
Experience with managing, developing, and operating large data warehouses.
Experience in developing data-based solutions with a programming language (e.g. Python, C#)
Experience in a cloud platform operations a plus (e.g., Azure, AWS, GCP)
Experience with a scripting language or with Devops automation a plus (e.g. Bash, Powershell)
Benefits
WHY UPCLEAR ?
Be part of a growing global SaaS company, with offices in NYC, London, Paris, Hong-Kong
Work on latest Cloud technology and build architecture for fast-growing Tech
Weekly happy hours, good office culture, global cross team collaboration, direct access to executive leadership for guidance.
UpClear employees have access to a range of competitive benefits, including
Various Health Care Plans you can choose from to best fits your needs (Medical, Dental & Vision)
Retirement Plan with company match (401k, IRA)
Generous Paid Time Off package that grows with seniority (Vacation, Sick, and Public Holidays)
Paid Maternity leave
Paid Parental bonding leave
One month paid sabbatical after five continuous years of work at Upclear
Hybrid work model
Competitive Salary ($140K - $190K)
The salary range listed is a good faith determination of potential base compensation that may be offered to a successful applicant for this position at the time of this job advertisement and may be modified in the future. When determining a team member's base salary several factors may be considered as applicable including, but not limited to, relevant education, qualifications, certifications, experience, skills, seniority."
1008922665963,Glassdoor,,,,"Data Integration and Migration Engineer
Job Category: Engineering
Time Type: Full time
Minimum Clearance Required to Start: TS/SCI with Polygraph
Employee Type: Regular
Percentage of Travel Required: Up to 10%
Type of Travel: Local

What You’ll Get to Do:

CACI is supporting the development of a Human Capital Management solution for a Government Agency in the Intelligence community. The new solution is a large-scale integration phased over multiple years which will consolidate and eliminate over 100 legacy systems. We are seeking a Data Migration and Conversion Engineer who will be will vital to the integration, development, and deployment of a cloud-based Personnel Management solution using Agile development processes.

More About the Role:
Perform the migration of data from legacy systems to new system.
Design and implement effective database solutions and models to store and retrieve migrated/mapped data
Support the development and testing of required conversions and integrations for this solution.
You will function as part of a development scrum, working with other technical and functional resources to deliver these elements
Identify, create, and secure test data as necessary
Provide hands-on support for test execution

You’ll Bring These Qualifications:
Bachelor's degree and 5+ years of experience computer science, computer engineering, or relevant field. Years of experience may be accepted in lieu of degree for certain roles. Certifications may be accepted in lieu of a degree for certain technical roles.
Experience with data modeling, data integration, and data warehousing
Experience with analyzing and extracting key data and information to meet an organization's information system needs and requirements.
Experience in data validation and cleaning to ensure the quality and integrity of data.
Experience with ETL
Experience with SQL
Active TS/SCI with Poly Clearance
These Qualifications Would be Nice to Have:
Amazon Web Services (AWS) certification.
Ability to execute projects and tasks with minimal guidance and supervision.
Possession of excellent oral and written communication skills.
Possession of excellent data gathering, analytical, and problem-solving skills.
Experience with business & data system requirements (understanding and implementing)
Knowledge of PeopleSoftAgile certification (CSM, SAFe, or equivalent)
Ability to communicate in a clear and concise manner
Must be a team player and be able to adjust to a dynamic working environment that supports a government agency
Must have strong written, verbal, and listening skills
Must have strong analytical skills and can demonstrate strong problem-solving skills

What We Can Offer You:

We’ve been named a Best Place to Work by the Washington Post.
Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.
We offer competitive benefits and learning and development opportunities.
We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.
For over 60 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.
Company Overview: At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic."
1008923107044,Glassdoor,,,http://www.arvest.com/,"Pay is based on a number of factors including the successful candidate’s job-related knowledge and skills, qualifications, and prior experience. Arvest offers a comprehensive suite of benefits, including a full range of health and life, financial, and wellness benefits. For more information about benefits, please visit www.arvest.com/careers/benefits .

Position is Monday through Friday from 8 am to 5 pm with the ability to work additional hours as project needs demand.
Incumbent should be located within the Arvest 4 State Footprint (AR, KS, MO, OK).
Remote work options may be available outside of the 4-state footprint upon further review during the interview process.

We are seeking an innovative Data Engineer to join our Data Engineering team at Arvest. You will play a key role in building out our Data Platform. The ideal candidate will have experience within OLTP & OLAP, PostgresSQL(SQL, stored procs/functions), Liquibase, Gitlab & CI/CD, Python, Google Cloud Platform (GCP), Airflow/Cloud Composer, and Dataflow.
The story of Arvest is one of commitment started by our founders in 1961, with an intense dedication to focusing on our customers. We will always be active and involved members of the communities we serve, and we will always work to put the needs of our customers first as we continue to fulfill our mission – People helping people find financial solutions for life.
Job Title: Data Engineer
A Data Engineer at Arvest is a technical team member who will create, maintain, and evolve the strategy for data storing, transformation and distribution. They use common data architecture practices to translate business requirements into conceptual, logical, and physical data models that will support data analysis/visualization and decision-making across the organization.
We are seeking candidates who embrace diversity, equity, and inclusion in a workplace where everyone feels valued and inspired.
What You’ll Do at Arvest: (Other duties may be assigned.)
• Develop resilient data pipeline solutions that are sustainable, fault-tolerant, and highly scalable using modern and new technologies of varying complexity and scope.
• Troubleshoot moderately complex problems and assists with root cause analysis. Support production workloads as necessary. Participate in on-call rotation, as needed.
• Utilize technical expertise to develop and execute queries to extract internal and external data from various sources that will be required for a robust and reliable data infrastructure.
• Build software that performs well, is secure, and is accessible to customers. Ensure that work product delivered by the team meets standards for reusability, security, and performance and that data is available, usable, and fit-for-purpose.
• Partner with Engineers, contractors, and 3rd parties to deliver solutions that are efficient, reusable, and impactful. May work with contractors and 3rd parties to accomplish goals.
• Collaborate with the Product Owner and End Users to ensure that acceptance criteria are met and satisfies the business need.
• Build and manage data quality and data loads using automated testing frameworks and methodologies such as Data-Driven Testing (DDT).
• Mentor and guide less experienced engineers to build skills and adopt practices.
• Create proofs-of-concept and proofs-of-technology to evaluate the feasibility of solutions, including recommendations based on the results.
• Make sound design/coding decisions keeping customer experience in the forefront.
• Research and recommend data for acquisition and evaluates suitability. Support the identification of anomalies and data quality issues.
• Participate in cross-product Communities of Practice and/or Guilds by attending sessions, volunteering for research topics, and presenting findings to the group. Promote the re-use of data across the Company.
• Perform code reviews. Test own work and reviews tests performed by more junior team members, as appropriate.
• Exhibit strong problem solving and analytical skills, as well as strong communication and interpersonal skills. Contribute to healthy working relationships among teams and individuals.
• Understand and comply with bank policy, laws, regulations, and the bank's BSA/AML Program, as applicable to your job duties. This includes but is not limited to; complete compliance training and adhere to internal procedures and controls; report any known violations of compliance policy, laws, or regulations and report any suspicious customer and/or account activity.

Responsibilities:

Toolbox for Success:
Bachelor’s Degree in Information Systems, Computer Science, Business Intelligence, or related field, or equivalent related work or military experience, is required.
3 years of experience in designing and developing data queries for ETL data movement, including merging large data sets for analysis, is required.
Experience with ETL data movement of structured data sources, is required.
Experience with programming languages like Python, Java, and C#, is required.
Experience in the following is preferred:
ETL tools such as DataFlow, Dataproc, Data Fusion, or similar tools
Transformation tools, such as DBT
Pipeline orchestration tools, such Apache Airflow or Cloud Composer
Cloud data solutions within Google Cloud Platform, Azure, or AWS
Working knowledge of standardization, security, governance, and compliance
Hands-on experience with Data Visualization tools, such as Tableau, Looker, or PowerBI)
Prior experience in banking or financial services is preferred.
Relevant military experience is considered for veterans and transitioning service members
Physical Demands:
The associate must be able to travel occasionally by themselves within the US, possibly overnight. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential functions.
We offer competitive compensation, benefits packages, and significant professional growth.
Along with an excellent benefits package, our associates are engaged, rewarded for performance, and encouraged to grow professionally and personally. Our future is driven by our associates. If you want to be recognized for your results and empowered to reach your potential, we urge you to apply.

Grade 16I
Pay Range: $102770 - $122037 per year"
1008924002706,Glassdoor,$93K,$132K,http://www.novonordisk.com/,"About the Department
Novo Nordisk Data Management and Informatics within the Digital Science and Innovation Organization provides informatics solutions, data products and analysis support to the research organization in Novo Nordisk. Data Management and Informatics is establishing a data products organization across our research sites. Staff will be co-located to one of our global sites in Seattle, WA, Fremont, CA, Lexington, MA, Oxford, UK and Denmark.

The Position
As a Data and Solutions Engineer, you will be an individual contributor with expertise on various types of data that are used for target selection and validation. There are numerous data sources coming from internal data generators and external data providers. Ultimately, you will set the direction and deliver analysis ready data products via appropriately architected data pipelines to solve complex scientific problems. This role focuses on providing findable, accessible, interoperable, and reusable (FAIR) data within our therapeutic areas that include diabetes, obesity, cardiovascular and rare diseases. You will provide support to both data generators such as laboratory scientists and data consumers including computational scientists, data scientists, and bots. You will use your knowledge of digital to speed up the ability of lab and data scientists to access and work with high-dimensional data.

You will use hands-on expertise to provide solutions using preferred tooling and technologies, and will work with other data engineers, product owners and specialists across Data Management & Informatics (DMI) and Global IT to address larger needs. You will also enable the visualization needs for data, be well versed in best practices required to streamline data handling and represent the local needs at the sites in the context of the global Data Management and Informatics organization.

Do you believe that the digitalization journey in Research and Early Development (R&ED) is crucial for the success of pharmaceutical companies in the future? Then apply to become part of the next wave of scientific discovery by joining Digital Science & Innovation (DSI).

Relationships
This position will report to the Senior Director, Data and Analytics Engineering, Targets and Translational. It will be a key Data and Solution Engineer for our strategic initiatives on the digitalization of R&ED, with a special focus on the development of our data products.

Essential Functions
Develop, implement, and maintain data models.
Establish data pipelines from raw data sources to cloud service publication.
Identify and establish storage solutions for historical data and align with existing data models.
Understand what is in the data to design more efficient data generation methods in the future.
Gather/organize large, complex data sets and develop transformations to move data through the processing pipeline. This will involve profiling, cleansing, transforming, and developing data structures, schemas, and dictionaries to create more efficient workflows.
Build automated monitoring mechanisms to ensure compliance and integrity of the pipelines and database.
Be proficient in concepts relating to DevOps including continuous integration, continuous delivery
Ensure scientists and data scientists are aware of available data and can access, integrate and query it in a performant manner.
Enable streamlined sharing of rich data with collaborators through cloud, accelerated compute and AI/ML approaches.
Assist with provisioning of compute and data pipelines to deliver performant data products via the research and enterprise data ecosystem.
Optimize workflows and exchange of research data.
Participate in sustaining a suite of tools and applications such as Python, R, Jupyter Hub, Domino, DataLab.

Physical Requirements
Up to 10% overnight travel required.

Qualifications
Master’s degree, or PhD highly preferred. Bachelor’s degree required; Degree within Life Sciences, Biomedical Engineering, Physics, Statistics, Computer Engineering preferred
Master’s Degree with 3+ years’ relevant experience, or PhD with little to no postdoctoral years of experience OR A Bachelor’s degree with 5+ years’ relevant experience can be considered
Relevant experience includes:
Experience in building and productionizing data pipelines with ETL.
Experience with database platforms and cloud services (AWS/Azure).
Experience in compiled, scripting programming language such as Python.
Experience working independently or with occasional guidance from manager/senior colleagues.
Experience communicating with bench scientist and/or other end-users and with middle management
Preferred experience:
2+ years’ experience in life sciences, medical device, or pharmaceutical industry
Automated testing skills
Domain knowledge in omics and high throughput cell assays

We commit to an inclusive recruitment process and equality of opportunity for all our job applicants.

At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.

Novo Nordisk is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, gender identity, sexual orientation, national origin, disability, protected veteran status or any other characteristic protected by local, state or federal laws, rules or regulations.

If you are interested in applying to Novo Nordisk and need special assistance or an accommodation to apply, please call us at 1-855-411-5290. This contact is for accommodation requests only and cannot be used to inquire about the status of applications."
1008923424974,Glassdoor,$66K,$100K,https://www.dtcc.com/,"Are you ready to explore a world of possibilities?
Join our DTCC family, and you’ll grow your expertise and become the best version of you. As you embark on a new journey, you’ll be supported and surrounded by other experts as you learn new skills, advance your career, and see the impact of your efforts every day.
Pay and Benefits:
Competitive compensation, including base pay and annual incentive
Comprehensive health and life insurance and well-being benefits, based on location
Retirement benefits
Paid Time Off and other leave of absence
DTCC offers a flexible/hybrid model of 3 days onsite and 2 days remote (Onsite Tuesdays, Wednesdays and a third day of your choosing)
Why you'll love this job:
IT Data Center Strategy & Operations team (DCS&O) takes complete ownership of our Data Center Complex. The team performs all aspects of installation and removal of our IT infrastructure across our global data center footprint. We serve as the first line of onsite support ensuring continuous availability of our critical environments and applications. We are committed to driving service excellence, identifying cost savings, proactively managing / mitigating IT risks and improving value from our data center and IT hardware throughout their lifecycle. DCS&O provides guidance to IT on third party colocation engagements, equipment decommissioning and disposal, equipment deployment service level agreements, sourcing, and vendor spend/cost analysis.
The Data Center Engineer supports the Data Center Strategy & Operations (DCS&O) leadership team on all internal and cross department programs with key collaborators (Procurement, Finance, IT, Third-Party Risk, etc). The successful candidate will develop and maintain all program/project plans, presentations, training materials and reporting.
Your Primary Responsibilities:
Provide for the oversight of installation, maintenance and operation of the physical hardware infrastructure which supports the data centers and other critical processing areas at all DTCC locations. Systems include fiber and copper infrastructure and physical rack and stack of IT hardware.
Support critical processing areas at both owned data centers which include hosted trusted partners.
Provide consulting services for Data Center Operations capital projects and other DTCC departments including Workplace Services, Communications and Physical Security.
Provide project planning, oversight, and technical review of outside consultants’ work. Manage activities of key consultants to meet the demands of IT.
Participate in technical reviews and evaluations of potential DTCC partners and service providers where expertise in physical plant and infrastructure is required.
Coordinate all physical data center access and vendor escort activities.
Provides decommissioning of retired IT assets and proper coordination of hard drive disposal.
Perform testing and commissioning for new facilities and critical systems.
Organize and manage programs that support vendor rationalization, risk management and process improvements
Manage operational plans for the department
Evaluate and assess the programs’ strengths and weaknesses
Determine sustainable goals for the associated programs
Collaborate with multiple stakeholders to discuss program goals
Status reporting and presentations
Identify and manage critical path while tracking risk, issues, and escalations
Support the execution of spend management and cost analysis
Mitigate risk by following established procedures and monitoring controls, spotting key errors, and demonstrating strong ethical behavior
A prime candidate is proactive, has the ability to multitask and work autonomously to support multiple teams and initiatives.
**NOTE: The Primary Responsibilities of this role are not limited to the details above. **
Talents Needed For Success:
Minimum of 4 years of related experience
Bachelor's degree preferred or equivalent experience
Additional Qualifications:
Familiarity supporting a service catalog to clients across IT teams
Knowledge of ITIL aspects inclusive of Service Now (SNOW) change, incident, and problem management.
Knowledgeable of fiber and copper infrastructure supporting physical data center environments
Familiar with data center deployments inclusive of mainframe, distributed, and network equipment
Who We Are:
The salary range is indicative for roles at the same level within DTCC across all US locations. Actual salary is determined based on the role, location, individual experience, skills, and other considerations. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

DTCC safeguards the financial markets and helps them run efficiently, in times of prosperity and crisis. We are uniquely positioned at the center of global trading activity, processing over 100 million financial transactions every day, pioneering industry-wide, post-trade solutions and maintaining multiple data and operating centers worldwide. From where we stand, we can anticipate the industry’s needs and we’re working to continually improve the world’s most resilient, secure and efficient market infrastructure. Our employees are driven to deliver innovative technologies that improve efficiency, lower cost and bring stability and certainty to the post-trade lifecycle.

DTCC proudly supports Flexible Work Arrangements favoring openness and gives people freedom to do their jobs well, by encouraging diverse opinions and emphasizing teamwork. When you join our team, you’ll have an opportunity to make meaningful contributions at a company that is recognized as a thought leader in both the financial services and technology industries. A DTCC career is more than a good way to earn a living. It’s the chance to make a difference at a company that’s truly one of a kind.
Learn more about Clearance and Settlement by clicking here .

IT Risk and Data Services department seeks to meet our clients’ needs by capitalizing on the progress made in both the Risk Technology Program and the Data Analytics work and driving adoption of these capabilities across the enterprise. Important initiatives like the Modernization and Resiliency Programs count on these foundational capabilities to succeed."
1008923968338,Glassdoor,$93K,$126K,https://www.wintrust.com/,"Wintrust is a financial holding company with approximately $50 billion assets under management and traded on the NASDAQ:WTFC. Built on the ""HAVE IT ALL"" model, Wintrust offers sophisticated technology and resources of a large bank while focusing on providing service-based community banking to each and every customer. Wintrust operates fifteen community bank subsidiaries with over 170 banking locations in the greater Chicago and southern Wisconsin market areas. Additionally, Wintrust operates various non-bank business units including commercial and life insurance premium financing, short-term accounts receivable financing, out-sourced administrative services, mortgage origination and purchase, wealth management services and qualified intermediary services for tax-deferred exchanges.
Location:
Job location –Rosemont, IL- Hybrid position with some telecommuting flexibility, but requirement to physically be in Rosemont, IL office occasionally/as needed.
Responsibilities:
Design, code, test, implement and maintain data solutions in the enterprise data warehouse as well as departmental data marts; Support multiple BI solutions using the Microsoft suite of database technologies (i.e., SSIS, SSRS and/or SSAS) including the development of stored procedures and functions.
Develop and support new and current ETL processes employing industry standards and CI/CD practices to enhance loading of data from and into different source/target systems ensuring data integrity and data quality.
Integrate modern data architecture technologies (Hadoop, Mulesoft Integration etc.) into existing ETL pipelines.
Processing complex and large volume data sets using big data technologies.
Performs complex coding tasks, participates in code reviews and write functional specs for small features.
Responsible for validating that all data processed through the ETL system is accurate before it is deployed to the end-user reporting layer.
Create data solutions for reporting and analytics team that assists them in implementing and optimizing our data tool.
Handle entire development life cycle of data warehouse projects, including a detailed technical documentation on design, develop, alter, maintain, and upgrade.
Recommend alternative approaches to the final designs and provide reasoning for the selection
Occasional oversight of off-shore employees.
Manage multiple, diverse projects simultaneously.

Job Requirements:
Bachelor’s degree in Computer Science, or related degree and 5 years of relevant experience. In the alternative, a Master’s degree in Computer Science, or related degree and 3 years of relevant experience will also be considered.
The position also requires:
3 years of experience with ETL methodologies, Business Intelligence and Data warehousing principles.
3 years of experience with Microsoft SQL Server or other relational database design, development and maintenance.
2 years of experience in the field of Data Warehousing and Business Intelligence with the following technologies: SQL Server Integration Services, SQL Server Reporting Services, TSQL, C#.Net, Azure SQL Database.
1 year of experience in designing REST APIs.
From our first day in business, Wintrust has been proud to serve a variety of unique communities and people from all walks of life. To be Chicago’s Bank® and Wisconsin's Bank®, we need to reflect that diversity both in all the communities we serve, the people we employ, the organizations we work with, and our banking and lending practices. Wintrust Financial Corporation, including community banking and financial services subsidiaries, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran or any other characteristic protected by law."
1008918195618,Glassdoor,$88K,$131K,http://www.vtekis.com/,"Company Description

VTekis Consulting LLC provides complete solutions for Staff Agumentation, Recruitment Process Outsourcing, Contract Hiring, Direct Hire and Outsourced Solutions. Our goal is to deliver quality professional services to our clients not just to find someone to do a job, we match the right professional for your staffing needs and earning confidence through the proper assignment of people. This alignment of people and companies allows us to create opportunity. Most importantly, We don’t consider the process complete until we find the perfect fit.

Job Description

Job Summary:
The Data Analytics Analyst designs data modeling/analysis services used to mine enterprise systems and applications for knowledge and information that enhances business processes.
This individual is also responsible for building, deploying, and maintaining data support tools, metadata inventories, and definitions for database file/table creation.
Create architecture documents and diagrams.
Participates in project estimation and management.
Conduct data model and architecture reviews.
Provide guidance on ETL process.
Perform analysis and profiling.
Work on the creation DDLs, maintenance and optimization of database.
Enforce architecture standard and framework process.
Design/develop SQL Server queries.

Additional Position Skills and Requirements
Bachelor's degree in computer science, Information Technology, or a related field
7+ years of experience as an architect
5 years of experience implementing MDM solutions
Proven experience in designing and implementing MDM solutions in an enterprise environment.
Strong knowledge of MDM platforms and technologies (e.g., Reltio MDM, Informatica MDM, SAP Master Data Governance).
Understanding of data modeling, data integration, and data quality best practices.
Familiarity with data governance frameworks and methodologies.
Expertise in creating mappings, trust and validation rules, match & merge process.
Experience in creating and maintaining entity objects, hierarchies, entity types and relationship objects
Excellent analytical, problem-solving, and communication skills.
Own the logical unit of development work “end-to-end” from concept to production, covering each phase of the SDLC.
Strong project management skills and the ability to lead cross-functional teams.
Relevant certifications in MDM or data management are a plus.
Regards,
Mohammed Ilyas,
PH - 229-264-4029 or text - 229-469-1455

Additional Information

All your information will be kept confidential according to EEO guidelines."
1008923435125,Glassdoor,$72K,$107K,http://www.limno.com/,"Come Work With Us:

Be Exceptional. Deliver Excellence. Make A Difference.
LimnoTech is a leading environmental engineering firm with clients who face water-related problems that are more challenging and costly than ever before. It is our job to help our clients make decisions based on the best available science and real-world constraints.

Are you ready to join a team of smart, talented people who are motivated every day to deliver excellence and make a difference for our clients, our partners, and the environment?

Advance your career working for an internationally respected industry leading environmental-water resources firm. LimnoTech’s focus is on developing and applying the latest tools in environmental-water resources engineering to effectively solve client problems and protect our water environment. LimnoTech offers great people to work with, numerous opportunities for professional development, and a company culture that emphasizes collaboration and continuous improvement.

We have an exciting opportunity for an early career water resources engineer, scientist, or data scientist to help meet ongoing/expanding project needs. The selected candidate will work in either our St. Paul, MN or Los Angeles, CA location.

Position Responsibilities
The engineer or scientist hired will provide support for a variety of interesting and innovative water resources projects in LimnoTech’s diverse service areas, such as:
Hydrologic, hydraulic, water quality and watershed assessments and planning
River, lake, estuarine and coastal studies
Urban stormwater management
River and wetland restoration design
Corporate water stewardship
Waterfront redevelopment
Water sustainability assessments and planning
Clean Water Act programs and compliance
Climate resiliency assessments and planning

Initial responsibilities will include technical tasks potentially including:
Data management, processing and assessment, including developing automated tools for data management, analysis, and visualization using modern data science tools, often with a geospatial context
Development, calibration, and application of environmental models, including workflow automation, optimization routines, and visualization capabilities for:
Hydraulic and hydrologic (H&H) modeling and evaluations
Water quality modeling and watershed assessments
Greenhouse gas exchange and carbon sequestration modeling
Researching and quantifying water benefits for corporate clients
Support restoration design processes, calculations, and drawings
Preparation of technical presentations and documents
Managing automated workflows within collaborative GitHub repositories

Our scientists and engineers work closely with senior staff to develop sound approaches for addressing our clients’ problems. LimnoTech emphasizes collaborative learning, advanced training, and professional leadership, providing team members with the tools and work environment needed to chart their career paths. Opportunities to grow will abound, including developing into roles making contributions in the following areas:
Technical task coordination and leadership
Project management
Subject matter expertise
Client management and business development

Motivated and enthusiastic team members with good interpersonal skills thrive in our collegial organization. If you like working with other smart, dedicated people solving challenging problems, we’d like to hear from you.

Qualifications
The following are required qualifications for this position:
Master’s degree or PhD in Environmental Engineering, Water Resource Science, or related environmental geoscience discipline from an accredited university program.
Alternatively, a bachelor’s degree with a minimum of 2 years of related work experience.
Capabilities in environmental and geospatial data management, analysis, visualization, and modeling.
Excellent oral and written communication skills are essential, as are strong analytical and computational abilities.
Must be legally able to work in the U.S. for any employer (proper documentation is required).

The following are desirable additional qualifications for this position:
Capabilities in surface water or groundwater simulation modeling (e.g., SWMM, HSPF, HSP2, SWAT, RAS, Modflow, GLM-AED, or similar).
2-5 years of relevant work experience.
Scientific computing experience and programming skills in Python, R, C++, or Fortran.
Machine Learning and advanced statistics experience with environmental and geospatial datasets.
Background of maintaining strong client relationships and developing new work.
Interested in and available for field work.

Compensation
LimnoTech values and rewards high achievement within a supportive working community. Individual achievement is rewarded through a unique merit review process based on recommendations from colleagues at all levels of the company, plus positive feedback from clients. This system drives pay increases and increased project and corporate responsibility. We track individual progress annually to ensure competitiveness within our industry and identify opportunities for targeted professional development.

Our collegial environment and management structure aren’t for everyone; there is no formal “corporate ladder” to climb. Instead, we offer employees the opportunity to chart their own path and we provide the tools and guidance to do that.

In addition to highly competitive compensation, LimnoTech offers an outstanding benefits package, including medical, dental, and vision coverage, 401k plan with company match, an employee stock ownership program (ESOP), flexible benefits program, medical leave, and more.
For more information about our firm, please visit www.limno.com
LimnoTech is an employee-owned (ESOP), affirmative action (AA) and equal employment opportunity (EEO) employer.
We value a diverse, equitable and inclusive workplace at LimnoTech. We believe that collaboration between diverse individuals with different perspectives and a unity of purpose will strengthen our company culture and yield innovative solutions for our clients. Therefore, we will intentionally increase awareness, foster dialogue, and seek continuous improvement in diversity, equity and inclusion throughout our company systems and practices. LimnoTech welcomes all qualified candidates for a diverse work force, and we are committed to equal opportunity and nondiscrimination. Employees are hired and promoted based strictly and solely on their competence to perform the work, without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.

LimnoTech uses E-Verify® in its hiring practices to achieve a lawful workforce.
We intend to have our website and job application functions accessible to everyone. If you or someone you know needs assistance completing an employment application, please contact us at 734-332-1200."
1008923641934,Glassdoor,,,http://www.att.jobs/,"JOB TITLE: Senior- Big Data Software Engineer

JOB LOCATION: 208 S. Akard Street Dallas, TX 75202 [and various unanticipated locations throughout the U.S.; may work from home]

Senior- Big Data Software Engineer needed by AT&T Services, Inc. in Dallas, TX [and various unanticipated locations throughout the U.S.; may work from home] to be responsible for building, designing, and the end-to-end ownership of a scalable software product tasked to deliver intelligent data driven products. Develop high performance, scalable, and distributed computing tasks using Java, Scala, and Python. Use big data programming languages and technology, write code, complete programming and documentation, and test and debug applications. Analyze, design, program, debug, and modify software enhancements and new products used in analytics and visualization solutions. Utilize self-service ingestion mechanisms to create automated ingestion pipelines including error checks and notifications. Aggregate multiple disparate datasets to create datasets for modelling, feature creation, and visualization using Python, R, SQL, Spark, and Power BI. Interact with data scientists and industry experts to understand how data needs to be converted, loaded and presented. Work within an Agile environment. Use SQL and apply knowledge of telecom Datasets. Utilize Azure cloud services and define project roadmaps. Define data requirements. Ensure and validate the quality of raw and derived datasets. Support the standardization, customization, and ad-hoc data analysis. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Explore new technologies in Azure to integrate in the current stack. Collaborate with data scientists and business partners to understand business problems. Create data and model based solutions to drive cost savings and revenue generation opportunities. Use machine learning techniques, visualizations, and statistical analysis to gain insight into various data sets.

MINIMUM REQUIREMENTS: Requires a Master’s degree, or foreign equivalent degree in Computer Science, Computer Engineering, or Computer Information Systems and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing high performance, scalable, and distributed computing tasks using Java, Scala, and Python; utilizing self-service ingestion mechanisms to create automated ingestion pipelines including error checks and notifications; aggregating multiple disparate datasets to create datasets for modelling, feature creation, and visualization using Python, R, SQL, Spark, and Power BI; working within an Agile environment; using SQL and applying knowledge of telecom Datasets; and utilizing Azure cloud services and defining project roadmaps.

Our Senior- Big Data Software Engineers earn between $137,000 - $231,100 yearly. Not to mention all the other amazing rewards that working at AT&T offers.

Joining our team comes with amazing perks and benefits:
Medical/Dental/Vision coverage
401(k) plan
Tuition reimbursement program
Paid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)
Paid Parental Leave
Paid Caregiver Leave
Additional sick leave beyond what state and local law require may be available but is unprotected
Adoption Reimbursement
Disability Benefits (short term and long term)
Life and Accidental Death Insurance
Supplemental benefit programs: critical illness/accident hospital indemnity/group legal
Employee Assistance Programs (EAP)
Extensive employee wellness programs
Employee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T
internet (and fiber where available) and AT&T phone

AT&T is an Affirmative Action/Equal Opportunity Employer, and we are committed to hiring a diverse and talented workforce. EOE/AA/M/F/D/V
*np*"
1008920738038,Glassdoor,$85K,$134K,http://www.integratedintelsolutions.com/,"Insider Threat Engineering Specialist Data Engineer – Level 4 - Position ID = SIIE-MJ-DO-0016

Work Description: Database Administrators maintain operational Oracle databases and supports the data transformation processes to enable storing and retrieval of customer data with a Data Warehouse. Database Administrators ingest data from internal and external sources and present that data for analytics and business intelligence. Database Administrators also main and administer application-specific databases. The Data Warehouse is currently implemented with the Data Vault 2.0 specification.

Duties include:
Design the logical data relationships and query structures of new databases considering factors such as access methods, access frequency, storage media, data volatility, query requirements, and operating environments to support insider threat detection application software and data analysis.
Design enterprise database strategies for functions such as backup, recovery and migration.
Evaluate data sets and engineer solutions for integrating into the Data Warehouse.
Sustain existing Data Warehouse and application databases.
Perform daily database administration functions such as developing queries and reports based on customer requirements, modifying or developing database views, and managing backup and recovery operations.
Develop, sustain and preserve user manuals and instructions that guide customers in executing data access functions such as running queries and reports.
Participate in multi-functional teams and manage work through JIRA
Demonstrates advanced subject matter expertise in job family.
Contributes to and may lead the planning and implementation of large programs in the function, and regularly interfaces with senior management and executive leadership.
Plays a role in overall functional strategic planning.

Required Skills and Experience:
Active TS/SCI security clearance
Eligible to obtain CI polygraph
Bachelor's Degree with 11-14 years of related experience or equivalent experience in a related field
Possess a minimum of five (5) years of experience in Application Software and Extract Transform Load (ETL) and/or Data, Database and/or Data Warehouse implementations
Possess experience with SQL and SQL Plus
Possess experience building and scheduling data integration scripts that automat ingest of data from multiple sources (Oracle, SQL, Postgres)
Possess experience using data Extract Transform Load (ETL) applications
Must have intermediate level proficiency in MS office products. (Word, Excel, PowerPoint, Outlook)."
1008918387316,Glassdoor,$64K,$96K,http://www.wellsky.com/,"The Solutions Engineer III – Data Services is responsible for working with WellSky clients and internal WellSky project teams to create database driven solutions to address the specific needs of a client and/or industry where technology and efficiency can help them grow their business. This role requires a collaborative approach with internal stakeholders.
A day in the life!
You will be responsible for the following:
Work directly with clients to create data exchange solutions to import, update and delete data from various databases.
Lead data migration engagements with clients where they need to provide data in prescribed formats for import into WellSky solutions.
Creates appropriate documentation such as implementation manuals, support manuals/playbooks, performance testing guidelines, etc. as needed to run/support the software
Maintain confidentiality of sensitive information, with special emphasis on Protected Health Information (PHI)
Participate in the training and/or mentoring programs as assigned or required
Adhere to the WellSky Values and support a positive company culture
Develop and test custom rules and automation solutions based on requirements
Other Duties as Assigned.

Relocation assistance provided to eligible candidates.

Do you have what it takes?

Required Qualifications:
Bachelor's degree in a related field or comparable work experience
4-6 years related work experience

Do you stand above the rest?
Preferred Qualifications:
5+ years working on complex data exchange projects including extracting data, creating data mapping requirements documents, transforming data, and importing data into databases.
5+ years building database solutions for Microsoft SQL Server
Experience creating solutions using Microsoft SSIS
Ability to translate business requirements into software solutions
Demonstrated results in delivering program/software solutions, data modeling and object-oriented design techniques
Experience/knowledge of developing in C#/NET, ASP.NET, WebAPI and Entity Framework, JSON, XML and other data file structures
Excellent written and verbal communication skills
Thorough understanding of SDLC methodologies and best practices
Able to travel up to 10%

#LI-KA1
#LI-Hybrid
WellSky is where independent thinking and collaboration come together to create an authentic culture. We thrive on innovation, inclusiveness, and cohesive perspectives. At WellSky you can make a difference.
WellSky provides equal employment opportunities to all people without regard to race, color, national origin, ancestry, citizenship, age, religion, gender, sex, sexual orientation, gender identity, gender expression, marital status, pregnancy, physical or mental disability, protected medical condition, genetic information, military service, veteran status, or any other status or characteristic protected by law. WellSky is proud to be a drug-free workplace.

Applicants for U.S.-based positions with WellSky must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. Certain client-facing positions may be required to comply with applicable requirements, such as immunizations and occupational health mandates.

Here are some of the exciting benefits you will receive as a Teammate at WellSky:
Excellent medical, dental, and vision benefits
Mental health benefits through TelaDoc
Prescription drug coverage
Generous paid time off, plus 13 paid holidays
Paid parental leave
100% vested 401(K) retirement plans
Educational assistance up to $2500 per year"
1008922519466,Glassdoor,,,,"Inclusively is partnering with a multinational financial services company to hire a Senior Data Engineer - Hybrid.
ABOUT INCLUSIVELY:
Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD). Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability.
The Role
Cloud and Platform Engineering (CAPE) is looking for a database/automation engineer to work in the Oracle squad. The role involves general maintenance task such as rehydration, upgrades, backup, recovery, and troubleshooting. Responsibilities also involve database security, monitoring and performance tuning of the database and application queries.
The Expertise
Bachelor or Master degree in Computer Science, Information Technology or Equivalent
8+ years of IT database experience
Requires in depth knowledge of Oracle RAC, Oracle Performance & Tuning and SQL Tuning.
Experience working on various Cloud Options (AWS/Azure).
Build, deliver, configure, and maintain Oracle databases on-premises and Cloud Infrastructure in AWS and Azure using industry standard deployment tools.
Standardize and implement Cloud user management, security, capacity, monitoring and configuring application tools
Experience with Aurora PostgreSQL, Cosmos DB, Cockroach DB and other cloud native database skills preferred in AWS or Azure.
Strong experience in production support and maintenance of high availability database systems with ability to manage large scale database projects.
Experience in Golden Gate replication on Oracle Real Application Clusters (RAC) & Exadata
Analytical skill in solving complex technology challenges including solid troubleshooting skills with advanced performance SQL tuning expertise.
Proven expertise in Realtime Application Testing, Oracle diagnostic tools.
Experience in configuring Monitoring tools like Data Dog, OEM and proactive detection.
Aurora PostgreSQL, Cosmos DB, Cockroach DB and other cloud native database skills preferred in AWS RDS and Azure.
The Skills You Bring
Your ability to learn and adapt to new technologies.
You have experience collaborating with multiple teams and stakeholders.
Your ability to work in fast paced, highly demanding environment.
Job Type: Full-time
Experience level:
8 years
Schedule:
Monday to Friday
Work Location: Remote"
1008922281274,Glassdoor,,,,"Summary
Posted: Sep 11, 2023
Role Number:200502024
The Apple Maps Metrics Engineering team needs great engineers to help us architect and build the next-generation Metrics pipeline in the Cloud. Our team develops and runs big data and computing platforms at a large scale to empower data engineers, statisticians, and data scientists to experiment with algorithms, to measure and improve the accuracy and quality of Apple Maps global datasets. Our responsibility covers the whole lifecycle of data, including storage platform, large-scale pipeline, data query, data quality, data recency, security, and privacy. The Metrics pipeline is the central hub of the decision-making process through the support of dashboarding, A/B testing, model training, and ad-hoc evaluation algorithms by data scientists. We are facing challenges every day to deal with data at a massive scale. That is why we are looking for strong engineers who love solving challenging problems through conducting independent research and collaborating with teams across Apple. We're looking for senior software engineers who have extensive working experience in delivering big data platforms or large-scale data pipelines or streaming systems in the public cloud. You'll be working on a unique and challenging big data ecosystem with focuses on storage efficiency, scalable and performant queries, expandability and flexibility, and related problems, with the goal to help better measure the quality of map data.
Key Qualifications
10+ years experience working in large-scale data processing pipelines in batching and/or streaming manners; familiar with MapReduce, Spark, Flink, Storm.
3+ years of experience architecting large-scale distributed computing systems with AWS or GCP technologies.
2+ years experience working in big data storage platforms and query engines with knowledge in cutting-edge technologies like Hive, Iceberg, Delta Lake, Hudi.
Solid in at least one JVM-based programming language; with an understanding of asynchronous I/O, concurrency; knowledge in the Java memory model will be a big plus.
A problem solver with independently investigative skills and with strong collaboration mindsets.
An advocate of software development best practices that focuses on engineering excellence and operational excellence.
Customer focus with good listening skills; strong communication and presentation skills.
Good time management skills and can incrementally deliver to tight schedules.
Description
You will work with engineers to build a big data platform that processes and manages Exabytes of data and enables efficient access to those data. By embracing various technologies around data storage, data processing, and query engines, we target to build the data platform to empower data-driven analysis and decision-making at Apple Maps and to improve the core product that touches millions of users worldwide each day. You will be responsible for the full software development lifecycle to deliver reliable systems that service a number of internal customers. The ideal candidate will be a highly motivated and proactive individual with good width and depth of related technical knowledge. You will face a lot of challenges and are expected to be goal-oriented and driven to deliver quality solutions in a demanding environment. You are expected to work with other senior engineers and to collaborate with them professionally. You should be able to express your opinion as well as listen to others. You should be able to deal with ambiguity and drive conversations toward clarity of scopes.
Education & Experience
BS in Computer Science/Electrical Engineering or related degree.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $199,800 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program."
1008921835932,Glassdoor,$76K,$102K,http://careers.walmart.com/,"Position Summary...

What you'll do...

The Walmart International data management team is in charge of organizing and storing data, ensuring the data infrastructure operates in a scalable and optimized manner, while maintaining cost efficiency.

The data management team works closely with other departments, such as IT, business intelligence, analyst, data scientist and operations, to ensure that data is accessible, accurate, and secure. By effectively managing and utilizing the company's data resources, the data management team plays a crucial role in driving business success and enabling informed decision-making.

We are seeking a self motivated ,passionate and innovative Data Engineer to join our growing team. The ideal candidate will have a strong understanding in data integration, ETL processes, and big data technologies. As a Data Engineer, you will be responsible for designing, developing, and maintaining scalable and reliable data pipelines and solutions to support various analytical and data science initiatives. You will also collaborate with data scientists, analysts, and other stakeholders to ensure seamless data flow and optimal data quality. If you have a passion for working with large datasets, developing new data solutions, and are eager to contribute to a data-driven organization.

About Team:
Focusing on customer, associate and business needs, this team works with Walmart International, which includes more than 5,200 retail units, operating in 23 countries such as Canada, Central America, Chile, China, India, Mexico and South Africa to name a few.

What you'll do:

Drive strategic goal of data consolidation for the whole of engineering to enable cross-domain analytics.

Own and establish Center of Excellence for Data Engineering practices by defining architecture, rules, and setting guardrails for data processing capabilities. This includes data Ingestion, quality control, transformation, and high availability.

Incorporate state-of-the-art practices in Data Engineering to scale the value we deliver in transforming data into insights.

Identify, design and implement internal process improvements, including data infrastructure, for scalability, optimizing data delivery, and automating manual processes.

Drive automation and think out of the box to develop new utility which can drive the business further.
Leverage your experience and proficiency in all aspects of data management, data cataloging, analytics solution architecture & design, and implementation roadmap.
Interact with Walmart international data users on daily basis to provide data solutions .

What you'll bring:

Good understanding of ETL (Extract-Transform-Load) process .
Must be detailed-oriented with a passion for data accuracy and reliable solution development.
Subject Matter Resource in designing and building high performance data pipelines to move and process data using modern tools.
Subject Matter Resource in SQL (advanced).
Must be proficient in at least one prominent programming language, such as Python (preferred),Scala or Java.
Experience with Git ,CICD platform like Jenkins is required
The ability to work with other team members, drive projects to completion, and work autonomously.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:
We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Computer Science or related field. Option 2: 2 years' experience in software engineering or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Masters: Computer Science

Primary Location...
2501 Se J St, Ste A, Bentonville, AR 72716-3724, United States of America"
1008923152608,Glassdoor,$96K,$134K,http://www.theice.com/,"Job Purpose
The Senior Data Quality Engineer will be responsible for developing, maintaining and automating tests to ensure all compliance reports, surveillance systems are accurate and complete. This role requires frequent interaction with software developers, testers, product managers and compliance professionals to ensure delivery of quality reports to internal and external users for business decision making and government compliance needs.
Responsibilities
Strong background in functional testing with the ability to design and develop test strategy and test cases.
Gather information from disparate systems to aid problem resolution and perform integration testing
Work with Business Analysts, Software developers, ETL and Data warehouse engineers to review technical requirements and produce test strategies, test scenarios, and test cases for the data warehouse team to validate ETL scripts and confirm correct data is being extracted from the source.
Work with trading systems for trade entry in order test surveillance systems for monitoring
Testing skills to validate the transformation logic; diagnostic and debugging skills. Performing source-to-target-validation and data quality testing
experience with programming skills/python coding/automation efforts and exposure to fixml/xml parsing
Ability to lead a distributed testing effort.
Excellent attention to detail.
Ability to work in an agile environment with an iterative approach to development.
Knowledge and Experience
Requires experience/knowledge of the following functional areas:
5+ experience in software application testing, with a 3 year experience in enterprise data warehouse environments.
Proficient in SQL and database systems
Experience Unix to analyze logs and ability to parse XML files
Track record of completing assignments on time with a high degree of quality.
Excellent analytical, problem-solving, communication and interpersonal skills.
Ability to work independently and productively under pressure.
Bachelor
s Degree or equivalent
Schedule
This role offers work from home flexibility of up to 2 days per week.
Intercontinental Exchange, Inc. is an Equal Opportunity and Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin or ancestry, age, disability or veteran status, or other protected status."
1008922281260,Glassdoor,,,,"Summary
Posted: Sep 11, 2023
Weekly Hours: 40
Role Number:200502400
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Statistics, Finance , Physics, Data Science or related field and 2 years of experience in the job offered or related occupation. 1 year of experience with each of the following skills is required: 1. Python 2. SQL 3. Machine Learning 4. Casual Inference 5. Statistics
Description
APPLE INC has the following available in Austin, Texas. Create causal machine learning models to understand and improve Apple’s Services’ marketing efforts. Collaborate with Apple Media Products team members and partners to use Causal Inference techniques that help us optimize our Marketing efforts, focusing on Services such as Apple TV+, Apple Music, Apple Fitness+, Apple Arcade, the App Store, and Apple One. Engineer end-to-end scalable and robust Causal Inference products which provide Apple with an understanding of the health of our Services’ marketing efforts. Dive deep into large-scale data sources to uncover opportunities for Causal Inference automation, predictive methods, and quantitative modeling across Apple services. Partner with other Apple organizations on data engineering, data governance, voicing support for Causal Inference techniques, and democratizing data. 40 hours/week.
Education & Experience
Additional Requirements"
1008917693542,Glassdoor,,,,"Date Posted:
2023-10-06
Country:
United States of America
Location:
HTX99: Field Office - TX Remote Location, Remote City, TX, 73301 USA
Position Role Type:
Remote
Do you love data, exploration and solving challenging problems? Are you motivated to work for an organization that provides businesses actionable, aviation data and allows family & friends to track their loved ones when traveling?
FlightAware, part of the Connected Aviation Solutions (CAS) unit of Collins Aerospace, has built the world's leading aviation software platform, processing over 180+ million incoming messages an hour from over 30,000 individual data feeds—2 terabytes a day and growing! We provide the best, most complete, and most accurate real-time flight-tracking service and are proud to have built a wide variety of successful products on this foundation that have become central to the aviation industry at large.
As an Aviation Data Engineer at FlightAware, your role is to harness our extensive aviation data to design and deliver custom reports that provide practical solutions for our diverse customer base. You'll be at the crossroads of aviation and data, using your skills to offer valuable insights and tailored solutions. You will be at the forefront of technology and by leveraging your technical skillset and interest in aviation data, you’ll have the opportunity to directly support building product features and growing the reach of our data. You will also be a member of a dynamic and high functioning team where your opinion matters and your work will have a highly visible impact. We also make time to have fun, share our passions, and be ourselves.
Regardless of role, we expect excellent interpersonal and communication skills across all hires at FlightAware. We look for candidates who will thrive here, meaning they demonstrate clear communication, embrace open feedback, trust their colleagues, and are driven to execute, deliver, and complete projects independently and efficiently.
What YOU will do:
YOU will be a valued member of the Data Reports team; a small and passionate group of aviation & data geeks.
YOU will serve as a solutions engineer for customer requests and help think creatively about how to use FlightAware data to solve real-world problems. You will also use your technical background to help innovate and expand our product capabilities to grow our reach within the market.
YOU will support growth in our data reporting business by driving new technologies and helping to expand our move to cloud-based services.
YOU will help us ramp up our initiatives as they relate to increased speed (though leveraging cloud technologies), and also new reporting capabilities like data visualizations and greater self service options.
YOU will mentor junior members of the team and support them in deepening their skills and experience.
YOU will work in a supportive environment with a team of people who treat each other with respect and care about building and delivering a high quality web experience for users.
What YOU will learn:
YOU will develop your technical acumen by building new and innovative technology, grow your interpersonal skills, and develop a broader understanding of our domain area.
YOU will learn how to apply the largest aviation dataset in the world to solve real-world problems and how to do that with new and innovative technologies.
YOU will be challenged because the amount of data is vast, and the use cases we see on a daily basis are virtually endless. Onboarding may take some time to become fully aquainted with the data structures and our customer needs; however, for the right candidate this will be part of the draw of this role.
YOU will gain experience in building new product features and being the technology advocate for expanding our capabilities in cloud warehouses and self service tools.
YOU can use this experience to drive deeper into the technical domain with support from some of the most talented engineers in the world, or you can lean toward product growth and the intersection of technology and product development practices. The opportunities are vast!
Education & Experience:
Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) unless prohibited by local laws/regulations and minimum 2 years of prior relevant experience or an Advanced Degree in a related field or in absence of a degree, 6 years of relevant experience
Must be authorized to work in the U.S. without sponsorship now or in the future. RTX will not offer sponsorship for this position.
Skills You Must Have:
Proficiency in SQL and a strong grasp of relational data is essential.
Comfortable using the command line and source control.
Proficiency in other programming languages like Python is essential.
Professional organizational skills and effective written & verbal communication.
Skills We Value:
Prior experience with data reporting.
Experience with data visualization and tools such as Tableau/Esri/PowerBI.
Familiarity with cloud services such as AWS/GCP/Azure.
You have experience in airline or business aviation operations, are an aviation enthusiast, private pilot, or you are looking to pursue your private pilot license.
With a true culture of curiosity and exploration, we love people who are self directed and like being empowered to build solutions and bring new and innovative ideas to their work. You thrive on initiative, delivering results independently.
Collins Aerospace, a Raytheon Technologies company, is a leader in technologically advanced and intelligent solutions for the global aerospace and defense industry. Collins Aerospace has the capabilities, comprehensive portfolio, and expertise to solve customers’ toughest challenges and to meet the demands of a rapidly evolving global market.
Connected Aviation Solutions:
Our Connected Aviation Solutions team provides advanced information management systems, products and services that enable the connected ecosystem by bringing together Collins’ unique breadth of aviation, surface transportation and critical infrastructure products with our smart digital solutions to help us enhance every aspect of the end-to-end travel experience. We help airlines, airports, business aircraft and rail operators turn data into value to streamline operations, increase efficiency and reduce cost, enhance the passenger experience and contribute to sustainable flight. By combining the best networks, connectivity and data/analytics solutions, we’re solving big problems for our customers and the world, while enhancing the security and connectivity of systems both on and off the aircraft, to help operators and passengers stay more connected and informed and create a more sustainable, efficient, reliable and enjoyable travel experience. Aviation connects the world. Our Connected Aviation Solutions team connects aviation. Sustainably. Seamlessly. Securely.
Collins Aerospace Diversity & Inclusion Statement:
Diversity drives innovation; inclusion drives success. We believe a multitude of approaches and ideas enable us to deliver the best results for our workforce, workplace, and customers. We are committed to fostering a culture where all employees can share their passions and ideas so we can tackle the toughest challenges in our industry and pave new paths to limitless possibility.
WE ARE REDEFINING AEROSPACE.
Please consider the following role type definitions as you apply for this role.
Remote: Employees who are working in Remote roles* will work primarily offsite (from home). An employee may be expected to travel to the site location as needed.
This position is remote; however, if you live within a reasonable commute of a Collins site with other colleagues you interact with, your manager will discuss whether there is a degree of onsite presence associated with this role.
Some of our competitive benefits package includes:
Medical, dental, and vision insurance
Three weeks of vacation for newly hired employees
Generous 401(k) plan that includes employer matching funds and separate employer retirement contribution, including a Lifetime Income Strategy option
Tuition reimbursement program
Student Loan Repayment Program
Life insurance and disability coverage
Optional coverages you can buy: pet insurance, home and auto insurance, additional life and accident insurance, critical illness insurance, group legal, ID theft protection
Birth, adoption, parental leave benefits
Ovia Health, fertility, and family planning
Adoption Assistance
Autism Benefit
Employee Assistance Plan, including up to 10 free counseling sessions
Healthy You Incentives, wellness rewards program
Doctor on Demand, virtual doctor visits
Bright Horizons, child and elder care services
Teladoc Medical Experts, second opinion program
And more!
At Collins, the paths we pave together lead to limitless possibility. And the bonds we form – with our customers and with each other - propel us all higher, again and again.
Apply now and be part of the team that’s redefining aerospace, every day.
The salary range for this role is 62,000 USD - 124,000 USD; however, RTX considers several factors when extending an offer, including but not limited to, the role and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance.
RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.
Privacy Policy and Terms:
Click on this link to read the Policy and Terms"
1008918490061,Glassdoor,$89K,$131K,https://www.lockheedmartin.com/,"JOB ID: 647949BR
Date posted: Oct. 10, 2023
Program: F-35

Description:
By bringing together people that use their passion for purposeful innovation, at Lockheed Martin we keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work. With our employees as our priority, we provide diverse career opportunities designed to propel development and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. At Lockheed Martin, we place an emphasis on empowering our employees by fostering innovation, integrity, and exemplifying the epitome of corporate responsibility. Your Mission is Ours.

Lockheed Martin Aeronautics in Fort Worth, Texas is seeking a full-time Early Career Data Quality Engineer. In this role, you will 1) perform aircraft flight and part data processing, integration, and delivery; 2) coordinate with data users, application teams, and suppliers; and 3) apply data analysis and problem-solving techniques to assess and drive data, system, and process integrity. The successful candidate will have knowledge of data manipulation and analysis techniques using spreadsheets, databases, or equivalent as well as have familiarization with critical-thinking methods like The 5 Why's, Fishbone, Cause and Effect Maps, or equivalent to solve complex problems and enhance customer experience.

Must be a US Citizen.; This position will require a government security clearance.; This position is located at a facility that requires special access.
Basic Qualifications:

Bachelors degree in Industrial, Systems, or Data Engineering. Aerospace, Computer, and Software Engineers will also be considered.

Proficient with collecting, compiling, processing datasets involving the use of formulas, charts, queries, and/or tables.

Coursework in or familiar with product/data quality control methods like Total Quality Management (TQM), Six-Sigma, Agile/Kaizen, or equivalent.

Must be a US Citizen.; This position will require a government security clearance.; This position is located at a facility that requires special access.
Desired Skills:

Familiar with software coding/scripting with SAS, Python, Visual Basic, or equivalent.

Familiar with eXtensible Markup Language (XML).

Basic experience performing queries using Standard Query Language (SQL).

Basic experience with data visualization tools like Tableau, Power BI, or equivalent.

Coursework in or application of mathematical modeling or statistical methods.

Coursework in or experience with formal presentation development and delivery including the use of PowerPoint
Security Clearance Statement:
This position requires a government security clearance, you must be a US Citizen for consideration.
Clearance Level:
Secret
Other Important Information You Should Know

Expression of Interest:
By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely:
Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.
Work Schedules:
Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position:
4x10 hour day, 3 days off per week
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.
Experience Level:
4 yr and up College
Business Unit:
AERONAUTICS COMPANY
Relocation Available:
Possible
Career Area:
Systems Engineering: Other
Type:
Full-Time
Shift:
First

At Lockheed Martin, we apply our passion for purposeful innovation to keep people safe and solve the world's most complex challenges.
Mission-Focused Innovation: From aerospace to outer space to cyber space, you can solve the world's most complex challenges for our customers.
Foundational Values: Our culture of performance excellence, ethics, teamwork and inclusion is embedded in everything we do.
Diverse Career Opportunities with Meaningful Work: Grow your career and skills for life. Our technology-driven learning platforms and programs enable your development and agility.
Your Health, Your Wealth, Your Life: Our flexible schedules, competitive pay and comprehensive benefits enable you to live a healthy, fulfilling life at and outside of work.
Empowered to Be Your Best: Use your strengths to make a difference in the lives of one another, our customers, our communities and our planet.
Commitment to Sustainability: We foster innovation, integrity and security to preserve the environment, strengthen diverse communities and propel growth.
Here, the possibilities are endless because we offer:
Flexible Schedules, dependent on role
Levels: Student, Entry, Mid, Senior, Management
Locations: Nationwide & OCONUS Positions"
1008923439178,Glassdoor,,,https://www.dgrsystems.com/,"DGR Systems is looking for a Sr. Engineer, Infrastructure Solutions, with experience in data solutions backup. You will be responsible for designing and implementing backup solutions with our clients using Cohesity DataProtect. You will collaborate with internal and external stakeholders to develop and maintain robust data protection strategies and solutions.
The ideal candidate must be an excellent communicator with an ability to simplify complex topics into clear messages and must be consultative in focus with a growth mindset and passion for continuous learning to bring the best solutions to our clients. The candidate will bring technical experience, solutions leadership, and business acumen to DGR Systems.

Why DGR?
DGR Systems helps solve the most complex business and operational challenges for their clients. Our team of top-level industry experts takes an innovative and straightforward approach to consulting, design, deployment, and ongoing Assurance Services to meet client needs.
At a glance, DGR Systems was founded in 2009 in Tampa, Florida and provides full-service solutions in the areas of Modern Workplace (Endpoint Solutions, Collaboration), Security (Identity and Access Management, Zero Trust, Information Protection) Modern Infrastructure and Cloud, and Applications (Collaboration Apps, SQL Reporting, Power Platform). With an impressive depth of experience across the Microsoft technology solution stack combined with our focus on integrating solutions from multiple leading vendors, we help organizations design and execute against their most challenging digital transformations. At DGR Systems, our culture is built around one simple standard: Excellence is our Baseline - and we deliver on that standard with every client, every day.
Core Values

DGR Systems core values are an essential and enduring tenant of our organization. They are a small set of timeless guiding principles describing who we are, how we treat people and how we run our business.
Passion - Love what you do and make it evident through your approach to your work and the attitude you display.
Ownership - Be accountable for outcomes. Take initiative to start and move things forward to make something better.
Integrity - Do the right thing. Always. Every time. Without exception.
Navigation - Find solutions to problems. Evolve, adapt, and embrace change around you for tomorrow will be different than today.
Teamwork - Be approachable and engage with the team around you constantly. We win or lose together.


Responsibilities
Provide service ownership through the understanding and evangelizing of how technology solutions can help solve business challenges and guide the development of services to meet those needs
Ensure the execution of service delivery for our clients to a standard of excellence expected by our clients
Engage with existing and prospective clients, partnered with our sales organization, to help design, implement, and maintain backup and recovery solutions, including data backup, replication, and restoration processes to solve client challenges
Develop backup and data retention policies that align with client’s business objectives and compliance requirements.
Implement security best practices for data protection and ensure compliance with industry regulations and data privacy laws
Identify and resolve backup and recovery issues promptly. Perform root cause analysis for failures and implement corrective actions
Assess storage capacity requirements and plan for scalability to accommodate future data growth
Create comprehensive documentation of backup and recovery processes, configurations, and procedures
Work closely with internal and external teams, including system administrators, network engineers, and database administrators, to ensure data protection is integrated seamlessly into the organization's infrastructure
All other duties as assigned.
Requirements
5+ years of experience in backup solutions design and implementation
Strong knowledge of backup concepts, methodologies, and technologies
Understanding of disaster recovery principles and methodologies
Desired experience in Cohesity Backup products
Proficient in backup solutions for various platforms, applications, and databases, such as Windows, Linux, VMware, Hyper-V, SQL Server, Oracle, Exchange, SharePoint, etc.
Experience in backup solutions for cloud environments, such as AWS, Azure, GCP, etc.
Experience in backup solutions for hybrid and multi-cloud scenarios
Experience in backup solutions for large-scale and complex environments
Experience in backup solutions for disaster recovery and business continuity
Demonstrated client-focus solutions provider excelling at understanding customer needs and translating those needs to solutions
Excellent problem-solving, collaboration, organizational, presentation, product demonstration, writing, and verbal communication skills
Ability to work independently and collaboratively in a fast-paced and dynamic environment
Certification in Cohesity products is a plus
Certifications in relevant areas (e.g., Certified Information Systems Security Professional (CISSP), Certified Backup and Recovery Engineer (CBRE)) are a plus
Benefits
Health Care Plans (Medical, Dental & Vision)
Health Savings Account
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Paid Time Off (Vacation, Sick & Public Holidays)
Family Leave (Maternity, Paternity)
Short-Term & Long-Term Disability
Training & Development
Work from Home Program
We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas."
1008921164536,Glassdoor,,,,"Are you up for the challenge? Do you want free money in your 401k? Do you want job security and a company that invests in you? You need to check us out!
In this exciting role you will work with real-time data and create tools using cutting-edge visualization, development, and analytic technologies.
ALONG WITH COMPETITIVE SALARIES AND OUR COMPREHENSIVE BENEFITS, WE OFFER:
Employee Performance Incentives
Ongoing Training Opportunities
Boeing Employee Discount Program
Health Insurance Opt-out Incentives
Generous 401k Contribution – 10% contribution (NOT A MATCH)
Student Debt Payoff
Up to $30k Tuition Assistance
HSA Contributions
Professional Development Program
Every day, Boeing Intelligence & Analytics supports global missions by building and delivering intelligence, analytics, and cyber solutions that enable users to advance national security. We have provided our customers with the tools needed to counter the evolving global and cyber threats, and to improve wartime decision making. Our talented employees bring software development, systems engineering, and advanced analytics expertise. We offer numerous prime contract opportunities with customers headquartered in Maryland, Virginia, and the District of Columbia, as well as subcontract opportunities that align with our areas of focus and additional opportunities nationwide through our parent company.
What you will do (day in the life):
Boeing Intelligence & Analytics is looking for a Data Engineer to join their team. This position is responsible for working with DIA Technical Leadership and IC Analysts to develop, deploy and configure data centric Zero Trust solutions. These solutions should adhere to Zero Trust best-practices, reference frameworks, regulations, and guidelines. Position requires:
Interfacing with customer stakeholders and engineering teams
Performs highly specialized and technical tasks associated with the most current and cutting-edge technologies
Coordinates with contract management and customer to ensure the problems have been properly defined and the solutions satisfy customer needs
Performs complex system development, design, modeling, analysis, integration, and sustainment of systems for new or existing computer systems within an Enterprise.

Work Location: NCR Area (DC, MD, VA) and New Jersey.
Telework Availability: Hybrid
Qualifications
Active TS/SCI clearance
Must be familiar with Zero Trust Fundamentals
Understanding of Zero Trust pillars, best practices, frameworks, and implementation strategies.
Experience with data-centric security solutions, data engineering and policy models.
Understanding of IC Data Encoding Specifications
Enterprise Data Header (EDH)
Trusted Data Format (TDF)
Experience with design, development and implementation of data architectures, data standards, data tagging, and data formats to include XML, JSON, RDF and CSV.
Experience with implementing database, data warehouse, or data analytics solutions.
Experience with Splunk dashboards.
Experience with data modeling and analytics in Python.
Strong experience with cloud environments such as AWS, Azure, Oracle Cloud, and Google Cloud.
Education (Required Skills/Experience)
HS/GED + 14 years
Associates Degree + 12 years
Bachelor’s Degree + 10 years
Master’s Degree + 8 years
PhD + 6 years
Preferred Qualifications (Desired Skills/Experience):
Active TS/SCI clearance with polygraph
Knowledge of federal policies, regulations, and standards:
CISA Cloud Security Technical Reference Architecture
CISA Zero Trust Maturity Model
DoD Zero Trust Reference Architecture
M-22-09 Federal Zero Trust Strategy
National Security Systems Zero Trust Reference Architecture
NIST CSWP Planning for a Zero Trust Architecture - A Starting Guide for Administrators
NIST SP 800-207 Zero Trust Architecture
Boeing Intelligence & Analytics Benefits:
Employees are more effective on the job when they are not distracted by health and financial worries. To support our workforce, we offer a wide variety of health, life and other insurance benefits (as described above) that allow each employee to choose the coverage best suited to their needs and the needs of their family.
Summary Pay Range: Please note that the information shown below is a general guideline only. Pay is based upon candidate experience and qualifications, as well as market and business considerations.
$150,000 - $190,000
BI&A is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Equal Employment Opportunity is the Law (PDF)"
1008923429137,Glassdoor,,,http://www.uptalent.com/,"This is an exceptional opportunity to work with a nationwide Oil & Gas Services Company at their base in Shreveport, LA
Hours: 8am - 5pm
Job Summary:
The role of Electrical Engineer is to support the Engineering Lead and Product Engineering Manager.
They will be accountable for the electrical scope and systems in large scale data centers across the design, construction, assembly, testing, installation, and commissioning phases.
The Electrical Engineer will be responsible for checking and approving drawings / designs; interface communication, and ensuring the accuracy, reliability, efficiency, and safety of the electrical scope of work for Hyperscale Data Center Modules meets customer’s requirements and Industrial Standards.
The Electrical Engineer will play a critical role with supporting the plant during the manufacturing stage.
They will also be assisting various stakeholders in troubleshooting site installation and commissioning problems.
Roles and Responsibilities:
Checking and approving drawings, information, and documentation which meets Industrial standards to enable the manufacturing group and other departments to produce Data Center Infrastructure Modules.
Attend and initiate Design and Development Planning and Review session to meet customer’s and industry’s need.
Prepare TRs (Technical Requisitions) for electrical systems, fire systems, and various components.
Review vendor quotations and provide feedback to procurement team.
Prepare and complete various electrical engineering deliverable drawings, documents, and calculations such as electrical load list, cable sizing / schedule, single line diagrams.
Design and complete earthing protection systems.
Design and complete lighting studies and system.
Prepare bulk MTOs (Material Take Offs) and detailed BOMs (Bill of Materials).
Ability and willingness to think outside of the box to find creative and innovative solutions to reduce costs while managing impact to quality, cost, or schedule.
Keeps informed of new developments and requirements affecting the organization for the purpose of recommending changes in programs and applications.
Interprets, organizes, executes assignments in a self-driven and self-sufficient manner.
Makes decisions independently on technical problems and methods and represents the organization in meetings to resolve important questions.
Applies advanced or state-of-the-art knowledge and experience to resolve crucial issues and/or unique conditions. The knowledge and expertise required for this level of work usually results from progressive experience.
Supervision received is essentially administrative, with assignments given in terms of broad general objectives and limits.
Analyze electrical systems to identify and resolve issues, including load balancing, capacity planning, and power consumption optimization.
Stays up to date with advancements in electrical engineering and data center technologies and recommend new technologies to improve the reliability and efficiency of our data center product line.
Represent company with customers during review meetings. Act as the primary point of contact for clients, responding to their inquiries and concerns in a timely and professional manner.
Provide technical support during the construction phase, responding to RFIs and addressing any issues that arise.
Attend job site visits, project meetings, and commissioning activities as needed.
Education:
Bachelor of Science Degree in Electrical Engineering from a recognized university.
Professional Engineering License (Strongly Preferred)
Experience:
A minimum of 7 years’ experience in electrical design and/or electrical engineering, with a focus on data center infrastructure.
Ability to produce drawings/sketches to illustrate design/ideas.
General knowledge and direct experience with the construction, operation, and maintenance of data center or building electrical systems.
Experience with high-density data centers and hyperscale environments
Understand the principle of electrical power and its components, procedures, and standards for power system equipment sizing and design.
Understands the purpose of electrical system for facility.
Knowledge of industry standards, codes, and regulations, including but not limited to
o IEC – International Electrotechnical Commissiono IBC – International Building Codeo OSHA – Occupational Safety and Health Administrationo NEC – National Electric Codeo NFPA – National Fire Protection Association
Experience working with computer-aided design (CAD) and building information modeling (BIM) software.
Fast track design/build projects and or multiple significant upgrade projects
Detailed understanding of UPS (uninterruptable power sources), diesel generators, medium and low voltage electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, electrical control systems, low voltage rectification systems, and other critical electrical equipment found within data centers.
Familiarity with medium and high voltage power distribution systems design
Basic understanding of mechanical equipment and system design within data center driving or affecting electrical scope.
Direct experience in negotiating with regulatory agencies regarding departures from code and ultimately achieving design approval and permitting.Computer Skills:
Mastery knowledge and proficiency in:
Microsoft Office 365 Suite (Outlook, Word, Excel, PowerPoint, Teams, SharePoint)
PDF Editor (Adobe, Foxit, or other equivalent)
ETAP
Dialux
Operational knowledge in:
SAP (ERP Tool w/ Engineering Modules and Transactions)
Solid Works
Autodesk Revit
Autodesk BIM 360
Autodesk AutoCAD
Navisworks Manager / Freedom
General:
Excellent problem-solving and analytical skills
Ability to work independently and manage multiple projects simultaneously.
Performs well under pressure in high stress environments.
Extremely comfortable with task switching as priorities change.
Ability to build and maintain strong relationships with clients.
Ability to think creatively and identify opportunities to enhance the client experience.
Extreme work ethic and maintains high level of quality of work and due diligence.
Communication Skills:
Express complex ideas effectively in both individual and group situations.
Organize and express ideas clearly in written documents.
Strong communication and collaboration skills, with the ability to work effectively with a cross-functional team.
Note that if you get hired you must undergo a background check, a driving records check and a drug screening
Job Type: Full-time
Salary: From $100,000.00 per year
Schedule:
Day shift
Work Location: In person"
1008917303591,Glassdoor,,,,
1008921255082,Glassdoor,,,,"Overview:
Want to be part of a customer focused, high performance, high integrity team of technology professionals? OneNeck IT Solutions is in search of a dynamic individual who is passionate about technology and providing best-in-class customer service. Our managed services engagements allow our employees to have access to a variety of technologies and environments, broadening your skillset while preparing you for future growth. Come join and add value to our team as a Data Protection & Storage Engineer.
Responsibilities:
The Data Protection & Storage Engineer performs systems engineering and administration of the backup and security platforms. Qualified applicants will have a familiarity in data protection and storage technologies.

This position will be called upon as a subject matter expert and will work across many departments and teams in support of delivering services to OneNeck clients; breaking down any barriers to ensure effectiveness and efficiency. The Data Protection & Storage Engineer continuously develops work instructions to ensure technical activities are conducted in a controlled and repeatable manner. This position also develops technical plans, conducts technical reviews, and executes upon plans in support of incident, change, and problem management efforts.

Responsibilities:
Be an escalation point for issues and requests that cannot be serviced by other groups, working issue to resolution, improving upon process, procedure, and knowledge to reduce future escalations.
Be a member of project teams in the planning and delivery of activities to support on-time and on-budget completion.
Conduct technical peer reviews of change plans and activities; providing recommendations, guidance, and authorization as appropriate.
Continually develop and enhance technical operating procedures and documentation to improve upon efficiency and effectiveness of operations.
Continuously identify and own problems and/or opportunities for improvement; working toward developing and deploying temporary and permanent fixes.
Periodically construct and facilitate training with other groups in support of increasing capabilities, efficiencies, and effectiveness.
Provide input on architecture, roadmaps, and best practice standards as requested.
Qualifications:
Required Qualifications:
Bachelor’s degree in related field -OR- 4+ years professional work experience
5+ years of backup and/or storage experience
Availability to consult, assist and/or perform after-hours support and participate in on-call rotations
Other Qualifications:

Professional or higher certification/experience preferred in any of the following backup solutions: CommVault V11, Veeam, etc.
Certification/experience in any of the following storage solutions: Nutanix, Nimble, EMC XIO, etc.
Sound judgment and decision-making skills
Expert analytical, statistical, and problem-solving skills
Strong commitment to customer satisfaction and quality
Results and execution oriented, self-motivated requiring minimal supervision
Advanced communication skills regarding project teams and management
Proficient with all Microsoft Office applications
OneNeck IT Solutions LLC offers hybrid IT solutions including cloud and hosting solutions, managed services, enterprise application management, advanced IT services, hardware and local connectivity via top-tier data centers across the U.S. OneNeck's team of technology professionals manage secure, world-class, hybrid IT infrastructures and applications for businesses around the country.

We offer competitive salary and a strong total rewards package. To learn more about this position or our company, visit oneneck.com.

EEO/AA Employer/Vets/Disability."
1008919616294,Glassdoor,$61K,$95K,http://www.kenjya-trusant.com/,"POSITION: Systems Engineer - Level 5
LOCATION: Annapolis Junction, MD 20701
REQUIRED CLEARANCE: TS/SCI w/FS POLYGRAPH

Job Description:
Kenjya-Trusant is hiring a System Engineer provide transition and decommission support services to a data flow and routing systems engineering team to support the transition and decommission of legacy systems. Required support includes documenting system functionality, features, interconnections, dependencies and performance and degradation. You will support configuration management functions by creating visual representations of the system, depicting system inputs, servers, processes and system outputs (configuration management).
Job Duties and Responsibilities:
Support T&D requirements and processes to include project planning/management/monitor/control, risk/mitigation management
Assist with developing, evaluating, documenting and creating new system designs, facilitating technology transition, and evaluating solutions.
Document and/or validate the current system design against the as-is implementation. Identify, characterize and map system limitation vs customer expectations.
Support the management and modernization of data formats and coordinate changes/modifications.
Provide support to technical leaders by coordinating activities pertaining to the development, documentation and maintenance associated with changes to the system.
Support cross-directorate Integrated Product Teams (IPTs), and engage stakeholders in accomplishing work for technology insertion projects.
Research and document dataflow processes according to standards of compliance in support of the Enterprise Data Header (EDH) initiatives. Support will include research, analysis, documentation, and integration of how data can be identified, protected, tracked and handled throughout its life cycle.
Individual Capabilities/Experience Required:
A Bachelor’s degree in Computer Science, Electrical Engineering, Systems Engineering, or a related discipline and at least 15 years of systems engineering experience. A Master’s or PhD Degree may be substituted for two years of experience. Note: a High School Diploma or GED plus 19 years of systems engineering experience would also be acceptable.
Excellent oral and written communications skills.
Position requires TS/SCI clearance with polygraph
Individual Capabilities/Experience Desired:
Broad experience in the system engineering disciplines, with experience in dataflow analysis, transitioning and decommissioning, system architecture.
Demonstrated experience in cross-program/cross-organization integration; ability to work constructively and successfully with diverse stakeholders to resolve mission and technical issues is critical
A self-starter, have a high level of attention to detail, and possess excellent oral and written communication skills, and be proficient with Microsoft Office Tools.





THE KENJYA-TRUSANT GROUP, LLC is a Service-Disabled Veteran-Owned Small Business that was established in 2015 as a merger between The Kenjya Group, Inc. and Trusant Technologies, LLC. Our mission is to implement, support and protect the nation’s advanced technology systems, business processes and high-technology facilities. Working with the Department of Defense, Department of Homeland Security, the Intelligence Community, state and local governments, and commercial clients, Kenjya-Trusant provides cyber protection, information technology, engineering, construction management and acquisition support services. We are a small company with big company benefits, including Health, Dental, Vision, 401K, Bonus Potential, Flexible Spending Account, Life Insurance, Short- and Long-Term Disability, Paid Time Off, and a culture of teamwork and continuous learning. Come grow with us!

The Kenjya-Trusant Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. If you require accommodations, please contact our Human Resources Department at (410) 740-4045."
1008923381830,Glassdoor,$83K,$126K,http://www.capitalonecareers.com/,"Category
Engineering
Experience
Sr. Manager
Primary Address
Richmond, Virginia
Overview
West Creek 8 (12080), United States of America, Richmond, Virginia
Senior Lead Data Engineer (Remote-Eligible)
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Senior Lead Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Manage and develop a Java-based pipeline and query tools depending on HIve Metastore, AWS S3, Kafka and ORC
Develop analytics tooling to solve business problems driven by scale and international expansion
Optimize configurations for analytics tools to support growing business and organization
“Capital One is open to hiring a Remote Employee for this opportunity.”
Basic Qualifications:
Bachelor’s Degree
At least 8 years of experience in application development (Internship experience does not apply)
At least 2 years of experience in big data technologies
At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud)
Preferred Qualifications:
9+ years of experience in application development including Python, Javascript, or Java
4+ years of experience with AWS
5+ years experience with Distributed data/computing tools (Trino, Hive, Kafka or Spark)
4+ year experience working on real-time data and streaming applications
4+ years of experience with NoSQL implementation (Cassandra)
4+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Data Engineer
San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Data Engineer
Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Data Engineer
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC)."
1008918465320,Glassdoor,$103K,$153K,https://aws.amazon.com/careers/why-aws/,"1+ years of software development, or 1+ years of technical support experience
Experience troubleshooting and debugging technical systems
Minimum of 1+ years of related professional experience and bachelor’s degree in Engineering/Computer Science/ Mathematics or any related field or equivalent military experience.
Knowledge or experience with system administration, and troubleshooting any operating system (Linux and/or Windows) and networking (HTTP/s, TCP/IP, DNS, OSI model, routing, switching, firewalls, LAN/WAN, traceroute, iperf, dig, CURL or related).
Knowledge or experience with Hadoop ecosystems (Apache Spark, Apache Hive).
Knowledge or experience in data lake architecture and administration.
Ability to communicate effectively in English (written and spoken) within technical and business settings.
As a Cloud Support Engineer you will learn at an accelerated pace how to use and leverage many different cloud technologies to help our customers succeed. You will act as the Cloud Ambassador across AWS products, providing our customers with required tools and tactics to scale their impact in world-wide markets.

The Big Data role supports our services that leverage data and produce business insights, which may include using machine learning/artificial intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industry’s most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

Key job responsibilities
Your day as a Cloud Support Engineer will include, but not be limited to, the following activities.
You will be primarily responsible for solving customer’s cases through a variety of contact channels (telephone, email, and web/live chat), applying advanced troubleshooting techniques to provide tailored solutions and working with them to dive deep into the root cause of an issue.
You will drive initiatives that improve support-related processes and our customers’ experience. These can include tutorials, how-to videos, technical articles, trainings, among others.
You will leverage your customer support experience to provide feedback to internal AWS teams on how to improve our services, and work on critical, highly complex customer problems that may span multiple AWS services.
You will be continuously learning groundbreaking technologies, and developing new technical skills and other professional competencies.
You will act as interviewer in hiring processes, and coach/mentor new team members.
This role requires the flexibility to work 5 days a week (occasionally on weekends) on a rotational basis. Schedules may align to Sunday - Thursday, Tuesday – Saturday or Monday - Friday.

About the team
AWS Support Engineering is a customer-facing global organization that provides technical support to our customers as well as our internal teams. As a member our team, you will be at the forefront of this transformational technology, operating on a follow-the-sun model. You will be assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications.

We are open to hiring candidates to work out of one of the following locations:

Dallas, TX, USA

Knowledge or experience utilizing data analysis techniques such as quantitative or qualitative analysis.
Knowledge or experience in various big data or distributed systems (NoSQL, search and streaming).
Understanding of cloud computing concepts and/or experience with any cloud platforms (AWS, Azure, Google Cloud).
Experience scripting or developing in one or more of the following languages: UNIX Shell, Python, R, Ruby, GO, Java, .NET (C#), JavaScript.
Knowledge of security concepts/best practices in securing application architectures from external threats.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
1008922100311,Glassdoor,,,http://www.christushealth.org/,"Job Description
Summary:
A Data and Analytics Engineer Senior is responsible for development, expansion and maintenance of data pipelines of the echo system. A Data and Analytics Engineer uses programming skills to develop, customize and manage integration tools, databases, warehouses, and analytical systems.
The Data and Analytics Engineer Senior is responsible for implementation of optimal solutions to integrate, store, process and analyze huge data sets. This includes an understanding of methodology, specifications, programming, delivery, monitoring, and support standards.
Individual must have extensive knowledge of designing and developing data pipelines and delivering advanced analytics, with open source Big Data processing frameworks such as Hadoop technologies. Individual must have proven competency in programming utilizing distributed computing principles.
This role will support Data Management and Analytics objectives to deliver high quality, contemporary, best-in-class solutions across CHRISTUS Health.

Responsible for analyzing and understanding data sources, participating in requirement gathering, and providing insights and guidance on data technology and data modeling best practices.
Analyze ideas and business and functional requirements to formulate a design strategy. • Act as a tenant to draw out a workable application design and coding parameters with essential functionalities. • Work in collaboration with the team members to identify and address the issues by implementing a viable technical solution that is time and cost-effective and ensuring that it does not affect performance quality.
Develop code following the industry's best practices and adhere to the organizational development rules and standards.
Involved in the evaluation of proposed system acquisitions or solutions development and provides input to the decision-making process relative to compatibility, cost, resource requirements, operations, and maintenance
Integrates software components, subsystems, facilities, and services into the existing technical systems environment; assesses the impact on other systems, and works with cross-functional teams within information Services to ensure positive project impact. Installs configure and verify the operation of software components
Participates in the development of standards, design, and implementation of proactive processes to collect and report data and statistics on assigned systems
Participates in the research, design, development, and implementation of application, database, and interface using technologies platforms provided.
Researching, designing, implementing, and managing programs
Fix problems arising across the test cycles and continuously improve the quality of deliverables.
Reference and document each phase of development for further reference and maintenance operation.
Requirements:
Bachelor degree in Computer Science, Engineering, Math or related field is required.
Software Development Life Cycle and process
Algorithm and Data Structure
Critical and analytical thinking skills
The candidate must also have had experience in large scale data lake data and data warehouse implementations and demonstrate proficiency in open source technology, for example, Python, Spark, Hive, HDFS, NiFi etc.
The candidate will additionally demonstrate substantial experience and a deep knowledge of data mining techniques, relational, and non-relational databases.
Experience with data integration with ETL techniques using Big Data processing frameworks such as Spark, MapReduce, HDFS, Python or R.
Experience with Big Data querying tools, such as Hive, and Impala.
Experience with building stream-processing systems, using solutions such as NiFi or Spark-Streaming is preferred.
Good understanding of Lambda Architecture
Advanced level of SQL programing techniques for Data Integration and Consumption using MPP and columnar databases.
Solid understanding of BI and analytics landscape, preferable in large-scale development environments.
Minimum eight (8) years of experience in MapReduce, Spark programming.
Minimum eight (8) years of experience developing analytics solutions with large data sets within an OLAP, MPP and columnar architecture.
Minimum eight (8) years of experience with design, architecture and development of Enterprise scale platforms built on open source frameworks.
Certifications in Hadoop or Java are a plus.
Work Type:
Full Time Onsite

EEO is the law - click below for more information:
https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf
We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at (844) 257-6925.

Req. No
157106
Job Title
Data Analytics Engineer Senior
Market
CHRISTUS System Office
Category
Information Technology
Facility
CHRISTUS Corp Irving Offices 919 and 909 Buildings
Address
919 Hidden Ridge
Irving, TX 75038
US
Type
FULL TIME"
1008922980341,Glassdoor,$83K,$115K,http://www.ferguson.com/,"Job Posting:
Ferguson is North America’s leading value-added distributor across residential, non-residential, new construction and repair, maintenance, and improvement (RMI) end markets. Spanning 34,000 suppliers and more than one million customers, we deliver local expertise, value-added solutions, and the industry’s most extensive portfolio of products. From infrastructure, plumbing, and appliances, to HVAC, fire protection, fabrication, and more, we make our customers’ complex projects simple, successful, and sustainable.
Ferguson has an exciting opportunity for a Lead Azure Data Engineer to join the Enterprise Data & Analytics team, within the Ferguson IT organization. This role will support the customer domain and come with experience in large digital and data management transformations. This is a lead role, under our IT Enterprise Data & Analytics (EDA), Data Application Technology department. The ideal candidate will have prior experience in a MDM implementation for the wholesale/distributor industry.
**This role is approved to be Remote or Hybrid in accordance with company policy.**
The Lead Azure Data Engineer is accountable for the successful delivery of Ferguson’s Master Data Management Customer technology. The engineer will carry out the activities responsible for the design and configuration of the Customer MDM in Reltio. The ideal candidate will be well versed in Cloud based technologies such as AWS, Azure Cloud and GCP with experience in Databricks and Azure Data Factory. Knowledge in data integration, data quality, project life cycle phases, and best practices is expected. Furthermore, we expect you to help other developers through code reviews, pair programming, and technical leadership. Your passion will lead to our customers success!
Duties and Responsibilities:
Work with Users, and Business Analysts to understand and translate functional requirements to technical design.
Analysis and resolution of sophisticated data relationships and data cleansing/profiling scenarios.
Hands-on configuration experience of hierarchies, entity types, attributes, relationships, and crosswalks in an MDM.
Solid understanding of high-level enterprise architecture patterns for data ingesting, storing, processing, and publishing
Experience configuring Out-of-the-box and Custom Cleanse Functions within an MDM.
Experience configuring External matches, and their usage to profile the incoming data for new sources.
Configuration and usage of advanced queries, Workflow management, User Management, and UI Config. Experience with LCA configuration for customizations.
Strategic problem solver - somebody who can conceptualize and lead the engineering of an MDM project.
Experience in designing master data (Customer Master, Product Master, etc.) hierarchies and reference data preferred.
Expert in Cloud & Data Technology and the market trends within Azure and AWS ecosystems.
Work with project management to develop the overall implementation solution, roadmap and plan.
Advanced Reltio experience desired but not required in areas of RIH (Reltio Integration Hub), Reltio L1, L2, L3 configuration layers, Reltio APIs, Reltio Open Collaboration System, etc.
Qualifications and Requirements:
12+ years of overall IT experience
Experience with hands-on implementation of Master Data Management (MDM) solutions using one of the major MDM platforms (Reltio Customer 360 - preferred, Informatica MDM, Stibo Systems)
5+ years’ Experience working as either: Software Engineer/Data Engineer: query tuning, performance tuning, troubleshooting, and debugging big data solutions.
Experience using and designing solutions on cloud infrastructure and services, such as AWS, Azure, or GCP
Experience with Development Tools for CI/CD, Unit and Integration testing, Automation and Orchestration, REST API, BI tools, and SQL Interfaces.
Expert level experience developing designs, data specific crosswalks and end user training documents.
History working with Databricks, Cloud Data Platforms, BI, Data Warehousing, Data Lakes, Data Science & Predictive Analytics
Expert in building Databricks notebooks in extracting the data from various source systems and perform data cleansing, data wrangling, data ETL processing and loading to AZURE SQL DB.
Expert in developing JSON Scripts for deploying the Pipeline in Azure Data Factory (ADF) that process the data.
Expert in using Databricks with Azure Data Factory (ADF) to compute large volumes of data from different sources.
Performed ETL operations in Azure Databricks by connecting to different relational database source systems.
Solid grasp of environment management, release management, code versioning, and deployment methodologies.
Familiarity with platform authentication patterns (SAML, SSO, OAuth).
Experience using a No SQL database such as Mongo or Cosmos is a plus.
Experience using development tools like JSON, Postman, Terraform, etc. is a plus.
Experience working in both a Waterfall and Agile environment is a plus.
Work directly to collaborate and mentor team members in differing levels across the world.
Be a subject matter expert and a go-to team member that makes valuable contributions daily.
Be willing to focus and contribute to seeking information, when needed.
Ferguson is dedicated to providing meaningful benefits programs and products to our associates and their families—geared toward benefits, wellness, financial protection, and retirement savings. Ferguson offers a competitive benefits package that includes medical, dental, vision, retirement savings with company match, paid leave (vacation, sick, personal, holiday, and parental), employee assistance programs, associate discounts, community involvement opportunities, and much more!
#LI-REMOTE
Pay Range:
Actual pay rate may vary depending upon location. The estimated pay range for this position is below. The specific rate will depend on a candidate’s qualifications and prior experience.
$8,470.59 - $14,834.37
Estimated Ranges displayed are Monthly for Salaried roles OR Hourly for all other roles.
This role is Bonus or Incentive Plan eligible.
The Company is an equal opportunity employer as well as a government contractor that shall abide by the requirements of 41 CFR 60-300.5(a), which prohibits discrimination against qualified protected Veterans and the requirements of 41 CFR 60-741.5(A), which prohibits discrimination against qualified individuals on the basis of disability.
Ferguson Enterprises, LLC. is an equal employment employer F/M/Disability/Vet/Sexual Orientation/Gender Identity.
Equal Employment Opportunity and Reasonable Accommodation Information"
1008918095437,Glassdoor,,,,"Summary
Posted: Oct 9, 2023
Role Number:200509844
As part of Apple's AI and Machine Learning org, we encourage and create groundbreaking technology for large-scale ML systems, computer vision, natural language processing, and multi-modal understanding. The Data and Machine Learning Innovation (DMLI) team is looking for a passionate Machine Learning Engineer to explore new methods, challenge existing metrics or protocols, and develop new insightful practices that will change how we understand data and overcome real-world ML challenges. Are you excited to work on some of the most ambitious technical challenges in the field? Your role will involve collaborating closely with machine learning researchers, engineers, and data scientists. Together, we will spearhead groundbreaking research initiatives and develop transformative products designed to build a significant impact for billions of users worldwide.
Key Qualifications
Demonstrated expertise in machine learning with a passion for data-centric machine learning.
Experience with natural language processing (NLP), and large language models, such as BERT, GPT, or Transformers.
Staying on top of emerging trends in LLMs.
Strong programming skills and hands-on experience using the following languages or deep learning frameworks: Python, PyTorch, or Jax.
Strong problem-solving and communication skills.
5+ years of experience with developing and evaluating ML applications, and demonstrated experience in understanding and improving data quality.
Demonstrated publication record in relevant conferences (e.g. ACL, EMNLP, NeurIPS, ICML, ICLR, , etc) is a plus.
Description
As a Machine Learning (ML) Engineer, you will be entrusted with the critical role of innovating and applying innovative research in ML to tackle complex data problems. The solutions you develop will significantly impact future Apple products and the broader ML development ecosystem. You will work with a multidisciplinary team to actively participate in the data-model co-design and co-development practice. Your responsibilities will extend to the design and development of a comprehensive data curation framework. You will also build robust model evaluation pipelines, integral to the continuous improvement and assessment of ML models. Additionally, your role will entail an in-depth analysis of collected data to underscore its influence on model performance. Furthermore, you will have the opportunity to showcase your groundbreaking research work by publishing and presenting at premier academic venues. Your work may span a variety of topics, including but not limited to: - Designing and implementing semi-supervised, self-supervised representation learning techniques for growing the power of both limited labeled data and large-scale unlabeled data. - Developing evaluation protocols centered on the end-to-end user experience, with a focus on anticipating potential failure modes, edge cases, and anomalies. - Employing data selection techniques such as novelty detection, active learning, and core-set selection for diverse data types like images, 3D models, natural language, and audio. - Uncovering patterns in data, setting performance targets, and using modern statistical and ML-based methods to model data distributions. This will aid in reducing redundancy and addressing out-of-distribution samples.
Education & Experience
Ph.D/MS degree in Machine Learning, Natural Language Processing, Computer Vision, Data Science, Statistics or related areas.
Additional Requirements
#AIML #DMLI #SCV
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program."
1008920167928,Glassdoor,$63K,$100K,http://www.riteaid.com/,"Company
Rite Aid
Shift
Day
Job Type
Full time
Requisition
JR020134
Last Updated
2023-10-09
Department
TS Business Intelligence
Job Locations
Valley Green - Corporate - 200 Newberry Commons, Etters, PA, 17319
Remote- United States
Job Summary
The Sr Google Data Engineer will define and deliver solutions that leverage data to enable the company to scale and accelerate its growth within the cloud. The role will take the lead and build data pipelines, data models and data integrations and other business systems into the Google data platform that will empower the business and analysts to make data-driven decisions. This person will Setup Google infrastructure, automation and visualization platforms and setup and manage data platform including Enterprise Data Warehouse. The Google Cloud Lead Engineer will be a key member of the Riteaid Enterprise Data Services group. They will provide best practices on secure foundational cloud implementations, automated provisioning of infrastructure and applications, cloud-ready application architectures, and more. Through the cloud engineer's guidance, we will ensure our teams have an excellent experience in building, modernizing, migrating, and maintaining applications in our hybrid multi cloud environment. The cloud engineer also serves as a guide and subject matter expert elevating the overall cloud capabilities within Riteaid.
Job Responsibilities
•Refine, evangelize, and deliver on Rite Aid’s Modernization vision and strategy •Partner in the delivery of cloud-based technical architectures, migration approaches, and application optimizations that enable business objectives •Collaborate with Product Owners, Scrum Masters, Developers, Product Architects to implement technical solutions •Evolve and drive our automation capabilities by enabling a DevOps and SRE culture •Support the adoption of Cloud practices and drive the institutionalization of the practices •Identify risk and mitigation plans associated with security, legal, data, compliance, and regulatory requirements •Contribute to the development of internal best practices as well as new innovative capabilities •Hands on-Technical lead to guide, mentor, and coach
qualifications
EDUCATION REQUIREMENTS Education Level GED Bachelor Degree Area of Specialization Information Services or related field LICENCES/CERTIFICATIONS Not Applicable WORK EXPERIENCE Experience combined roles of cloud engineer, infrastructure engineer, DevOps engineering, SRE or application development designing, building, and deploying scalable cloud-based solutions in GCP with automating infrastructure provisioning and/or continuous integration/delivery Experience with containerization and container orchestration technologies with cloud architecture and implementation features (OS, multi-tenancy, virtualization, orchestration, elastic scalability) Experience in supporting and troubleshooting large-scale applications deployed in a hybrid multi-cloud Familiarity with standard IT security practices such as identity and access management, data protection, encryption, certificate, and key management Experience one or more languages, such as Java, Python, Go, JavaScript, C++, or similar Experience with “on-premises to cloud” migrations or IT transformations Experience leading by example in a large, highly complex, and ever-changing organization; preferably in a hybrid cloud environment. Hand on experience using Cloud data platforms. Setup automation and visualization platforms. Experience building data platforms and data warehouse from ground up Experience with visualization platforms (Tableau, Excel) Expertise in ETL design, implementation and maintenance Expert in schema design and dimensional OLTP data modeling Building data design and modeling from ground up Expert usage of SQL and python (must be able to code in python) Practical application of basic statistical methods: Regression and other techniques to be used for statistical models
Fair Chance Act
Fair Chance Act Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the California Fair Chance Act, we will consider qualified applicants with a criminal history. You do not need to disclose your criminal history or participate in a background check until a conditional job offer is made to you. After making a conditional offer and running a background check, if we identify a conviction that is directly related to the job, you will be given the chance to explain the circumstances surrounding the conviction, provide mitigating evidence, or challenge the accuracy of the background report. Find out more about the Fair Chance Act by visiting the Civil Right’s Department Fair Chance Act webpage.
For more detailed information around city/state required notices, click here to access a list of disclosures.
New Jersey Law Against Discrimination (LAD)
The New Jersey Law Against Discrimination (LAD) prohibits unlawful employment discrimination based on an individual's race, creed, color, national origin, nationality, ancestry, age, sex (including pregnancy), familial status, marital/civil union status, religion, domestic partnership status, affectional or sexual orientation, gender identity and expression, atypical hereditary cellular or blood trait, genetic information, liability for military service, and mental or physical disability (including perceived disability, and AIDS and HIV status)."
1008921146782,Glassdoor,$93K,$139K,http://www.adswizz.com/,"Lawrenceville, New Jersey; Washington, Washington, DC
Agency Temp Full-Time
R-2023-10-27

Who We Are:
SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners - in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are. This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.
SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.
How you’ll make an impact:
In this role you will be a member of a team responsible for designing, developing and supporting a data platform which will be used across data organization and other groups.
What you’ll do:
Build cloud-based data platform which supports Datalake, Job Orchestration, ETL template, ETL Compute, integration with third party tools like fivetran, Monte Carlo
Design, code and maintain infrastructure as a code (IaC) using CDK, typescript, CDKTF.
Build and improve workflow orchestration tooling to support efficient data pipelines E.g., airflow plugins, systems integration, deployments.
Strengthen best practices around data platform setup and configuration.
What you’ll need:
BS or MS in Computer Science or related technical field
7+ years’ experience developing infrastructure as Code such as AWS CDK, typescript/or Python.
3+ years of experience working on a cloud platform (ex. GCP, AWS, etc.)
AWS CDK with Typescript as language for CDK development
Working Experience for Job Orchestration tool – Airflow/MWAA
Working Experience/Expertise creating AWS infrastructure for AWS services including but not limited to: S3 Datalake, Kms keys, IAM Role/Policy, MWAA, RDS, Lambda function
Experience/Expertise on Databricks is a plus.
Experience architecting, designing and building infrastructure in AWS.
Experience using GitHub for code PR management.
Working Experience in Linux Operating System
Nice to Have - Knowledge/Expertise on tools viz (Fivetran, Monte-Carlo, Datadog, Tableau/Looker)
Excellent written and verbal communication skills.
Ability to work independently and in a team environment.
Ability to pay attention to details and be organized.
Ability to handle multiple tasks in a fast-paced environment.
Willingness to take initiative and to follow through on projects.
Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.
Must have legal right to work in the U.S
Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.
The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.
R-2023-10-27"
1008921261273,Glassdoor,,,http://databricks.com/company/careers,"P-58
At Databricks, we are passionate about enabling data teams to solve the world's toughest problems, from security threat detection to cancer drug development. We do this by building and running the world's best data and AI infrastructure platform, so our customers can focus on the high value challenges that are central to their own missions. Our engineering teams build technical products that fulfill real, important needs in the world. We always push the boundaries of data and AI technology, while simultaneously operating with the resilience, security and scale that is important to making customers successful on our platform.
We develop and operate one of the largest scale software platforms. The fleet consists of millions of virtual machines, generating terabytes of logs and processing exabytes of data per day. At our scale, we observe cloud hardware, network, and operating system faults, and our software must gracefully shield our customers from any of the above.
As a Staff Software Engineer working on the Data Platform team you will help build the data platform for Databricks. You will architect and run highly-available, large-scale, multi-geo data pipelines for analyzing product telemetry and logs, and using it to guide business decisions. You will do this using the latest, bleeding-edge Databricks product and other tools in the data ecosystem - the team also functions as a large, production, in-house customer that dog foods Databricks and guides the future direction of the product.
The impact you will have:
Design and run the cross-company Data Lakehouse, which contains every business and product metric used to run Databricks. You’ll play a key role in developing the right balance of data protections and ease of shareability for the Lakehouse, as we transition to a public company.
Develop tooling and infrastructure to efficiently manage and run Databricks on Databricks at scale, across multiple clouds, geographies and deployment types. This includes CI/CD processes, test frameworks for pipelines and data quality, and infrastructure-as-code tooling.
Design and run the Databricks metrics store that enables all business units and engineering teams to bring their detailed metrics into a common platform for sharing and aggregation, with high quality, introspection ability and query performance.
Design the base ETL framework used by all pipelines developed at the company.
Partner with our engineering teams to provide leadership in developing the long-term vision and requirements for the Databricks product.
Build reliable data pipelines and solve data problems using Databricks, our partner’s products and other OSS tools. Provide early feedback on the design and operations of these products.
Establish conventions and create new APIs for telemetry, debug, feature and audit event log data, and evolve them as the product and underlying services change.
Represent Databricks at academic and industrial conferences & events.
What we look for:
BS (or higher degree) in Computer Science, or a related field
Experience providing technical leadership on large projects similar to the ones described above - ETL frameworks, metrics stores, infrastructure management, data security.
Experience building, shipping and operating reliable multi-geo data pipelines at scale.
Experience working with and operating workflow or orchestration frameworks, including open source tools like Airflow and DBT or commercial enterprise tools.
Experience with large-scale messaging systems like Kafka or RabbitMQ or commercial systems.
Excellent cross-functional and communication skills, consensus builder.
Passion for data engineering and for enabling others by making their data easier to access.
Benefits
Comprehensive health coverage including medical, dental, and vision
401(k) Plan
Equity awards
Flexible time off
Paid parental leave
Family Planning
Gym reimbursement
Annual personal development fund
Employee Assistance Program (EAP)
Pay Range Transparency
Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.

Local Pay Range
$192,000—$260,000 USD
About Databricks
Databricks is the data and AI company. More than 9,000 organizations worldwide — including Comcast, Condé Nast, and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
Our Commitment to Diversity and Inclusion
At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance
If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone."
1008922060642,Glassdoor,$92K,$135K,http://www.siriusxm.com/,"Responsibilities:
Who We Are:
SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners - in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are. This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.
SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.
How you’ll make an impact:
In this role you will be a member of a team responsible for designing, developing and supporting a data platform which will be used across data organization and other groups.
What you’ll do:
Build cloud-based data platform which supports Datalake, Job Orchestration, ETL template, ETL Compute, integration with third party tools like fivetran, Monte Carlo
Design, code and maintain infrastructure as a code (IaC) using CDK, typescript, CDKTF.
Build and improve workflow orchestration tooling to support efficient data pipelines E.g., airflow plugins, systems integration, deployments.
Strengthen best practices around data platform setup and configuration.
What you’ll need:
BS or MS in Computer Science or related technical field
7+ years’ experience developing infrastructure as Code such as AWS CDK, typescript/or Python.
3+ years of experience working on a cloud platform (ex. GCP, AWS, etc.)
AWS CDK with Typescript as language for CDK development
Working Experience for Job Orchestration tool – Airflow/MWAA
Working Experience/Expertise creating AWS infrastructure for AWS services including but not limited to: S3 Datalake, Kms keys, IAM Role/Policy, MWAA, RDS, Lambda function
Experience/Expertise on Databricks is a plus.
Experience architecting, designing and building infrastructure in AWS.
Experience using GitHub for code PR management.
Working Experience in Linux Operating System
Nice to Have - Knowledge/Expertise on tools viz (Fivetran, Monte-Carlo, Datadog, Tableau/Looker)
Excellent written and verbal communication skills.
Ability to work independently and in a team environment.
Ability to pay attention to details and be organized.
Ability to handle multiple tasks in a fast-paced environment.
Willingness to take initiative and to follow through on projects.
Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.
Must have legal right to work in the U.S
Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.
The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice."
1008923163843,Glassdoor,$112K,$168K,http://www.amazon.jobs/,"5+ years of non-internship professional software development experience
5+ years of programming with at least one software programming language experience
5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience as a mentor, tech lead or leading an engineering team
Are you interested in working with the latest technology in the cloud computing space?

The Amazon Foundational People Data Services (FPDS) organization is building cutting-edge solutions to enable employees and managers to self-serve changes across all human resource processes.

Join us in building an innovative technology using Amazon Web Services to meet the complex and unique demands of managing nearly 3,000,000 employees globally. We dive deep to insist on the highest standards in architecture, coding, testing, deploying, and maintaining every aspect of our offerings.

Mentorship & Career Growth: Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship.

Work/Life Balance: Our team also maintains an inclusive team culture, and we put a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success.

We are looking for developers with solid computer science fundamentals, including data structures, object-oriented design, algorithm design, problem-solving, and complexity analysis. We want to talk to you if you have a track record of designing and building scalable, complex solutions across distributed systems in an agile environment.

Key job responsibilities
Architect and build highly available software components in a distributed architecture
Collaborate with cross-functional teams
Define and drive software best practices, including coding standards, code reviews, source control management, agile development, build processes, and testing
Coach and mentor engineers on the team to foster a supportive culture of collaboration, scalability, and performance
A day in the life
You'll work on cutting-edge projects at the forefront of innovation, pushing boundaries and creating solutions that are shaping the future. You'll be surrounded by a team of talented individuals who are passionate about what they do. In this role, you'll have the unique ability to influence software architecture on a global scale. Your expertise and insights will have a direct impact on how our products are developed and implemented worldwide. You'll be working on projects that directly impact our customers and contribute to their success. And while you're making a difference, you'll also have continuous learning and professional growth opportunities.

About the team
The Data Producer eXperience (DPX) organization’s primary mission is to enable data producers to securely and efficiently store, describe, and vend data to downstream data consumers at Amazon scale, providing a seamless experience with greater visibility, security and privacy built into all of our services. We strive to empower data producers to get their data to market faster with improved time to value.
Our teams provide access and storage of human capital information to an extensive ecosystem across Amazon and its associated vendors as we build new systems to take us into the future. Data from our platform is vital to calculate compensation, payroll, benefits, hiring, onboarding and separation activities, security and access controls, fulfillment center operations, and provide many other low-friction business processes and world-class experiences for everyone at Amazon who innovates on behalf of our customers.
Our engineers continuously strive to build and run an infrastructure that can process billions of queries, provide data consistency and availability-related solutions in a distributed systems architecture, functional data materialization for unique business use cases, data visualization and analytics products, and set up data privacy controls. We are building a one-of-a-kind cloud-native platform uniquely positioned to accelerate delivering customer value across Amazon!

We are open to hiring candidates to work out of one of the following locations:

Boston, MA, USA

5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
1008923208636,Glassdoor,,,https://www.bloomberg.com/company,"Bloomberg runs on data, and data drives the market. At Bloomberg, data is at the core of our operations, driving the financial market. We are seeking a dedicated Business Intelligence Engineer to join our team in London. As part of the Data Management Lab (DML), you will collaborate with our Data organization to ensure data management excellence and provide comprehensive business intelligence solutions for data-driven decision making.

The Team:
DML sits within the Data organization, and supports Data's pursuit of data management excellence through aligning industry best practices with Bloomberg's established expertise in financial market data. DML empowers our data professionals to make their products ""ready-to-use"", through promoting increased data discoverability, accessibility, appraisability, interoperability, and analysis-readiness. The Business Intelligence team sits alongside our Data Quality and Process Engineering teams, supporting DML's mission in empowering data teams to analyze their operations from our clients' perspective. Our Data Quality team leads the charge to ensure Bloomberg provides our clients with high quality data that moves markets around the world.

The Role:
As a Business Intelligence Engineer, you will be part of a dynamic and empowered group that acts as a catalyst for data-driven decision-making across multiple business units within the department. We play a vital role in leveraging data to drive strategic business decisions, improve operational efficiency, and uncover valuable insights! In this position, you will collaborate closely with our Product, Engineering and other cross-functional teams, bridging the gap between data and business objectives to provide meaningful and actionable insights. By understanding the unique requirements and challenges of each business unit, you will develop tailored analytical solutions and standardized reporting frameworks that support their specific goals.

Your responsibilities will extend beyond traditional data analysis as you guide key stakeholders through the data exploration process - helping them uncover trends, patterns, and key performance indicators. By distilling complex datasets into clear and impactful visualizations, you will effectively communicate insights and recommendations to drive informed decision-making at all levels of the organization.
We are seeking a highly motivated and analytical individual who thrives in a fast-paced environment. As a key member of our Business Intelligence team, you will play a critical role in transforming raw data into actionable insights, empowering our business units to make data-driven decisions that propel our organization forward.

We'll trust you to:
Lead global projects for operational analytics, business performance management, and data quality reporting for the Bloomberg Data products
Showcase subject-matter expertise in organizational business intelligence
Engage with internal stakeholders and senior management to understand their business needs and to define data measurement requirements, ultimately delivering analytical insights and visualizations to measure both product (external, client-facing) and operational (internal, data management oriented) concerns
Perform data profiling and analysis, leveraging appropriate statistical methodologies to support decision making
Champion organizational change around business intelligence, through developing standard practices and training counterparts on the solutions developed
You'll need to have:
A BA/BS degree or higher in Computer Science, Mathematics, Finance or relevant data technology field, or equivalent Business Intelligence work experience
Minimum of 4+ years of professional work experience such as extracting, loading and analyzing large volume of data or experience in data management/governance, within finance or technology industries
Proven experience in building dashboard applications such as Qlik Sense, Tableau
Project management experience developed in a matrixed stakeholder environment and cross-regional business
Experience in designing and developing metrics and reporting across organization
We'd love to see:
Experience in Data Profiling/Analysis tools such as Python, SQL, Excel would be an added advantage
A creative and flexible approach to problem-solving, coupled with an experimental posture, to challenge past assumptions and provide new ways of thinking
Up-to-date knowledge of financial markets, and how Bloomberg products deliver value to our clients
Demonstrated continuous career growth within an organization
Does this sound like you?
Apply if you think we're a good match! We'll get in touch shortly regarding next steps.

Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or maternity/parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law.

Bloomberg provides reasonable adjustment/accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable adjustment/accommodation to apply for a job or to perform your job. Examples of reasonable adjustment/accommodation include but are not limited to making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you would prefer to discuss this confidentially, please email AMER_recruit@bloomberg.net (Americas), EMEA_recruit@bloomberg.net (Europe, the Middle East and Africa), or APAC_recruit@bloomberg.net (Asia-Pacific), based on the region you are submitting an application for.

Salary Range: 110,000 - 170,000 USD Annually + Benefits + Bonus

The referenced salary range is based on the Company's good faith belief at the time of posting. Actual compensation may vary based on factors such as geographic location, work experience, market conditions, education/training and skill level.

We offer one of the most comprehensive and generous benefits plans available and offer a range of total rewards that may include merit increases, incentive compensation [Exempt roles only], paid holidays, paid time off, medical, dental, vision, short and long term disability benefits, 401(k) +match, life insurance, and various wellness programs, among others. The Company does not provide benefits directly to contingent workers/contractors and interns."
1008920056809,Glassdoor,$67K,$92K,https://www.quest-global.com/,"Quest Global is an organization at the forefront of innovation and one of the world’s fastest growing engineering services firms with deep domain knowledge and recognized expertise in the top OEMs across seven industries. We are a twenty-five-year-old company on a journey to becoming a centenary one, driven by aspiration, hunger and humility.
We are looking for humble geniuses, who believe that engineering has the potential to make the impossible, possible; innovators, who are not only inspired by technology and innovation, but also perpetually driven to design, develop, and test as a trusted partner for Fortune 500 customers.
As a team of remarkably diverse engineers, we recognize that what we are really engineering is a brighter future for us all. If you want to contribute to meaningful work and be part of an organization that truly believes when you win, we all win, and when you fail, we all learn, then we’re eager to hear from you.
The achievers and courageous challenge-crushers we seek, have the following characteristics and skills:

This could be a remote opportunity for someone with the right experience.
Roles & Responsibilities:
Review quality and field data to identify common themes in support of driving continuous improvement.
Develop a Tableau dashboard that pulls data from multiple sources to drive daily management of Engineering Quality leading indicators and metrics.
Recommend areas of focus to help drive root cause analysis and continuous improvement projects.
Required Skills (Technical Competency):
Bachelor of Engineering degree
2+ years of experience with engineering data analysis, preferably including Tableau.
Desired Skills:
Experience with gas turbine components, design processes, and/or systems.
Quality related experience.
Physical Requirements & Work Environment:
Mostly Office Environments, Occasional Shop Floor involvement.
Substantial amounts of telephone and computer work.
Heavily Regulated Industries with strict adherence to procedures.
Flexibility to meet business deadlines by staying late or arriving early.
Typical 8 hour days plus lunch / 40 hour weeks / core (required) hours are 9AM to 4PM
Ability to use personal transportation to visit customer locations.
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education Type
BEng-Bachelor of Engineering
Job Type
Full Time-Regular
Experience Level
Entry Level
Total Years of Exp
1 - 3"
1008920416112,Glassdoor,$87K,$133K,http://www.bms.com/,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Position Summary
As a Batch-ETL Data Integrations Support Lead, you will work with a team of Bristol Myers Squibb and Service Provider’s resources to provide day-to-day hands-on operational and production support for Batch-ETL platforms. Primary focus will be to provide hands-on application support for the data integrations running on Enterprise ETL/Batch AWS Glue Studio platform and file transfer services running on Seeburger Managed File Transfer (MFT) and SFTP MOVEit platforms. Secondary will be to assist, when needed, application operational support for other data integration platforms managed by the Enterprise Data Integration organization.
Major Duties and Responsibilities
You will report into the Lead for Operations & Support. You will have accountability to provide hands-on application production support for various data integrations. To provide appropriate support, you will collaborate with Data Integration Development & Support team, Business, and IT Partners. You will be responsible to resolve incidents, work on enhancements and service requests related to data integrations or file transfer services for various applications. Enterprise application integrations span internally hosted applications, SaaS applications, and/or external partners.
This role offers the selected candidate the opportunity to interact with Bristol Myers Squibb professionals globally, partnering with other IT organizations and business organizations across the company. You will work with passionate and motivated individuals. As a member of the Enterprise Integration team, you will have the opportunity to gain insight into all faucets of Bristol Myers Squibb businesses from early discovery to manufacturing & logistics to commercial and financial operations. You will be a valued member of the Enterprise Integration team focused on fulfilling the Bristol Myers Squibb mission to discover, develop and deliver innovative medicines that help patients prevail over serious diseases.
Key Responsibilities
Day to day hands-on production support (Incidents resolution, enhancements, continuous improvement) of Batch/ETL data integrations on the AWS Glue Studio platform and file transfer services on Seeburger Managed File Transfer (MFT) and MOVEit SFTP platforms.
Accountable to work with applications stakeholders for timely resolution of incidents within BMS defined SLAs.
Handle service requests or inquiries from applications stakeholders related to their data integrations or file transfer services.
Assist in platform upgrade activities every couple of years.
Collaborate with Infrastructure teams for capacity planning / performance optimization.
Provide proactive and appropriate communication (written and verbally) to technical and non-technical stakeholders.
Proactively analyze and optimize Data Integrations performance.
Participate in recurring and ad-hoc meetings related to support activities between Hyderabad and US teams.
Provide non-business hours, weekend, on-call support on rotational basis for production releases and high priority incidents resolution.
Willing to learn and support other Batch/ETL data integration technologies that are supported by the team.
Qualifications & Experience
Bachelor’s or Master’s degree in computer science, information systems, or a related field, or equivalent experience.
10+ years of experience in Data Integration domain as an ETL Developer or Production Support engineer.
3+ years hands-on experience in developing or supporting data integrations in AWS Glue Studio.
Understanding of Cloud Services Platforms.
Proven experience as a member of an application development or production support team with knowledge of common SDLC models
Experience working with on and offshore resourced teams.
Nice to have a certification in or understanding of IT Service Management (ITSM) and Information Technology Infrastructure Library (ITIL) frameworks.
Nice to have experience in MFT and SFTP technologies.
Exceptional customer interaction and communication skills, including interaction with non-technical audiences
#LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations."
1008919664917,Glassdoor,$66K,$95K,http://www.datwyler.com/,"In billions of syringes and in every second car worldwide, Datwyler components make an important contribution to the safety of patients and drivers. The high-tech company focuses on high-quality, system-critical elastomer components and holds leading positions in attractive global markets such as healthcare, mobility, connectivity, general industry and food & beverage. With over 25 production sites on four continents, sales in more than 100 countries and over 8,000 employees, the company, headquartered in Switzerland, generates annual sales of more than CHF 1,000 million.
Our employees are the heart of Datwyler - we treat each other with respect, trust and appreciation. We have strong roots and values that have been well established in our 100-year corporate history. Become part of our great team as a...

Summary
The Master Data/Industrial Engineer will be the local representative of for Master Data and reports into site Supply Chain function. This position will collaborate with digital process owners such as Quality, Process Engineering, Production, Maintenance, Project Engineering, Finance, Sales and Customer Service, as well as Datwyler global functions including the Global Industrial Engineer and the Master Data Management team (DIT). The goal of this position is to ensure data integrity for all information that is collected, organized and loaded into the digital system to assure business continuity and consistency. This position will also collaborate with counterparts at other various Datwyler sites as supported by Digitalization@HS and the Global Supply Chain.
Essential Functions / Four Most Important Tasks
Ensure the management of the central Master Data of the HS Digital Solutions (ERP - SAP S/4, MES, and other systems), in order to provide the group management and the various affiliates with timely, accurate and consistent business data for the support and guidance of operations and business processes. This position will monitor requests for new finished goods creation and revision to existing goods while overseeing of implementing the request at the local site through change control, including Master Data for product characteristics, product codes, customer specific information, Bill of Material, Bill of Operations, work center parameters, etc.
Coordinate the production transfer process from other sites and monitor and report status for the introduction and start-up of new production at the local site. Coordinates meetings to ensure all internal/external parties and stakeholders are meeting milestones and timelines following prescribed procedures, change control, and checklists
Collaborate with global counterparts, DIT, and other external consultants to contribute and improve functional system design and data accuracy. Maintains and improves upon local and shared procedures to ensure accurate group information
Provides back up assistance to production planning by cross training in functions required to support the issuance and maintenance of weekly production schedules.
Responsibilities
Works accurately and can follow organizational procedures and work specific instructions.
Assists site Supply Chain manager with various department or site related projects
Coordinates master data process with site validation schedules
Provides system related training to other employees as required
Maintains, creates, and revises work instructions and as it relates to the master data process.
Prepares and distributes reports as required to support the site Supply Chain manager
Assists in globally lead system or system functionality implementations and enhancements
Participates in department and other team meetings. Suggests improvements and works alone or with others to implement improvements, as assigned.
Supports continuous improvement activities and initiatives
Ability to travel up to 20%
Physical Demands
While performing the duties of this job, the employee is frequently exposed to elements including environmental heat and high heat from moving mechanical parts, small parts may be encountered on the floor, and dust particles may float in the air. Work is done in both office space and in the plant where safety is a critical concern. PPE must be worn.
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential job functions, provided it does not create an undue hardship on the Company, in accordance with applicable law. Work conditions are those that are present in normal manufacturing environment.
The position requires moving about as much as 60% of the workday in and throughout the plant; and the occasional lifting of up to 25 pounds. This position can require occasional squatting, stooping, bending or crouching. Use of computer involves some repetitive motion. Business needs require that the employee in this position work an established 40-hour workweek and on occasion work additional hours outside of the standard schedule.
Be yourself at Datwyler
We are convinced that people make the difference. At Datwyler, you will experience diversity and a wide range of career opportunities that only an international company can provide. Together, we are increasing our agility, accelerating digitalization and fostering sustainability. For motivated and talented employees, we offer interesting development opportunities with training and assignments in a global environment. With us, you can contribute with all of your creativity and all your ideas."
1008923499947,Glassdoor,,,,"Overview:
Our data link test team is searching for new test engineer professionals that can help us design and execute test events. If you enjoy working in a fast-paced environment, learning new technology areas, this is the place for you. We provide a number of opportunities to learn ranging from on-the-job training with other team members to formal courses for unique technology areas.
We realize that no one will have all of these qualifications. We are looking for people that have experience with Link 16 and system testing. And have the drive and motivation to learn all other required areas.
This position provides support to the 96 Cyber Test Group, 46 Test Squadron, Data Link Test Flight at Eglin AFB as a member of an platform integration team responsible for planning, designing, and executing test events for tactical communications systems. This is NOT a telework or remote position; however, telework opportunities may be authorized as mission requirements allow.

LOCATION: Eglin AFB, FL
JOB STATUS: Full Time
TRAVEL: 25% CONUS / OCONUS TDYs

REQUIRED QUALIFICATIONS (Education, Certifications, Experience, Skills)
SECURITY CLEARANCE: Secret and be able to obtain and maintain a Top Secret clearance – US citizenship required
EDUCATION: BS Degree in a Computer Science, Computer Engineering, or a related technical field (i.e., CS, AE, ME, etc.)
CERTIFICATIONS: None
EXPERIENCE LEVEL: 3-10 years of applicable experience

OTHER QUALIFICATIONS/SKILLS:
US citizenship required
Active Top Secret clearance
Experience with tactical data link radios and terminals
Experience with computer network design concepts, configuration, and operation
Analytical skills and problem-solving skills
Excellent self-initiative and self-motivation with the ability to work under minimal supervision
Ability to work effectively in small and large team settings to solve complex problems
Capable of traveling to contractors' facilities, test sites, and other locations, both CONUS and OCONUS. Travel is on average is 25% of total time worked
Good organization, decision making, verbal and written communication skills
Proficiency in MS Office products to include Word, Excel and PowerPoint

PREFERRED SKILLS:
Relevant technical experience in the areas of software system and hardware integration testing
An understanding of DOD developmental test and evaluation processes
Knowledge of computer networking principles and configuration
Experience using interpreted languages (Python, Ruby, JavaScript, PHP, etc.)
Security+ certification

RESPONSIBILITIES:
Perform as a member of the Platform Integration Element test team
Interface directly with System Program Offices, users, test support organizations, and product development contractors
Plan, execute, and report on tests for Air Force advanced tactical communications programs to include Link 16, Situation Awareness Data Link (SADL) and emerging next generation tactical data links
Utilize Military Standards to evaluate system compliance
Proficient/familiar with various radios such as: MIDS-JTRS, SADL, PRC-117G, etc
Review customer requirements and participate in test planning meetings
Develop test plans and procedures, schedules, and execute tests within the constraints of customer requirements and produce timely test reports
Capable of performing as a team leader in directing and executing system testing
Author technical documents and briefings and conduct formal presentations
Travel to other locations as required to attend meetings and conduct tests

What we offer:
Competitive salaries
Continuing education assistance
Professional development allotment
Multiple healthcare benefits packages
401K with employer matching
Paid time off (PTO) along with a federally recognized holiday schedule

Who We Are
Oasis Systems is a premier provider of customer-driven, cost-effective, and quality Engineering Services; Enterprise Systems and Applications; Human Factors Engineering; Information Technology and Cyber Security; Professional Services; and Specialized Engineering Solutions to the Department of Defense, Federal Aviation Administration, Nuclear Regulatory Commission, and other Federal Agencies.

We strive to be an exciting and welcoming company that attracts, develops, motivates and retains the most talented, skilled and dedicated people in the industry; where they are encouraged to achieve personal excellence, purpose, and their full potential and career aspirations, while supporting mission-critical national security technologies and programs.

Oasis Systems is an Equal Employment Opportunity/Affirmative Action Employer. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
""Oasis Systems Cyber Division"""
1008918448288,Glassdoor,$117K,$175K,https://www.shell.us/,"Where you fit in
Projects and Technology (P&T) supports Shell’s operated and non-operated assets, safely improving performance and raising the bar being a responsible operator. We use our technical, commercial, and digital skills to competitively optimise production and we replicate technologies across the portfolio. P&T also has a role to play making our assets top quartile on emissions intensity.
What’s the role?
We are looking for a highly experienced Data Engineer to join our Data & Analytics team in Shell Energy Trading Americas. This position will be a hybrid role between Data and DevOps Engineering and the successful candidate will be leading the modernization of our Data & Digital landscape. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Accountabilities:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure, AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure, AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large, disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong domain knowledge of Energy &/or Trading.
Experience supporting and working with cross-functional teams in a dynamic environment
What we need from you?
Must have legal authorization to work in the US on a full-time basis for anyone other than current employer
Minimum fifteen (15) years of experience in a Data Engineer or DevOps & Build Engineer role
Bachelors degree is a must
Experience with Azure: ADLS, Databricks, Stream Analytics, SQL DW, COSMOS DB, Analysis Services, Azure Functions, Serverless Architecture, ARM Templates
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with object-oriented/object function scripting languages: Python, SQL, Scala, Spark-SQL etc.
Nice to have experience with big data tools: Hadoop, Spark, Kafka, etc.
Nice to have experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
For regular full-time or regular part-time employees of the Company (participating companies as listed in the Summary Plan Description), insurance coverage options include medical, dental, vision coverage, life Insurance, Business Travel Accident Insurance, and Occupational Accidental Death Benefit programs. Employees also participate in a company pension plan and a 401(k) plan. Paid leave includes up to 6 weeks of paid vacation time, up to 11 paid holidays, and parental leave offering 16 weeks of paid leave to birthing mothers, and 8 weeks of paid leave for non-birthing parents. Additionally, employees are eligible for disability leave for up to 52 weeks at 100% or 50% of base pay. Shell also offers other compensation such financial reimbursement for adoption, wellness, education, and personal learning expenses, and some roles are eligible for discretionary long-term incentives. For interns, eligible benefits include medical, dental, and vision coverage, life insurance, Business Travel Accident Insurance, and Occupational Accidental Death Benefit programs; participation in a 401(k) plan; and paid leave for up to 11 paid holidays. Additional information on Shell’s US benefit programs can be found at
https://www.shell.us/careers/about-careers-at-shell/rewards-and-benefits.html
COMPANY DESCRIPTION
Shell is a global group of energy and petrochemicals companies with over 90,000 employees in more than 70 countries and territories. In the US, we have operated for over a century and are a major oil and gas producer onshore and in the Gulf of Mexico, a recognized innovator in exploration and production technology, and a leading manufacturer and marketer of fuels, natural gas and petrochemicals. We deliver energy responsibly; operate safely with respect to our neighbours and work to minimize our environmental impact. We are in search of remarkable people who will thrive in a diverse and inclusive work environment to deliver exciting projects locally and globally. People who are passionate about exploring new frontiers. Innovators and pioneers. People with the drive to help shape our future. Because remarkable people achieve remarkable things.
An innovative place to work
There’s never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change.
Join us and you’ll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy or developing technology that helps the world to use energy more efficiently.
An inclusive place to work
To power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we’re nurturing an inclusive environment – one where you can express your ideas, extend your skills and reach your potentials.
We’re creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply, and we’ll take it from there
We’re closing the gender gap – whether that’s through action on equal pay or by enabling more women to reach senior roles in engineering and technology
We’re striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity
We consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application
A rewarding place to work
Combine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice.
We’re huge advocates for career development. We’ll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible."
1008920308749,Glassdoor,,,http://www.geopaqlogic.com/,"Job Title : Data Center / Network Administrator
Work Location: : Mountain View, CA
Contract Period: 12+Months
Must be able to speak Korean/English bilingual
Responsibilities
Datacenter On-site Support
Analyze, research, configure, install networks & computer systems
Works with OEM on server repair warranty and parts replenishment
Escorts visitors within datacenter
Interface with electrical and infrastructure vendors for routine maintenance visits
Order supplies to replenish data center stock or for upcoming projects
Uses advanced troubleshooting skills for hardware and infrastructure problem or failure remediation
Generates and works from ticket system to provide support and project
Operating Windows / Linux / Storage
Visual Inspection, On-site network Cable wiring
Qualification
3+ years’ experience of datacenter network operation, data center and infrastructure engineer in medium to large data center environments (100-500 servers with supporting infrastructure servers)
3+ years’ experience of Server / Storage Hardware Management (DELL / HP / IBM / Oracle)
Experience with cabling system (UTP, Optical Fiber)
3+ years hands on experience with server repair and warranty parts service
Experience with protocols and services based on TCP/IP
Experience with routers & switches
Experience working in a Highly Available datacenter environment with high uptime with little to no disruption in services or availability
Ability to work well within a Team
Bachelor Degree in Computer Science or related field preferred
PHYSICAL DEMANDS AND WORKING CONDITIONS
Physical requirements include occasional lifting/carrying of 50 pounds; visual acuity, speech and hearing; hand and eye coordination and manual dexterity necessary to operate a computer keyboard
and basic office equipment.
Subject to sitting, standing, reaching, walking, twisting, and kneeling to perform the essential functions.
Working conditions are primarily inside an office environment with travel to various locations on an occasional basis.
Job Types: Contract, Full-time
Pay: $7,000.00 - $9,000.00 per month
Benefits:
Health insurance
Paid time off
Schedule:
8 hour shift
Day shift
Monday to Friday
Ability to commute/relocate:
San Jose, CA 95110: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data center/Network: 3 years (Required)
Language:
Korean (Required)
Work Location: In person"
1008923171887,Glassdoor,,,http://captivation.us/,"Build Something to Be Proud Of.

Captivation Software has built a reputation on providing customers exactly what is needed in a timely manner. Our team of engineers take pride in what they develop and constantly innovate to provide the best solution. Captivation Software is looking for a talented Data Engineer to support the acquisition of mission critical and mission support data sets. The preferred candidate will have a background in supporting cyber and/or network related missions within the military spaces, as either a developer, analyst or engineer. Must be willing to work in a hybrid role with some on-site work with a great team.
Essential Job Responsibilities
The ideal candidate will have worked with big data systems, complex structured and unstructured data sets, and have supported government data acquisition, analysis, and/or sharing efforts in the past.
To excel in the position, the candidate shall have a strong attention to detail, be able to understand technical complexities, and have the willingness to learn and adapt to the situation.
The candidate will work both independently and as part of a large team to accomplish client objectives.
Requirements
Security Clearance:
A current Secret level security clearance is required and therefore all candidates must be a U.S. Citizen
Minimum Qualifications:
5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience.
Experience with programming languages such as Python and Java.
Proficiency with acquisition and understanding of network data and the associated metadata.
Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics.
Experience with Kibana and Elasticsearch.
Familiarity with various log formats such as JSON, XML, and others.
Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions).
Ability to decompose technical problems and troubleshoot system and dataflow issues.
Must be able to work on-site in a hybrid role with a great team.
Preferred Requirements
Experience with NOSQL databases such as Accumulo desired
Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer.


This position is open for direct hires only. We will not consider candidates from third party staffing/recruiting firms.
Benefits
Annual Salary: $125,000 - $250,000 (Depends on the years of experience)
Up to 20% 401k contribution (no matching required)
Above market hourly rates
$3,000 HSA Contribution
5 Weeks Paid Time Off
Company Paid Employee Medical / Dental / Vision Insurance / Life Insurance / Short-Term & Long-Term Disability / AD&D"
1008919892619,Glassdoor,,,,"Summary
Posted: Aug 10, 2023
Weekly Hours: 40
Role Number:200495053
Do you believe Machine Learning and AI can change the world? We truly believe it can! We are the Data Team of System Intelligence and Machine Learning. We are responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features for many Apple products (iPhone, iPad, Mac, Apple Watch and even AirPods). Such features go from the smart wallpaper on your iPhone Lock Screen, to the models that highlight the faces of your loved ones in your Photos app, to input experiences (eg autocorrect, next word prediction, handwriting recognition). We’re looking for an exceptional engineering lead who is passionate about Apple products and values, who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. We invite you to join us at this exciting time. Grow fast and positively impact multiple critical features on your first day at Apple!
Key Qualifications
8+ years of proven experience as a software engineer, with recent involvement in parts of the ML lifecycle
2+ years as a tech lead, specializing in data engineering/infrastructure
Experience designing and building large scale data processing systems
Consistent track record of managing complex data projects, while establishing and enforcing the right software engineering culture for a software team
Experience in building data pipelines to process large scale datasets, using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in large language models, or generative AI
Expertise in Python or another modern programming language
Strong ability to design and lead a technical roadmap, work with cross functional teams, with proven capacity to influence and build alignment
Proven track record of mentoring and growing engineers, and establishing a strong software engineering culture
Description
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data visualization and tools, data enrichment and monitoring tools. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. Our team of data engineers will use these systems to support end-to-end data flows tied to collection/annotation/QA operations, deliver high quality data quickly to ML teams, ensure traceability and versioning of data objects, and enforce compliance to contractual and regulatory obligations. You will work with SIML Data functions and with ML teams to assess data engineering needs tied to shipping ML features. You will partner with and influence the roadmap of teams that build infrastructure blocks that we rely upon (eg storage & labeling platforms), in order to contribute to a best-in-class ML Data Engine.
Education & Experience
Bachelors, Masters or PhD in Computer Science, Mathematics, Physics, or a related field; or equivalent practical experience.
Additional Requirements
Strong understanding of applied machine learning topics
Strong knowledge of either NLP or Computer Vision is desired
Experience with ETL frameworks like Airflow is desired
Kubernetes and Docker experience is desired
Excellent written and verbal communication skills, ability to work efficiently with members of other data functions who are not engineers
Self-starter, able to handle ambiguity, identify risks, troubleshoot, and find the right people and tools to get the job done
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program."
1008923443579,Glassdoor,,,https://www.metacareers.com/,"The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!


Software Engineer - Data Center Networking Responsibilities:
Design and implement drivers (and/or Firmware) for (network) ethernet adapter functions, Transport stack for RDMA, control functions with the host/accelerators.
Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).
Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI
Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
4+ years of experience in C/C++ and Python
4+ years experience in Systems programming, TCP/IP, HTTP/HTTPS, SPDY, DNS, and load balancers
Experience with network devices (routers, switches, load balancers) and an understanding of network routing protocols
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment



Preferred Qualifications:
Experience with Linux Kernel, especially drivers and network stack
Working knowledge of transport stack particularly RDMA (RoCEv2)
Experience with Qemu, FPGA Emulation environment is a plus
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
1008921355231,Glassdoor,,,https://www.snap.com/,"Snap Inc.
is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are
Snapchat
, a visual messaging app that enhances your relationships with friends, family, and the world;
Lens Studio
, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses,
Spectacles
.
Snapchat
is a camera and messaging app that connects people to their friends and the world. Every day around the globe, millions of people use Snapchat to communicate with friends, build relationships, play, and learn. No matter where you are or how you express yourself, it’s always the fastest way to share a moment!
We’re looking for a Security Engineer to join the Data Protection team at Snap Inc!
What you’ll do:
Design and implement robust security measures to fortify Snap’s data and infrastructure across multiple cloud platforms, especially in identity and access management.
Conduct in-depth security reviews of new platforms and services, and build tools to enhance data privacy and security throughout its lifecycle.
Perform code reviews and ensure exceptional code quality
Be a champion for security and user privacy
Knowledge, Skills & Abilities:
Excellent programming and software design skills, including debugging, performance analysis, and test design.
Experience with microservices architecture, distributed systems and cloud security technologies.
Excellent verbal and written communication skills, with high attention to detail.
Security knowledge in one or more team-relevant domains and technologies:
Identity and access management in GCP or AWS.
Balancing the principle of least privilege with productivity and security.
Implementing large-scale data privacy and security policies.
Minimum Qualifications:
BS/BA degree in a technical field such as Computer Science or equivalent years of experience.
3+ years of software development experience.
Experience designing, securing, and deploying large systems to Google Cloud or AWS.
Compensation
In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
Zone A (CA, WA, NYC)
: The base salary range for this position is $165,000 - $230,000 annually
Zone B
: The base salary range for this position is $157,000 - $219,000 annually
Zone C
: The base salary range for this position is $140,000 - $196,000 annually
This position is eligible for equity in the form of RSUs
This position is eligible for equity in the form of RSUs.
""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week).
At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at
accommodations-ext@snap.com
.
Our Benefits
: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!"
1008921835807,Glassdoor,,,http://careers.walmart.com/,"Position Summary...

What you'll do...

At Walmart's Emerging Tech Extended Reality team, we own some of the most challenging, fascinating, and impactful work in the fields of Computer vision, Machine learning and Deep Learning for next generation Augmented Reality and Virtual Reality experiences.

We are looking for a Senior Data Engineer with algorithms, programming and/or experience with Big Data Technologies such Hadoop, Hive and Spark.

About Team:
Our team creates reusable technologies to help with customer acquisition, onboarding, and empowering merchants, while ensuring a seamless experience for both of these stakeholders. We also optimize tariffs and assortment in accordance with Walmart's Everyday Low Cost philosophy. We not only create affordability, but we also deliver customized experiences for customers across all channels - in-store, mobile app, and websites.

What you'll do:
Process medium scale Walmart datasets using distributed cloud computing technologies to measure, understand, and bring insight to our merchandise data.
Build and maintain data pipelines using GCP, Spark, GPU, Hive that are highly scalable and performant.
Build and maintain data flows for our data lake.
Support business objectives by collaborating with business partners to identify opportunities to improve our high-priority initiatives.
Collaborate with the Data Science team to enable high quality user experiences powered by AI/ML.
End to end ownership and collaboration with product, engineering, vendors, and annotation partners.
Build insights across different dimensions of Brand, Time, Categories, etc.


What you'll bring:
Experience with data engineering, database engineering, business intelligence, or business analytics.
Experience with Hadoop, Hive, Spark using Scala or Python.
Experience with cloud computing like GCP, BigQuery, Azure, AWS.
Experience with data integration tools like Airflow.
Demonstrated knowledge of the following programming Languages: Scala, Java, Python, Hadoop Map-Reduce experience. Build Manager (Maven), Distributed Version Control (GIT), Continuous Integration (Jenkins) experience.
4+ years of experience in a technical role in small to medium scale complex cross-functional projects.
Experience in leading small groups of data engineers by providing directions and tasks.
Experience in using BI tools like Looker, Tableau, or Power BI. • Experience with data architecture in designing, implementing and management. • Experience with optimization of data query performance.
Experience in building standards across engineer teams.
Demonstrated knowledge with data modeling with data strategy for data pipelines and data products.


About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people and put a smile on their face. That's what we do at Walmart Global Tech. We're a team of 15,000+ software engineers, data scientists and service professionals within Walmart, the world's largest retailer, delivering innovations that improve how our customers shop and empower our 2.3 million associates. To others, innovation looks like an app, service, or some code, but Walmart has always been about people. People are why we innovate, and people power our innovations. Being human-led is our true disruption. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work
We use a hybrid way of working that is primarily virtual, while remaining near the locations Global Tech calls home. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives and spend less time commuting. Of course, being together in person is an important part of our culture and shared success. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities.

Benefits:
Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .

The annual salary range for this position is $136,000.00-$200,000.00

Additional compensation includes annual or quarterly performance incentives.

Additional compensation for certain positions may also include:

Regional Pay Zone (RPZ) (based on location)

Stock equity incentives

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Computer Science and 3 years' experience in software engineering or related field. Option 2: 5 years' experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 1 year's experience in software engineering or related
field.
2 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Master's degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area.

Primary Location...
640 W California Avenue, Sunnyvale, CA 94086-4828, United States of America"
1008918838237,Glassdoor,$85K,$131K,https://www.deloitte.com/,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do
Monitor and support updates to the legacy systems interface agreements, requirements, and designs until systems are retired.
Support the engineering analysis and requirements refinement of additional legacy system interfaces.
Profile data quality; provide feedback to representatives and system owners.
Support resolution of identified data errors with Stakeholders.
Issue and track Data Calls to source systems.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:
Bachelor's degree required
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Active Secret security clearance required
5+ years of consulting experience
5+ years of experience in SQL querying
Demonstrated experience with multiple interfaces, ensuring data quality, and presenting to stakeholders

Preferred:
Previous federal consulting experience
Experience with PeopleSoft"
1008918771062,Glassdoor,$77K,$110K,http://www.cognizant.com/,"Cognizant (NASDAQ: CTSH) is a leading provider of information technology, consulting, and business process outsourcing services, dedicated to helping the world's leading companies build stronger businesses. Headquartered in Teaneck, New Jersey (U.S.). Cognizant is a member of the NASDAQ-100, the S&P 500, the Forbes Global 1000, and the Fortune 500 and we are among the top performing and
Practice - AIA - Artificial Intelligence and Analytics
About AI & Analytics: Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.
By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data, and provides businesses a clear way to transform how they source, interpret and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence
Here are few bullet points about technical expertise from the candidate –
Analyzes complex data structures from disparate data sources and design large scale data engineering pipeline
Develops large scale data structures and pipelines to organize collect and standardize data that helps generate insights and addresses reporting needs
Collaborates with product business and data science team to collect user stories and translate into technical specifications
Uses knowledge in Cloud & Hadoop architecture HDFS commands and experience designing & optimizing queries to build data pipelines
Uses strong programming skills in PySpark Python Java or any of the major languages to build robust data pipelines and dynamic systems
Builds highly scalable and extensible data marts and data models to support Data Science and other internal customers on Cloud. Integrates data from a variety of sources assuring that they adhere to data quality and accessibility standards.
Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions
Experiments with available tools and advice on new tools to determine optimal solution given the requirements dictated by the model/use case
Required Qualifications
3+ years of progressively complex related experience in cloud data engineering and data analysis
Knowledge in programing languages such as PySpark Java Python Hive SQL
Knowledge in Cloud Technology Hadoop architecture HDFS commands and experience designing & optimizing queries against data in the HDFS environment
Strong knowledge of large-scale search applications and building high volume data pipelines preferably using Dataproc composer services on GCP or other Cloud Platforms

Preferred Qualifications
Ability to leverage multiple tools and programming languages to analyze and manipulate datasets from disparate data sources
Ability to understand complex systems and solve challenging analytical problems
Experience with bash shell scripts UNIX utilities & UNIX Commands

Primary: USTXRIAC01-Richardson - TX USA CLT
Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:
Medical/Dental/Vision/Life Insurance
Paid holidays plus Paid Time Off
401(k) plan and contributions
Long-term/Short-term Disability
Paid Parental Leave
Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.
Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment.
Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service
# L1-AV1# CB#Ind123
Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Oct 10 2023
About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.
Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.
Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.
If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information."
1008917473502,Glassdoor,,,,"Job ID: 651432BR
Date posted: Sep. 06, 2023

Description:We are Lockheed Martin.

Our products play an important role in the national security of the United States and more than 70 other countries, ensuring peace and stability around the world. Highly trained and specialized personnel and facilities are key to the company's unrivaled success in the aeronautics industry. Our workforce of more than 25,000 has preeminent expertise in advanced aircraft design and production, modification and support, stealth technology, and systems integration.

Join us as a Lockheed Martin Aeronautics Flight Test Data Processing Engineer. In this role, you'll interact directly with the customer as you perform tasks in preparing pre- and post-processing flight test data products, troubleshoot real-time systems, and act as the system administration and IT system build expert in support of the world's premier aircraft.

Some shift, extended hours, weekend work and travel may be required.

** Must be a US Citizen. This position is located at a facility that requires special access. No dual citizenship will be considered. **

A level 4 employee typically has 9-14 years of professional experience.

What's In It For You

Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually.

Here are some of the benefits you can enjoy:
Medical
Dental
401k
Paid time off
Work/life balance
Career development
Mentorship opportunities
Rewards & recognition

Learn more about Lockheed Martin's comprehensive benefits package here.

REF: Engineering, Aeronautics, aeroTE, aeroFTDPE

Basic Qualifications:
Bachelor's degree.
At least nine years of professional experience.
Data processing expertise in preparing for flight tests, supporting real-time operations, and post-processing including experience in finding anomalies, troubleshooting missing data to IRIG 106 Standards, evaluating telemetry, resolving network system issues, and leveraging Curtiss-Wright IADS and Omega Engineering instrumentation.

Desired Skills:
ABET-accredited bachelor's or higher degree in computer science, engineering, or related field.
System administration abilities such as software installation, server and workstation administration, Active Directory management, user account setup, database support, scripting, Linux and Solaris use, backups, security audit compliance, etc.
Software programming and scripting experience.
Hardware design and troubleshooting background in communication protocols such as Ethernet, MIL-STD-1553, ARINC 429, Fibre Channel, IEEE-1394, CAIS Bus, RS-485, etc., using related test equipment and tools.
Security+ certification within three months of hire.

Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.
Clearance Level: Top Secret
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: 4x10 hour day, 3 days off per week
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.
Experience Level: Experienced Professional
Business Unit: AERONAUTICS COMPANY
Relocation Available: Possible
Career Area: Aeronautical Engineering
Type: Full-Time
Shift: Multiple shifts available"
1008923035100,Glassdoor,,,,
1008923028752,Glassdoor,,,,"Plano 5 (31065), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC)."
1008922149972,Glassdoor,$98K,$143K,http://careers.autozone.com/,"Summary
The Senior Systems Engineer will design data model solutions and ensure alignment between business and IT strategies, operating models, guiding principles, and software development with a focus on the information layer. The Senior Systems Engineer works across business lines and IT domains to ensure that information is viewed as a corporate asset. This includes its proper data definition, creation, usage, archival, and governance. The Senior Systems Engineer works with and mentors other Data Architects to design overall solutions in accordance with industry best practices, principles, and standards. The Senior Systems Engineer strives to create and improve the quality of systems, provide more flexible solutions, and reduce time-to-market.

Job responsibilities include:
Enhance and maintain the AutoZone information strategy
Ensure alignment of programs and projects with the strategic AZ Information Roadmap and related strategies
Perform gap analysis between current data structures and target data structures
Enhance and maintain the Enterprise Information Model
Work with service architects and application architects to assist with the creation of proper data access and utilization methods
Gather complex business requirements and translate product and project needs into data models supporting long-term solutions
Lead data model peer review sessions for other data modelers / architects throughout the life cycle
Serve as a technical data strategy expert and lead the creation of technical requirements and design deliverables
Define and communicate data standards, industry best practices, technologies, and architectures
Check conformance to standards and resolve any conflicts by explaining and justifying architectural decisions
Recommend and evaluate new tools and methodologies as needed
Manage, communicate, and improve the data governance framework

Experience:
Minimum of 8 years of data modeling or related experience preferred
Experience and proficiency in enterprise data modeling for large, high-volume systems
Ability to lead sessions with stakeholders to determine data rules and review data models
Extensive architecture and design experience with complex applications, preferably in the retail industry, for relational and non-relational databases
Experience working with API Management and Service Oriented Architecture (SOA)
Demonstrated ability to coach and mentor less experienced members of an engineering team

Position Requirements:
Bachelor's degree in MIS, Computer Science or similar degree or experience required
Experience and knowledge of database systems such as Oracle, Postgres, UDB/DB2, BigQuery, Spanner, JSON, and Couchbase
Relational & NoSQL database design capability across OLTP & OLAP
Excellent analytical and problem-solving skills
Excellent verbal and written communication skills
Ability to facilitate modeling sessions and communicate appropriately with IT and business customers
Experience with Agile software development methodologies
Experience with large-replicated databases across distributed and cloud data centers"
1008923092247,Glassdoor,$80K,$113K,https://www.cgi.com/us/en-us/careers,"Azure Data Engineer with GenAI

Position Description
We are seeking a highly skilled and motivated Azure Data Engineer to join our team at CGI and contribute to our groundbreaking GenAI projects. As an Azure Data Engineer with a focus on GenAI, you will play a pivotal role in designing, developing, and maintaining data solutions that power our artificial intelligence and machine learning applications.

The position can be worked remotely or from any of the CGI offices.

Your future duties and responsibilities
Work collaboratively with various teams, including, Infrastructure, Data Science, Product, Marketing, Finance, and Research to understand their data needs and provide solutions.
Implement robust and fault-tolerant systems for data ingestion and processing.
Participate in data architecture and engineering decisions, bringing your strong experience and knowledge to bear.
Ensure the security, integrity, and compliance of data according to industry and company standards.

Proven experience as a data engineer with a strong focus on Azure cloud services.

Knowledge of GenAI principles, machine learning concepts, and their practical application.

Proficiency in SQL, Python, and other data processing languages.

Strong problem-solving skills and the ability to work collaboratively in a fast-paced environment.

Experience with data security and compliance standards.

Excellent communication skills and the ability to translate technical concepts to non-technical stakeholders.

Required qualifications to be successful in this role
At least 4-6 years of experience working with Azure openAI services with following expertise:
Azure Platform Engineering & Operation:
Expertise in AZURE Services
GenAI Infra foundation Azure OpenAI
Azure API management
Vector DB expertise (cloud agnostic)
Service Reliability Engineering
A good data engineer or data
Ability to experiment with LLMs and Streamlite and other Lannchain apis

Experience working with multi-cloud environment such as AWS and Azure and GCP is plus..

Azure certifications (e.g., Microsoft Certified: Azure Data Engineer) are a plus.

Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to: skill set level; experience and training; and licensure and certifications. CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $74,600 - 156,700.

At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:
Competitive base salaries
Eligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category
401(k) Plan and Profit Participation for eligible members
Generous holidays, vacation, and sick leave plans
Comprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;
Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and more

#LI-MP2
#DICE

Insights you can act on

While technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees ""members"" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.

Ready to become part of our success story? Join CGI - where your ideas and actions make a difference.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information."
1008922327505,Glassdoor,$60K,$84K,http://www.turnerandtownsend.com/,"Company Description

From the inception of a project through to completion and beyond, Turner & Townsend help to deliver the outcomes that matter through transformational programs covering the full spectrum of consultancy, project delivery and post-project operations.
With offices located globally, you're never far away from our services. Working from 118 offices in 50 countries, we make the difference to projects across the real estate, infrastructure and natural resources sectors worldwide.
Our team is dynamic, innovative and client-focused, supported by an inclusive and fun company culture. Our clients value our proactive approach, depth of expertise, integrity and the quality we deliver. As a result, our people get to enjoy working on some of the most exciting projects in the world.

Job Description

Turner & Townsend are seeking a driven Cost Engineer to join our team and support a global technology client on their large-scale Data Center construction program.
Working as part of an industry leading team, you’ll be eager and excited to learn the role and build upon your cost skillset that will set you up for a successful career in the construction industry.
To be successful you’ll have strong analytical skills, be well organized and able to work effectively under pressure, and have great commercial acumen.
The role will initially entail supporting our estimating and cost review leads with take-offs, benchmarking and managing stakeholders.

Job Objectives:

Tracking cost review and estimate requests as they are submitted by the client.
Preparing documents as required by the team.
Issuing RFIs and chasing responses.
Document control.
Analyzing existing cost data and producing benchmark information.
Weekly reporting to the client.
Meet and negotiate costs with contractors.
Reconciling actual costs with contract pricing.
Develop cost estimates from drawings and specifications.
Provide input into value engineering exercises.

Qualifications
A minimum of 2-3 years post-graduate experience working in a cost role on large Data Center, Commercial, Healthcare, High-tech or related projects.
Passion and enthusiasm for construction and numbers!
Strong analytical skills and advanced proficiency using spreadsheets.
Experience using estimating software, e.g. on screen take off, Revit.
Working knowledge of Microsoft Office and Google Suite: Docs, Sheets, Slides, and Drive.

Additional Information

*On-site presence and requirements may change depending on our client's needs*
Our inspired people share our vision and mission. We provide a great place to work, where each person has the opportunity and voice to affect change.
We want our people to succeed both in work and life. To support this we promote a healthy, productive and flexible working environment that respects work-life balance.
Turner & Townsend is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees and actively encourage applications from all sectors of the community.
Please find out more about us at www.turnerandtownsend.com/ and https://www.heery.com/
All your information will be kept confidential according to EEO guidelines.
#LI-MB1
Join our social media conversations for more information about Turner & Townsend and our exciting future projects:
Twitter
Instagram
LinkedIn
It is strictly against Turner & Townsend policy for candidates to pay any fee in relation to our recruitment process. No recruitment agency working with Turner & Townsend will ask candidates to pay a fee at any time.
Any unsolicited resumes/CVs submitted through our website or to Turner & Townsend personal e-mail accounts, are considered property of Turner & Townsend and are not subject to payment of agency fees. In order to be an authorised Recruitment Agency/Search Firm for Turner & Townsend, there must be a formal written agreement in place and the agency must be invited, by the Recruitment Team, to submit candidates for review."
1008918465092,Glassdoor,,,https://aws.amazon.com/careers/why-aws/,"6+ years of data engineering experience
Experience with data modeling, warehousing and building ETL pipelines
5+ years of data engineering, database engineering, business intelligence or business analytics experience
Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
Experience mentoring team members on best practices
Experience building data products incrementally and integrating and managing data sets from multiple sources
AWS Global Demand & Operations (GDO) team is seeking a seasoned Sr. Data Engineer to empower business decision making along Lead Flow Process by building our owned data service. You will own and build GDO's next-generation data repository, offer data solution for optimizing lead flow process. If you are passionate about building data platform/pipeline solutions for AWS Global Demand & Operations central team, please join us!

Key job responsibilities

As a Sr. Data Engineer at AWS GDO team, you will:
Work in a large, extremely complex and dynamic data warehousing environment. You will integrate multiple heterogeneous data sources, such as Salesforce, Adobe Target, Adobe Connect with data warehouse across multiple teams;
Build and deliver high quality data solutions to meet both analytics and deployment requirements;
Work closely with Scientists, BI Engineer, software developers, product managers, and business owners to develop and define key business questions, then build the data sets and/or solution.
Design, implement, and operate stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing reporting applications.
Leverage new cloud architecture and data engineering patterns to ingest, transform and store data.
Learn new technologies and implement solutions using these technologies to enable upgrades of the existing platform.
Preference for this role to be in Austin or Seattle, but open to any other location within the US that has an AWS Corporate office. Relocation offered from within the US to any of these locations.

A day in the life
Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future

About the team
GDO consists of seven global sub-teams, Lead Management & Operations (LMO), Global Demand and Solution Center (GDSC, previously MRC), and Localization (LOC) each aligning with its vertical business. Horizontally, there are four functional teams supporting Strategy & Analytics, Engineering, Business Operations, Event Platforms across entire GDO. Our mission/goal is to improve AWS customer’s cloud journey in order to generate demand throughout the buyer lifecycle, through personalized human engagement, advanced lead management technology, and best-in-class language experience.

We are open to hiring candidates to work out of one of the following locations:

Austin, TX, USA | Seattle, WA, USA

Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
Experience operating large data warehouses
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $123,700/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site."
1008921507066,Glassdoor,$75K,$110K,http://www.scjohnson.com/,"SC JOHNSON IS A FIFTH-GENERATION FAMILY COMPANY BUILT ON THE SPIRIT OF OUR PEOPLE. We have been leading with purpose for over 130 years, building iconic brands that win the hearts and minds of consumers – such as Raid®, Glade®, Ziploc® and more, in virtually every country around the world. Together, we are creating a better future – for the planet, for future generations and for every SCJ team member. Join our winning team of Wave Makers and Go Getters and help us write the next chapter in the SCJ story.
Summary:
As the Associate Manager, Data Network Engineer, you will be responsible for providing Level 3 and above support within Network Engineering and Operation Teams. You will serve as point of contact on troubles affecting both Networks and Infrastructure Security services.
This is an onsite role in Racine, WI.
Essential Duties and Responsibilities:
Use Architecture High Level and Low-Level designs and security standards
Acceptance of Site-Specific Design provided by Implementation Engineers
L3 and above support on network and infrastructure security services: LAN, WAN, Wireless, IPSEC, Firewalls, DMZ, DNS, DHCP, NTP, Routing, Switching, IPv4 and IPv6, QoS, WANAN Optimization, Load Balancer, IDP, IDS, Web and Content filtering, DLP and Malware
Escalate tickets to L3 support
Primary network contact for North America and Latin America regions
Collaborate with Vendors and Suppliers
Provide report during Problem Management and Root Cause Analysis
Required Skills / Experience / Competencies:
Bachelor’s degree in data communications, Communications Engineering or Computer Science, with coursework in Infrastructure (Network, Data Centers) Security or military experience considered in lieu of education requirement
5+ years’ experience which must include: (Will accept Master’s degree and 3+ years of experience in lieu of BS and 5+ years)
CCNA Routing and Switching Certification
Qualified candidates must be legally authorized to work in the United States
Preferred Skills / Experience / Competencies:
Cisco Routing, Switching, LAN, WAN and Data Center associated solutions, QoS and WAN Optimization experience
IP telephony (Avaya/Cisco, etc.)
Microsoft Office including Visio (complex Network and Security diagrams), DNS, DCHP
Intrusion Detection System (IDS), Web and Content filtering, GRE and IPSEC
College level proven coursework with Network and Security specialization
Job Requirements:
Full time
0 - 15% travel
Office Environment
Ability to lift 10 – 40 pounds
SC Johnson’s total compensation packages are at or above industry levels. In addition to salary, total packages may include bonuses, long-term incentives, matching 401(k) contributions and profit sharing based on company profitability, job level and years of service. As a family company, we’re committed to providing benefits such as subsidized health care plans, maternity/paternity/adoption leave, flexible work arrangements, vacation purchase options, recreation and fitness centers, childcare, counseling services and more.
#LI_MHI
Better Together
At SC Johnson, we strive to create a positive, inclusive and unique workplace. We strongly believe SCJ people are able to achieve their best when they can collaborate and work together in person.
Equal Opportunity Employer
The policy of the Company is to ensure equal opportunity for all qualified applicants and employees without regard to race, color, religion, gender, marital status, sexual orientation, national origin, ancestry, age, gender identity, gender expression, disability, citizenship, pregnancy, veteran status, membership in any active or reserve component of the U.S. or state military forces, genetic history or information or any other category protected by law.
Accommodation Requests
If you are an individual with a disability and you need an accommodation or other assistance during the application process, please call our Human Resources department at 262-260-3343 or email your request to SCJHR@scj.com. All qualified applicants are encouraged to apply. Download the EEO is the Law poster for more information."
1008920654060,Glassdoor,,,,"About this role:

Wells Fargo is seeking a Senior Network Engineer to join our Internal Hosting implementation team. This team provides the foundational global network infrastructure (data center routers and switches) which includes building capacity and managing the lifecycle of our internal network modules.

In this role, you will:
Lead or participate in implementing network security policies across routers and firewalls
Manage production networks including Internet Protocol backbone, data centers and edge pops across the globe
Ensure the continuous availability of all data network services
Identify gaps, risks and issues and navigate organizational structure to resolve them
Perform quarterly proactive network testing to ensure proper functioning and reliability of the network
Investigate and remediate network capacity related issues
Apply knowledge of security and regulatory policies to design and implement foolproof secured network solutions
Provide resolution information and work with other teams to complete impact analysis
Deliver comprehensive and maintenance plans for change management review and approval
Mentor and train network operations team in the installation, configuration, and maintenance
Partner cross-functionally with other Product Infrastructure teams in order to continuously improve and apply standards and policies relevant to operational excellence
Required Qualifications:
4+ years of Network Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education
4+ years of Network Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education
4+ years of experience with configuration of routing and switching latest platforms and solutions - Cisco Nexus and/or Arista product line
4+ years of experience designing LAN/WAN/Datacenter solutions for large enterprises
4+ years of experience with IP routing protocols (BGP, OSPF, RIP) in a large enterprise environment
Desired Qualifications:
Excellent documentation and verbal communication skills
Demonstrated skill with creating and/or updating technical design documentation used by engineering teams
Experience with Microsoft Office, Visio Professional
Experience working in an agile environment utilizing Atlassian Jira products
Strong understanding of the following routing protocols: OSPF, BGP, EIGRP
Bachelor's degree in Computers or Electronics with 7-9 Years of Networking Experience
CCNA, CCNP/DP or CCIE Certification preferred - Datacenter
Strong understanding of QoS configurations to support enterprise standards.
Strong experience in configuring Cisco and Arista Routers/Switches
Strong understanding of the following layer 2 switching protocols: Spanning Tree, Trunking, Etherchannel
Strong understanding of the following: HSRP, CBWFQ, DSCP, NAT/SNAT, TCP/IP, Multicast, Ethernet, EVPN, MLAG, CVP
Strong understanding of DNS/domain services
Python/Ansible/GITHUB experience a plus
Experience and familiarity with Change control processes - Service Now
Job Expectations:
Flexibility to frequently be on call beyond normal working hours
Ability to travel up to 10% of the time
Telecommuting is not an option for this position
This position offers a hybrid work schedule
Relocation assistance in not available for this position
This position is not eligible for visa sponsorship
Execute changes into the above environments via the Wells Fargo change control process, assist on mitigating risk for the enterprise by proactively addressing capacity problems or system related issues, participate in enterprise level projects from an engineering perspective and responsible for Design, reviewing, implementing, testing/validating, and researching industry best practices
This team works under a product model with dedicated teams supporting our products
We Value Diversity

At Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.

Employees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.

Candidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.

Candidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process.

Drug and Alcohol Policy

Wells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more."
1008918465143,Glassdoor,,,http://www.amazon.jobs/,"5+ years of non-internship professional software development experience
5+ years of programming with at least one software programming language experience
5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience as a mentor, tech lead or leading an engineering team
Amazon Fashion and Fitness (F2) is one of the fastest growing segments of Retail. We are building a new team to develop undifferentiated data access tools to support making Amazon’s online store the preferred fashion and fitness shopping destination for customers globally. Our goal is to power products and customer experiences by building best in class data tools tailored for the organization. From computer vision and machine learning, to ads and recommendations, we aim to provide a valuable data foundation for all of F2.

Key job responsibilities
We are looking for an innovative leader who wants to fully own defining their customers’ experience and team roadmap, while delivering scalable technical solutions to help solve complex problems in retail. Above all, you have a willingness to learn, lead and teach while solving ambiguous problems upholding Amazon’s Leadership Principles.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $134,500/year in our lowest geographic market up to $261,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site."
1008923163788,Glassdoor,$89K,$132K,,
1008921319710,Glassdoor,,,http://www.cherokee-federal.com/,"GEIS Data Engineer
The GEIS Data Engineer will support the Armed Forces Health Surveillance Division (AFHSD) Global Emerging Infections Surveillance (GEIS) Branch efforts to coordinate infectious disease surveillance data collection, management, analysis and visualization activities within the Department of Defense (DoD) in order to provide early detection, prevention and response to infectious disease threats of military relevance. Successful candidates will have strong data engineering, management and analysis skills and experience working with U.S. government agencies, such as the DoD.
Compensation & Benefits:
Estimated Starting Salary Range for GEIS Data Engineer : $120,000.00 - $130,000.00
Pay commensurate with experience.
Full time benefits include Medical, Dental, Vision, 401K, and other possible benefits as provided. Benefits are subject to change with or without notice.
Work location: Weekly Schedule: on-site in the Silver Spring, MD and tele-work.
GEIS Data Engineer Responsibilities Include:
Oversee the GEIS data lake environment to ensure data is properly ingested and high-quality raw data is available for analysis.
Establish a data governance strategy, including data lifecycle policies, object tagging and data catalog development to maintain an accessible data lake environment.
Leverage MOVEit Automation to create pipelines for data ingestion to the AWS S3 bucket.
Understand, document, and evolve the business and technical requirements for the GEIS data lake, collaborating with a team of developers to maintain the data lake.
In collaboration with GEIS staff, develop and maintain Tableau dashboards for use on GEIS’ CarePoint portal.
In collaboration with GEIS staff, replace data source connections in existing Tableau workbooks to the appropriate data warehouses in AWS Redshift.
Ensure data is readily accessible and available to GEIS staff members for analysis; assist with analysis on an as-needed basis to translate data into actionable information for senior level officials to inform force health protection.
Once the data lake infrastructure has been established, work to automate data download pipelines that extract data from open-source websites to be combined with GEIS-generated data for downstream analyses.
Performs other job-related duties as assigned
GEIS Data Engineer Experience, Education, Skills, Abilities requested:
Bachelor’s or Master’s degree in Computer Science, Information Science or relevant field and a minimum of 2 years of practical experience in data engineering. Professional, Associate, and Specialty AWS Certificates will also be considered.
Have hands-on practice manually migrating data between MOVEit, Amazon Redshift clusters and Amazon S3.
Proficiency in a wide array of programming languages, especially R, SAS, and SQL.
A minimum of 1 year experience developing Tableau Dashboards.
Demonstrated experience using clear and concise writing skills to explain complex data or systems to others.
Demonstrated experience supporting Federal clients, particularly DoD.
Must be a US citizen.
Must be able to obtain a Secret Clearance.
Past applicable job experience may include, but is not limited to: Data Analyst, Data Architect, and Data Operations Engineer.
Must pass pre-employment qualifications of Cherokee Federal
Company Information:
Cherokee Nation Strategic Solutions (CNSP) provides support, services, and solutions to federal and commercial customers. The company takes a personalized approach to solving our clients' toughest challenges, helping you make the most of your skills. CNSP is part of Cherokee Federal – a team of tribally owned federal contracting companies. For more information, visit cherokee-federal.com.
#CherokeeFederal #LI-DNI
Similar searchable job titles
Data Analysis
Machine Learning Engineer
Data Architect
Military Health
Data Operations Engineer
Data Mining
Data Warehousing
Data Modeling
Data Visualization
DoD
Legal Disclaimer: Cherokee Federal is an equal opportunity employer. Please visit cherokee-federal.com/careers for information regarding our Affirmative Action and Equal Opportunity Employer Statement, Accommodation request, and Presidential EO 14042 Notice."
1008918898466,Glassdoor,,,http://www.utah.gov/,"Job Description


The Planning Division of the Utah Department of Transportation (UDOT) invites applications from dynamic individuals to join our team as a Model and Data Analyst Planning Manager. We are seeking an enthusiastic, self-motivated, collaborative, and driven professional who is passionate about shaping the future of transportation planning. As a key member of UDOT’s planning analytics team, you will play a pivotal role in the development, enhancement, and maintenance of the data for the state’s travel demand and land use models. These models serve as critical tools to support a diverse range of planning efforts, including the long-range plan, corridor studies, and various strategic initiatives.

The ideal candidate will see beyond the status-quo, demonstrating a keen ability to assess existing processes and envision innovative approaches to enhance efficiency, responsiveness, and clarity. If you thrive in a collaborative environment and are excited about contributing to the advancement of transportation planning in Utah, we encourage you to apply and become an integral part of our progressive team.

The Region
Utah is one of the fastest growing states in the country, and for very good reason; there are unparalleled outdoor recreation opportunities, great job opportunities and vibrant communities. The person in this Model and Data Analyst Planning Manager position at UDOT will be uniquely positioned to be on the forefront of the extensive opportunities this growth presents. They will be able to lead the DOT in the forecasting space and find opportunities to be innovative and creative in this arena. Through the forecasting work they do, the person in this position will be able to support transportation decisions that affect both visitors and residents of the state of Utah for years to come, enhancing what is already a high quality of life in the region.

The Organization
UDOT operates across the entire state of Utah planning for, constructing, and maintaining state roadway facilities while also helping to support countless local projects through funding mechanisms available at the state level. Additionally, UDOT, now more than ever, is in the business of planning and building for those on foot, bike, or transit. Utah’s Transportation Vision, or UVision, is the statewide strategic plan for transportation centered on the four pillars of Good Health, Strong Economy, Better Mobility, and Connected Communities. UDOT is an important and trusted resource in statewide multi-modal transportation decision-making and it is an extremely exciting time to be involved!

Principal Duties
As the Model and Data Analyst Planning Manager you will be responsible for:
Updating and managing data for travel demand and land use models, such as highway and transit networks, socioeconomic datasets, college and recreation datasets, etc.
Developing and enhancing travel demand model components, including recreation and long-distance modules.
Reviewing and processing model output data to support planning studies and applications.
Performing travel demand and land use model validation and sensitivity analyses and identify areas for improvement.
Using Geographic Information Systems (GIS) tools for spatial analysis, enhancing the visual representation of travel demand model information.
Clearly communicating model-related information to diverse stakeholders.
Collaborating with partner agencies to maintain consistency across state travel demand models.
Attending and contributing to model user group and interagency model technical committee meetings.
Maintaining comprehensive documentation for travel demand and land use models.
Providing training on model usage and interpretation for internal staff and external stakeholders.
The Ideal Candidate
The best person for this position:
Must have a PE license in Utah
Must have at least four years of engineering experience following licensure as a PE
Critical Thinking: ability to exercise initiative and independent judgment, creative thinking, and analytical problem solving to address challenges encountered during data processing, and/or model development and application.
Data analysis: experience with data cleaning, validation, and integration into travel demand models.
Interpret and communicate results: Ability to analyze data and draw meaningful conclusions. Must be able to process and analyze transportation datasets, and draw conclusions and communicate them to internal groups within UDOT, as well as partner-agencies and consultant audiences.
Excel/Google Sheets for analysis, data processing, filtering, and visualization: Ability to follow existing workflows, troubleshoot with little guidance, and develop new workflows.
ESRI ArcGIS for mapping and spatial analysis to enhance visual representation and analysis of travel demand model data.
Technical writing to document processes and analysis results: Ability to document processes and write memorandums and reports to communicate analysis results.
Aesthetically pleasant visuals: Ability to create graphics, visuals and charts that successfully convey technical information to internal and external audiences is a plus.
Position may be underfilled for those who have a PE license, but do not have at least four years of post PE experience. In order to qualify for the underfill, you must have at least two years of post PE experience. Salary range for the underfill is $35.94 - $57.03.

Preferences
Preference may be given to those with experience in at least one of the following areas:

Travel demand modeling tools to forecast future volumes: Familiarity with travel demand modeling software such as CUBE, TransCAD, or ActivitySim.
Programming languages for data analysis: basic understanding or interest in Python, SQL, R, or other coding languages to automate and enhance analytical and modeling processes.
Big Data to support transportation analysis: experience with StreetLight or other big data vendors or experience working with Access or other big data platforms.
Existing Transportation Data to support planning: experience working with UDOT or partner agency data (UGRC, UTA, WFRC, etc.).
Supplemental Information
Here is some information you should be aware of:
This position is eligible for telework, based on supervisor approval, although some in-office work will still be required.
May need to travel within the State of Utah.
Working Conditions - Risks found in the typical office setting, which is adequately lighted, heated and ventilated, e.g., safe use of office equipment, avoiding trips and falls, observing fire regulations, etc.
Physical Requirements - Typically, the employee may sit comfortably to perform the work; however, there may be some walking; standing; bending; carrying light items; driving an automobile, etc. Special physical demands are not required to perform the work.

Why Should You Join Our Team?
The work we do matters. If you want to make a positive difference doing meaningful work, this is the right place for you. Our mission statement is, “Enhance quality of life through transportation.” We define quality of life through a framework of Good Health, Connected Communities, Better Mobility, and Strong Economy. We help the State of Utah and its traveling public to get to where they want, when they want, in the way they want - and we make sure they can do it safely.

You will become part of a team with an internal culture of Trust, Teamwork, and Flexibility. Our organization lives by the values of Respect, Integrity, and Caring. If these are your values too, you'll be a great fit.

Aside from working for a cause-driven, cutting edge agency that is leading all other transportation departments in the nation, you will receive great health and retirement benefits. Working for the State of Utah provides a positive work-life balance. Click here to view a summary of the benefits we offer.

The Agency
UDOT is a strengths-based organization, which means its approach is based on identifying and developing individual and organizational strengths. Our philosophy is to address challenges by bringing our strengths to each situation and create the best solutions. Candidates are encouraged to be familiar with their strengths and consider how they may potentially be of benefit to the roles for which they are applying. UDOT uses the CliftonStrengths Assessment, but there are multiple strengths assessment tools available online, and no formal assessment is required.

For more information on the Utah Department of Transportation please click here."
1008921907588,Glassdoor,,,,"Date Posted:
2023-10-10
Country:
United States of America
Location:
PW100: East Hartford 400 Main Street, East Hartford, CT, 06118 USA
Position Role Type:
Hybrid
Pratt & Whitney is working to, once again, transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious.
Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future.
Innovation through diversity of thought. At Pratt & Whitney, we believe diversity of thought enables creativity, innovation, and a foundation for inclusion. By fostering an inclusive culture, we accept a shared accountability and responsibility to recognize, sponsor, coach, hire and promote talent equally. We welcome our employees to be their whole - best - selves at work because trust, respect and integrity, are a part of our DNA.
At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond?
Control & Diagnostic Systems (CDS) is a dynamic engineering organization focused on the development and certification of military, commercial and industrial gas turbine engine control and diagnostic systems. CDS is responsible for all aspects of Pratt & Whitney engine control and diagnostic system development, including requirements analysis & definition, system & software architecture, algorithm design, and product software design, verification & validation. We integrate the control and diagnostic system design across other engine system modules and with the air vehicles and provide support throughout the complete engine product life cycle.
The Diagnostics, Prognostics and Health Management (DPHM) discipline within CDS is responsible for the development and deployment of cutting-edge data acquisition systems, diagnostics, prognostics, and analytics. This includes Usage Based Lifing (UBL) for P&W engines and components and deploying state of the art development tools & methodologies.
The DPHM Data Engineer will be responsible for developing and maintaining cloud-based flight data ingestion pipelines and distributed analytics tools to facilitate engine health monitoring analysis and diagnostic and prognostic algorithm development.
Basic Qualifications:
Bachelor’s degree in engineering - Mechanical Eng, Electrical Eng, Computer Science, Computer Eng
U.S. Person or eligible to obtain necessary export authorizations required.
Fluent in English (verbal/written)
Minimum GPA of 3.0
Preferred Qualifications:
Basic proficiency with one or more of the following Python, Java, Kubernetes, Apache Spark, and Agile
What is my role type?
In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is:
Hybrid: Employees who are working in Hybrid roles will work regularly both onsite and offsite. This means that responsibilities of the job need to be performed onsite on a regular basis.
Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility.
RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.
Privacy Policy and Terms:
Click on this link to read the Policy and Terms"
1008921777244,Glassdoor,,,https://www.cei.com/,"Posting Title: Project Engineer
Reports To: Production Manager
Location: New Albany, Ohio
Salary Range: $65,000 to $75,000
Final determination of a successful candidate’s starting pay will vary based on a number of factors, including market location and may vary depending on job-related knowledge, skills, education and experience. The pay scale listed for this position is generally for candidates that meet the specified qualifications and requirements listed on this specific job description. We provide a competitive compensation package that recognizes your experience, credentials, and education alongside a robust benefits program to meet your needs. Our compensation reflects the cost of labor across several US geographic markets.
WHO WE ARE
For nearly 70 years, Cupertino Electric, Inc. (CEI) has been powered by people who’ve built a reputation for delivering high-profile, complex projects. Real, tangible things that alter the landscape and improve lives. But even more than that, we’ve built a reputation for integrity. We’re problem solvers and innovation seekers. We’re team players and safety fanatics. And we always—always—do the right thing. Even when no one is looking. Because what we do here is important, but how we do it is everything.
THE DATA CENTER TEAM
We build mission-critical data centers throughout the U.S. to ensure crucial information accessed by millions of people is always available and secure. For two decades, CEI has designed, installed and commissioned more than 11.5 million square feet of data center space totaling $2.3 billion worth of electrical systems.
ABOUT THE ROLE
We’re seeking a Project Engineer ready to be on the front lines of a project-giving daily support to the field, project management, and customer teams. Our Project Engineers (PE) are vital in keeping our processes moving along and assists in the execution of project plans. This role will be responsible for specific activities such as coordinating material onsite delivery dates, maintaining RFI, submittals, and change order logs, and will serve as a key point of contact for internal customers.
ABOUT YOU
You are willing and excited to learn—with a continuous focus on cultivating a growth mindset. You bring a wide range of skills from being organized to communicating through various channels and collaborating with your team members. You are comfortable taking initiative and ownership of your work. You are not afraid to throw on a pair of boots and your protective personal equipment (PPE)—safety first!
WHAT YOU WILL GAIN
At Cupertino Electric you’ll be on a career development path to project management. You’ll work directly for a project manager or project executive on a team that partners with field, engineering, and design teams. It’s ok if you don’t have a deep understanding of electrical construction, just be ready to learn and get fired up. You'll have the opportunity to soak up knowledge from everyone you work with – from the journeyman and general foreman to the project team assigning daily tasks. In addition to on-the-job experience and mentoring from your peers, you’ll attend vendor off sites, training classes, and other learning opportunities.
MINIMUM QUALIFICATIONS
Any combination of education and experience that, in the sole judgment and discretion of Company, would likely provide the required knowledge, skills and abilities as well as possession of any required licenses or certifications may qualify.
Education: High School Diploma or GED required. Bachelor’s Degree in Construction Management, Business, Engineering, or similar preferred.
Licensure/Certifications: None required.
Experience: Zero (0) years of construction or related experience required. Two (2) years of construction or related experience preferred.
Driving Record: Valid state-issued driver’s license and satisfactory driving record.
*Applicants must be authorized to work in the United States. This position is not eligible for sponsorship."
1008918336518,Glassdoor,,,http://www.nvidia.com/,"NVIDIA has been redefining computer graphics, PC gaming, and accelerated computing for 30 years. It’s an outstanding legacy of innovation that’s motivated by extraordinary technology—and outstanding people. Today, we’re tapping into the unlimited potential of AI to define the next era of computing. An era in which our GPU acts as the brains of computers, robots, and self-driving cars that can understand the world. Doing what’s never been done before takes vision, innovation, and the world’s best talent. As an NVIDIAN, you’ll be immersed in a diverse, encouraging environment where everyone is inspired to do their best work. Come join our team and see how you can make a lasting impact on the world.
NVIDIA's Cloud data centers host ground-breaking products across high-performance computing to machine learning applications for autonomous vehicles and healthcare. At the heart of our data centers is the ability to engineer mechanical and electrical designs in close coupling to NVIDIA's industry-leading GPU and DGX products. We are seeking a Data Center Electrical Design Engineer to support the electrical design of our high performance data centers.
What you’ll be doing:
Collaborate with product owners and technical leads to identify and collect requirements for our next-generation data centers.
Support the global design standards for the data center controls and monitoring (DCCM) system, collaborating with internal teams to develop an execution strategy and life cycle management
Responsible for evolving control systems strategies & processes, including design requirements, specifications, programming, control logic & sequences, simulation, testing, evaluation and integration, as well as vendor and commissioning oversight..
Support standardization in controls engineering quality approval, process control, product evaluation, vendor proposals, evaluate product reliability, automated testing and software
Collaborate with cross functional teams to make modifications to control settings and alarm thresholds to manage the data center space.
Manage vendors while supporting DC Operations teams, including direct oversight to all system configuration and component upgrades.
What we need to see:
Have excellent interpersonal and leadership skills will be critical for success: success depends on building rapport and credibility with multiple stakeholders across the organization
BS in Engineering, CS and/or equivalent experience
8+ years of experience with control system design, development and management on industrial or mission critical systems
Working knowledge of mechanical, electrical, life safety, and IT Networking systems associated with critical environments
Understanding of SNMP, OPC-UA, and Modbus (TCP & RTU) protocols and how to integrate using this protocol.
Troubleshooting, problem-solving skills and experience driving root cause analysis to complex projects under pressure
Experience with equipment commissioning, testing, or related activities
Experience with startup and configuration of Programmable Logic Controllers (PLCs) and SCADA workstations.
Ways to stand out from the crowd:
Experience with software programming languages: Python, PHP, SQL and with Ignition SCADA software development and deployment.
Experience with MQTT communication protocol, higher level data strategies, and integration to IT systems
Strong understanding of data center systems, components and their interface and working in a leased colocation data center environment
Strong understanding of data center commissioning including Level 1 through Integrated Systems Testing
Working knowledge and experience with Data Center Infrastructure Management (DCIM) and EPMS systems and knowledge of data center power and cooling solutions, including advanced systems such as liquid cooling
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. If you're creative and autonomous, we want to hear from you!
The base salary range is $176,000 - $327,750. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law."
1008920064257,Glassdoor,,,,"Job Description Summary
The Application Operations Engineer will be responsible for ensuring the smooth operation and support of integrations to/from Oracle Enterprise Performance Management (EPM) systems. This role includes troubleshooting, maintenance, performance tuning, and ensuring high availability for all integration tools plus specific Oracle EPM applications within the technology landscape.
Job Description
Key Responsibilities:
Maintenance & Support: Handle day-to-day operational tasks, including the resolution of system issues, outages, and end-user support requests related to Oracle EPM applications.
Performance Tuning: Monitor system performance metrics and optimize Oracle EPM applications to ensure efficient operation and minimized response times.
Upgrades & Patches: Coordinate with Oracle and internal IT teams to install, test, and deploy patches, updates, and version upgrades to maintain application health and integrate new features.
Backup & Recovery: Implement and monitor backup procedures for Oracle EPM systems and perform data recovery tasks when necessary.
Security & Compliance: Ensure that Oracle EPM systems meet organizational security standards and compliance requirements, including regular system audits and updates to security policies.
Documentation: Maintain thorough documentation on system configurations, operational procedures, and troubleshooting guidelines.
Collaboration: Work closely with cross-functional IT teams, finance teams, and external vendors to ensure Oracle EPM solutions meet business requirements and are integrated smoothly with other technologies.
Training: Provide training and resources to end-users and IT teams to optimize the use of Oracle EPM systems.
Continuous Improvement: Keep abreast of the latest Oracle EPM developments and industry best practices to recommend improvements and enhancements to the system.
Incident Management: Respond to and resolve critical incidents, collaborating with relevant stakeholders to ensure minimal disruption to business operations.
Minimum Qualifications:
Bachelor’s degree in computer science, IT, or a related field
4+ years of hands-on experience in Oracle's Hyperion Financial Management (HFM), Oracle Planning, Oracle Essbase
2+ years of hands-on experience in data integration tools including FDMEE, ODI, and Automic
Strong understanding of finance and accounting principles, including corporate month end close - consolidation, translation, elimination, and financial reporting activities.
Understanding of Oracle EPM architecture, components, and integration points.
Familiarity with Oracle databases, WebLogic servers, and related Oracle technologies.
Solid experience in troubleshooting and performance tuning of Oracle applications.
Knowledge of ITIL processes, especially incident, problem, and change management.
Excellent communication and interpersonal skills.
Proven ability to collaborate effectively with technical and non-technical stakeholders.
Desired Qualifications:
Oracle EPM certification.
Experience with cloud-based Oracle EPM deployments.
Familiarity with other integration agents like Informatica, Talend, etc.
Familiarity with scripting languages like Shell, Python, or Perl
The Application Operations Engineer is a critical role that ensures the consistent and efficient operation of Oracle EPM systems, directly impacting organizational performance management processes. The ideal candidate will be proactive, detail-oriented, and capable of handling complex technical challenges.
Eligibility Requirement:
Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job.
For Candidates in the US:
The salary range for this position is $107,500 - $179,200. The specific salary offered to a candidate may be influenced by a variety of factors including the candidate’s experience, their education, and the work location. In addition, this position is eligible for a performance bonus/variable incentive plan.
GE provides a comprehensive benefits package that provides access to plans which support the overall wellbeing of our employees and their dependents. These benefits include, but are not limited to, healthcare coverage (medical, dental, vision, pharmacy), a retirement plan that includes Company Retirement Savings and a 401K with Company matching, Life Insurance options, Disability coverage, paid time-off, EAP, and more."
1008923384113,Glassdoor,,,,"EY focuses on high-ethical standards and integrity among its employees and expects all candidates to demonstrate these qualities. At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

IT Advisor, Technology Consulting, Digital and Emerging Technologies, Microsoft –Data & AI -Azure Data Platform Engineer (Manager) (Multiple Positions), Ernst & Young U.S. LLP, San Antonio, TX.

Help clients with designing and building data and analytics architectures to enable better business outcomes. Support the strategy, planning, and implementation of data design services, providing sizing and configuration assistance, and performing needs assessments. Develop and maintain data lake and data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. Collect, aggregate, and analyse structured/unstructured data from multiple internal and external sources, present patterns and insights, and scaling data for use in Machine Learning and Artificial Intelligence use cases. Collaborate with Cloud Solution Architects in implementing complex end-to-end Enterprise solutions on Microsoft Azure platform. Work with clients to understand their overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.

Manage and motivate teams with diverse skills and backgrounds. Consistently deliver quality client services by monitoring progress. Demonstrate in-depth technical capabilities and professional knowledge. Maintain long-term client relationships and networks. Cultivate business development opportunities.

Full time employment, Monday – Friday, 40 hours per week, 8:30 am – 5:30 pm.

MINIMUM REQUIREMENTS:
Must have a Bachelor’s degree in Management Information Systems (MIS), Computer Science, Information Technology, Statistics, Engineering, Mathematics, Data Science, Machine Learning or a related field and 5 years of progressive, post-baccalaureate advisory and/or consulting work experience. Alternatively, will accept a Master’s degree in Management Information Systems (MIS), Computer Science, Information Technology, Statistics, Engineering, Mathematics, Data Science, Machine Learning or a related field and 4 years of advisory and/or consulting work experience.

Must have 4 years of experience in data engineering and data architecture.

Must have 1 year of experience with analytics and big data technologies within Microsoft Azure, using tools such as Azure Data Factory, Azure Machine Learning, Azure Cognitive Services, Azure Databricks, or Azure Synapse Analytics.

Must have 2 years of experience in two or more of the following:
Data Ingestion and Storage using Azure Data Factory, Azure Databricks, Azure SQL, SQL Server, Azure Data Lake, Azure Synapse Analytics, and/or Cosmos DB
Technical experience using large data systems on T-SQL and/or Python
Big Data Analytics in Azure Synapse Analytics, Azure Analysis Services, and/or Snowflake
Data Governance, Data Catalog, and Master Data Management (MDM).

Must have 2 years of experience with ELT (extract, loading, transform) and data ingestion/cleansing.

Must have 2 years of experience counselling and mentoring junior level consultants by providing structured, on-the-job feedback.

Requires domestic travel up to 70% to serve client needs.

Employer will accept any suitable combination of education, training or experience.

Please apply on-line at ey.com/en_us/careers and click on ""Careers - Job Search”, then “Search Jobs"" (Job Number – 1452469).

What we offer
We offer a comprehensive compensation and benefits package where you’ll be rewarded based on your performance and recognized for the value you bring to the business. The base salary for this job is $152,152.00 per year. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Under our flexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances. You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, financial, and emotional well-being.
Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
EY | Building a better working world
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.
EY is an equal opportunity, affirmative action employer providing equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law.
EY is committed to providing reasonable accommodation to individuals with disabilities. If you are a qualified individual with a disability and either need assistance applying online or need to request an accommodation during the interview process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY’s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com.
This particular position at Ernst & Young in the United States requires the qualiﬁed candidate to be a ""United States worker"" as deﬁned by the U.S. Department of Labor regulations at 20 CFR 656.3. You can review this deﬁnition at https://www.gpo.gov/fdsys/pkg/CFR-2011-title20-vol3/pdf/CFR-2011-title20-vol3-sec656-3.pdf at the bottom of page 750. Please feel free to apply to other positions that do not require you to be a ""U.S. worker."""
1008917152424,Glassdoor,$71K,$108K,http://www.saic.com/,"Job ID: 2313967
Location: CHANTILLY, VA, US
Date Posted: 2023-10-09
Category: Information Technology
Subcategory: Network Engineer
Schedule: Full-time
Shift: Night Job
Travel: No
Minimum Clearance Required: TS/SCI with Poly
Clearance Level Must Be Able to Obtain: None
Potential for Remote Work: No

Description
SAIC is seeking an organized and highly motivated Infrastructure Engineer to join our team. You will join an experienced team of individuals who work in a fast paced Data Center-Like Environment. In this role you will also have the opportunity to have face to face Customer Interactions. In addition, you will work closely with System Administrators, Network Engineers, Software Engineers, and Integration Engineers.

The Engineer can expect to perform the following duties:
Design/Update/Implement Data Center Layouts
Install/De-install rack mountable computer equipment
Track equipment via tracking software and/or spreadsheets
Be responsible for the maintenance of a Server Room (including organization, cleaning, and access lists)
Perform basic System Administration duties such as configuring Power Management Systems
Maintain Metrics of Power and Space utilization in an effort to estimate future growth
Travel in the WMA and CONUS locations (<5-10% of the time)
Qualifications
Must have an active TS/SCI with Poly
3-5 Years in a data center environment
9+ years overall relevant experience
Physical networking knowledge/experience
Experience using Microsoft Office
Ability to lift up to 50 lbs. individually and up to 100 lbs. with a partner
Understand power configurations
Experience installing and laying out racks
Experience with/understanding of various cables, i.e. fiber, copper, single/multi-mode, etc

Covid Policy: SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site."
1008922783440,Glassdoor,,,http://www.jll.com/,"JLL supports the Whole You, personally and professionally.

Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you’ve got deep experience in commercial real estate, skilled trades, and technology, or you’re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally.
ESSENTIAL DUTIES & RESPONSIBILITIES include, but not limited to the following:
Operate systems in a safe and efficient manner in accordance with government regulations, company policies and standard operating procedures.
Perform the installation, maintenance, repair and operation of mechanical, electrical and power generation equipment and systems to support the critical environment.
Quickly learn building controls, electrical and UPS systems, utilizing on the job training, operations manuals and documentation.
Perform predictive, planned, preventative and routine maintenance as well as equipment rounds, and service requests as directed. Perform maintenance in accordance with the JLL Preventative Maintenance Program. Assist with the development and improvement of preventative maintenance programs, schedules, work instructions, SOP’s and operational procedures.
Inspect and repair pumps, fans, valves, and motors ensuring proper operation of the equipment and systems.
Perform visual and operational inspection of associated equipment and interpret specifications, blueprints and job standards to perform assigned duties.
Determine and/or assist with analyzing and resolving work problems and achieving work goals
Maintain time and production records and customer service requests.
Must be comfortable and flexible enough to work with a wide-ranging and changing scope of responsibilities while adhering to the constraints of procedures put in place to minimize the risk for human error.
Team player with the desire to foster teamwork to help create a positive working environment.
Monitor operation and maintain refrigeration, water cooling and air conditioning equipment, boilers, heating, ventilating and hot water equipment, pumps, valves, piping and filters, other mechanical and electrical equipment
Perform and/or complete all tenant service requests accurately and expediently.
Complies with all policies and procedures established for the building, including safe storage, usage, and disposal of hazardous materials while maintaining a clean and safe workplace
Periodically acts as the on-call engineer as requested by supervisor.
Actively participate in emergency response procedures, technical and safety training programs.
Perform all work using the proper safety equipment and in a safe manner.
Performs additional job duties as requested.
The M&E Technician will also assist with implementation and compliance with JLL’s Key Performance Indicators (KPI’s).
III. MINIMUM REQUIREMENTS
Must have 4+ years of hands-on experience in a data center/critical facility, including UPS Systems, emergency generators, switch-gear, and mechanical cooling systems.
High School diploma or GED equivalent is required. Training and certification from an accredited trade school or Union apprentice program in HVAC, electronics, electrical is preferred.
State and local licensures, where required.
Certification as a Universal Technician for CFC’s (or within 90 days of employment), if required by local jurisdiction.
Should be knowledgeable in the safe and proper use of the following tools: ladders, lifts, basic hand tools, voltmeter, manual drain auger, safety goggles, ear protection, and fire extinguisher.
Working knowledge of computer applications including Word and Excel, and business applications, such as CMMS and Change Management is preferred.
Physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. The employee frequently is required to stand; walk; reach with hands and arms; climb or balance; and stoop, kneel, crouch, or crawl. The employee must regularly lift and/or move up to 10 pounds, frequently lift and/or move up to 25 pounds, and occasionally lift and/or move up to 50 pounds.
The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. While performing the duties of this job, the employee is regularly exposed to risk of electrical shock, moving mechanical parts and heights up to 30ft. The employee is occasionally exposed to wet and/or humid conditions as well as very cold and uncomfortable heat while inside and out of the facility. The noise level in the work environment is at times moderately loud.
Demonstrated strong verbal/written communication skills.
Proven record of excellent internal and external customer service.
Estimated compensation for this position is:
93,600.00 – 97,760.00 USD
The pay range listed is a total compensation range including bonus, if applicable. The provided range is an estimate and not guaranteed. An employment offer is based on applicant’s education, experience, skills, abilities, geographic location, internal equity and alignment with market data.
Location:
On-site –Aurora, CO
If this job description resonates with you, we encourage you to apply, even if you don’t meet all the requirements. We’re interested in getting to know you and what you bring to the table!

Personalized benefits that support personal well-being and growth:
JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health. Some of these benefits may include:
401(k) plan with matching company contributions
Comprehensive Medical, Dental & Vision Care
Paid parental leave at 100% of salary
Paid Time Off and Company Holidays
Flexible and Remote Work Arrangements may be available
About JLL –
For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500® company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com.
JLL Privacy Notice
Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.
For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.
For additional details please see our career site pages for each country.
For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here.
This position may require you to be fully vaccinated against COVID-19. If required, you’ll be asked to provide proof that you’re fully vaccinated upon your start date. You’re considered fully vaccinated two weeks after you receive the second dose of a two-dose vaccine series (e.g., Pfizer or Moderna) or two weeks after a single-dose vaccine (e.g., Johnson & Johnson/Janssen). Failure to provide proof of vaccination may result in termination.
Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.
Pursuant to the Arizona Civil Rights Act, criminal convictions are not an absolute bar to employment.
Pursuant to Illinois Law, applicants are not obligated to disclose sealed or expunged records of conviction or arrest.
Pursuant to Columbia, SC ordinance, this position is subject to a background check for any convictions directly related to its duties and responsibilities. Only job-related convictions will be considered and will not automatically disqualify the candidate.
California Residents only
If you are a California resident as defined in the California Consumer Privacy Act (CCPA) please view our Supplemental Privacy Statement which describes your rights and disclosures about your personal information. If you are viewing this on a mobile device you may want to view the CCPA version on a larger device.
Pursuant to the Los Angeles Fair Chance Initiative for Hiring Ordinance, JLL will consider for employment all qualified Applicants, including those with Criminal Histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records."
1008923430562,Glassdoor,,,http://www.uptalent.com/,"This is an exceptional opportunity to work with a nationwide Oil & Gas Services Company for a big Project in Shreveport, LA
Pay Rate: starting $100k +
Hours: 8am - 5pm
Job Summary:
The role of Mechanical / HVAC Engineer is to support the Engineering Lead and Product Engineering Manager.
They will be accountable for the mechanical and piping scope and systems in large scale data centers across the design, construction, assembly, testing, installation, and commissioning phases.
The Mechanical / HVAC Engineer will be responsible for checking and approving drawings / designs; interface communication, and ensuring the accuracy, reliability, efficiency, and safety of the overall mechanical scope of work for Hyperscale Data Center Modules meets customer’s requirements and Industrial Standards.
The Mechanical / HVAC Engineer will play a critical role with supporting the plant during the manufacturing stage.
They will also be assisting various stakeholders in troubleshooting site installation and commissioning problems.
Roles and Responsibilities:
Checking and approving drawings, information and documentation which meets Industrial standards and code to enable the manufacturing group and other departments to produce Data Center Infrastructure Modules.
Review and monitor Engineering work, as required, to assure accuracy and conformance with Client and / or Company Specifications, governing codes, good engineering practices, good safety practices, project procedures, and job requirements.
Attend and initiate Design and Development Planning and Review session to meet customer’s and industry’s need.
Prepare TRs (Technical Requisitions) for mechanical HVAC systems and various related components.
Review vendor quotations and provide feedback to procurement team.
Prepare and complete various mechanical engineering deliverable drawings, documents, and calculations such as HVAC Flow Diagrams, Equipment and Plumping Layouts, Determining the Critical Load and Heat Load, specifying data sheets for HVAC main equipment or ancillary equipment, details of fire suppression system, etc.
Perform CFD (Computational Fluid Dynamic) Modeling for Airflow
Prepare bulk MTOs (Material Take Offs) and detailed BOMs (Bill of Materials).
Ability and willingness to think outside of the box to find creative and innovative solutions to reduce costs while managing impact to quality, cost, or schedule.
Keeps informed of new developments and requirements affecting the organization for the purpose of recommending changes in programs and applications.
Interprets, organizes, executes assignments in a self-driven and self-sufficient manner.
Makes decisions independently on technical problems and methods and represents the organization in meetings to resolve important questions.
Applies advanced or state-of-the-art knowledge and experience to resolve crucial issues and/or unique conditions. The knowledge and expertise required for this level of work usually results from progressive experience.
Supervision received is essentially administrative, with assignments given in terms of broad general objectives and limits.
Stays up to date with advancements in electrical engineering and data center technologies and recommend new technologies to improve the reliability and efficiency of our data center product line.
Advise and assist project and discipline engineers with the interpretation and clarification of applicable industry Codes and Client Specification requirements.
Create or check “Design Basis” document specific to the project. The document is based on the applicable Codes, client specifications, company scope of supply, and approved exception list.
Represent company with customers during review meetings. Act as the primary point of contact for clients, responding to their inquiries and concerns in a timely and professional manner.
- Create or check ""Design Basis"" document specific to the project
Education:
Bachelor of Science Degree in Mechanical Engineering from a recognized university.
Other Degrees will be considered (Industrial Engineering, Mechatronics, etc.) but will require increase relevant data center expertise.
Professional Engineering License (Strongly Preferred).
Experience:
A minimum of 10 years of experience in mechanical HVAC design and engineering, with a focus on data center infrastructure.
Ability to produce drawings/sketches to illustrate design/ideas.
General knowledge and direct experience with the construction, operation, and maintenance of data centers or mechanical HVAC systems and components.
Strong Knowledge in HVAC system design and construction.
Knowledge of HVAC grills, plenums, fire, smoke dampers, electric heaters, configurations, etc.
Knowledge of industry standards, codes, and regulations, including but not limited to:
o AHRI – Air-Conditioning, Heating, & Refrigeration Instituteo AMCA – Air Movement and Control Association Internationalo ANSI – American National Standards Instituteo ASHRAE – American Society of Heating, Refrigerating, and Air-Condition Engineerso ASME – American Society of Mechanical Engineers (specifically B31.3)o ASTM – American Society of Testing and Materialso CIBSE – Chartered Institution of Building Services Engineerso IBC – International Building Codeo OSHA – Occupational Safety and Health Administrationo NFPA – National Fire Protection Associationo SMACNA – Sheet Metal and Air Conditioning Contractors National Associationo TEMA – Tubular Exchanger Manufacturers Association
Experience working with computer-aided design (CAD) and building information modeling (BIM) software.
Fast track design/build projects and or multiple significant upgrade projects
Detailed understanding of chillers, cooling towers, direct and indirect evaporative cooling, mechanical control systems, fan systems, duct work, acoustics, pumps, vessels, valves, CAHU (Critical Air Handling Units), cooling towers, chillers, and other critical mechanical equipment / systems found within data centers.
Basic understanding of electrical equipment and system design within data center driving or affecting mechanical scope.
Direct experience in negotiating with regulatory agencies regarding departures from code and ultimately achieving design approval and permitting.Computer Skills:
Mastery knowledge and proficiency in:
Microsoft Office 365 Suite (Outlook, Word, Excel, PowerPoint, Teams, SharePoint)
PDF Editor (Adobe, Foxit, or other equivalent)
Trane TRACE 700 and Carrier HAP (or other Heating and Cooling Load Calculation Design Software)
Operational knowledge in:
SAP (ERP Tool w/ Engineering Modules and Transactions)
Solid Works
Autodesk Revit
Autodesk BIM 360
Autodesk AutoCAD
Navisworks Manager / Freedom
General:
Excellent problem-solving and analytical skills, with the ability to make sound decisions and think creatively.
Ability to work independently and manage multiple projects simultaneously.
Performs well under pressure in high stress environments.
Extremely comfortable with task switching as priorities change.
Ability to build and maintain strong relationships with clients.
Ability to think creatively and identify opportunities to enhance the client experience.
Extreme work ethic and maintains high level of quality of work and due diligence.
Communication Skills:
Express complex ideas effectively in both individual and group situations.
Organize and express ideas clearly in written documents.
Strong communication and collaboration skills, with the ability to work effectively with a cross-functional team.
Note that if you get hired you must undergo a background check, a driving records check and a drug screening
Job Type: Full-time
Salary: From $100,000.00 per year
Schedule:
Day shift
Work Location: In person"
1008921481844,Glassdoor,,,http://www.stanford.edu/,"Stanford University is seeking a Software Developer 1 to join the Kundaje lab in the Department of Genetics to lead and assist with the development of data processing pipelines and integrative analysis methods for large-scale multi-omic data (transcriptome, epigenome, lipidome, metabolome and proteome). Specifically, the candidate will be a key member of the Data Analysis and Coordination Center of the newly announced consortium for multi-omics in health and disease (MOHD) https://www.nih.gov/news-events/news-releases/nih-awards-503-million-multi-omics-research-human-health-disease.
Duties include:
Collaborate and participate in large consortia to assess needs and requirements
Develop and maintain data processing pipelines
Processing and quality control of consortium data with pipelines
Troubleshoot and solve technical problems.
Develop tutorials and demos for software products
Design and develop integrative analysis methods for multi-omic data
Maintain and update existing machine learning frameworks for multi-omic data integration
- Other duties may also be assigned.
DESIRED QUALIFICATIONS:
Strong experience with bioinformatics tools for analysis of one or more of the following multi-omic data modalities (RNA-seq, ATAC-seq, lipidomes, metabolome, proteome)
Strong data science and software engineering experience in Python, R, Unix scripting
Strong experience developing and deploying bioinformatics pipelines for biology in cloud computing environments with tools such as WDL/Nextflow
Experience leading collaborations between clinicians, wet lab biologists, and computational scientists.
Experience building community around computational biology, such as hosting conference, meetups, or other events related to machine learning and cloud computing for biological applications.
Product management experience defining requirements and managing project timelines from early development to broad deployment.
Project management experience leading small teams to deliver products in a timely fashion.
Ability to define and solve logical problems for technical applications.
Solid analytical skills.
Excellent written and oral English communication and interpersonal skills.
Ability to understand scientific literature, experimental procedures and their limitations, and current needs of the research community.


EDUCATION & EXPERIENCE (REQUIRED):
Bachelor's degree and three years of relevant experience or a combination of education and relevant experience.
KNOWLEDGE, SKILLS AND ABILITIES (REQUIRED):
Current knowledge of latest software and design standards.
Ability to define and solve logical problems for technical applications.
Knowledge of and ability to select, adapt, and effectively use a variety of programming methods.
Ability to recognize and recommend needed changes in user and/or operations procedures.
Basic knowledge of software engineering principles.
Strong knowledge of at least one programming language
CERTIFICATIONS & LICENSES:
None.

PHYSICAL REQUIREMENTS*:
Constantly perform desk-based computer tasks.
Frequently sit, grasp lightly/fine manipulation.
Occasionally stand/walk, writing by hand.
Rarely use a telephone, lift/carry/push/pull objects that weigh up to 10 pounds
- Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.

WORKING CONDITIONS:
May work extended hours based on project needs
The expected pay range for this position is $80,000 to $135,000 per annum. Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.

At Stanford University, base pay represents only one aspect of the comprehensive rewards package. The Cardinal at Work website (https://cardinalatwork.stanford.edu/benefits-rewards) provides detailed information on Stanford’s extensive range of benefits and rewards offered to employees. Specifics about the rewards package for this position may be discussed during the hiring process.
WORK STANDARDS (from JDL):
Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University's Administrative Guide, http://adminguide.stanford.edu."
1008920877701,Glassdoor,,,https://www.randstad.com/,"summary
$130,000 - $150,000 per year
permanent
bachelor degree
category
computer and mathematical occupations
reference
1029934

job summary:
The client is building out a best-in-class data science platform as being on the forefront of data management and analytics is core to our investment platform. Based out of our London office, this position will play an integral role as the team implements new data management platforms, creates new data ingestion pipelines, and sources new data sets. The Software Developer will assist with all aspects of data - from data architecture design to on-going data management and will have significant exposure to our Risk and Commercial investing teams globally.

Responsibilities:
Execute data architecture and data management projects for both new and existing data sources.
Development on our existing market data platforms utilizing Python or Java with Python strongly preferred.
Help transition existing data sets and databases to a new technology stack (Oracle 11 to Snowflake).
Manage end to end data ingestion process and publishing to investing teams.
Own the process of mapping, standardizing, and normalizing fundamental analytics data.
Assess data loads for tactical errors and build out appropriate workflows, as well as create data quality analysis that identifies larger issues with our data platform.
Properly prioritize and resolve data issues based on business usage to determine which market data sets are critical to the business.
Assist with managing strategic initiatives around big data projects for the commercial (trading) business.
Liaise with commercial in order to gain understanding of current data flow, data architecture, investment process as well as gather functional requirements.
Qualifications:


Bachelor's degree in Computer Science, Mathematics, Physics, Engineering or related field of study.
Minimum of 5 years' experience in DevOps production environment, ideally in financial services or energy commodities.
Proficient in Python programming with a deep understanding of its libraries like Beautiful Soap, Selenium, Urllib3, Pandas, NumPy etc, data structures, and algorithms.
Proficiency in writing efficient, reusable, and modular code.
Proficiency in Java programming is a plus.
Experience with front-end technologies such as HTML, CSS, JavaScript, and modern front-end frameworks (e.g., React, Angular) is a plus.
In-depth knowledge of Snowflake columnar database and ability to design and optimize complex SQL queries.
Familiarity with Oracle and PostgreSQL.
Proficient in using version control systems like Git to manage code repositories effectively.
strong analytical and problem-solving skills to tackle complex technical challenges.
Proficiency in debugging and performance optimization techniques.
Experience leading development teams and mentoring junior developers.
Ability to provide technical guidance and code reviews to ensure high-quality deliverables.
Thorough understanding of the software development lifecycle, from requirements analysis to testing and deployment.
Enthusiasm for staying up-to-date with the latest developments in Python and related technologies.
Excellent verbal and written communication skills to articulate technical concepts and collaborate effectively with team members and stakeholders.

location: STAMFORD, Connecticut
job type: Permanent
salary: $130,000 - 150,000 per year
work hours: 8am to 4pm
education: Bachelors

responsibilities:
CCI is building out a best-in-class data science platform as being on the forefront of data management and analytics is core to our investment platform. Based out of our London office, this position will play an integral role as the team implements new data management platforms, creates new data ingestion pipelines, and sources new data sets. The Software Developer will assist with all aspects of data - from data architecture design to on-going data management and will have significant exposure to our Risk and Commercial investing teams globally.

Responsibilities:
Execute data architecture and data management projects for both new and existing data sources.
Development on our existing market data platforms utilizing Python or Java with Python strongly preferred.
Help transition existing data sets and databases to a new technology stack (Oracle 11 to Snowflake).
Manage end to end data ingestion process and publishing to investing teams.
Own the process of mapping, standardizing, and normalizing fundamental analytics data.
Assess data loads for tactical errors and build out appropriate workflows, as well as create data quality analysis that identifies larger issues with our data platform.
Properly prioritize and resolve data issues based on business usage to determine which market data sets are critical to the business.
Assist with managing strategic initiatives around big data projects for the commercial (trading) business.
Liaise with commercial in order to gain understanding of current data flow, data architecture, investment process as well as gather functional requirements.
Qualifications:


Bachelor's degree in Computer Science, Mathematics, Physics, Engineering or related field of study.
Minimum of 5 years' experience in DevOps production environment, ideally in financial services or energy commodities.
Proficient in Python programming with a deep understanding of its libraries like Beautiful Soap, Selenium, Urllib3, Pandas, NumPy etc, data structures, and algorithms.
Proficiency in writing efficient, reusable, and modular code.
Proficiency in Java programming is a plus.
Experience with front-end technologies such as HTML, CSS, JavaScript, and modern front-end frameworks (e.g., React, Angular) is a plus.
In-depth knowledge of Snowflake columnar database and ability to design and optimize complex SQL queries.
Familiarity with Oracle and PostgreSQL.
Proficient in using version control systems like Git to manage code repositories effectively.
strong analytical and problem-solving skills to tackle complex technical challenges.
Proficiency in debugging and performance optimization techniques.
Experience leading development teams and mentoring junior developers.
Ability to provide technical guidance and code reviews to ensure high-quality deliverables.
Thorough understanding of the software development lifecycle, from requirements analysis to testing and deployment.
Enthusiasm for staying up-to-date with the latest developments in Python and related technologies.
Excellent verbal and written communication skills to articulate technical concepts and collaborate effectively with team members and stakeholders.
Employee Programs & Benefits:

CCI offers competitive benefits and programs to support our employees, their families and local communities. These include:
Competitive comprehensive medical, dental, retirement and life insurance benefits


Employee assistance & wellness programs


Parental and family leave policies


CCI in the Community: Each office has a Charity Committee and as a part of this program employees are allocated 2 days annually to volunteer at the selected charities.


Charitable contribution match program


Tuition assistance & reimbursement


Quarterly Innovation & Collaboration Awards


Employee discount program, including access to fitness facilities


Competitive paid time off


Continued learning opportunities

qualifications:
Experience level: Experienced
Minimum 5 years of experience
Education: Bachelors

skills:
Data Science

Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.

At Randstad Digital, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.

Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility)."
1008924013123,Glassdoor,$87K,$121K,http://www.amazon.jobs/,"Bachelor’s Degree in Mechanical Engineering or equivalent experience.
6+ cumulative years of experience with industrial or commercial engineering in Mission Critical facilities including but not limited to: data centers, power generation, oil / gas facilities. (Experienced Engineer)
As an Amazon Field Engineer, you will provide full life-cycle support to AWS Data Centers from design inception through site improvement and maintenance. You will be the ‘go to’ engineering resource for your region when technical advice is needed, and will use your subject matter expertise and engage with diverse teams to:
Troubleshoot, conduct Root Cause Analysis (RCA) and create Corrective Action (CA) documentation for site/equipment failures.
Directly support operational issues with ad-hoc training, complex operating procedure reviews, including critical equipment, and event support.
Own the conceptual design for existing data center upgrades and design-solutions, which add capacity, improve availability, and increase efficiency.
Interface with internal data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.
Work on concurrent projects, sometimes in multiple geographical regions.
Initiate and lead engineering audits including on-site visits within Amazon’s owned or colo data centers. Produce reports outlining risks with recommended mitigations and remediations
Act as resident engineer during new construction projects. Support construction, commissioning, and turnover.
A day in the life
Amazon's vision is to be the world's most customer-centric company, and this role is key to that vision. As a Field Engineer, you will be leading projects to fit out our data centers to meet ever-evolving customer needs as we continue expanding our fleet to hyper-scale. As an ideal candidate you:
Possess Strong Engineering Judgement and are able to provide recommendations despite uncertainty
Are detail and data oriented
Have experience managing engineering projects and consultants.
Build trust and relationships with different stakeholders (e.g., Operations, Commissioning, Construction and Design)
Are adaptable and inclined to get into the field to see things up close
Each day you will interact with different teams responsible for all aspects of the data centers. You will prioritize your activities to support data center capacity availability and safety focusing on the actions that are most impactful. You will have the opportunity to work on projects locally and globally.

We have an immediate opening for a Field Engineer in northern Virginia. If you meet these qualifications, exude passion, and enjoy the challenge of innovative projects at hyper-scale, this job is for you!

About the team
Why AWS?
About AWS
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud
platform. We pioneered cloud computing and never stopped innovating — that’s why customers
from the most successful startups to Global 500 companies trust our robust suite of products and
services to power their businesses.

Inclusive Team Culture
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster
a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning
experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender
diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth
We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.
That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing
resources here to help you develop into a better-rounded professional.

We are open to hiring candidates to work out of one of the following locations:

Herndon, VA, USA

Organized and have the ability to set priorities and meet deadlines and budget
Possess leadership and problem-solving skills
Experience using a variety of web based and other software tools for calculation and data processing.
Direct experience with the design, construction, operation, or maintenance of mission critical facilities, especially data centers.
Experience as resident engineer or hands-on (in the field) design consultant.
Knowledge of building codes and regulations for your region.
Experience reading, interpreting, and creating construction drawings, specifications, and submittal documents.
Ability to carry design concepts through exploration, development, and into deployment/mass production
Possess excellent communication and writing skills, attention to detail, maintain high quality standards
Basic understanding of both mechanical, instrumentation, and electrical equipment/design related to data centers (Including but not limited to: uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc...)
EPMS/SCADA/BMS Controls system experience (software and/or hardware)
Registered Professional Engineer
Advanced degree in engineering, business, or related field.
Have fluent knowledge of continuous operating redundant electrical systems, cooling systems, air flow containment systems and building management systems. (Including but not limited to: uninterruptable power sources, AC/DC conversion, P&ID loops, diesel generators systems and complex arrangements, direct evaporative cooling systems, etc...)
Ability to develop solutions and execute plans on complex projects
Previous ownership of fast track design/build projects and or multiple significant upgrade projects
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
1008920056176,Glassdoor,,,https://www.boeing.com/,"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
At Boeing, we are all innovators on a mission to connect, protect, explore and inspire. Come be a part of a diverse multi-disciplined team of engineers, operating in an agile environment, using the latest tools and methodologies. Find your future with us. #TheFutureIsBuiltHere.
Boeing Global Services is currently seeking an Experienced Product Data Management Engineer to become part of the Configuration Management team in Berkeley, Mo.
Position Responsibilities:
Define, plan, coordinate and conduct a comprehensive set of product and subsystem level reviews, change boards, and audits to manage change incorporation.
Develop the implementation of Configuration and Data Management Customer Deliverables.
Support the definition and allocation of Configuration Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Track and report data to monitor adherence to regulatory, configuration and contractual requirements.
Support development of media, Software product end items, and other baseline deliverables to the Customer.
Act as liaison between Software Configuration Control Board and other functions as needed.
Administration of SCM tools such as ClearCase/ClearQuest and CM Pro.
This position requires the ability to obtain a US Security Clearance for which the US Government requires US Citizenship. An interim and/or final U.S. Secret Clearance Post-Start is required.
Hybrid:
This Hybrid position allows some telecommuting. The selected candidate will be required to perform some work onsite at one of the listed location options (Berkeley, MO). This is at the hiring team’s discretion and could potentially change in the future.
Basic Qualifications (Required Skills/Experience):
Bachelor, from an accredited course of study in engineering, computer science, mathematics, physics or chemistry.
1+ years of experience with Product Lifecycle Management (PLM) and Configuration Management systems, Change Management, and PLM Processes and Tools.
1+ years of experience coordinating engineering tasks across external and internal stakeholders.
Preferred Qualifications (Desired Skills/Experience):
Active U.S. Security Clearance.
5+ years of experience with Engineering Document/Drawing Creation and/or Release.
3+ years of experience using CATIA V5 and ENOVIA.
3+ years of experience with CM Pro.
3+ years of experience administering software configuration management tools such as ClearCase, ClearQuest, Version1, Confluence.
Typical Education & Experience:
Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) and typically 5 or more years' related work experience or an equivalent combination of technical education and experience (e.g. PhD, Master+3 years' related work experience). In the USA, ABET accreditation is the preferred, although not required, accreditation standard.
Relocation:
Relocation assistance is not a negotiable benefit for this position. Candidates must live in the immediate area or relocate at their own expense.
Drug Free Workplace:
Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.
Shift Work Statement:
This position is for 1st shift.
General:
All information provided will be checked and may be verified.
Please apply ASAP for this role as recruitment may commence before the end date.
At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.
The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.
The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.
Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations.
Summary pay range: $90,100 – $121,900.

Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Equal Opportunity Employer:
Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law."
1008918988255,Glassdoor,,,,"Job ID: 651116BR
Date posted: Sep. 06, 2023

Description:Platform Technical Lead - Data Engineer - Level 5

We are Lockheed Martin

The selected candidate can expect to lead the development leveraging current AI paradigms including computer vision, natural language processing, deep learning, and reinforcement learning, applying these techniques to solve complex problems and field innovative solutions. This candidate will define the architecture of autonomous components of a Lockheed Martin product from concept to specifications, recommending and making technical decisions on techniques, solutions, and how solutions will be integrated and deployed with other systems to meet customer requirements. This candidate will provide architectural guidance on autonomous systems on or across project teams and demonstrate the ability to lead multi-functional teams and lead multiple teams to communicate and coordinate work as one team with common goals. The candidate will also be expected to assume technical lead responsibilities and mentor junior data scientists and data engineers. Must exhibit self-motivation, a strong work ethic, time management, interpersonal skills, strong team collaboration, and the ability to work in a fast-paced team environment.

The selected individual will support the Enterprise Integration Platform Team as the Technical Manager for the VISION platform. Support will be provided in the following areas:
Drive the execution and implementation of data science initiatives
Interfaces with product owners to translate customer requirements into high level technical specifications
Mentor and guide development with early career data scientists and data engineers
Develop technical roadmap based on stakeholders and customer requirements
Oversee and manage the data science, data engineering, and front end deliverables
Understanding the tool stack and architecture of products and platforms to highlight gaps and opportunities

What's In It For You
Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually. Here are some of the benefits you can enjoy:
Medical
Dental
401k
Paid time off
Work/life balance
Career development
Mentorship opportunities
Rewards & recognition

Learn more about Lockheed Martin's comprehensive benefits package here.

Fort Worth, TX
This position is in Fort Worth, TX Discover Fort Worth.
Basic Qualifications:
Bachelor's Degree in Engineering, Computer Science, other related discipline considered.
Experience using AI/ML frameworks (Pytorch, Tensorflow, etc.)
Experience with Python libraries (NumPy, OpenCV, Scikit, Pandas, etc.)
Experience with DevOps tools: Docker, Git [GitLab, GitHub], Continuous Integration [CI], Continuous Deployment [CD]
Experience working with Agile methodologies
Experience interfacing with relational databases (SQL, Postgre , etc.)
Desired Skills:
Ability to coordinate efforts across multiple technical teams
Experience with high-performance computing
Familiarity with cloud platform management and provisioning including AWS GovCloud and Microsoft Azure
Familiarity with distributive computing
Familiarity graph databases (Neo4J)
Familiarity with Elastic Search
Strong communicator and active participant in team communication channels such as Slack/Email
Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.
Clearance Level: Secret
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: 4x10 hour day, 3 days off per week
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.

With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.

If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications.
Experience Level: Experienced Professional
Business Unit: AERONAUTICS COMPANY
Relocation Available: Possible
Career Area: Data Science
Type: Full-Time
Shift: First"
1008922497493,Glassdoor,$70K,$99K,http://www.nordson.com/,"Collaboration drives Nordson’s success as a market leader in Industrial Precision Solutions and Advanced Technology. Our employees thrive in an environment where we help each other reach our personal best and enable our company to continuously improve and grow, and our customers to succeed. You will find Nordson employees sharing our success by giving back in the communities around the world where we live and work.
At Nordson Electronics Solutions we have big goals, an innovative spirit, and a vision to become the preferred partner to electronics manufacturers worldwide. If you believe in big goals, consider joining our team to help solve reliability challenges for the world's largest semiconductor, printed circuit board, and precision assembly manufacturers. Our fluid dispensing and surface treatment solutions help make reliable electronics an everyday reality – from mobile devices to the Internet of Things to self-driving vehicles, life-saving medical equipment, and beyond.
Job Summary
CyberOptics-Nordson is a global leader in high-precision sensor technology in the areas of 3D machine vision and semiconductor process measurement. Our sensors are deployed in electronics and semiconductor factories across the planet. The device you are using to read this notice most likely contains integrated circuits inspected by our sensors during their manufacture. Our products are a tight integration of optics, electronics, embedded and application software, and algorithms.
We are looking for a Senior Electrical Engineer who will play an integral role in our R&D team designing the next generation of high precision electronics and semiconductor inspection sensors. You will be involved in this process from product conception to production. This position requires design conceptualization to meet product requirements, project planning and tracking, design implementation, test and verification to specifications, transition to production, continuation, and documentation.
Essential Job Duties and Responsibilities
Design of electronic circuits for products that sense physical phenomenon such as capacitance, temperature, humidity, light, vibration, inclination, gases, particles, resistivity, and more.
Experience in the amplification, signal conditioning, filtering, and digitization of low-level signals for measurement and logging.
Design wireless low powered battery-operated support circuitry with embedded processors, FPGAs, ADCs and DACs, Bluetooth or WIFI communication, and power management.
Ability to solve challenging problems with creative designs and processes.
Supervision of PCB layout that packages electronics into challenging spaces and environments (temperature and vacuum) that often require high performance materials.
Interpret internal and customer requirements and translate those into product specifications and design concepts.
Risk reduction of design concepts through simulation, prototype testing, and feasibility studies.
Project planning requiring the estimation of tasks, resources, schedules, NRE, production costs, and manufacturing support.
Manage suppliers that fabricate prototype and production electrical designs.
Design verification testing of designs to product specifications.
Ability to design products to meet CE and other international compliance requirements.
Education and Experience Requirements
MS Electrical Engineering degree preferred, or BS considered with additional experience.
5+ Years work experience desired.
Experienced in the design of data acquisition and analog circuitry that measures physical properties for the purpose of datalogging or real time reporting via a Bluetooth or WIFI radio.
Low power embedded processor or FPGA hardware design experience.
Digital filtering and signal processing in DSP or FPGA hardware.
Verilog or VHDL experience.
Experience with high-speed digital designs and communication protocols.
Analog and Digital Simulation skills with tools like Spice or MATLAB.
Lithium-Ion batteries, Qi wireless charging, power management, and fuel gauge estimation.
High efficiency low-noise power supply design.
Photodiode, Laser Diode, CMOS imager, and LED Illumination design experience considered a plus.
Skills and Abilities
Ability to execute new electronic designs from concept to production.
Self-management, planning, communicating, and working effectively in a multi-functional team.
Proficient with high-end schematic capture tools, design constraints, documentation source control, component database management, and approved vendor list (AVL) management.
Verify high speed signal integrity compliance by either test methods or third party PCB simulations.
Incorporation of manufacturability and testability into designs.
Skilled at troubleshooting with high end scopes, DVMs, Logic and Protocol Analyzers, and other tools.
Working with the manufacturing department to help development calibration and alignment processes and fixtures.
Keep up to date on the latest electronics technology and its applicability to the problems we are trying to solve.
Manage outside contractors, suppliers and supply chain issues affecting the production of products.
Address continuation issues on released products.
Familiarity with ISO development processes.
Mentoring of Junior Engineers and Technicians.
Working Conditions and Physical Demands
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed above are representative of the knowledge, skill, and/or ability required. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.
Travel Required
None
#LI-CL1
Nordson Corporation provides equal employment opportunity to all applicants and employees. No person is to be discriminated against in any aspect of the employment relationship due to race, religion, color, sex, age, national origin, ancestry, disability, sexual orientation, gender identity, genetic information, citizenship status, marital status, pregnancy, veteran status or any other status protected by applicable federal, state, or local law. All employment offers are contingent upon successful completion of our pre-employment drug screening and background/criminal check, consistent with applicable laws.Third party recruiters and agencies should not contact employees of Nordson or its subsidiaries directly. Any resumes sent to a hiring manager or submitted to Nordson employees are considered unsolicited and property of Nordson. Nordson will not pay a placement fee unless the agency or recruiter has a signed contract with Nordson’s Human Resources department in advance of submitting a candidate for consideration. Verbal and written approvals will not be considered a valid contract for service."
1008922346647,Glassdoor,$73K,$107K,https://www.jpmorganchase.com/,"JOB DESCRIPTION

Launch your career in Technology Operations and put your creative problem solving into action, delivering solutions that shape the future of global business. You'll work directly with clients to build strong customer relationships and problem-solve technical issues to make businesses more productive. Alongside a motivated team of fellow analysts, supervisors and stakeholders, you'll develop innovative solutions to troubleshoot and resolve issues while accurately diagnosing problems and providing effective user support. Finally, your strong technology background will ensure that the security and standards of our commitment to excellence are met. And because professional development is a key component of our culture, you'll receive coaching, mentoring — and a host of other development opportunities — alongside your invaluable on-the-job experience.
This role requires a wide variety of strengths and capabilities, including:
Ability to identify problems and clearly communicate strategic solutions to clients
Desire to develop a working knowledge of change management, corporate IT audit processes, IT risk management, technical problem resolution, operations systems, and data sources knowledge
Strong initiative and desire to learn
Ability to effectively collaborate with team members and clients to achieve common goals
Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis
Working knowledge of Microsoft Office products
Strong analytical and problem resolution skills
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our Global Technology Infrastructure group is a team of innovators who love technology as much as you do. Together, you’ll use a disciplined, innovative and a business focused approach to develop a wide variety of high-quality products and solutions. You’ll work in a stable, resilient and secure operating environment where you—and the products you deliver—will thrive."
1008920877967,Glassdoor,,,,
1008918465323,Glassdoor,$68K,$96K,http://www.amazon.jobs/,"A four-year degree in a technical field such as engineering, construction management, or a trade school OR 4+ years of related construction experience in lieu of a degree.
+2 years’ experience working in the construction industry or an engineering organization.
Experience updating and managing construction data including milestone dates, requests for information (RFI), design changes, and change orders.
Experience with developing workflows and tracking systems including change management, vendor equipment delivery, and document controls across 3 or more organizations/teams.
Experience reading and interpreting construction drawings and specifications.
As a Data Center Project Engineer, you will be a part of a creative, diverse team tasked with solving fascinating problems constructing Amazon Data Centers. Our data centers are industry examples of energy efficient, cost-effective designs. You will work alongside partner teams such as Operations, Networking, Controls, Security, and Commissioning to build Data Centers that directly support our Customers.

As our Data Center Project Engineer, you will support the teams that build some of the most interesting electrical and mechanical systems in the world. You will be on the construction site, daily interacting with the construction managers and stakeholders and be directly responsible for supporting the fast, high-quality delivery of our data center construction. The Data Center Project Engineer will be part of the onsite Construction Management team and will own the communication coordination with our vendors, information workflow, and coordination of document management including requests for information (RFI), change orders, report, and schedule updates.

At Amazon, we are all Owners and leverage unique opportunities presented to us by owning everything from the design review to construction bidding to construction execution and final hand-off to our customers. We are a diverse, upbeat, creative, team of engineers and managers working on a daily basis to develop innovative data centers for our Customers.

The Data Center Project Engineer will be responsible for:
Establishing communication and coordination across a data center region’s general contractors, stakeholders, and internal teams. Example includes sending out region wide changes to construction trailer setup, COVID-19 testing procedures, or location to access documents.
Develop and maintain a tracking system for design changes, RFI’s (requests for information), and change orders and dashboard and track this information for regional leadership review. Include tracking status of priority and due dates.
Requesting and reviewing MOPs (Method of Procedure) for proper detail, necessity, and risk.
Onboarding new vendors for badging and orientation.
Updating project management software with milestone dates, correspondence, and documents.
Monitor delivery of owner furnished material to site.
Compiling and storing construction data from vendors.
Managing checklist including various checklists including substantial completion checks, safety, and quality.
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

We are open to hiring candidates to work out of one of the following locations:

Herndon, VA, USA

Experience working with IT tools such as MS Office Suite including Project, Excel, and Word.
Experience with project management software tools such as Procore and document control.
Experience with AutoCAD or similar computer aided design software.
Experience in a mission critical data center.
Experience with mechanical systems including air handlers and building management systems.
Experience with electrical systems including diesel generators, uninteruptible power systems, switchboards, transformers, and power distribution units. Experience with project management principles and best practices.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
1008921293531,Glassdoor,$63K,$91K,https://www.sentinel.com/,"Responsibilities:
Sentinel is looking for a Data Center Systems Engineer with 5+ years of working experience. The Systems Engineer will be responsible for setting up Windows Remote Desktop servers, Active Directory and Group Policy management, Systems Center configuration, and Standard Server Management. The ideal candidate will have the ability to work both individually and collaboratively. This is a full time opportunity reporting to our Downers Grove, IL Corporate Headquarters, with the ability to work remote with occasional onsite support in Downers Grove, IL.
Qualifications:
5+ years of experience in a similar role
Hands on experience working with Windows Server 2008/2012/2016/2019, Active Directory, Group Policy, DHCP/DNS
Experience with AWS, VMware, EMC/Avamar, and Rubrik preferred
Good communication skills, written and verbal
The candidate must have a car, as this position requires travel between location and the transportation of equipment
A valid driver’s license and proof of vehicle insurance will be required
Legally authorized to work in the US without sponsorship
Must demonstrate a “can-do” attitude

We focus on candidates that display our “ACE” factor – Attitude, Compassion, and Enthusiasm to deliver quality solutions with exceptional customer service.

What you get:
We offer an energetic work environment with many corporate culture amenities, competitive salary, and rich benefit plan including: Medical, Dental, Vision, 401K, 529, Life Insurance, Income Protection Short and Long-Term Disability, Medical and Child/Elder Care, Flexible Spending Account Plans, Employee Assistance Program, Two weeks vacation, additional paid time-off for Personal and Sick, certification and hands-on training, and discounts for local event entertainment and health clubs.
Overview:
MOTIVATED…..make IT happen!
Sentinel Technologies, Inc. has been rated a top workplace every year since 2012!

About Us:
Sentinel delivers solutions that can efficiently address a range of IT needs – from security, to communications, to systems & networks, to software applications, to cloud and managed services; all of which include our staffing solutions for our clients. Since 1982, Sentinel has grown from providing technology maintenance services to our current standing as one of the leading IT services and solutions provider in the US. We have aligned with many of today’s global technology leaders including Cisco, Dell, VMware and Microsoft. Sentinel services customers both nationally and internationally with primary support operating centers in Downers Grove (HQ), Chicago, and Springfield, IL; Phoenix, AZ.; Detroit, Lansing, and Grand Rapids, MI; Milwaukee, WI; Denver, CO; and Fort Lauderdale, FL.

If you are MOTIVATED… you can make IT happen at Sentinel. Our commitment to our employees is to create a work environment that encourages creativity, an entrepreneurial spirit, fosters growth through certification and hands-on training, and values a team-oriented culture with rewards based on impact!

If you share our passion about what technology can do and want to be part of a top workplace environment – we’d like to have you join our team. Learn more at www.sentinel.com/careers.

As part of Sentinel's employment process, candidates will be required to complete a background check. Only those who meet the minimum requirements will be contacted. No phone calls please.

Sentinel is proud to be an equal opportunity/affirmative action employer committed to a diverse and inclusive work environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, marital status, genetics, disability, pregnancy, veteran status or any other basis protected by law.

If you are an individual with a disability and need assistance in applying for a position, please contact SentinelHR1@sentinel.com."
1008923155957,Glassdoor,,,http://www.northropgrumman.com/,"Requisition ID: R10134206
Category: Research and Sciences
Location: Schriever AFB, Colorado, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Days (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman Space Systems – Launch and Missile Defense Systems has an exciting career opportunity for a Principal Engineer Data – X-Lab Data Engineer (23-626) to join our team of qualified, diverse individuals. This position will be out of Schriever Space Force Base, Colorado Springs, CO.
Position Overview:
This position will focus on the development of database tools and will contribute to other ongoing X-Lab and external stakeholder projects as needed. The team will extract value from experimental C2BMC systems by cleaning, aggregating, and visualizing the generated data, adapting to system changes, and presenting customer-quality products.
The Data Engineer will apply these results to identify analysis opportunities and work to enhance C2BMC for future operations. The candidate should be comfortable with rapidly changing requirements, design challenges that require novel solutions, fast-paced activities, and tight deadlines. Responsible for full lifecycle support for database development projects.
Essential Functions:
Database Implementation - Define schema and table structure data relationships.
Build ETL pipelines and implement data automation.
Integrate DBMS tools Database Management - Understand and adapt pipelines to data format changes.
Integrate new data into the database and clearly explain relationships.
Support customer requests for data
Experience in working on IRAD-type projects.
Experience with DBeaver and pgAdmin.
Experience with Python, Pandas library, MATLAB, Excel, and Tableau.
Experience with Gitlab and Gitlab Runner.
Operating systems experience with Windows & Unix/Linux.
Knowledge of physics & mechanics of missile flight and satellite orbits.
Theory and application of the Missile Defense System and space domain.
Theory and application of command and control systems.
Theory and application of track correlation algorithms.
Experience with Agile development techniques and tools.
Integration practices and methods.
Basic Qualifications:
Please note your updated security clearance and IAT/relevant certifications on your resume, if applicable.
An active Secret clearance is required to start with the ability to obtain TS/SCI clearance.
5 years with a Bachelor’s degree in a related field; 9 years experience in lieu of a degree.
Experience contributing to an integrated team environment with other systems, software, and specialty engineers to develop solutions that include a background in all aspects of the analysis life cycle.
Experience designing a database, ingesting and cleaning data, automating database load, and adapting to data changes.
Demonstrated ability to interpret high-level customer needs and deliver quality data projects.
Demonstrated ability to communicate effectively and present technical approaches and findings.
Familiarity with standard office productivity tools such as the MS Office suite.
Experience with PostgreSQL
Preferred Qualifications:
An active TS/SCI clearance is highly desired.
Some travel may be required.
Occasional off-hours work may be required.
The position is located full-time at the Missile Defense Integration and Operations Center (MDIOC) in Schriever, SFB, CO, and is not a remote work position.
What We Can Offer You:
Northrop Grumman provides a comprehensive benefits package and a work environment that encourages your growth and supports the mutual success of our people and our company. Northrop Grumman benefits give you the flexibility and control to choose the benefits that make the most sense for you and your family. Your benefits will include the following:
Health Plan
Savings Plan
Paid Time Off
Education Assistance
Training and Development
Flexible Work Arrangements
https://benefits.northropgrumman.com/us/en2/BenefitsOverview/Pages/default.aspx
NGSpace
COSpace
NGFeaturedJobs
C2BMC
Additional Northrop Grumman Information:
Salary Range: $95,100 - $142,700
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions."
1008922465263,Glassdoor,,,,"Minimum qualifications:
Bachelor's degree in Engineering, related technical field, or equivalent practical experience.
5 years of experience in the design-build environment for mission critical facilities (e.g., data centers, power plants, industrial, etc).
Experience in estimating, mechanical design, operation and commissioning of central utility plants, water processing systems, air distribution systems, and PLC/SCADA controls systems.

Preferred qualifications:
Professional Engineering License.
Experience with project total cost of ownership (TCO).
Construction administration or construction management experience.
Experience with large-scale mission critical facilities' mechanical infrastructure systems.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
In this role, you will have a primary focus on providing a deep technical understanding of Google’s data center design to field execution and operations teams in support of their initiatives. You will also support other teams in the development and evaluation of conceptual design.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
The US base salary range for this full-time position is $136,000-$203,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Participate in the project specific design review process including conceptualizing ways to reduce total cost of ownership (TCO) while maintaining Google standards.
Coordinate with consulting engineers preparing construction documents as they develop detailed documentation based on the conceptual design standards developed and provided by others internally.
Work with the general contractor (GC) to develop a high level understanding of the design intent and on-time development of coordinated design details and delegated design elements in alignment with Google standards.
Monitor work in the field to ensure it is being executed in line with Google’s design intent and standards, as well as meeting the local codes and requirements.
Support systems startup and commissioning processes by providing a technical understanding of the gear being installed and how the systems are designed to function.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
1008920543115,Glassdoor,,,,
1008924013092,Glassdoor,,,http://www.amazon.jobs/,"Bachelor’s Degree in Electrical Engineering or equivalent experience.
3+ cumulative years of experience with industrial or commercial engineering in Mission Critical facilities including but not limited to: data centers, power generation, oil / gas facilities. (Experienced Engineer)
We have an immediate opening for a Field Engineer in the Aurora, CO region.

As an Amazon Field Engineer, you will provide full life-cycle support to AWS Data Centers from design inception through site improvement and maintenance. You will be the ‘go to’ engineering resource for your region when technical advice is needed, and will use your subject matter expertise and engage with diverse teams to:

Perform design and equipment submittal review for new Data Centers in your region.
Troubleshoot, conduct Root Cause Analysis (RCA) and create Corrective Action (CA) documentation for site/equipment failures.
Directly support operational issues with ad-hoc training, complex operating procedure reviews, including critical equipment, and event support.
Own the design for existing data center upgrades and design-solutions, which add capacity, improve availability, and increase efficiency.
Lead, Review, and approve designs for existing co-location (colo) data center upgrades which improve availability/efficiency.
Interface with internal data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.
Work on concurrent projects, sometimes in multiple geographical regions.
Initiate and lead engineering site audits within Amazon’s owned or colo data centers. Produce reports outlining risks with recommended mitigations and remediations.
Act as resident engineer during new construction projects. Support construction, commissioning, and turnover.
Amazon's vision is to be the world's most customer-centric company, and this role is key to that vision. As a Field Engineer, you will be leading projects to fit out our data centers to meet ever-evolving customer needs as we continue expanding our fleet to hyper-scale. As an ideal candidate you:

Possess Strong Engineering Judgement and are able to provide recommendations despite uncertainty
Are detail and data oriented
Have experience managing engineering projects and consultants.
Build trust and relationships with different stakeholders (e.g., Operations, Commissioning, Construction and Design)
Be inclined to get into the field to see things up close.
Each day you will interact with different teams responsible for all aspects of the data centers. You will prioritize your activities to support data center capacity availability and safety focusing on the actions that are most impactful. You will have the opportunity to work on projects locally and globally.

This position requires that the candidate selected be a U.S. citizen and obtain and maintain an active TS/SCI security clearance with polygraph. Upon application you will be asked qualifying questions that will be used only in relation to the US Government Security Clearance required for this role.

This position involves on-call responsibilities. We don’t like getting paged in the middle of the night or on the weekend, so we work to ensure that our systems are fault tolerant. When we do get paged, we work together to resolve the root cause so that we don’t get paged for the same issue twice.

If you meet these qualifications, exude passion, and enjoy the challenge of innovative projects at hyper-scale, this job is for you!

Our team is dedicated to supporting new team members. Our team has a broad mix of experience levels and Amazon tenures, and we’re building an environment that celebrates knowledge sharing and mentorship.

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Our team also puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren’t focused on how many hours you spend at work or online. Instead, we’re happy to offer a flexible schedule so you can have a more productive and well-balanced life—both in and outside of work.

Up to 25% travel may be required.

About the team
ADC (Amazon Dedicated Cloud) Field Engineering provides engineering support to the data center operations personnel at sites supporting the US intelligence community.

We are open to hiring candidates to work out of one of the following locations:

Aurora, CO, USA

Organized and have the ability to set priorities and meet deadlines and budget
Possess leadership and problem-solving skills
Experience using a variety of web based and other software tools for calculation and data processing.
Direct experience with the design, construction, operation, or maintenance of mission critical facilities, especially data centers.
Experience as resident engineer or hands-on (in the field) design consultant.
Knowledge of building codes and regulations for your region.
Experience reading, interpreting, and creating construction drawings, specifications, and submittal documents.
Ability to carry design concepts through exploration, development, and into deployment/mass production
Possess excellent communication and writing skills, attention to detail, maintain high quality standards
Basic understanding of both mechanical and electrical equipment/design related to data centers (Including but not limited to: uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc...)
EPMS/SCADA/BMS Controls system experience (software and/or hardware)
Registered Professional Engineer
Advanced degree in engineering, business, or related field.
Have fluent knowledge of continuous operating redundant electrical systems, cooling systems, air flow containment systems and building management systems. (Including but not limited to: uninterruptable power sources, AC/DC conversion, P&ID loops, diesel generators systems and complex arrangements, direct evaporative cooling systems, etc...)
Ability to develop solutions and execute plans on complex projects
Previous ownership of fast track design/build projects and or multiple significant upgrade projects
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
About AWS
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop
celebrating our uniqueness.

Mentorship & Career Growth
We have a career path for you no matter what stage you’re in when you start here. As we strive to become Earth’s Best Employer, we know we must continuously raise our performance bar. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $93,500/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site."
1008917152405,Glassdoor,,,http://www.saic.com/,"Job ID: 2313947
Location: COLORADO SPRINGS, CO, US
Date Posted: 2023-10-09
Category: Engineering and Sciences
Subcategory: Systems Engineer
Schedule: Full-time
Shift: Day Job
Travel: Yes, 10 % of the Time
Minimum Clearance Required: TS/SCI
Clearance Level Must Be Able to Obtain: TS/SCI
Potential for Remote Work: No

Description
SAIC’s Horizon 2 Program is seeking a Sr. Principal Data Engineer to join our National Space Test and Training Complex (NSTTC) program located in Colorado Springs, CO.
The Data Engineer will coordinate with government and partner data stewards across the program and US Space Force data enterprise to manage data strategies, cross-cutting infrastructure, and processes to drive consistent data governance for test and training purposes while ensuring enterprise solutions so that data consumers and producers can find, securely access, and use data more effectively and confidently. We are looking for self-motivated, enthusiastic people who are excited about taking on a variety of challenges as we continue to develop a test and training enterprise data governance solution and support enterprise data & analytic solutions. Successful candidates will be able to work under only very general supervision.
Occasional travel may be required to engage with key stakeholders.
Responsibilities include but are not limited to:
Independently evaluate, select, adapt, and modify data strategies, plans, and potential solutions and conduct engineering assessments for integration into large-scale enterprise data governance
Engage with government technical data stewards to aid in conducting data lineage, deriving business rules (attributes, calculations, derivations, etc.), and understanding data attribute’s purpose and utilization
Direct the definition, aggregation, and maintenance of critical data elements needed to populate modeling, simulation, and analysis software
Coordinate with government data stewards to create enterprise level data quality metrics and a quality data model, consistent across enterprise solutions
Support on-boarding and integration of data sources and serve as a liaison between government organizations in support of a federated governance model
Analyze complex data problems and apply principles and practices of the data disciplines while devising new approaches and solutions to data problem sets
Partner with government customer data administrators to ensure that standards and governance are understood and well implemented
Manage day-to-day activities to ensure the data processes run smoothly and support issue and resolution tasks for data issues
Create capabilities to perform data quality audits, find data collection issues, and suggest improvements while acting on findings as necessary and implementing fixes
Qualifications
Qualifications:
Masters in IT, computer science, software engineering, or a related field and 14+ years experience in related field
Must have a current background investigation commensurate with Top Secret security clearance and be able to obtain a Sensitive Compartmented Information access and consent to a counter-intelligence polygraph examination
Certified Information Systems Security Professional (CISSP)
DevSecOps Certification
Experience with Cybersecurity, IT, ML, and AI
Experience with Agile DevSecOps models for software
Experience with coding languages/interfaces and design/architecture processes and toolsets
Experience with SQL Server and SQL Server Integration Services
Experience with mathematical evaluation approaches to data integration and enterprise-wide data infrastructure
Experience with Amazon Web Services (AWS) and cloud systems
Desired Qualifications:
PhD in IT, computer science, software engineering, or related field of expertise

Target salary range: $175,001 - $200,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.

Covid Policy: SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site."
1008920853937,Glassdoor,,,http://www.zapatatechnology.com/,"Seeking SAP HANA Data Systems Engineer, Level IV, with 12+ years of information technology experience, and 7+ years of directly relevant experience, to provide subject matter expertise support for INSCOM Cloud Initiative (ICI) and the Army Intelligence Data Platform (AIDP), provide technical ingestion expertise to ICI & AIDP assigned exercises, and provide oversight of ICI & AIDP operational entity databases.
As a crucial member of our dynamic, innovative team, you have the chance to leverage your extensive experience and expertise to unlock the hidden insights within data and help save lives. Embrace the opportunity work and contributing to our life-saving mission. Say yes to your dream job and apply today!
Job Qualifications:
This is a database management position requiring constant interaction with military message data.
Qualifications and Skills include:
Experience with DoD 5000.02 documentation requirements.
SAP HANA databases or other DBA experience.
Experience with JavaScript and SQL for backend server-side JavaScript development to be used with SAP HANA Extended Application Services.
Experience with RedHat Linux or similar Linux variants.
Experience with developing technical project artifacts.
Desired Certifications and Relevant Experience:
Bachelor's degree in systems engineering. Certified Systems Engineering Professional (CSEP), Expert Systems Engineering Professional (ESEP), and DAWIA Systems Engineering Level III.
Knowledge of U.S. Army operations and exercises, training requirements and United States Message Text formats (USMTF) is highly desired.
Apache NiFi
Education:
Bachelor's degree in STEM field and 12 years of experience. Seven (7) years of position-relevant work experience. A candidate holding a relevant Master’s degree may be granted 2 years’ experience credit. A candidate holding a relevant PhD degree may be granted 4 years experience credit. HS graduates require four (4) additional years of relevant experience or an Associate's degree and two (2) years of additional relevant experience may be accepted in lieu of required BA/BS degree.
Certifications: DoD 8570.01-m IAT Level III.
Position Type:
Full time position
Travel:
Travel up to 10%
Clearance Type:
Requires a current TS/SCI. Employment is contingent on having or obtaining the required active security clearance or successfully passing the required background check, as well as other factors, including, but not limited to, drug screens.
AAP/EEO Statement:
Equal Opportunity Employer – M/F/Disabled/Veteran
Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status.
Job Type: Full-time
Pay: $105,000.00 - $125,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee discount
Health insurance
Life insurance
Paid time off
Referral program
Tuition reimbursement
Vision insurance
Compensation package:
Yearly pay
Experience level:
7 years
Schedule:
8 hour shift
Experience:
SQL database management: 7 years (Required)
SAP HANA: 7 years (Preferred)
License/Certification:
IAT Level III (Required)
Security clearance:
Top Secret (Required)
Work Location: In person"
1008918459597,Glassdoor,,,http://www.northropgrumman.com/,"Requisition ID: R10132217
Category: Engineering
Location: Colorado Springs, Colorado, United States of America | Roy, Utah, United States of America+ 1 more
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 2
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Embark on a career putting innovative, reliable, and agile products and ideas into orbit, and beyond. Northrop Grumman has opportunities waiting for you that play a vital role in human space exploration, national defense, and scientific discovery, supporting multiple programs across the universe. With us, you’ll discover a culture of curiosity and collaboration that will have you Defining Possible from the day you start. Our space systems connect and protect millions of people on earth every day, now and for the future. Explore your future and launch your career today.
Northrop Grumman Space Systems is seeking Wing Data Simulator Software Engineer Manager. This position will be located in Colorado Springs, Co or Roy, Utah and will support the Sentinel program.
The Wing Data Simulator project is developing a complex Software/Hardware modeling and simulation capability that will be used to test the GBSD weapon system. This position will develop software in a dynamic environment using the Agile (Scrum) framework using a variety of languages including C++, JavaScript, and Python. This SW engineering position will join a scrum team of 6-8 engineers to develop software capability. Experience developing software in the early stages of a project is useful but not required. Experience using design patterns early in projects to develop a strong foundation for the entire product lifecycle is suggested. The project heavily leverages CI/CD and automated test concepts, so DevSecOps experience is useful. Experience with Linux OS is required. Experience with code packaging and configuration management is very useful.
This position is a dual-hat position requiring the candidate to perform functional management activities as well as program responsibilities on the Wing Data Simulator project. It is expected that the functional management role will comprise approx. 20% of the candidate’s time and the remaining 80% will be on Wing Data Simulator project. Functional responsibilities include, but not limited to, assess staffing needs, support recruitment activities, provide career development recommendations, mentoring.
As a full-time employee of Northrop Grumman Space Systems, you are eligible for our robust benefits package including:
Medical, Dental & Vision coverage
401k
Educational Assistance
Life Insurance
Employee Assistance Programs & Work/Life Solutions
Paid Time Off
Health & Wellness Resources
Employee Discounts
This position’s standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off. This role may offer a competitive relocation assistance package.
You’ll Bring These Qualifications:
Degree in Computer Science, Computer Engineering, or similar field with 6 years experience or and additional 4 years of related experience in lieu of degree
2 years of professional C++ development experience
2 years of professional Python development experience
2 years of experience with SW development in a Linux environment
2 years of experience with Model-Based Systems Engineering languages (SysML/UML) and concepts
1 year of formal engineering manager or technical lead roles
Active DoD Secret Clearance adjudicated in the last 6 years with ability to obtain SAP.
These Qualifications Would be Nice to Have:
2 years of experience with software development using a DevOps pipeline and Automated testing.
2 years of experience with Hardware/Software interface design.
2 years of experience with software and hardware certification/accreditation.
2 years of experience with embedded systems.
2 years of experience with Agile development
2 years of experience with Atlassian tool suite
2 years of experience with code design documentation using UML
2 years of experience with Test Driven Development
2 years of experience with databases (structure, design) and query languages.
2 years of experience with real-time operating systems.
Experience with secure software development such as DO-178C compliant or similar.
1 year of experience UML modeling experience using Cameo.
1 year of experience with JavaScript, Python languages.
1 year of experience with GUI Development & Testing.
#GBSDsoftware
#GBSDleadership
Salary Range: $127,700 - $191,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions."
1008920064194,Glassdoor,,,,
