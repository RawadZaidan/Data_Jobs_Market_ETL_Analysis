{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "ddd = pd.read_csv('csvs/linkedin_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscraping import linkedin_driver\n",
    "\n",
    "driver = linkedin_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscraping import linkedin_page_go_to,linkedin_get_text_values_by_class,linkedin_get_href_by_class\n",
    "from webscraping import linkedin_get_href_by_class,linkedin_driver, linkedin_get_elements_by_css\n",
    "from time import sleep\n",
    "from webscraping import linkedin_job_find_next_page_button, linkedin_click\n",
    "from webscraping import By, find_technologies_in_string\n",
    "from random import randint\n",
    "\n",
    "login = r'https://www.linkedin.com/login?emailAddress=&fromSignIn=&fromSignIn=true&session_redirect=https%3A%2F%2Fuk.linkedin.com%2Fjobs%2Fview%2Fdata-engineer-at-iq-eq-3741507411%3FrefId%3Did3VRcGHCt8KUHuyFlp%252BRQ%253D%253D%26trackingId%3D0HBMkGcz00qUBabeUAttyA%253D%253D%26position%3D1%26pageNum%3D0%26trk%3Dpublic_jobs_jserp-result_search-card&trk=public_jobs_nav-header-signin'\n",
    "linkedin_page_go_to(driver, login)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# To load the password from the pickle file, you can use the following code:\n",
    "with open('linkedin_user.pkl', 'rb') as file:\n",
    "    username = pickle.load(file)\n",
    "with open('linkedin_password.pkl', 'rb') as file:\n",
    "    password = pickle.load(file)\n",
    "\n",
    "user_field = driver.find_elements(By.ID, 'username')[0]\n",
    "pass_field = driver.find_elements(By.ID, 'password')[0]\n",
    "\n",
    "user_field.send_keys(username)\n",
    "pass_field.send_keys(password)\n",
    "\n",
    "element = driver.find_element(By.XPATH, '//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "linkedin_click(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found elements\n"
     ]
    }
   ],
   "source": [
    "from webscraping import linkedin_page_go_to,linkedin_get_text_values_by_class,linkedin_get_href_by_class\n",
    "from webscraping import linkedin_get_href_by_class,linkedin_driver, linkedin_get_elements_by_css\n",
    "from time import sleep\n",
    "from webscraping import linkedin_job_find_next_page_button, linkedin_click\n",
    "from webscraping import By, find_technologies_in_string\n",
    "from random import randint\n",
    "\n",
    "data_list = []\n",
    "counter = 0\n",
    "for row in ddd.iterrows():\n",
    "    counter+=1\n",
    "    if counter>1:\n",
    "        break\n",
    "    ID = row[1][0]\n",
    "    SOURCE = row[1][-1]\n",
    "    # print(ID)\n",
    "    linkedin_page_go_to(driver, row[1][5])\n",
    "    sleep(randint(2,4))\n",
    "    # sleep(1)\n",
    "    try:\n",
    "        lower,higher = None , None\n",
    "        button = driver.find_element(By.CLASS_NAME, 'jobs-description__footer-button')\n",
    "        linkedin_click(button)\n",
    "        # print('clicking btton')\n",
    "        items = driver.find_elements(By.CLASS_NAME,'jobs-box__html-content')[0].text\n",
    "        print('found elements')\n",
    "        # link = linkedin_get_href_by_class('topcard__org-name-link',driver)\n",
    "        # print('finding link')\n",
    "        # data = {'ID':ID, 'source':SOURCE, 'min_yearly_salary':lower,\n",
    "        #         'max_yearly_salary':higher,'company_link':link,'description':items}\n",
    "        # techs = find_technologies_in_string(items)\n",
    "        # data.update(techs)\n",
    "        # print('appending data')\n",
    "        # data_list.append(data)\n",
    "    except:\n",
    "        pass\n",
    "df_new = pd.DataFrame(data_list)\n",
    "# df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About the job\\nCompany Description\\n\\nIQEQ is a preeminent service provider to the alternative asset industry. IQEQ works with managers in multiple capacities ranging from hedge fund, private equity fund, and mutual fund launches; private equity fund administration; advisory firm set-up, regulatory registration and infrastructure design; ongoing regulatory compliance (SEC, CFTC, and 40 Act); financial controls and operational support services; compliance and operational related projects and reviews; and outsourced CFO/controller and administration services to private equity fund investments – portfolio companies, real estate assets and energy assets. Our client base is growing, and our existing clients are engaging the firm across the spectrum of our services offerings.\\n\\nJob Description\\n\\nN.B. this role is based in Belfast.\\n\\nWe have a fantastic opportunity for an experienced Data Engineer to join our global team. This role will play a major part in the delivery of our Group Data Strategy and Data Transformation Journey by delivering, enhancing, and maintaining our IQEQ Data Platform which will drive how our data is managed and used to deliver outcomes in a host of key areas to maximise business value and growth delivering improvements for internal and external stakeholders and clients.\\n\\nThis role will be responsible for expanding and optimizing our data and data pipeline architecture. The ideal candidate is an experienced data pipeline builder and data wrangler who will support our software developers, database architects, data analysts and data scientists on data initiatives to navigate and leverage our significant data assets to build the optimal production models. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.\\n\\nTasks (what does the role do on a day-to-day basis)\\nCreate and maintain optimal data pipelines based on the inhouse stack.\\nAssemble complex data sets that meet functional / non-functional business requirements.\\nBuild/Maintain data models on the financial data currently used\\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs\\nImplement data flows to connect operational systems, data for analytics and business intelligence (BI) systems\\nDocument source-to-target mappings\\nRe-engineer manual data flows to enable scaling and repeatable use\\nWrite ETL (extract, transform, load) scripts and code to ensure the ETL process performs optimally\\nDevelop/Maintain DAG workflows for BAU processes, Data Pipelines and Transformations\\nKey behaviours we expect to see\\n\\nRole\\n\\nIn addition to demonstrating our Group Values (Authentic, Bold, and Collaborative), the role holder will be expected to demonstrate the following:\\nCommunicates Effectively – Adjusting communication style to fit the audience & message. Providing timely information to help others across the organisation. Encourages the open expression of diverse ideas and opinions\\nAction Orientated – Readily taking action on challenges without unnecessary planning and identifies new opportunities, taking ownership of them\\nInterpersonal Savvy – Relating comfortably with people across all levels, functions, cultures & geographies. Builds rapport in an open, friendly & accepting way\\nAn analytical mind, excellent problem-solving & diagnostic skills, attention to detail\\nQualifications\\n\\nEducation / professional qualifications\\nBachelor's degree in computer science or another related field\\n3+ years of experience in software engineering.\\nBackground in Financial Industry preferred.\\nBackground & Technical Experience\\nProficiency in Linux fundamentals and Bash scripting skills.\\nStrong programming expertise in Python and exposure to more languages, mainly: Go, JS\\nExpertise on Python libraries - Pandas, Numpy\\nGood knowledge of Algorithms and Data Structures\\nDeep understand of database systems e.g., PgSQL/MySQL and Microsoft SQL server\\nExperience with at least one cloud platforms e.g., AWS, Azure, GCP, Preferably Azure\\nExposure to one or more Datalakes/Datawarehouses - Snowflake / DataBricks / Redshift etc\\nKnow how in Stream processing - Kafka, Kineses etc\\nBasic Experience with Node.js and JavaScript.\\nExperienced in the implementation of Data warehousing solutions\\nExperienced in the implementation of API solutions and tooling\\nOther Company, Product, And Market Knowledge\\nExperience of working in a complex, multi-country professional services, financial services or BPO organisation with complex processing requirements\\nMulti-country experience and demonstrates an ability to work in a multi-cultural, talented, and demanding team environment.\\nPossess the skills and the personality to operate effectively in a very fast-paced complex global business with an in-depth knowledge of program management\\nExcellent communication skills in both written and oral form, with staff members, customers, suppliers, and the management team with the ability to make decisions, act and get results\\nPassion, dynamism, and drive\\nPersonal presence, integrity, and credibility\\nAbility to solve problems either independently or by utilising other members of the team where necessary\\nStrong analytical and troubleshooting skills.\\nAbility to investigate and analyse information, and to draw conclusions, i.e RCA\\nExperience/Exposure to ISO 27001 Infosec compliances\\nLanguages\\nFully proficient spoken and written English, additional European languages will be an asset\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=118.0.5993.71)\nStacktrace:\n\tGetHandleVerifier [0x01074DE3+43907]\n\t(No symbol) [0x01000741]\n\t(No symbol) [0x00EF32B0]\n\t(No symbol) [0x00F27958]\n\t(No symbol) [0x00F1FF9A]\n\t(No symbol) [0x00F42B5C]\n\t(No symbol) [0x00F1F9D6]\n\t(No symbol) [0x00F42DD4]\n\t(No symbol) [0x00F555CA]\n\t(No symbol) [0x00F42956]\n\t(No symbol) [0x00F1E17E]\n\t(No symbol) [0x00F1F32D]\n\tGetHandleVerifier [0x01325AF9+2865305]\n\tGetHandleVerifier [0x0136E78B+3163435]\n\tGetHandleVerifier [0x01368441+3138017]\n\tGetHandleVerifier [0x010FE0F0+605840]\n\t(No symbol) [0x0100A64C]\n\t(No symbol) [0x01006638]\n\t(No symbol) [0x0100675F]\n\t(No symbol) [0x00FF8DB7]\n\tBaseThreadInitThunk [0x75627BA9+25]\n\tRtlInitializeExceptionChain [0x7743BD3B+107]\n\tRtlClearBits [0x7743BCBF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\96171\\Desktop\\Final_Project\\tester2.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/96171/Desktop/Final_Project/tester2.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m close:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/96171/Desktop/Final_Project/tester2.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m closing \u001b[39min\u001b[39;00m close:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/96171/Desktop/Final_Project/tester2.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         linkedin_click(closing)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/96171/Desktop/Final_Project/tester2.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfound close button\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/96171/Desktop/Final_Project/tester2.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sleep(randint(\u001b[39m2\u001b[39m,\u001b[39m4\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\96171\\Desktop\\Final_Project\\webscraping.py:262\u001b[0m, in \u001b[0;36mlinkedin_click\u001b[1;34m(button_element)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlinkedin_click\u001b[39m(button_element):\n\u001b[1;32m--> 262\u001b[0m     button_element\u001b[39m.\u001b[39;49mclick()\n",
      "File \u001b[1;32mc:\\Users\\96171\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:93\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclick\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(Command\u001b[39m.\u001b[39;49mCLICK_ELEMENT)\n",
      "File \u001b[1;32mc:\\Users\\96171\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:394\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[0;32m    393\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[1;32m--> 394\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[1;32mc:\\Users\\96171\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    345\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\96171\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=118.0.5993.71)\nStacktrace:\n\tGetHandleVerifier [0x01074DE3+43907]\n\t(No symbol) [0x01000741]\n\t(No symbol) [0x00EF32B0]\n\t(No symbol) [0x00F27958]\n\t(No symbol) [0x00F1FF9A]\n\t(No symbol) [0x00F42B5C]\n\t(No symbol) [0x00F1F9D6]\n\t(No symbol) [0x00F42DD4]\n\t(No symbol) [0x00F555CA]\n\t(No symbol) [0x00F42956]\n\t(No symbol) [0x00F1E17E]\n\t(No symbol) [0x00F1F32D]\n\tGetHandleVerifier [0x01325AF9+2865305]\n\tGetHandleVerifier [0x0136E78B+3163435]\n\tGetHandleVerifier [0x01368441+3138017]\n\tGetHandleVerifier [0x010FE0F0+605840]\n\t(No symbol) [0x0100A64C]\n\t(No symbol) [0x01006638]\n\t(No symbol) [0x0100675F]\n\t(No symbol) [0x00FF8DB7]\n\tBaseThreadInitThunk [0x75627BA9+25]\n\tRtlInitializeExceptionChain [0x7743BD3B+107]\n\tRtlClearBits [0x7743BCBF+191]\n"
     ]
    }
   ],
   "source": [
    "lower,higher = None , None\n",
    "close = driver.find_elements(By.ID, 'close-small')\n",
    "if close:\n",
    "    for closing in close:\n",
    "        linkedin_click(closing)\n",
    "        print('found close button')\n",
    "sleep(randint(2,4))\n",
    "button = driver.find_element(By.CLASS_NAME, 'jobs-description__footer-button')\n",
    "linkedin_click(button)\n",
    "print('button clicked')\n",
    "items = driver.find_elements(By.CLASS_NAME,'show-more-less-html__markup')[0].text\n",
    "print('finding elements')\n",
    "link = linkedin_get_href_by_class('topcard__org-name-link',driver)\n",
    "print('finding link')\n",
    "data = {'ID':ID, 'source':SOURCE, 'min_yearly_salary':lower,\n",
    "        'max_yearly_salary':higher,'company_link':link,'description':items}\n",
    "techs = find_technologies_in_string(items)\n",
    "data.update(techs)\n",
    "print('appending data')\n",
    "data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = driver.find_elements(By.ID, 'close-small')[0]\n",
    "linkedin_click(close)\n",
    "close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = '''\"MP DATA en résumé :\\n\\nMP DATA est une société spécialisée dans l’acquisition,\n",
    "le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne\n",
    "ses clients, majoritairement industriels, dans le management de leur performance et\n",
    "l’exploitation de leurs données.\\n\\nLes collaborateurs, tous issus de grandes écoles,\n",
    "incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. \n",
    "Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences\n",
    "au service de missions et projets au sein de grands groupes français.\\n\\nMP \n",
    "DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise :\n",
    "Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.\\n\\nChez MP DATA, les \n",
    "équipes commerciales cherchent des missions en fonction des envies des collaborateurs\n",
    "et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de \n",
    "la mobilité géographique, au changement de junior secteur d’activité en passant par le\n",
    "développement de nouvelles compétences.\\nRejoindre MP DATA, c’est la garantie\n",
    "de travailler sur des sujets passionnants avec un cadre technique fort.\\nMission \n",
    ":\\n\\nMP DATA, recrute un développeur, avec des affinités pour le métier de Data\n",
    "Engineer ou un Data Engineer afin de travailler pour nous rejoindre. Accompagné\n",
    "par un Lead Data Engineer, vous aurez l’occasion de monter en compétences sur\n",
    "la manipulation de gros volumes de données.\\n\\nLocalisation : Cannes,\n",
    "Antibes, Nice.\\nTélétravail : À définir\\n\\nProfil recherché \n",
    ":\\n\\nIngénieur-e issu-e de grande école, spécialisé-e en développement\n",
    "informatique / data engineering, vous justifiez de deux ou trois ans \n",
    "d’expérience professionnelle au cours desquelles vous avez pu développer\n",
    "les compétences techniques suivantes :\\n\\nLangages : Scala,\n",
    "Python\\nFramework : Spark (connaissance de DataBricks),\n",
    "Hadoop (connaissance de Map Reduce)\\nTechnologies de stockage \n",
    ": Snowflake / Scality\\nEnvironnement : Azure\\n\\nVous êtes reconnu(e) \n",
    "pour votre autonomie, votre excellent relationnel et votre capacité à être force de proposition\n",
    ".\\n\\nProcess de recrutement :\\n\\nPremier échange en visio de 30 minutes.\\nEntretien technique \n",
    "avec notre direction technique.\\nÉchange avec l'équipe\\nBienvenue dans nos équipes !\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscraping import find_technologies_in_string\n",
    "# Test the function\n",
    "data = find_technologies_in_string(items)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
