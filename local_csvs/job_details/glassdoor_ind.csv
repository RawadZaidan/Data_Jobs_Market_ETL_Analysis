ID,source,company_name,company_id,min_yearly_salary,max_yearly_salary,company_link,description,python,sql,r,scala,tableau,power_bi,mysql,postgresql,nosql,etl,dax,aws,azure,remote,hybrid,on_site,junior,mid,senior
1008931248248,Glassdoor,ARA Diagnostic Imaging,1735373358,71000,97000,"https://www.glassdoor.com/Overview/Working-at-ARA-Diagnostic-Imaging-EI_IE454233.11,33.htm","ARA Diagnostic Imaging is seeking an experienced Data Engineer I to join our growing team!

Summary:
This position is responsible for the management, retrieval, visualization, and dissemination of Financial and Operational information. The key success factors include technical knowledge including SQL (SSMS, SSIS, SSRS, T-SQL, SQL Service Job Management), Tableau, Database Management (Table Structures, optimization, and triage), and storytelling through data visualization techniques (Tableau, Excess, SSRS, Crystal, etc.).

Essential Functions:
Generates automated reports and monitors SQL Reporting server to ensure recurring automated reports generate timely.
Develops, designs, and modifies reports for end users.
Researches, inquiries and performs ad-hoc queries.
Interacts with end users and application managers to assist in report development and/or troubleshooting issues.
Produces monthly compilation of physician productivity.
Produces, analyzes and interprets monthly Operation reports with variance analysis.
Assists Operations and Accounting departments with budgeting and cost accounting.
Monitors administrative expenses monthly to ensure conformance to budgetary limits.
Generates monthly invoices for all Client Accounts and maintain client account database.
Analyzes insurance contracts in order to identify discrepancies and/or variances.
Education/Experience:
Bachelor’s Degree required. Minimum of 2 years of experience in data analysis, data modeling, data cleansing, data mart and data warehouse design and construction, database management, and/or report writing to include skill in using SQL. Healthcare industry experience preferred.
Skills/Knowledge:
Querying Language
SQL: Functional
T-SQL: Functional

Data Retrieval
SSMS: Functional

Data Delivery
SSRS: Functional
Tableau: Functional
Excel: Expertise
Crystal: Ready to Learn
ETL
Concepts: Functional
SSIS: Functional

Data Management
Structure: Functional
Maintenance: Functional
Optimization: Ready to Learn

Data Warehousing
Structure: Functional
Maintenance: Functional
Optimization: Ready to Learn

Stored Procedures
Creation: Functional
Modification: Functional
Triage: Functional
Optimization: Ready to Learn

Job Management
Creation: Functional
Modification: Functional
Triage: Functional
Optimization: Ready to Learn

Ability to work independently and to exercise discretion and independent judgment.
Must be able to collaborate and work as part of a team.
Demonstrates strong customer service.
Communicates effectively through writing and verbal presentations.
Proficient in word processing, spreadsheets, Internet and presentation software.
Curiosity to learn.
Flexibility to shift to changing priorities.
Excellent interpersonal relations skills.
Ability to build and maintain effective relationships with multiple levels of the workforce.
Highly organized with strong attention to detail.
Working conditions:
May be exposed to negligible electromagnetic radiation. Must have the ability to lift up to 40 lbs.
Success factors:
Successful incumbent possesses high energy, drive and positive attitude; is committed to customer service and teamwork; has the ability to multitask; and is focused on achieving results.


Location: ARA Diagnostic Imaging · Accounting
Schedule: Full Time, Day Shift, M-F; 8:00am to 5:00pm",FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931549364,Glassdoor,Sunwater Capital,537753514,78000,124000,"https://www.glassdoor.com/Overview/Working-at-Sunwater-Capital-EI_IE3261992.11,27.htm","REFRAME DATA SERVICES
Reframe Data Services is a technology company specializing in software development, data management, data acquisition, and analysis. With a focus on delivering high-quality solutions to innovative businesses across various industries, Reframe Data Services uses its expertise to help clients develop disruptive products and optimize their data-related processes.
POSITION
Reframe Data Services is seeking a Data Engineer who has a background in engineering or computer science and is highly skilled in SQL and database services technologies to help develop data-driven technology platforms that will have significant impact on politics, scientific knowledge creation, and healthcare.
The ideal candidate will possess strong problem-solving skills, excellent communication, and a great technical aptitude. The individual in this position will provide project support and help drive team initiatives. The candidate will be creative, and comfortable working in small teams and coordinating with US and non-US-based developers.
Responsibilities
Develop data models to store and manage large amounts of structured and unstructured data.
Design efficient ETL processes to move and integrate data from different sources into the enterprise warehouse.
Write complex queries using SQL Server etc. to analyze large datasets.
Identify trends, patterns, and correlations within datasets by performing exploratory analysis.
Ensure high quality of data by implementing best practices on storage, maintenance, indexing techniques, etc
Coordinate project status updates between teams and communicate deliverables and timelines.
Requirements
Bachelor’s degree in technical field (Computer Science, Engineering or equivalent)
4+ years of experience in a similar role
Required strong knowledge and experience with MS SQL Server
Desired experience with DB platforms such as MySQL, Aurora, PostgreSQL.
Desired experience with NoSQL databases such as MongoDB, neo4j, Neptune, DynamoDB
Required strong experience in writing complex queries using SQL language; developing stored procs, views etc.
Required experience with end-to-end ETL Processes
Required experience with AWS platform including AWS Glue, Lambda, RDS.
Desired experience with AWS Redshift or similar warehouse solutions.
Ability to develop effective reports that help drive business decisions.
Must be able to work effectively with teams but be able to work independently on tasks to meet tight deadlines.
Exceptional communication skills verbal, written, and active listening.
Extreme attention to detail and accuracy
If you think you have the relevant skillset and would like to join a leading organization that is always on the lookout for innovative ideas, then please send your resume. We look forward to hearing from you!",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931533187,Glassdoor,Austin Radiological Association/ ARA Diagnostic Imaging,373358124,71000,97000,"https://www.glassdoor.com/Overview/Working-at-ARA-Diagnostic-Imaging-EI_IE454233.11,33.htm","ARA Diagnostic Imaging is seeking an experienced Data Engineer I to join our growing team!

Summary:
This position is responsible for the management, retrieval, visualization, and dissemination of Financial and Operational information. The key success factors include technical knowledge including SQL (SSMS, SSIS, SSRS, T-SQL, SQL Service Job Management), Tableau, Database Management (Table Structures, optimization, and triage), and storytelling through data visualization techniques (Tableau, Excess, SSRS, Crystal, etc.).

Essential Functions:
Generates automated reports and monitors SQL Reporting server to ensure recurring automated reports generate timely.
Develops, designs, and modifies reports for end users.
Researches, inquiries and performs ad-hoc queries.
Interacts with end users and application managers to assist in report development and/or troubleshooting issues.
Produces monthly compilation of physician productivity.
Produces, analyzes and interprets monthly Operation reports with variance analysis.
Assists Operations and Accounting departments with budgeting and cost accounting.
Monitors administrative expenses monthly to ensure conformance to budgetary limits.
Generates monthly invoices for all Client Accounts and maintain client account database.
Analyzes insurance contracts in order to identify discrepancies and/or variances.
Education/Experience:
Bachelor’s Degree required. Minimum of 2 years of experience in data analysis, data modeling, data cleansing, data mart and data warehouse design and construction, database management, and/or report writing to include skill in using SQL. Healthcare industry experience preferred.
Skills/Knowledge:
Querying Language
SQL: Functional
T-SQL: Functional

Data Retrieval
SSMS: Functional

Data Delivery
SSRS: Functional
Tableau: Functional
Excel: Expertise
Crystal: Ready to Learn
ETL
Concepts: Functional
SSIS: Functional

Data Management
Structure: Functional
Maintenance: Functional
Optimization: Ready to Learn

Data Warehousing
Structure: Functional
Maintenance: Functional
Optimization: Ready to Learn

Stored Procedures
Creation: Functional
Modification: Functional
Triage: Functional
Optimization: Ready to Learn

Job Management
Creation: Functional
Modification: Functional
Triage: Functional
Optimization: Ready to Learn

Ability to work independently and to exercise discretion and independent judgment.
Must be able to collaborate and work as part of a team.
Demonstrates strong customer service.
Communicates effectively through writing and verbal presentations.
Proficient in word processing, spreadsheets, Internet and presentation software.
Curiosity to learn.
Flexibility to shift to changing priorities.
Excellent interpersonal relations skills.
Ability to build and maintain effective relationships with multiple levels of the workforce.
Highly organized with strong attention to detail.
Working conditions:
May be exposed to negligible electromagnetic radiation. Must have the ability to lift up to 40 lbs.
Success factors:
Successful incumbent possesses high energy, drive and positive attitude; is committed to customer service and teamwork; has the ability to multitask; and is focused on achieving results.",FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008933165915,Glassdoor,N/A,1797317630,,,N/A,N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931661150,Glassdoor,Dama Technology Inc,842907232,,,"https://www.glassdoor.com/Overview/Working-at-Dama-WA-EI_IE6808502.11,18.htm","About Dama Financial
At Dama Financial, we use technology to solve problems that critically impact the growth and reputation of the cannabis industry. We offer innovative, compliant, sustainable financial and traceability products, removing the barriers that exclude cannabis businesses from accessing the fundamental solutions required to support a rapidly growing industry. We have a diverse team of professionals with deep expertise in financial services, payments technology, cannabis regulations, and successfully building and growing companies. Throughout the organization, you’ll find people who solve problems, deliver solutions, and deal with uncertainties while building best in class products for the industry.

The Role
The Data & Analytics team within Dama is growing to help clients scale their retail operations with a world-class point-of-sale system and flexible payment options. The team is also responsible for helping internal teams become more data-driven by helping them to understand, utilize and extract value from the data generated by our systems and available in our warehouse.

Although we’re a growth-stage company, our environment is typical of a start-up
We work in small, high-performing teams, are fast-paced, and we all get a lot done by everyone wearing many hats.
We are serious about optimizing our time and staying focused on the most important goals and outcomes.
We are a 100% remote team meaning we focus on communication to ensure we can stay in sync despite our physical distance.

What you'll do
Report to Director of Data & Analytics
Build and maintain pipelines to move data from source systems into our cloud data warehouse
Transform and model data using SQL & Python
Monitor data pipelines for errors/data quality issues and work with Dev Ops Engineering to improve observability and alerting
Improve data quality, reliability, efficiency, and performance while optimizing cost
Document data models, schemas, business logic, pipelines, and other metadata
Collaborate with engineers and product managers to understand data requirements

What we’re looking for
You’re a great creative problem solver with an analytical mind who loves to dig in and solve hard problems
You see data flowing and you can’t stop yourself from classifying, categorizing, organizing and directing those flows to create efficient/performant, useful and usable datasets for both operations and decision support
You’re not just a “data person”, you’re an Engineer who specializes in data and metadata.
You love learning new things and have a passion for building, monitoring and improving a well-oiled “data machine”
You have the ability to work both independently and collaboratively as part of a remote team

Required Experience
1-3 years of experience in a Data Engineer role working with the “Modern Data Stack”
SQL. You know SQL. SQL is a friend of yours. You two probably share a secret handshake
Ideal candidate will have experience with both BigQuery & dbt (including Python)

Nice-to-have Experience
Integration tools (Airbyte, Stitch, Fivetran)
Orchestration tools (Dagster, Airflow, dbt Cloud)
Metadata tools (DataHub, OpenMetadata)
BI/Dashboard tools (Looker, Superset, PowerBI)

Benefits
Healthcare
401K
Generous PTO
Collaborative Environment

What we offer
A low ego environment where you can give and receive direct feedback.
Managers who care about your career development.

Due to the nature of financial systems, you will be required to pass a background check.

Send resumes to jobs@damafinancial.com

CHR: Jr./Mid-Level Data Engineer

LI: Jr./Mid Level Data Engineer

Salary commensurate upon experience

Bonus goals based on company goals",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE
1008931551759,Glassdoor,Sia Partners,615448041,78000,117000,"https://www.glassdoor.com/Overview/Working-at-Sia-Partners-EI_IE663009.11,23.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932816081,Glassdoor,Octagon Talent Solutions,1180511161,,,"https://www.glassdoor.com/Overview/Working-at-Octagon-Technology-Staffing-EI_IE1091407.11,38.htm","Octagon Talent Solutions seeks an experienced and enthusiastic Data Engineer to join our client company team! Our ideal candidate will have a strong background in working with Azure Data Factory and experience in database design and development. Applicants should be able to demonstrate their knowledge of ETL (extract, transform, load) processes and data engineering concepts such as database architecture, coding using SQL, stored procedures, and developing schemas. An understanding of best practices related to data governance is also expected. This is an excellent opportunity for a self-motivated person who is excited about technology! The successful candidate must be a creative problem solver with excellent analytical skills. They must have the ability to stay organized while managing multiple tasks simultaneously. The person selected should also demonstrate exceptional communication skills, both written and verbal. If you have what it takes, we want you on our team!

RESPONSIBILITIES:

Design and develop databases, stored procedures, triggers, and functions following best practices.
Create ETL pipelines efficiently using Azure Data Factory to support data storage and processing.
Develop automated processes for loading, transforming, and integrating data from multiple sources.
Monitor the health of databases & ETL pipelines, troubleshoot issues, and recommend optimizations for performance.
Collaborate with stakeholders to ensure best practices are followed regarding data governance.
Execute data quality checks to identify problems and resolve accuracy issues.
Build dashboards, trackers, and reports as required by business needs.

REQUIREMENTS:
Proven experience working with Azure Data Factory.
Knowledge of database architecture, design, and development.
Proficient in Python, SQL coding, and developing stored procedures.
Experience with ETL processes, including data extraction, transformation, and loading.
Strong problem-solving skills combined with excellent analytical skills.
Exceptional communication skills, both written and verbal.
Highly organized with the ability to manage multiple tasks concurrently.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931467107,Glassdoor,UnitedHealthcare,2146711661,,,"https://www.glassdoor.com/Overview/Working-at-UnitedHealthCare-EI_IE3000093.11,27.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931254212,Glassdoor,Emergent Software,165507301,,,"https://www.glassdoor.com/Overview/Working-at-Emergent-Software-EI_IE1201534.11,28.htm","** This is a direct-hire opportunity with our client and is a hybrid role located in Minneapolis, MN. Candidates must be able to work in the US without sponsorship.**
We are seeking a highly motivated and detail-oriented Data Engineer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining data solutions to drive our business objectives forward. If you have a passion for working with data, a technical background, and a desire to contribute to projects that leverage advanced analytics, then this role is an excellent opportunity to make a meaningful impact. You will work collaboratively with a team to create innovative data-driven solutions, with a focus on data engineering, cloud technologies, data analytics products, and advanced analytics. If you're ready to take your career to the next level and make a difference in a data-driven world, we encourage you to apply.
Responsibilities:
Data Solutions Development: Design, develop, and implement data solutions to address business needs, leveraging your understanding of data modeling, SQL proficiency, and coding skills in languages such as Python, C#, and JavaScript.
Continuous Improvement: Identify and seize opportunities to enhance existing data solutions, optimizing performance, scalability, and efficiency.
Data Visualization: Collaborate with cross-functional teams to create engaging data visualizations that provide actionable insights to stakeholders.
Data Engineering and Cloud: Show a keen interest in data engineering and cloud technologies, actively participating in related projects to support our data infrastructure and architecture.
Data Analytics Products: Contribute to the development and maintenance of data analytics products, ensuring they meet the highest quality standards and satisfy business requirements.
Advanced Analytics: Work on projects related to advanced analytics, including predictive modeling, machine learning, and statistical analysis, to help drive informed decision-making.
Collaborative Teamwork: Act as an effective team member by participating in collaborative projects, sharing knowledge, and supporting colleagues in achieving project goals.
Project Documentation: Assist in the creation of high-quality project documentation and other project artifacts, ensuring that all aspects of the solution are well-documented for future reference and audits.
Qualifications:
Bachelor's degree in a technical field or equivalent practical experience.
Ability to understand and implement solutions for business needs, effectively bridging the gap between technical knowledge and business objectives.
Excellent written and oral communication skills to convey complex technical concepts to non-technical stakeholders.
Exceptional attention to detail and note-taking skills for precise problem-solving and documentation.
Proficiency in SQL for data manipulation and analysis.
Experience with one or more coding languages like Python, C#, or JavaScript.
Data-driven mindset with a strong analytical orientation.
Demonstrated interest in data visualization, data engineering, cloud technologies, data analytics products, and advanced analytics.
Willingness to contribute as a collaborative team member on various projects, fostering a culture of knowledge sharing and innovation.
Our Vetting Process
At Emergent Software, we work hard to find Data Engineers who are the right fit for our clients. Here are the steps of our vetting process for this position:
Application (5 minutes)
Online Assessment (40 minutes)
Initial Phone Interview (30-45 minutes)
2-3 Interviews with the Client
Job Offer!
Job Type: Full-time
Pay: $100,000.00 - $125,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Compensation package:
Bonus opportunities
Schedule:
8 hour shift
Monday to Friday
Work Location: In person",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE
1008931458008,Glassdoor,HC,108701848,47000,74000,"https://www.glassdoor.com/Overview/Working-at-High-Cotton-USA-EI_IE1380330.11,26.htm","Purpose
The Data / Composition Engineer applies their specialized technical knowledge to build and maintain large data-heavy processing applications designed to meet the specific needs of HC3's clients. This role serves as a subject matter expert who ensures data is processed according to customer requirements and quickly resolves any issues that are identified. The knowledge and expertise provided by this role are critical to building and maintaining client trust in our products and services.
Responsibilities
The responsibilities for this position include the following:
Build and support programs that translate various customer data formats for automated composition workflows.
Build and maintain document composition workflows and templates.
Evaluate, reverse engineer, and work with quality assurance to test workflows.
Identify potential points of failure, maintaining high standards of data security and integrity.
Work closely with Quality Assurance to problem solve and streamline HC3’s processing system.
Collaborate with the Project Management team to successfully onboard new clients or implement projects for existing clients.
Collaborate with the Account Management team to resolve client incidents and implement requested modifications.
Understand and adhere to documented processes and standards for data automation systems and quality testing.
Competencies and Qualities
Qualified candidates must have the following competencies and qualities:
Able to handle client issues and/or complaints with diplomacy
Able to work well with clients of varying technological abilities to resolve issues
Strong technological troubleshooting skills
Deadline and detail-oriented
Strong analytical and critical thinking skills
Curious and interested in learning new technologies and languages
Resourceful and creative problem solver
Self-starter with the ability to work on multiple projects simultaneously
Able to effectively communicate and collaborate with coworkers to work toward common goals
Education, Experience, and Certifications
Required
Bachelor's degree in Computer Science, Software Engineering, or related field
2+ years experience in a professional development environment
Experience with strongly typed languages such as C# or Java
Experience with loosely typed languages such as JavaScript or Python
Some experience with relational databases and SQL
Understanding of common Git source control workflows
Preferred
Experience in print and mailing industry
Familiar with object-oriented patterns, TDD, and other modern software engineering principles
Experience with common data formats such as XML, fixed-width data, and financial statements
Experience with data conversions
Experience with IText Sharp library
Experience with reporting tools such as Quadient Inspire Designer, SQL Server Reporting Services (SSRS), or similar large data composition tool
Experience with client-side web development
Familiarity and/or experience with color management/color theory
Supervisory Responsibility
This position has no direct supervisory responsibilities.
Work Environment
In most cases, work will be performed in a climate-controlled office space. If approved for remote work, employees may work from a home office that is appropriate for focused work without distractions; all remote work must comply with the Remote and Telework Policy.
Travel
This role requires no travel.
Physical Demand
This role will require using a computer for long periods of time while either sitting or standing.
Position Type and Expected Hours
This is a full-time position for five, eight-hour days (at least 40 hours) per week. Typical workdays begin at 8:00 AM and end at 5:00 PM local time, Monday through Friday, and include a one-hour lunch break, circumstances may require night and weekend work in order to remain available for area(s) of oversight.
Other Duties
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities. Activities, duties, and responsibilities may change at any time with or without notice.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931943397,Glassdoor,Microchip Technology,1140002622,88000,123000,"https://www.glassdoor.com/Overview/Working-at-Microchip-Technology-EI_IE2298.11,31.htm","Are you looking for a unique opportunity to be a part of something great? Want to join a 20,000-member team that works on the technology that powers the world around us? Looking for an atmosphere of trust, empowerment, respect, diversity, and communication? How about an opportunity to own a piece of a multi-billion dollar (with a B!) global organization? We offer all that and more at Microchip Technology, Inc.
People come to work at Microchip because we help design the technology that runs the world. They stay because our culture supports their growth and stability. They are challenged and driven by an incredible array of products and solutions with unlimited career potential. Microchip’s nationally-recognized Leadership Passage Programs support career growth where we proudly enroll over a thousand people annually. We take pride in our commitment to employee development, values-based decision making, and strong sense of community, driven by our
Vision, Mission, and 11 Guiding Values
; we affectionately refer to it as the Aggregate System and it’s won us countless awards for diversity and workplace excellence.
Our company is built by dedicated team players who love to challenge the status quo; we did not achieve record revenue and over
30 years of quarterly profitability
without a great team dedicated to empowering innovation. People like you.
Visit our
careers
page to see what exciting opportunities and company
perks
await!
Job Description:
We are seeking a driven, detail-oriented Data Scientist I to join our growing team. In this role, you will use your analytical, statistical, and programming skills to collect, analyze, and interpret large data sets. You will then use this information to develop data-driven solutions to difficult business challenges.
Requirements/Qualifications:
Requirements:
BS (or higher) in Computer Science, Engineering or relevant field
Proven experience as a Data Scientist or Data Analyst
Experience in Python, including scientific libraries (e.g. NumPy, SciPy, and pandas)
Experience in machine learning libraries (e.g. TensorFlow, Keras, and PyTorch)
Knowledge of cloud-based data organization and machine learning pipeline implementation (e.g. AWS, Azure).
Experience with MLOps tools (Databricks, Airflow, and MLFlow preferred)
Strong math skills (e.g. statistics, algebra, calculus)
Problem-solving aptitude
Excellent communication and presentation skills
Responsibilities:
Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build and deploy predictive models and machine learning algorithms
Produce recommendations and use statistical techniques and hypothesis testing to validate your findings
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering, product development, and operations teams
Travel Time:
0% - 25%
Physical Attributes:
Hearing, Seeing, Talking, Works Alone
Physical Requirements:
80% sitting, 10% standing, 10% walking, 100% inside
Microchip Technology Inc is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

For more information on applicable equal employment regulations, please refer to the
EEO is the Law Poster
and the
EEO is the Law Poster Supplement
. Please also refer to the
Pay Transparency Policy Statement
.",TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932370041,Glassdoor,AURA TECHNOLOGIES LLC.,1644061540,71000,108000,"https://www.glassdoor.com/Overview/Working-at-AURA-Technologies-LLC-EI_IE2570014.11,32.htm","AURA TECHNOLOGIES, LLC (AURA) is an advanced research and development (R&D) and technology company creating game-changing innovations for the US Department of Defense in Artificial Intelligence (AI) and in other systems-level implementation of cutting-edge technology. We are creating advanced intelligent power systems for the US Army; unconventional tactical lights for the US Marines; revolutionary satellite manufacturing for the US Air Force; and a range of AI platforms for DoD implementation. AURA partners with some of the best companies in the world, such as Boeing, Northrop Grumman, and Lockheed Martin. We also collaborate with the best and brightest at our nation’s universities, including Georgia Tech and NC State University.

If you are a smart, capable, and talented individual who possesses high integrity, thrives in a fast-paced environment, wants to chart your own course based on your capabilities, and is willing to be accountable for failures and successes, then continue reading because you may be the ideal candidate to join our growing R&D business.


AURA has an immediate opening for a full-time Data Engineer (remote).

ESSENTIAL DUTIES AND RESPONSIBILITIES:
You will work side-by-side with other team members to provide technical direction and recommendations on how to: standardize, normalize, and format data; extract valuable features from large data sets; develop data pipelines and write preprocessing algorithms; and train others to use and maintain developed tools/applications.

Work on projects involving time-series data, image recognition, computer vision, and geometric shape modeling
Preprocess and extract features from sensor-based, three-dimensional, and visual data
Develop applications to sustain data pipelines, interact with databases, and ensure uptime
Interact with big data applications for visual, video, and geometric information
Collaborate closely with data scientists to ensure that data throughput and preprocessing requirements are met
Work in a team environment to collaborate with coworkers, partners, and clients to produce an integrated solution. Given the demanding, diverse, and fast-paced environment, the Data Engineer must also possess exceptional attention to detail.

WORK EXPERIENCE, EDUCATION & TECHNICAL REQUIREMENTS:

Minimum Years of Work Experience:
Minimum of 1 year of experience in a data engineer, cloud engineer, database management, or similar role (advanced degrees may be substituted for experience in the case of a qualified candidate)

Minimum Education:
Masters degree in Computer Science, Engineering, Data Science, Statistics, or a related technical degree

Minimum Technical Requirements:
Expertise in one or more structured database management system types/vendors such as MySQL, Oracle, or SQLite
Programming expertise in one or more scripting languages, such as Python or R

PREFERRED REQUIREMENTS
Prior DoD or military experience
Doctorate degree in Computer Science, Engineering, Data Science, Statistics, or a related technical degree

ADDITIONAL REQUIREMENTS:
US citizenship status is required for this position due to AURA’s contractual obligations to the US Department of Defense (DoD) requiring all employees working in performance of DoD contracts to be US citizens.


BENEFITS:
401(k) Safe Harbor Contribution
Flexible schedule
Health insurance
Discretionary Leave
14 Paid holidays

TO APPLY FOR THIS POSITION:
Submit your resume/CV in PDF format via instructions at the following link: http://aura.company/careers/
No phone calls after submission. We will let candidates know via automated reply that we have received their resumes and will contact them if there is a good fit after the closing date for this job.

AURA Technologies, LLC is an Equal Opportunity Employer and affirmative action employer of veterans protected under the Vietnam Era Veterans’ Readjustment Assistant Act (VEVRAA). We are a Drug Free Workplace and thus, all job offers are contingent on successful criminal background check and drug screen. As a US Federal Contractor, AURA uses the Department of Homeland Security e-Verify system to determine eligibility to legally work in the United States. Most of AURA’s work is for the federal government, and federal regulations may in the future require AURA’s employees to be fully vaccinated against the COVID-19 virus.

Write a carefully crafted, well-written cover letter that elaborates on your interest in this position and why you think you are the best candidate for the job. Submit your cover letter, CV and three professional references (one of which must be from a current or former supervisor) in PDF format ONLY via BambooHR.

Any attachments must be in PDF format or will not be opened due to virus concerns. No phone calls after submission. We will let candidates know via automated reply that we have received their resumes and will contact them if there is a good fit after the closing date for this job.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931763843,Glassdoor,Combined Insurance,730049659,89000,124000,"https://www.glassdoor.com/Overview/Working-at-Combined-Insurance-EI_IE14569.11,29.htm","As a Sr. Data Engineer on our team, you will work on implementing complex data projects focusing on collecting, parsing, managing, analyzing, and visualizing large sets of data to turn information into insights using multiple platforms. We will look to you to be able to decide on hardware and software design needs and act according to the decisions as well as develop a proofs of concept for the selected solutions.
We are looking for someone with a strong background in computer programming, data analysis, and visual analytics who is eager to tackle problems with large, complex datasets using the latest skills. You are a self-starter who will take ownership of your projects and deliver high-quality data-driven analytics solutions. You can solve diverse business problems using various tools, strategies, algorithms, and programming languages.
Responsibilities
Utilize the data engineering skills within and outside of the developing Chubb information ecosystem for discovery, analytics, and data management
Work with the data SME, Business Analyst team to design the solutions
You will be using strong SQL skills to convert one 'raw' data from XML to a structured format
Work with various relational and non-relational data sources with the target being Azure-based SQL Data Warehouse
Sourcing data from underwriting applications, profiling, cleansing, and conforming to create master data sets for analytics use
Clean, unify, and organize messy and complex data sets for easy access, different levels of abstractions, and analysis
Hands-on data preparation activities using the SSIS package development
Partner with the Global Data Analytics team to navigate the discovery solutions for data ingestion
Work closely with the Data Science team to perform complex analytics and data preparation tasks
Build, deploy, and support applications, services, and APIs that meet business requirements in a highly complex technical environment
Co-ordinate with business stakeholders, business analysts, and project stakeholders to ensure proper assignments of a user story that meets business needs and SLAs
Interfaces with business areas and other Chubb IT teams to coordinate work, manage cross-functional dependencies, and foster collaboration
Ensuring application stability, and participating in resolving incidents and problems.
Leverage your technical insights to stay on top of technical trends, evaluate new technologies, and develop proofs of concept for incorporation into our infrastructure",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931252403,Glassdoor,Red Bull North America,1931458236,90000,138000,"https://www.glassdoor.com/Overview/Working-at-Red-Bull-EI_IE12190.11,19.htm","Reporting to the Senior Director, Data Science, you will join the Red Bull North America data science team and work with our HQ data science team in Austria. As the Data Engineer you will apply your expertise in developing data pipelines and data models to support mainly data scientists to build statistical models and complete analyses more efficiently. You'll partner with data scientists and business leaders, helping them define and refine their data needs and then build sustainable data pipelines and structures. This is a unique opportunity for a Data Engineer to work directly within a data science team in the business to solve big problems and make a difference. You will stay on top of the latest data technology developments and act as a knowledge hub for data-related issues at Red Bull North America but also globally. If you're motivated by solving problems and making an impact with data, this is the role for you.

RESPONSIBILITIES

Areas that play to your strengths

All the responsibilities we'll trust you with:
MANAGE DATA SCIENCE

Manage data science data projects from ideation through delivery.

Work with data scientists and collaborators (marketing, sales, operations, and supply chain) to gather needs, communicating easily and comfortably while promoting partnership.

SOLVE DATA PROBLEMS

Partner with IT and BI to ensure data models and pipelines are designed to be available, scalable, maintained, and accurate.

Solve challenging data integration problems, using ETL patterns, frameworks, query techniques, sourcing from all structured and unstructured data sources.

EXPERIENCE

Your areas of knowledge and expertise

that matter most for this role:
5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field. Bonus if within the CPG industry.
Experience with data modeling, data warehousing, and building ETL pipelines. Bonus if you've experience preparing data for machine learning model training and real-time use cases.
Experience working with data scientists to grow model training, explore new data sources, and feature extraction.
Experience in SQL and Python coding languages. R coding experience.
Experience conceptualizing and overseeing end-to-end data models and evaluating design tradeoffs within systems.
Experience working with both technical and non-technical collaborators to understand data needs and turn into data models.
Experience working with a cloud-based service such as AWS, Azure or GCP.
Experience using big data technologies.
Proficient in Tableau and/or PowerBI and/or SAP Analytics Cloud.
Knowledge of data management fundamentals and data storage principles.
Bachelor's or Master's degree in computer science, engineering, mathematics, or a related technical discipline preferred.
Travel 0-10%
Permanent
Benefits eligible

WHERE YOU'LL BE BASED

Santa MonicaCalifornia, United States

United StatesRed Bull North America

JOIN THE TEAM",TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931864801,Glassdoor,HCA Healthcare,1033307533,76000,104000,"https://www.glassdoor.com/Overview/Working-at-HCA-Healthcare-EI_IE2062.11,25.htm","Introduction
Are you looking for a work environment where diversity and inclusion thrive? Submit your application for our Data Engineer opening with HCA Healthcare today and find out what it truly means to be a part of the HCA Healthcare team.
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.
We are seeking a Data Engineer for our team to ensure that we continue to provide all patients with high quality, efficient care. Did you get into our industry for these reasons? We are an amazing team that works hard to support each other and are seeking a phenomenal addition like you who feels patient care is as meaningful as we do. We want you to apply!
Job Summary and Qualifications
This position is part of an ETL development team responsible for analysis, design, development, and support of Data Warehouse ETL pipelines. The Data Engineer will spend time writing, testing, and reviewing ETL pipelines alongside other developers. Other tasks include researching, architecting, requirements gathering, designing, documenting, and modifying software throughout the complete production life cycle.
This position works with business analysts and project managers on business requirement reviews, task breakdown and estimation, and technical documentation.
Major Responsibilities:
Our Purpose
Applied to this position, your skills will help transform healthcare through technology and solutions that dramatically improve patient care and business operations.
At HCA ITG, your deliverables will influence patient care. Every process, technology and decision matters.
Develop, maintain, and optimize streaming, near real-time, and batch ETL pipelines using a combination of SQL, Teradata BTEQ and TPT scripts, Unix/Linux shell scripts, and Python scripts.
Contribute to and participate in peer code reviews.
Participate in on-call support rotation.
Adhere to established development guidelines.
Translate business requirements into technical design specifications.
Estimate, establish, and meet target dates.
Create and maintain technical documentation, including source-to-target mappings, job scheduling and dependency details, and business-driven transformation rules.
Propose and implement process improvements with reporting applications and the overall development process.
Mentor and assist junior team members during onboarding and day-to-day tasks.
Practices and adheres to the “Code of Conduct” philosophy and “Mission and Value Statement.”
Education & Experience:
Bachelor's degree preferred
5+ years of experience in Information Technology required
3+ years of experience in Data Warehouse ETL/ELT Development required
1+ year(s) of experience in Google Cloud Platform (GCP) Data Engineering required
1+ year(s) of experience in Healthcare IT preferred
Or equivalent combination of education and/or experience
Knowledge, Skills, Abilities, Behaviors:
Data Warehouse experience on Teradata and GCP BigQuery
Experience with ETL tools such as ConnectETL/DMExpress, DataStage, and/or StreamSets.
Experience with orchestration tools such as Apache Airflow.
Experience with Oracle, SQL Server, and other database platforms.
Scripting experience with Unix/Linux shell and Python.
Experience with Git and GitHub source control.
Knowledge of issue tracking tools such as Jira and ServiceNow.
Ability to troubleshoot, maintain, reverse engineer and optimize existing ETL pipelines.
Ability to analyze and interpret complex data, and offer solutions to complex clinical problems.
Ability to work independently on assigned tasks.
Strong written and verbal communication skills including the ability to explain complex technical issues in a way that non-technical people may understand.
Excellent problem-solving and critical thinking skills.
Knowledge of IT governance and operations.

HCA Healthcare has been recognized as one of the Worldâ€™s Most Ethical CompaniesÂ® by the Ethisphere Institute more than ten times. Â In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Across HCA Healthcare’s more than 2,000 sites of care, our nurses and colleagues have a positive impact on patients, communities and healthcare.
Together, we uplift and elevate our purpose to give people a healthier tomorrow.""- Jane Englebright, PhD, RN CENP, FAAN
Senior Vice President and Chief Nursing Executive
If you find this opportunity compelling, we encourage you to apply for our Data Engineer opening. We promptly review all applications. Highly qualified candidates will be directly contacted by a member of our team. We are interviewing apply today!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE
1008931622786,Glassdoor,"Intelliswift Software, Inc.",991104980,,,"https://www.glassdoor.com/Overview/Working-at-Intelliswift-EI_IE232377.11,23.htm","Title - Data Engineer
Location • San Jose, CA
Duration • 12 Months
Pay rate • $99.13 per hour on W2
Write complex SQL queries that help Adobe identify and measure the non-genuine software base. Apply business logic to determine categorize the non-genuine base into opportunities Use Big Data best practices to help scale the piracy conversion program Create dashboards in tableau Apply statistical methodologies and data mining skill sets on large volume of data Analyze data and provide insights to senior executives
SQL Expertise. Hadoop expertise. Can work in hive, pig etc Create dashboards in tableau and excel Modelling in Excel. Power Pivot expertise a must Understanding of statistics concepts Ability to interpret data and present Excellent written and verbal communication skills",FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932739910,Glassdoor,CareFirst BlueCross BlueShield,1310865191,,,"https://www.glassdoor.com/Overview/Working-at-CareFirst-BlueCross-BlueShield-EI_IE269607.11,41.htm","Resp & Qualifications
PURPOSE:
The Lead Data Engineer is responsible for orchestrating, deploying, maintaining and scaling cloud OR on-premise infrastructure targeting big data and platform data management (Relational and NoSQL, distributed and converged) with emphasis on reliability, automation and performance. This role will focus on leading the development of solutions and helping transform the company's platforms deliver data-driven, meaningful insights and value to company.

ESSENTIAL FUNCTIONS:
Lead the team to design, configure, implement, monitor, and manage all aspects of Data Integration Framework. Defines and develop the Data Integration best practices for the data management environment of optimal performance and reliability.
Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Informatica, Snowflake, and Azure SQL.
Provides detailed guidance and performs work related to Modeling Data Warehouse solutions in the cloud OR on-premise. Understands Dimensional Modeling, De-normalized Data Structures, OLAP, and Data Warehousing concepts.
Oversees the delivery of engineering data initiatives and projects. Supports long term data initiatives as well as Ad-Hoc analysis and ELT/ETL activities. Creates data collection frameworks for structured and unstructured data. Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources.
Enforces the implementation of best practices for data auditing, scalability, reliability and application performance. Develop and apply data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources.
Interprets data, analyzes results using statistical techniques, and provides ongoing reports. Executes quantitative analyses that translate data into actionable insights. Provides analytical and data-driven decision-making support for key projects. Designs, manages, and conducts quality control procedures for data sets using data from multiple systems.
Improves data delivery engineering job knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies.

SUPERVISORY RESPONSIBILITY:
Position does not have direct reports but is expected to assist in guiding and mentoring less experienced staff. May lead a team of matrixed resources.

QUALIFICATIONS:

Education Level: Bachelor's Degree in Computer Science, Information Technology or Engineering or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.

Experience: 8 years Experience in leading data engineering and cross functional team to implement scalable and fine tuned ETL/ELT solutions for optimal performance. Experience developing and updating ETL/ELT scripts. Hands-on experience with application development, relational database layout, development, data modeling.

Knowledge, Skills and Abilities (KSAs)
Knowledge and understanding of Informatica including Cloud version (IICS).
Knowledge and understanding of Cloud Platforms (ie. Azure).
Knowledge and understanding of Cloud Databases (ie. Snowflake, Azure SQL).
Knowledge and understanding of at least one programming language (i.e., SQL, NoSQL, Python).
Knowledge and understanding of database design and implementation concepts.
Knowledge and understanding of data exchange formats.
Knowledge and understanding of data movement concepts.
Strong technical and analytical and problem solving skills to troubleshoot to solve a variety of problems.
Requires strong organizational and communication skills, written and verbal, with the ability to handle multiple priorities.
Able to effectively provide direction to and lead technical teams.
Must be able to meet established deadlines and handle multiple customer service demands from internal and external customers, within set expectations for service excellence. Must be able to effectively communicate and provide positive customer service to every internal and external customer, including customers who may be demanding or otherwise challenging.

Salary Range: $105,408 - $209,352
Salary Range Disclaimer
The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the work is being performed. This compensation range is specific and considers factors such as (but not limited to) the scope and responsibilites of the position, the candidate's work experience, education/training, internal peer equity, and market and business consideration. It is not typical for an individual to be hired at the top of the range, as compensation decisions depend on each case's facts and circumstances, including but not limited to experience, internal equity, and location. In addition to your compensation, CareFirst offers a comprehensive benefits package, various incentive programs/plans, and 401k contribution programs/plans (all benefits/incentives are subject to eligibility requirements).
Department
Department: ODS/ETL Members
Equal Employment Opportunity
CareFirst BlueCross BlueShield is an Equal Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.
Where To Apply
Please visit our website to apply: www.carefirst.com/careers
Federal Disc/Physical Demand
Note: The incumbent is required to immediately disclose any debarment, exclusion, or other event that makes him/her ineligible to perform work directly or indirectly on Federal health care programs.
PHYSICAL DEMANDS:
The associate is primarily seated while performing the duties of the position. Occasional walking or standing is required. The hands are regularly used to write, type, key and handle or feel small controls and objects. The associate must frequently talk and hear. Weights up to 25 pounds are occasionally lifted.
Sponsorship in US
Must be eligible to work in the U.S. without Sponsorship
#LI-LD1",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931864702,Glassdoor,N/A,1797317630,,,N/A,N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931312093,Glassdoor,InvoiceCloud,2001606548,,,"https://www.glassdoor.com/Overview/Working-at-InvoiceCloud-EI_IE1715431.11,23.htm","About InvoiceCloud:
InvoiceCloud, an EngageSmart solution, is a leading provider of online bill payment services. Founded in 2009, the company has grown to be one of the leading disruptors in the cloud-based electronic bill presentment and payment (EBPP) space, helping institutions put customer experience first. By switching to InvoiceCloud, clients can improve customer engagement, loyalty, and efficiency while reducing churn and missed payments in the process. With over 50 million payments processed annually, InvoiceCloud is one of the most secure, innovative, and inclusive fintech solutions in the market. To learn more, visit www.InvoiceCloud.com.
As a Data Conversion Engineer on our integrations team, you will work to convert data for InvoiceCloud clients as they transition or upgrade their core processing system, ensuring their customers' online bill paying experience remains consistent and uninterrupted. You will be responsible for analyzing the source data, designing the target data format, extracting existing data, and performing the transform & load. You will be encouraged to develop automated scripts and tools to facilitate repeatable conversions where possible.
As a Data Conversion Engineer You Will:
Understand how to write and troubleshoot complex SQL queries
Understand ETL (Extract, Transform, and Load) processes and tools
Create wikis for data conversion processes and tools
Able to handle a fast-paced environment
Able to multitask efficiently
What We Seek:
Bachelor's Degree preferred or equivalent combination of education and experience required
5 years of Experience using Microsoft Technologies including VB.NET, ASP.NET, C#, Visual Studio
Proficiency with SQL Server and Microsoft ETL tools
Machine learning and automation experience a plus
Self-led, capable of working with little direction
Skilled communicator with a collaborative spirit
Base Compensation Range: ($70,000.00 to $90,000.00) annually
Base salary is one component of total compensation. Employees may also be eligible for an annual bonus or commission and equity. Some roles may also be eligible for overtime pay.
The above represents the expected base compensation range for this job requisition. Ultimately, in determining your pay, we'll consider many factors including, but not limited to, skills, experience, qualifications, geographic location, and other job-related factors.
Benefits
We offer a competitive benefits program including:
Medical, dental, vision, life & disability insurance
401(k) plan with company match & employee stock purchase plan (ESPP)
Flexible Time Off (FTO), wellbeing days, paid holidays, and summer Fridays
Mental health resources
Paid parental leave & Backup Care
Tuition reimbursement
Employee Resource Groups (ERGs)
Invoice Cloud is an Equal Opportunity Employer.
Invoice Cloud provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at our company, please contact jobs@engagesmart.com.
Click here to review EngageSmart's Job Applicant Privacy Policy.
To all recruitment agencies: Invoice Cloud does not accept agency resumes. Please do not forward resumes to our job's alias, employees, or any other organization location. Invoice Cloud is not responsible for any fees related to unsolicited resumes.",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931270559,Glassdoor,Fifth Third Bank,76421804,84000,116000,"https://www.glassdoor.com/Overview/Working-at-Fifth-Third-EI_IE1395.11,22.htm","Make banking a Fifth Third better®

We connect great people to great opportunities. Are you ready to take the next step? Discover a career in banking at Fifth Third Bank.
GENERAL FUNCTION:
Designs and implements software & support solutions as a member of an agile squad. Software in scope are 3rd party software applications which support finance and regulatory reporting business functions. Technical support functions include ETL, file transfer services, job scheduling, multiple environment support, data quality, upgrades, incident & problem resolution, etc. Being assigned to an agile squad means this role also participates in all agile ceremonies driving activities from design to delivery. Follows best practices and standards and participates in communities of practice to continuously refine and document these standards, following any required compliance & governance requirements.
Responsible and accountable for risk by openly exchanging ideas and opinions, elevating concerns, and personally following policies and procedures as defined. Accountable for always doing the right thing for customers and colleagues, and ensures that actions and behaviors drive a positive customer experience. While operating within the Bank's risk appetite, achieves results by consistently identifying, assessing, managing, monitoring, and reporting risks of all types.
ESSENTIAL DUTIES AND RESPONSIBILITIES:
Provide technical knowledge, leadership and collaboration as an ETL developer & designer
Develop and maintain data transfer jobs & schedulers, as required, including to identify & execute opportunities to automate
Achieve operational excellence by automating processes and writing maintainable, supportable, and testable code
Assist with problem resolution for end users and customers, including incident & problem management
Support both application and environment upgrades, new implementations & patches, as required.
Develop software meeting code quality standards and metrics
Participate in communities of practice by contributing to and following standards, test driven development, reviewing others code, and sharing knowledge
Maintain effective partnerships with operations and engineering teams to drive service improvement
Remain current on IT trends pertaining to their area of practice
Contribute to the definition of operational procedures for software development
Maintain appropriate controls and documentation to ensure compliance of audit requirements
MINIMUM KNOWLEDGE, SKILLS AND ABILITIES REQUIRED:
Prior experience with Alation, Snowflake, NIFI/KAFKA, API utilization
Strong SQL Skills with ability to perform ETL
Strong understanding of database design and data modeling techniques
Understanding of data management and info security best practices
Familiarity with relational database systems (SQL Server, Oracle, Postgres, DB2)
Understanding of Object-Oriented Programming Languages
Understanding of Software Development Lifecyle
Demonstrated practice for scripting languages, like Python, Java, Powershell
Understanding of Agile Software Development methodologies and ability to write user stories in gherkin syntax
Prior experience with PowerBI, Tableau, & Git is a plus
Demonstrated problem solving skills
Demonstrated collaboration skills
Excellent verbal and written communication skills
#LI-RW1
Data Engineer II
LOCATION - Cincinnati, Ohio 45227
Fifth Third Bank, National Association is proud to have an engaged and inclusive culture and to promote and ensure equal employment opportunity in all employment decisions regardless of race, color, gender, national origin, religion, age, disability, sexual orientation, gender identity, military status, veteran status or any other legally protected status.",TRUE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932012078,Glassdoor,Lumen,1548728967,,,"https://www.glassdoor.com/Overview/Working-at-Lumen-EI_IE248324.11,16.htm","About Lumen
Lumen is a global technology leader, digitally connecting people, data and applications – quickly, securely, and effortlessly. Together, we are building a culture and company from the people up – committed to teamwork, trust and transparency. People power progress. We’re looking for top-tier talent and offer the flexibility you need to thrive and deliver lasting impact. Join us as we digitally connect the world and shape the future.
The Role
Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen’s reputation as a technology leader?

In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence.
The Main Responsibilities
You are a great fit for this position if you:
Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions.
Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments.
Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in.
Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations.
What We Look For in a Candidate
Qualifications:
Experience building data models and performing complex queries using SQL
Experience performance tuning large datasets
Experience building large data pipelines and/or web services
Strong programming skills with Python and other scripting languages
4+ years of Business Intelligence or software development experience using industry technologies
3+ years of experience in building integration with upstream and downstream systems with REST APIs
Excellent problem solving, critical thinking, and communication skills
Ability to communicate effectively with technical and business teams, drive issues to closure
Strong understanding of data engineering and data stewardship roles in an organization
Strong time management and organization skills. Ability to work on multiple projects concurrently.
BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science

Other Qualifications:
Strong familiarity with Azure ecosystem is highly valuable
Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable
Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies
Combined IT and Marketing background
Machine Learning, Data Science, and statistical modeling experience are highly valued
Compensation
The starting salary for this role differs based on the employee's primary work location. Employees typically do not start at the top of the range, though compensation depends on each individual's qualifications.
Location Based Pay Ranges
$80510 - $100635 in these states: AR, ID, KY, LA, ME, MS, NE, SC, and SD.
$84740 - $105923 in these states: AZ, FL, GA, IN, IA, KS, MO, MT, NM, ND, OH, OK, PA, TN, UT, VT, WV, WI, and WY.
$88980 - $111218 in these states: CO, HI, MI, MN, NV, NH, NC, OR, and RI.
$93210 - $116513 in these states: AK, CA, CT, DE, DC, IL, MD, MA, NJ, NY, TX, VA, and WA.
As with the pay range variety that's based on the region of a country, specific offers are determined by various factors such as experience, education, skills, certifications and other business needs.
Requisition #: 331444
Background Screening
If you are selected for a position, there will be a background screen, which may include checks for criminal records and/or motor vehicle reports and/or drug screening, depending on the position requirements. For more information on these checks, please refer to the Post Offer section of our FAQ page. Job-related concerns identified during the background screening may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Equal Employment Opportunities
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, gender expression, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
Disclaimer
The job responsibilities described above indicate the general nature and level of work performed by employees within this classification. It is not intended to include a comprehensive inventory of all duties and responsibilities for this job. Job duties and responsibilities are subject to change based on evolving business needs and conditions.
Salary Range
Salary Min :
80510
Salary Max :
116513
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931105109,Glassdoor,Hero Digital - Job Board,639528106,101000,146000,"https://www.glassdoor.com/Overview/Working-at-Hero-Digital-EI_IE977686.11,23.htm","The Data Engineer role at Avionos, a Hero Digital Company is an integral member of our analytics team responsible for working with our clients to extract, integrate and transform their data to make it accessible and ready to be developed into visualizations using business intelligence tools. This role manages our cutting edge data stack, including FiveTran, Snowflake and Tableau to prepare fully integrated data sets that our visualization team can use to develop dashboards for internal and external clients. As a B2B demand generation agency, we have extensive marketing and sales performance data from many different platforms that must be joined together and normalized in order to develop always on, fresh data for our clients. This role also serves as a consultant to our clients to help enable their analytics team to leverage the data that our system provides to incorporate in their internal reporting. The Data Engineer works closely with our closed-loop system product team to design systems to get the data our clients need to fuel their business, and it works with the BI visual design team to build interactive dashboards for the internal and external execution teams.
The right candidate will be able to use our ETL tool and data warehouse (FiveTran and Snowflake) to aggregate all relevant data, and will possess advanced SQL skills to integrate data from multiple sources including Salesforce, Marketo, Pardot, Google Adwords, Bing, Facebook, LinkedIn and other media sources. Familiarity with the Salesforce data model is a major plus for this role, as are experience with media and web analytics platforms (especially Google products). Superior problem solving skills, impeccable attention to detail, and a passion for data are required traits for success in this role.
What you'll do
Managing the data tech stack, including the ETL and data warehouse
Setup and maintenance of data extraction and data collection processes
Joining, blending and cleansing data using SQL (and related languages)
Troubleshooting data. Finding points of failure in the data collection or sales process and working with the revenue operations team to implement solutions
Analyzing client data to identify opportunities for improvement within the sales and marketing programs
Developing innovative solutions to enable self-serve data cleansing, categorization and maintenance for our internal team and clients
Consulting with clients to enable them to use our data sets and data models to support their internal BI teams
Who you are
Minimum of 2 years of data integration and data engineering experience
Advanced SQL experience (R and Python are a plus)
Familiarity with the Salesforce and marketing automation platform data models
Deep experience working with relational databases
BI platform experience, with working knowledge of Tableau Desktop and Tableau Online is a big plus
Advanced analytics, critical thinking and problem solving skills
Excellent interpersonal and communication skills
Strong project management experience
Keen interest in using data to drive business and marketing decisions for clients
Acute attention to detail and rigor around your work
Wants to be part of building an agency from the ground up with people who challenge you
Enjoys working directly with clients, consulting them on opportunities to embrace a data driven culture

All qualified applicants will receive consideration for employment without regard to race, color, age, marital status, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, medical condition, physical or mental disability, genetic information or military and veteran status
Who we are
We are a leading independent customer experience agency in North America that was born in California, at the intersection of business, design and technology. Our purpose is to bring moments of Truth & Beauty into people's lives by creating customer experiences that are good for people and good for business. We drive growth and loyalty through a relentless focus of placing our client's customers at the center of their business. Led by the experts in strategy, marketing, data, design, and technology, we work in blended teams, solving client problems and delivering results at market speed. These teams help Fortune 500 companies like Comcast, Oracle, Twitter, U.S. Bank, Salesforce, Sephora, UnitedHealthcare, and TD Ameritrade Institutional invent, transform, and perform to deliver new brand and business value.
Do you share the values that set our company apart?

We are expanding our team of humble and hardworking people who share the qualities we believe in. We seek those who are Wholehearted, Craft-driven, and Bright.
We are grounded in the values of who we are that ultimately lead to moments of Truth & Beauty. We celebrate leaders at all levels who take risks and create magic. We bring our complete, genuine, and whole-hearted selves forward each day. We are craft-driven in nature, with strong curiosities, but with a diligent and meticulous approach. And we bring an unexpected brightness through imagination, inspiration and an optimistic mindset. The commitment we make to our work is the source of our pride and the basis of our reputation.
Above all, Hero Digital is committed to creating an inclusive employee experience. One that reflects the world we live in today. We are an equal opportunity employer that welcomes people regardless of backgrounds, experiences, abilities, and perspectives.",TRUE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931571132,Glassdoor,N/A,1797317630,,,N/A,"Lead Data Engineer:
Building Climate Solutions for Cities
Link to application: https://noteforms.com/forms/openearth-job-application-ctwllg
Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats.
Open Earth Foundation is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis.
We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in climate finance, biodiversity tracking, community empowerment and other critical problems and solutions.
We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups.
We have funding and a team of experts focused on Earth systems and digital innovation.
Your mission, should you choose to accept it:
As a lead data engineer, you will leverage your data and engineering expertise and analytical skills to build open digital infrastructure, with a particular focus on our newly launched CityCatalyst project.
As a Lead Data Engineer you will provide leadership and hands-on data management in our climate accounting technology programs. Your work will cover climate data pipelines, infrastructure design and implementation, working on greenhouse gas data inventories from satellite imagery and diverse data sources, being part of a software production team and even interfacing with new AI and LLM tools for data harmonization.
You will be part of the technical team and work directly with the Director of Open Technology. You will also work with a variety of team members in the organization from the Product Team and Community Manager.
The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them.
The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway. Let us know if there is something missing and how we can work together to make it up.
Essential Functions and Specific Duties:
Design, architect, build and maintain data pipeline systems
Write code for importing and updating large datasets to relational database and search indexes
Define and maintain database schemas and data file formats
Collaborate with web developers on optimizing database schemas for APIs and Web applications
Collaborate with a team of software engineering peers
Mentor and guide more junior data engineering staff
Define and maintain data management processes for the organization
Work with product managers to develop schedules, estimate tasks, and define success criteria
Collaborate with team members from other disciplines such as web development, design, product management, and devops
Coordinate with Open Source contributors
Coordinate with open standards community to define interoperability standards
Actively participate in team building and culture development activities at Open Earth Foundation
Other duties as assigned
Required skills:
Python programming focused on big data management
PostgreSQL or other relational database
Docker
Kubernetes
Git
Optional skills that will make a candidate stand out:
Generative AI and large language model (LLM) APIs and data applications
GIS tools such as ESRI
Amazon Web Services
ElasticSearch
Data pipeline tools, e.g. Pachyderm
Experience with 100Gb or larger data sets
Climate action data such as emissions, targets, and action plans
Physical (lat, lon, alt) and political (city, state, country) geographical data
Remote-sensing and satellite data
RESTful Web APIs
Engineering leadership
Open Source project maintainership
Machine learning, especially for anomaly detection, pattern recognition, clustering, time series analysis
Qualifications:
Bachelor’s degree in computer science, electrical engineering, or equivalent technical or scientific degree, or equivalent on-the-job experience
5 years of experience in software development for data systems
3 shipped projects
Interpersonal skills:
Clear communicator with good verbal and written skills in English (additional languages a plus)
Creative, flexible and efficient with a focus on details
Capacity to work with team members and partners at all levels and across time zones in a highly collaborative and often remote environment.
Ability to embrace new challenges, take ownership and initiative as a key team player.
Compensation and benefits
This position is full-time with compensation of $60,000-$105,000 /year, dependent on experience and location
Open Earth offers unlimited paid time off, paid holidays and paid sick leave
You will work remotely within a dynamic and international environment
We celebrate our achievements during our annual team retreat
OEF is an Equal Employment Opportunity Employer. We support diversity, equity and inclusion in teams, and believe people should align their work with their purpose. Join us if you love Earth.
Please apply by submitting your resume AND a cover letter, it is your opportunity to highlight why you feel you would be a great addition to the team.
We look forward to hearing from you!
Open Earth Foundation seeks diverse applicants from underrepresented communities. If you would like to pursue this job opportunity but don’t believe you meet all the requirements, please apply and note what’s missing in your cover letter.Lead Data Engineer:
Building Climate Solutions for Cities
Link to application: https://noteforms.com/forms/openearth-job-application-ctwllg
Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats.
Open Earth Foundation is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis.
We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in climate finance, biodiversity tracking, community empowerment and other critical problems and solutions.
We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups.
We have funding and a team of experts focused on Earth systems and digital innovation.
Your mission, should you choose to accept it:
As a lead data engineer, you will leverage your data and engineering expertise and analytical skills to build open digital infrastructure, with a particular focus on our newly launched CityCatalyst project.
As a Lead Data Engineer you will provide leadership and hands-on data management in our climate accounting technology programs. Your work will cover climate data pipelines, infrastructure design and implementation, working on greenhouse gas data inventories from satellite imagery and diverse data sources, being part of a software production team and even interfacing with new AI and LLM tools for data harmonization.
You will be part of the technical team and work directly with the Director of Open Technology. You will also work with a variety of team members in the organization from the Product Team and Community Manager.
The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them.
The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway. Let us know if there is something missing and how we can work together to make it up.
Essential Functions and Specific Duties:
Design, architect, build and maintain data pipeline systems
Write code for importing and updating large datasets to relational database and search indexes
Define and maintain database schemas and data file formats
Collaborate with web developers on optimizing database schemas for APIs and Web applications
Collaborate with a team of software engineering peers
Mentor and guide more junior data engineering staff
Define and maintain data management processes for the organization
Work with product managers to develop schedules, estimate tasks, and define success criteria
Collaborate with team members from other disciplines such as web development, design, product management, and devops
Coordinate with Open Source contributors
Coordinate with open standards community to define interoperability standards
Actively participate in team building and culture development activities at Open Earth Foundation
Other duties as assigned
Required skills:
Python programming focused on big data management
PostgreSQL or other relational database
Docker
Kubernetes
Git
Optional skills that will make a candidate stand out:
Generative AI and large language model (LLM) APIs and data applications
GIS tools such as ESRI
Amazon Web Services
ElasticSearch
Data pipeline tools, e.g. Pachyderm
Experience with 100Gb or larger data sets
Climate action data such as emissions, targets, and action plans
Physical (lat, lon, alt) and political (city, state, country) geographical data
Remote-sensing and satellite data
RESTful Web APIs
Engineering leadership
Open Source project maintainership
Machine learning, especially for anomaly detection, pattern recognition, clustering, time series analysis
Qualifications:
Bachelor’s degree in computer science, electrical engineering, or equivalent technical or scientific degree, or equivalent on-the-job experience
5 years of experience in software development for data systems
3 shipped projects
Interpersonal skills:
Clear communicator with good verbal and written skills in English (additional languages a plus)
Creative, flexible and efficient with a focus on details
Capacity to work with team members and partners at all levels and across time zones in a highly collaborative and often remote environment.
Ability to embrace new challenges, take ownership and initiative as a key team player.
Compensation and benefits
This position is full-time with compensation of $60,000-$105,000 /year, dependent on experience and location
Open Earth offers unlimited paid time off, paid holidays and paid sick leave
You will work remotely within a dynamic and international environment
We celebrate our achievements during our annual team retreat
OEF is an Equal Employment Opportunity Employer. We support diversity, equity and inclusion in teams, and believe people should align their work with their purpose. Join us if you love Earth.
Please apply by submitting your resume AND a cover letter, it is your opportunity to highlight why you feel you would be a great addition to the team.
We look forward to hearing from you!
Open Earth Foundation seeks diverse applicants from underrepresented communities. If you would like to pursue this job opportunity but don’t believe you meet all the requirements, please apply and note what’s missing in your cover letter.
Job Type: Full-time
Pay: $60,000.00 - $105,000.00 per year
Benefits:
401(k)
Dental insurance
Flexible schedule
Health insurance
Paid time off
Vision insurance
Compensation package:
Bonus opportunities
Yearly pay
Experience level:
3 years
4 years
5 years
6 years
7 years
8 years
Schedule:
8 hour shift
Monday to Friday
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE
1008931568416,Glassdoor,N/A,1797317630,,,N/A,"Pay Range:
$64-$74/hr
Minimum Qualifications:
Bachelor’s degree in Computer Science or related field plus a minimum of 4+ years of relevant work experience; or a Master's degree plus a minimum of 2+ years of relevant work experience; or a Ph.D. plus a minimum of 1+ years of relevant experience
Instead of a degree, qualified candidates would require 8+ years of relevant professional experience
Excellent with SQL
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages
Excellent understanding of patterns for data ingest into a data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, and star
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, and dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.
Experience utilizing reporting and data insights tools
Experience in supporting analytics teams' data needs, in addition to customer and business reporting
Requisition Disclaimer:
This job posting is for a temporary role as an employee of Atrium on assignment at Cox. The individual selected for this role will be offered the role as an employee of Atrium; compensation, medical benefits, fringe benefits and other terms and conditions of employment shall be presented by Atrium upon offer. The pay rate range provided is a reasonable estimate of the anticipated compensation range for this job at the time of posting. The actual pay rate will be based on a number of factors, including skills, competencies, experience, location and/or being pursued and other job-related factors permitted by law. In addition, this role will be eligible for overtime pay, in accordance with federal and state requirements

By applying for this position you agree to the Atrium Terms and Conditions. Agreeing to these terms, includes permission to use the email address and mobile phone number you provide during the application process or throughout the duration of your prospective or actual employees to notify you of job openings, profiles, articles, news, and other employment-related information, as well as to notify you of special promotions or additional products and services offered by us or our affiliates and partners (collectively, “Atrium Alerts”). Atrium Alerts may be sent by email, phone or text message. Your personal information will be safely stored in our database. Atrium does not sell your personal information to third parties. Text message and data rates may apply. To OPT OUT of text messaging or to modify your communication preferences for Atrium Alerts at any time, please contact us at privacyadministrator@atriumstaff.com.

If you do not agree with the Atrium Terms and Conditions, you can still complete your application for this position by emailing your resume to our team at coxrecruit@atriumworks.com. Please include the job title in the subject of your email.

As a woman-owned firm, Atrium values diversity. We are an equal opportunity employer and will consider all applications without regard to race, sex, age, color, religion, national origin, veteran status, disability, genetic information or any other characteristic protected by law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Posting: #zip",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931540110,Glassdoor,Medical Guardian LLC,1237184764,,,"https://www.glassdoor.com/Overview/Working-at-Medical-Guardian-EI_IE749526.11,27.htm","General Responsibilities:
We are looking for a skilled Data Engineer/Database Administrator to join our Data & Analytics team. The ideal candidate will have a strong background in database administration, data warehousing, SQL programming, experience with dbt (Data Build Tool), and Microsoft SQL Server. Familiarity with ETL tools is essential for integrating and transforming large sets of data. This position plays a crucial role in turning data into actionable insights to drive business decisions.
You will be working in a fast-paced environment and will build and develop an agile business data environment that will advance the business objectives of the company and include the following duties:
Manages all MS SQL databases and database servers.
Manage and optimize Microsoft SQL Server databases for operational and analytical workloads.
Perform database administration tasks, including backup, recovery, performance tuning, and user management to ensure high availability and consistent performance.
Contributes to the initial and ongoing data warehouse architecture.
Maintains the meta data and documentation process to support the data warehouse.
Monitors replications jobs, server and databases and ensures optimal performance.
Collaborate with data scientists, data analysts, and other stakeholders to understand data needs.
Write complex SQL queries for data transformation and aggregation.
Develop and maintain dbt models, tests, and transformations to ensure data accuracy and reliability.
Use ETL tools to move data between systems and build ETL pipelines for analytical and real-time reporting.
Work closely with the Information Security team to ensure data privacy and compliance standards are met.
Participate in architectural reviews, code reviews, and other processes aimed at ensuring data quality and application performance.
Provide technical guidance and mentorship to junior members of the team.

Technical Requirements:
Strong proficiency in SQL is essential, with experience writing complex queries, stored procedures, triggers, and performance tuning.
Hands-on experience with Microsoft SQL Server management, including performance tuning, backup, and recovery. Familiarity with SQL Server Integration Services (SSIS) or Azure Data Factory is a plus.
Familiarity with conceptual, logical, and physical data modeling techniques.
Experience with dbt for data modeling, transformation, and version control.
Experience with version control tools such as Bitbucket for managing codebase and dbt projects.
Experience with popular ETL tools such as Apache NiFi, Talend, or Informatica for data integration and transformation. Familiarity with building and maintaining ETL pipelines.
Experience with data visualization tools such as Tableau, Power BI, or Looker is beneficial.
Strong expertise in data management, analytics, and visualization tools (e.g., SQL, Python, R, Tableau, Power BI, etc.).
Proficiency in coding and scripting languages, especially for data manipulation and automation tasks (e.g., Python, Java, Scala).
Ability to leverage analytics to extract actionable insights from complex datasets.
Experience with cloud platforms like AWS, Azure, or Google Cloud for data storage, processing, and analytics.

Education/Experience:
Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field.
Minimum of 5 years of experience working in a Data Engineering role.
Experience in the healthcare and/or retail industry is a plus.
Excellent verbal communication, written communication, and social interaction skills.
Experience with working with offshore teams

Work Hours and Travel Requirements:
You must be open to assisting in troubleshooting and analysis in the event of off-hours production problems, as needed. The IT Team works in a hybrid environment that requires a minimum of one to two days per week in the Philadelphia office.

Founded in 2005, Medical Guardian is a leading provider of innovative medical alert systems that empower people to live a life without limits. A member of the National Aging in Place Council, Medical Guardian is headquartered in Philadelphia and provides support to hundreds of thousands of people across the country who are ready to take on the next chapter of life while remaining safe living in their own home. Whether it is an in-home system or a mobile device with GPS capabilities, Medical Guardian has the personal medical alert device to meet an array of needs and lifestyles. Medical Guardian has been named “Top Workplaces” by the Philadelphia Media Network, “Best Places to Work” by the Philadelphia Business Journal, ranked number 24 in The Philly 100 fastest growing companies, and has made the Inc. 5000 eight years in a row. Here at Medical Guardian, we believe that we are doing more than selling medical alert devices; we are saving lives. Learn more about Medical Guardian by visiting www.medicalguardian.com .",TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE
1008931099285,Glassdoor,Intone Networks,643047918,78000,113000,"https://www.glassdoor.com/Overview/Working-at-Intone-Networks-EI_IE375310.11,26.htm","Sr. Data Engineer with AI Vertex Notes: AI Vertex/AI and ML skills are must have Senior Data Engineer (GCP AI/Vertex and AI/Client skills) Job Duties and Responsibilities: Understand client requirements and understand case studies or current implementation for Predictive models, able to understand business domain needs and implement data pipelines & predictive models, Experience in Agile projects, work with multiple stakeholders like business, project team and deployment teams, ability to work independently and switch technical skills based on the project needs. Detail oriented self-starter capable of working independently. Experience in ETL and ETL cloud services like GCP Data Pipeline Product Details, GCP Glue Experience with private or public cloud technology. Excellent written and verbal communication skills, with ability to document and design proposals. Expert in writing software packaging and deploying into a fully automated environment. Experience in ServiceNow. Basic Qualifications: 5+ years of Release or Automation or Software Engineering experience, or equivalent. 5+ years Linux experience. 5+ years programming experience with Java or Python and scripting 3+ years of experience in DevSecOps tool chains/automation to achieve CICD, Blue-Green deployments, feature toggles (Git, Jenkins, uDeploy). 3+ years with Agile Scrum (Daily Standup, Sprint Planning and Sprint Retrospective meetings) and Kanban. CADM - Cloud Apps - GCP - 3-5 years Data and Intelligence - ETL - Architecture - ETL Tools - 3-5 years",TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932142868,Glassdoor,RPM Living,1753826711,77000,125000,"https://www.glassdoor.com/Overview/Working-at-RPM-Living-EI_IE702672.11,21.htm","Overview:
Looking for something different? We ARE that something different at RPM Living.
Dynamic and fast growth culture and multiple nationwide opportunities let YOU shape your future with us. Top industry pay and benefits, best industry practices, career training and education, people-first focus...… we show you the way to success.

Responsibilities:
Assembling large, complex sets of data that meet non-functional and functional business requirements
Identifying, designing and implementing data structures and selecting various tools to accomplish internal process improvements
Designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using Azure Cloud and SQL technologies
Building complete data pipelines and solutions with ability to understand and leverage best technology for given problem to appropriately accomplish the job.
Working with stakeholders to evaluate and solve data-related technical issues
Working with stakeholders to support their data infrastructure needs while assisting with data-related technical issues
Qualifications:
Bachelor's degree from four-year college or university; or one to two years related experience and/or training; or equivalent combination of education and experience.
Demonstrated ability to work within a deadline, and balance competing priorities.
Previous experience in real estate management preferred.
Ability to analyze complex data and implement statistical solutions to business problems
Experience with ETL operations, such as REST APIs and ETL tools
Highly proficient in SQL and database architecture
Highly proficient with Python
Proficient with Git methodology
Azure experience preferred (logic apps, automation)
Validation experience preferred
Some Accounting/Financial experience preffered
Tableau and Salesforce experience preferred
Multifamily Industry experience preferred
Some IT background and expereince with VMs and data transfer experience preferred

Employment with RPM Living is contingent upon successful completion of a background check and possessing a valid driver’s license.

RPM Living is an Equal Opportunity Employer.",TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931285225,Glassdoor,Farm Credit Financial Partners,1555126525,100000,134000,"https://www.glassdoor.com/Overview/Working-at-Farm-Credit-Financial-Partners-FPI-EI_IE306813.11,45.htm","For over 25 years, Farm Credit Financial Partners, Inc. (FPI) has provided technology products and services to the Farm Credit System. We care deeply about the agricultural credit associations (ACAs) we serve through our mission of delivering trusted technology solutions to help American agriculture thrive. As a customer-owned service organization, we support six ACAs from Maine to California with over 62,000 customer-members and over $40 billion in loan volume . Everyone here contributes to the success of our customers, and to the vibrant culture that makes FPI a great place to work. Throughout the year, you will find us having fun and jamming out to FPI’s band, coming together to support local charities, and celebrating our wins together.
We offer a robust benefits package that includes competitive earnings, hybrid and remote work options, tuition reimbursement, generous 401(k) matching, and development opportunities through company-sponsored trainings and certifications.
Come grow with us: financialpartners.com .
Farm Credit Financial Partners, Inc. is an Equal Opportunity Employer, and all qualified applicants will receive consideration for employment without regard to age, race, color, national origin, sex or gender, religion, pregnancy, marital status, status as a veteran, sexual orientation, gender identity, disability, or any other characteristic protected by law. EEO / AA / Minorities / Female / Disabilities / Veterans
#FPI

JOB SUMMARY: The Data Engineer III is responsible for transforming data that can be easily analyzed. The position will be responsible for expanding and optimizing our data and data pipeline for our Association partners. The Data Engineer III primarily works with project teams on developing new data platforms to support strategic initiatives in alignment with business and/or enterprise strategies.
ESSENTIAL FUNCTIONS:
Work with architects, modelers, and other data engineers to implement design and assemble large, complex data sets that meet end user business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Participate in technical design and code reviews to ensure quality and best practices are maintained.
Perform as technical lead on smaller projects and be a collaborative member on larger projects.
Contribute to the effective data governance of the organization’s business data. This includes data quality, data management, data policies, business process management, and risk management surrounding the handling of organizational data.
ADDITIONAL FUNCTIONS:
Coach and mentor junior engineers
Communicate effectively with stakeholders regarding project status and delivery time frames
Fosters innovative team culture and process improvement during development phase
OTHER DUTIES : This job description is not designed to cover or contain a full listing of activities, duties or responsibilities required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.

QUALIFICATIONS:
Bachelor's degree in computer science or MIS, and 5+ years’ experience in data modeling and cloud technologies. Strong working experience with the Azure technology stack including:
Databricks
Data Factory
SQL
Python
Power BI (Business Intelligence)
Experience with Agile and Waterfall methodologies
Strong organization, analytical, and communication skills
Proficiency in the following technologies: R, Microsoft Office Suite
Strong customer service focus (data consumers as customers)
Familiar with software development best practices
WORK ENVIRONMENT: Typical noise levels for an open, cubicle-styled environment.
PHYSICAL DEMANDS : This position requires periods of standing, walking, and the use of computer equipment. Additional physical demands include, but may not be limited to, talking or hearing, push/pull, stooping, kneeling, reaching w/hands and arms, and lifting at least 10 pounds.
WORK AUTHORIZATION: Authorization to work in the United States is required.
REASONABLE ACCOMMODATION : Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.",TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE
1008933147069,Glassdoor,Syngenta Crop Protection,765890441,93000,133000,"https://www.glassdoor.com/Overview/Working-at-Syngenta-EI_IE12862.11,19.htm","Company Description

As a world market leader in crop protection, we help farmers to counter these threats and ensure enough safe, nutritious, affordable food for all – while minimizing the use of land and other agricultural inputs.
Syngenta Crop Protection keeps plants safe from planting to harvesting. From the moment a seed is planted through to harvest, crops need to be protected from weeds, insects and diseases as well as droughts and floods, heat and cold.
Syngenta Crop Protection is headquartered in Switzerland.

Job Description

The Senior Data Engineer will be part of a team working in a collaborative DataOps environment assembled from data engineers, data scientists, visualization and analytics experts drawn from IT and R&D teams.
Specific duties include:
Support an analytical data infrastructure providing application, tool and ad-hoc access to large datasets consisting of complex data types including genomic, phenotypic, environmental, image and geospatial data.
Process huge data using Big Data tools and technologies like Spark, Hadoop and Hive and extract, transform and load data using various ETL tools.
Engage with business stakeholders to understand strategic roadmaps and build a technical strategy to support them.
Deploy high value, high performance datasets in Snowflake.
Create and support real-time data pipelines built on AWS technologies including Glue, S3, Lambda, EMR, EventBridge, Athena, Kinesis, and IoT Core.
Create end to end database architecture and data modeling in Oracle, Microsoft SQL Server, PostgreSQL and Sybase and creating complex SQL queries, stored procedures and functions to implement business logic.
Embed quality and intelligent reporting capabilities into data pipelines including detection of anomalies and changes in trends with meaningful alerts and statistics.
Maintain versions of code and implement CI/CD (continuous integration and continuous deployment) pipelines using Github, Teamcity, Jenkins and SVN.
Continually research the latest big data and visualization technologies to provide new capabilities and increase efficiency.
Collaborate with data scientists and other tech teams to implement advanced analytics algorithms into our data pipelines that exploit our rich datasets for statistical analysis, prediction, clustering and machine learning.
Help continually improve automation and simplifying data as a service.
Performing work using cloud technologies including AWS, EC2, S3, Kinesis, Glue, Redshift/Spectrum, Lambda, EMR, Athena, Data Pipeline.
Create Graphical User Interfaces by coding in advance HTML, Java and Javascript and create various utilities by programming in Python, Powershell and Unix Shell Scripting.
Position based at company headquarters in Greensboro, NC; may telecommute from anywhere in the U.S.

Qualifications

This position requires a Bachelor’s degree or equivalent in Computer Science, Information Science, Engineering, Mathematics or related technical discipline and 5 years of related (progressive, post-baccalaureate) experience.
Must also have 12 months of experience (which may have been gained concurrently) with each of the following:
Processing huge data using Big Data tools and technologies like Spark, Hadoop and Hive and extracting, transforming and loading data using various ETL tools.
Maintaining versions of code and implementing CI/CD (continuous integration and continuous deployment) pipelines using Github, Teamcity, Jenkins and SVN.
Creating end to end database architecture and data modeling in Oracle, Microsoft SQL Server, PostgreSQL and Sybase and creating complex SQL queries, stored procedures and functions to implement business logic.
Performing work using cloud technologies including AWS, EC2, S3, Kinesis, Glue, Redshift/Spectrum, Lambda, EMR, Athena, Data Pipeline.
Creating Graphical User Interfaces by coding in advance HTML, Java and Javascript and creating various utilities by programming in Python, Powershell and Unix Shell Scripting.
All experience may have been gained concurrently. Must pass a background check and drug test before beginning employment. Position based at company headquarters in Greensboro, NC; may telecommute from anywhere in the U.S.

Additional Information

What We Offer:
A culture that celebrates diversity & inclusion, promotes professional development, and strives for a work-life balance that supports the team members. offers flexible work options to support your work and personal needs
Full Benefit Package (Medical, Dental & Vision) that starts your first day
401k plan with company match, Profit Sharing & Retirement Savings Contribution
Paid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts, among other benefits
Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.
Family and Medical Leave Act (FMLA)
(http://www.dol.gov/whd/regs/compliance/posters/fmla.htm)
Equal Employment Opportunity Commission's (EEOC)
(http://webapps.dol.gov/elaws/firststep/poster_direct.htm)
Employee Polygraph Protection Act (EPPA)
(http://www.dol.gov/whd/regs/compliance/posters/eppa.htm)",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931827956,Glassdoor,Chubb,1978478009,99000,141000,"https://www.glassdoor.com/Overview/Working-at-Chubb-EI_IE150.11,16.htm","As a Sr. Data Engineer on our team, you will work on implementing complex data projects focusing on collecting, parsing, managing, analyzing, and visualizing large sets of data to turn information into insights using multiple platforms. We will look to you to be able to decide on hardware and software design needs and act according to the decisions as well as develop a proofs of concept for the selected solutions.
We are looking for someone with a strong background in computer programming, data analysis, and visual analytics who is eager to tackle problems with large, complex datasets using the latest skills. You are a self-starter who will take ownership of your projects and deliver high-quality data-driven analytics solutions. You can solve diverse business problems using various tools, strategies, algorithms, and programming languages.
Responsibilities
Utilize the data engineering skills within and outside of the developing Chubb information ecosystem for discovery, analytics, and data management
Work with the data SME, Business Analyst team to design the solutions
You will be using strong SQL skills to convert one 'raw' data from XML to a structured format
Work with various relational and non-relational data sources with the target being Azure-based SQL Data Warehouse
Sourcing data from underwriting applications, profiling, cleansing, and conforming to create master data sets for analytics use
Clean, unify, and organize messy and complex data sets for easy access, different levels of abstractions, and analysis
Hands-on data preparation activities using the SSIS package development
Partner with the Global Data Analytics team to navigate the discovery solutions for data ingestion
Work closely with the Data Science team to perform complex analytics and data preparation tasks
Build, deploy, and support applications, services, and APIs that meet business requirements in a highly complex technical environment
Co-ordinate with business stakeholders, business analysts, and project stakeholders to ensure proper assignments of a user story that meets business needs and SLAs
Interfaces with business areas and other Chubb IT teams to coordinate work, manage cross-functional dependencies, and foster collaboration
Ensuring application stability, and participating in resolving incidents and problems.
Leverage your technical insights to stay on top of technical trends, evaluate new technologies, and develop proofs of concept for incorporation into our infrastructure

Bachelor’s degree in Computer Science or any other IT-related field, or equivalent work experience
Minimum of 8-10 years of IT experience in a comparable role as a Data Engineer/Data Analyst
Nice to have experience in the P&C insurance/Life Insurance/ Investment/Banking domain
Experience working in agile environments with application team
Knowledge of DMBS’ with the ability to write SQL queries
Hands experience in Microsoft SQL server Database management and SSIS package development
Nice to have experience with R, Python, and data visualization tools like Qlik Sense/Power BI/Tableau/Alteryx
Experience with DevOps tools, Jenkins and Jira, or equivalent Agile tools
Nice to have experience in .NET or any equivalent technology stacks
Strong analytical skills and coordination skills to achieve results
Ability to identify, understand, and communicate business needs
Models company values; demonstrates high integrity; meets commitments
Demonstrates a sense of urgency and accountability; sets priorities and acts on key issues

Chubb is the world’s largest publicly traded property and casualty insurer. With operations in 54 countries, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. The company is distinguished by its extensive product and service offerings, broad distribution capabilities, exceptional financial strength, underwriting excellence, superior claims handling expertise and local operations globally.

At Chubb, we are committed to equal employment opportunity and compliance with all laws and regulations pertaining to it. Our policy is to provide employment, training, compensation, promotion, and other conditions or opportunities of employment, without regard to race, color, religious creed, sex, gender, gender identity, gender expression, sexual orientation, marital status, national origin, ancestry, mental and physical disability, medical condition, genetic information, military and veteran status, age, and pregnancy or any other characteristic protected by law. Performance and qualifications are the only basis upon which we hire, assign, promote, compensate, develop and retain employees. Chubb prohibits all unlawful discrimination, harassment and retaliation against any individual who reports discrimination or harassment.",TRUE,TRUE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931576474,Glassdoor,RM Staffing B.V.,1473680711,54000,79000,"https://www.glassdoor.com/Overview/Working-at-RM-Staffing-Associates-EI_IE1710087.11,33.htm","Do you want to go back to the source of your profession? Feel ‘IT’ again and move away from the view of your desktop monitor wall. Do you miss the feeling of good old-fashioned hardware engineering and want to go back to basics? Do you have an affinity with- or are you working in the IT Infrastructural industry? To go back to the roots of IT? Then this is your calling!
We are seeking a highly motivated Freelance IT/Datacenter Engineer to work with us on a project basis. The successful candidate will have extensive knowledge of data center operations, including managing and troubleshooting server hardware, network infrastructure, and storage systems. The ideal candidate will be a self-starter, have excellent problem-solving skills, and be comfortable working independently.
Responsibilities:
Manage and troubleshoot server hardware, network infrastructure, and storage systems in a large-scale data center environment.
Perform regular system maintenance and upgrades to ensure optimal performance and availability.
Collaborate with cross-functional teams to resolve technical issues and ensure efficient operation of the data center.
Identify and implement process improvements to optimize the data center infrastructure.
Manage data center assets, including inventory and procurement of equipment.
Monitor and respond to data center alarms and alerts.
Maintain a high level of security and compliance with relevant regulations and standards
If you meet the qualifications and are interested in this exciting freelance opportunity, please submit your resume and cover letter to us. We look forward to hearing from you!

Who are we?
Reboot Monkey is the one-stop shop for all infrastructural hardware and services. Starting in 2022 and with clients in 5 countries, we are moving quickly. We are proud to see our small team going above and beyond to deliver on our promise to make the infra world faster, easier, and better for everybody, including you!
What does working for Reboot Monkey look like?
Your work for Reboot Monkey will mostly go along with your existing freelance or permanent job. Whenever and as often as you want, you can choose to pick one or more tickets as long as you are within a 1-hour range of the client’s data center. Your work for us is a freelance assignment and invoiced from your privately owned company or via a payroll construction. The main philosophy is that you don’t have to commit to a minimum number of (set) hours and can be as flexible with your time as you, please. We offer a competitive reward, a professional work environment, and the possibility to finally get back to your profession's roots.
Are you the person that wants to reconnect with the practical side of our industry? Who wants to grow whenever possible and can be sure of compelling clients? Then, sign up and join Reboot Monkey!

Strong passion for IT Hardware
Minimum of 3 years of experience in data center operations.
Strong knowledge of server hardware, network infrastructure, and storage systems.
Excellent problem-solving skills and ability to work independently.
Ability to manage multiple projects simultaneously and work in a fast-paced environment.
Strong communication skills and ability to effectively convey technical information to non-technical stakeholders.
Ability to be physically available in the data center location as this is NOT a remote/online role.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931270579,Glassdoor,Sony Electronics,1213649287,,,"https://www.glassdoor.com/Overview/Working-at-Sony-Electronics-EI_IE19973.11,27.htm","Sony Corporation of America, located in New York, NY, is the U.S. headquarters of Sony Group Corporation, based in Tokyo, Japan. Sony's principal U.S. businesses include Sony Electronics Inc., Sony Interactive Entertainment LLC, Sony Music Entertainment, Sony Music Publishing and Sony Pictures Entertainment Inc. With some 900 million Sony devices in hands and homes worldwide today, a vast array of Sony movies, television shows and music, and the PlayStation Network, Sony creates and delivers more entertainment experiences to more people than anyone else on earth.

POSITION SUMMARY
Sony Corporation of America (SCA), is seeking a Senior Engineer, Data(Splunk) to join the Global Information Security Department.

JOB RESPONSIBILITIES
Provide industry standard expertise in the deployment, configuration, and maintenance of data and security solutions including but not limited to Splunk Enterprise and Splunk ES.
Deploy, operate, and maintain data and security solutions for new or existing entities.
Perform systems analysis, upgrades, and validations.
Review completion and implementation of system additions and/or enhancements and make recommendations to management.
Monitor capacity to maintain operational capacity and partnership with operations.
Follow change management processes and team procedures.
Develop documentation on new or existing systems.
Develop and directs tests to ensure systems meet documented user requirements.
Identify, analyze, and resolve system problems.
Provide specialized training and technical guidance.
Determine system specification, input/output processes, and working parameters for hardware/software compatibility.
Mentor and coaches less-experienced engineers.
Serve as a liaison with Sony operating companies, participating in meetings to ensure stakeholder requirements are met.
Maintain current knowledge of relevant technology as assigned.
Lead and/or participate in special projects as required.
Demonstrate a passion for data and help users find meaning in their data.
Translate business requirements into concrete data solutions.
Responsible for the successful initiation, planning, design, execution, monitoring, controlling, and closure of assigned projects and initiatives.
Responsible for gathering metrics for reporting for upward leadership and lateral visibility for our end-users.
Manage and drive the technical expectations and commitments of internal and external constituents to ensure the timely execution and completion of the data onboarding activities.
Work closely with users, security and IT teams, and vendors to diagnose and resolve configuration, system, and performance issues.
QUALIFICATIONS FOR POSITION
Your qualifications and experience should include:
Bachelor’s degree in Information Systems, Information Security, Engineering, or equivalent work experience.
Minimum 4 years’ data engineering or related experience with progressively increasing responsibilities.
Preferred 6+ years’ data engineering or related experience with progressively increasing responsibilities.
Minimum 2 years’ experience administering a large scale Splunk Enterprise environment.
Preferred 4+ years’ experience administering a large scale Splunk Enterprise environment.
Preferred 1+ years’ experience administering Splunk ES (Enterprise Security).
Preferred 1+ years’ experience administering Data Lakes, Data Warehouses or Data Mart solutions.
Demonstrated technical expertise with the following:
Splunk proficiency at an engineer or architect level
Regex proficient
Data Lake, Data Warehouse or Data Mart (AWS EMR preferred)
Unix/Linux OS
Proficient in SQL
Experience with one or more RDBMS products (Snowflake, Redshift, Oracle, Postgres, etc.)
SIEM content development and maintenance
GitLab, GitHub or similar DevOPS/Source Code Management tools
ETL/Pipeline/Workflow tools such as Kafka, Confluent, Cribl, Apache Airflow/NiFi
CI/CD pipelines
Python, Bash, SALT and Ansible
Technical writing experience:
Installation/Deployment Procedures
Document Requirements
Able to interact with customers and team members and product support personnel.
Experience with interpreting requirements and use cases.
Strong analytical and creative problem-solving skills.
Experience writing MS SQL.
Experience developing enterprise strategic implementation of Splunk deployments.
Splunk implementation and support experience.
Experience with Data Lakes or Data Warehouses.
Experience with code repository tools, ETL tools and CI/CD pipelines.
Certified Splunk Architect or Engineer highly preferred.
Experience leading team and projects highly preferred.
Candidates should possess strong interpersonal skills.
All candidates must be authorized to work in the US
The anticipated annual base salary for this position is $130,000 to $145,000. This range does not include any other compensation components or other benefits that an individual may be eligible for. The actual base salary offered depends on a variety of factors, which may include as applicable, the qualifications of the individual applicant for the position, years of relevant experience, specific and unique skills, level of education attained, certifications or other professional licenses held, and the location in which the applicant lives and/or from which they will be performing the job.
#LI-SC1
Sony is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy), gender, national origin, citizenship, ancestry, age, physical or mental disability, military status, status as a veteran or disabled veteran, sexual orientation, gender identity or expression, marital or family status, genetic information, medical condition, or any other basis protected by applicable federal, state, or local law, ordinance, or regulation.
Disability Accommodation for Applicants to Sony Corporation of America
Sony Corporation of America provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. For reasonable accommodation requests, please contact us by email at
careers@sonyusa.com
or by mail to: Sony Corporation of America, Human Resources Department, 25 Madison Avenue, New York, NY 10010. Please indicate the position you are applying for.
EEO is the Law
EEO is the Law Supplement
Right to Work (English/Spanish)
E-Verify Participation (English/Spanish)
While SCA does not require employees to be vaccinated against COVID-19, there are certain Sony offices that require employees to be vaccinated in order to enter. If you will be located at or travel to those offices, you will be required to be fully vaccinated to enter. The Company will consider requests for reasonable accommodations for documented medical reasons and for sincerely held religious beliefs in accordance with applicable law. Please do not include proof of vaccination status or any indication of a possible request for a vaccination accommodation when submitting your application materials. If applicable, the Company will follow up with you directly to request proof of vaccination and to discuss any potential accommodations.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932829359,Glassdoor,N/A,1797317630,,,N/A,N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931743989,Glassdoor,Google,364284807,,,"https://www.glassdoor.com/Overview/Working-at-Google-EI_IE9079.11,17.htm","Minimum qualifications:
Bachelor's degree in Computer Science, a related technical field, or equivalent practical experience.
5 years of experience with data migration strategies and moving production systems in on-premise/data center environments to the cloud.
5 years of experience with database technologies and database administration techniques.


Preferred qualifications:
Master's degree in Computer Science or a related technical field.
5 years of experience with optimizing database performance with respect to transactional or analytic workloads.
4 years of experience in technical sales or professional consulting in the fields of systems integration, data transfer/management, and enterprise database performance.
Knowledge of Disaster Recovery (DR) and data backup strategies.
Ability to learn, understand, and work with new emerging technologies, methodologies, and solutions in the Cloud/IT Technology space.
About the job
When leading companies choose Google Cloud it's a huge win for spreading the power of cloud computing globally. Once educational institutions, government agencies, and other businesses sign on to use Google Cloud products, you come in to facilitate making their work more productive, mobile, and collaborative. You listen and deliver what is most helpful for the customer. You assist fellow sales Googlers by problem-solving key technical issues for our customers. You liaise with the product marketing management and engineering teams to stay on top of industry trends and devise enhancements to Google Cloud products.
As an Enterprise Customer Engineer, you will work directly with the Technical Sales teams as an enterprise database subject matter expert to differentiate and portray the goal of Google Cloud to our customers. You will help prospective customers and partners understand Google Cloud, explain technical features, help customers design architectures, engage in proof- of-concepts, and troubleshoot potential roadblocks related to database migration and data back ends for new app development.
Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
The US base salary range for this full-time position is $118,000-$177,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Work with the team to identify and qualify business opportunities, identify key customer technical objections, and develop a strategy to resolve technical blockers.
Support the technical relationship with Google customers, including product and solution briefings, proof-of-concept work, coordination and prioritization of solutions impacting customer adoption of Google Cloud.
Work with customers to demonstrate and prototype Google Cloud product integrations in customer/partner environments.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to implement a complete solution using best practices on Google Cloud.
Travel to customer sites, conferences, and other related events as needed.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931147217,Glassdoor,RevaComm,61888625,,,"https://www.glassdoor.com/Overview/Working-at-RevaComm-Inc-EI_IE252606.11,23.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931947790,Glassdoor,Velocity Black,2099111377,109000,141000,"https://www.glassdoor.com/Overview/Working-at-Capital-One-EI_IE3736.11,22.htm","Category
Engineering
Experience
Principal Associate
Primary Address
McLean, Virginia
Overview
Center 3 (19075), United States of America, McLean, Virginia
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer
San Francisco, California (Hybrid On-Site): $171,500 - $195,800 for Senior Data Engineer
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,TRUE
1008933172497,Glassdoor,Western Governors University,38892720,,,"https://www.glassdoor.com/Overview/Working-at-Western-Governors-University-EI_IE244719.11,39.htm","The salary range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.
At WGU, it is not typical for an individual to be hired at or near the top of the range for their role, and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is:

Pay Range: $127,700.00 - $191,500.00

If you’re passionate about building a better future for individuals, communities, and our country—and you’re committed to working hard to play your part in building that future—consider WGU as the next step in your career.
Driven by a mission to expand access to higher education through online, competency-based degree programs, WGU is also committed to being a great place to work for a diverse workforce of student-focused professionals. The university has pioneered a new way to learn in the 21st century, one that has received praise from academic, industry, government, and media leaders. Whatever your role, working for WGU gives you a part to play in helping students graduate, creating a better tomorrow for themselves and their families.
Current WGU employees should submit an internal application before 10/27/2023 to be considered.
The Staff Data Engineer should be agnostic to tools and should be able to supervise, design, architect and code using Apache Spark and other cloud technologies. The position will supervise and design how data will flow through hybrid data environments comprised of open-source big data platforms and traditional database systems. The core responsibility for this position includes supervision of data engineering technical aspects, design of data and system architecture for the Data Lake and data warehouse, supervision of the technical aspects of a data engineering team and projects encompassing dimensional and normalized data modeling. The Staff Data Engineer will improve technical standards in the environment ensuring optimal use of data warehouse and other data stores to solve business problems. They will serve as the lead engineer and go to person for all aspects of the data engineer team including solution architecture of data systems.
Essential Functions and Responsibilities:
Supervise work on cloud technologies and architect scalable and performant Data Lake systems.
Establish design and methodology for database build processes.
Supervise the architecture and design of complete data model solutions.
Supervise necessary data protection and security processes.
Create and design extract processes for data access layer.
Translate business problems/information requirements accurately to logical/physical data models aligning with customers’ data architecture standards.
Supervise and perform research and analysis to find solutions for complex business problems.
Monitor job performance and fine tune Spark SQL queries as appropriate on a regular basis.
Supervise the profiling of data, the publishing of data profiles and corrective actions if required to ensure data quality.
Supervise and perform documentation / reverse engineering / analysis of data mapping using data integration code/tools.
Work with APIs for data wrangling and integrations with other systems data in the EDW.
Perform impact analysis using Data Integration/Data Virtualization tool repositories, DB data dictionary, UNIX scripts and frontend code on versioning systems.
Analyze / research data on multiple platforms as wells as multiple heterogeneous databases including custom developed databases.
Positively impact projects by completing tasks assigned on time.
Communicate technical and domain knowledge as it relates to work, to both technical and non-technical audiences.
Ingest and transform structured, semi-structured, and unstructured data from sources including relational databases, NoSQL, external APIs, JSON, XML, delimited files, and more.
Support business and functional requirements and translate these requirements into robust, scalable, solutions.
Collaborate with engineers to help adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation.
Help continually improve ongoing reporting and analysis processes, automate, or simplify self-service modelling and production support for customers.
Performs other related duties as assigned.
Knowledge, Skill and Abilities:
Expertise with analytical reporting tools, preferably Cognos and Tableau.
Mastery in code based ETL/ ELT tools for importing and exporting data across disparate systems.
Expertise in analytic skills related to working with unstructured datasets.
Use of industry best practices for code development, testing, implementation and documentation.
Ability to evaluate and prioritize work based on the organization’s needs.
Ability to supervise cross team projects to accomplish data integrations and pipelines.
Supervisory abilities for data engineering team with respect to technical design and architecture.
Excellent verbal & written communication, along with technical documentation
Ability to work and deliver in a team environment
Ability to manage the use of tools like Jira, Confluence, GitHub
Architect and Develop processes for audit of Data Integrity
Ability to mentor Associate/Senior/Data Engineer in data pipeline architecture and coding standards
Supervise Validation and testing to analyze and debug issues
Mastery of AWS cloud technologies, REST API, and HTML5
Mastery of relational SQL and NoSQL databases
Mastery with object-oriented/object function scripting languages: Python, Java, Scala
Mastery of big data tools: Hadoop, Spark, Kafka, Databricks, etc.
Competencies:
Organizational or Student Impact:
Recommends and implements changes in technical/business processes; identifies areas for improvement.
Helps lead/coordinate extremely complex technical projects and programs and leads development and implementation of innovative solutions for specialized technical issues.
Works proactively; identifies and helps prevent/ solve problems that may cross disciplines.
Fully understands and quantifies project risks with impact. Identifies, generates, and implements innovative solutions.
Problem Solving & Decision Making:
This individual accomplishes goals and objectives independently.
Builds and leads teams, influencing decisions and results.
Uses discretion to fully scope, design, and implement solutions to complex technical problems.
The individual provides regular technical advice and direction to technical teams and management.
Models and helps set high standards for effective interactions with internal and external individuals.
Communication & Influence:
Communicates with parties within and outside of their job function and typically has responsibilities for communicating with parties external to the organization.
Works to influence others to accept and understand new concepts, practices, and approaches. Requires ability to communicate with executive leadership regarding matters of significant importance to the organization.
This individual may conduct briefings with senior leaders within the technical function.
Leadership:
Frequently responsible for providing guidance, coaching, and training to other employees across the Company within the area of expertise.
Responsible for managing large, complex project initiatives or strategically important solutions to the organization, involving large cross-functional teams.
May have direct reports but generally fewer than three.
Job Qualifications:
M. S. in Business, Management Information Systems, Computer Science, or a related field, or an equivalent combination of experience and training.
Seven or more years of experience as a Data Engineer, Data Integration, Big Data, or Business Intelligence Engineer with a background as a Software Engineer.
Preferred Qualifications:
Strong experience with distance education and distance learning students is preferred.
Higher Education domain knowledge
Experience as a Lead or Staff Data Engineer
#LI-REMOTE
#LI-ZARD

As an equal opportunity employer, WGU recognizes that our strength lies in our people. We are committed to diversity.",TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE
1008932770624,Glassdoor,Amazon.com Services LLC,695687622,,,"https://www.glassdoor.com/Overview/Working-at-Amazon-EI_IE6036.11,17.htm","5+ years of data engineering experience
Experience with data modeling, warehousing and building ETL pipelines
Experience programming with at least one modern language such as C++, C#, Java, Python, Golang, PowerShell, Ruby
Experience working on and delivering end to end projects independently
Knowledge of distributed systems as it pertains to data storage and computing
3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience
3+ Years of hands on experience with big data framework and storage mechanisms like Apache Spark, EMR, Glue, Data Lake.
AWS Partner organization(APO) is a fast growing org which supports a number of personas including but not limited to Sellers, Partners, Partner Development Managers and AWS Marketplace. APO team is driven by the mission to provide best partner experience worldwide and create a better future for our customers and communities through a culture of Customer obsession, innovation and a relentless pursuit of excellence. Partner Intelligence is the Data and Analytics org within APO supporting all the Data initiatives.

As a Data Engineer on the AWS Partner Intelligence team, you will work directly with Software Engineering, Business Intelligence, Data Science and Product teams to continuously improve our of data infrastructure, design, tools and pipelines. Your work will directly influence and drive organizational insights, customer facing features and machine learning models.

To be successful in this role, you should have strong database design skills, comfort with large data sets and an eagerness to invent. You should have a passion for data and analytics with the technical skills needed to build for scale and automation.

About the hiring group

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.

Key job responsibilities
Architecture design and implementation of next generation data pipelines and BI solutions
Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc.
Build and deliver high quality data architecture and pipelines to support business analyst, data scientists, and customer reporting needs.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers
A day in the life
Collaborate with Software Engineers, Product Managers, Data Scientists and Business Intelligence Engineers to design, plan and deliver on high priority data initiatives serving internal stakeholders and AWS customers.
Build automated, fault tolerant and scalable data solutions leveraging state of the art technologies including but not limited to Spark, EMR, Python, Redshift, Glue and S3.
Look around corners and be creative - Continuously evaluate and improve our strategy, architecture, tooling and codebase to maximize performance, scalability and availability.
We are open to hiring candidates to work out of one of the following locations:

Jersey City, NJ, USA | Seattle, WA, USA

Master's Degree in Data Analytics
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $105,700/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931312091,Glassdoor,NextRow Digital,746710125,92000,133000,"https://www.glassdoor.com/Overview/Working-at-NextRow-EI_IE718945.11,18.htm","AWS Cloud Data Engineer
Chicago, IL
Long Term Contract
Description:


TECHNICAL QUALIFICATIONS:
6+ years of experience within the field of application/platform engineering or related technical work including business intelligence, analytics.
4+ years of experience with AWS Senior Cloud Data Engineering, management, maintenance, or architecting, implementing best practices and industry standards.
Experience with data warehousing platforms such as Snowflake, Redshift or similar.
Strong knowledge and established experience with AWS services including but not limited to: S3, EC2, RDS, Lambda, Cloud Formation, Kinesis, Data Pipelines, EMR, Step Functions, VPC, IAM, and Security Groups.
Experience with DB technologies (e.g., SQL, Python, PostgreSQL, AWS Aurora, AWS RDS, MongoDB, Redis).
Experience with CI/CD tools, pipelines, and scripting for automation. (GitHub Actions, Jenkins, AWS Code Pipeline tools, Cloud formation and Terraform).
High degree of knowledge in IAM Roles and Policies
Strong knowledge configuring AWS cloud monitoring and alerts for cloud resource availability.
Strong scripting experience using PowerShell and/or Python.
High degree of knowledge in PaaS and SaaS application performance.
Understand enterprise level application architecture diagrams and IT security requirements.

ADDITIONAL QUALIFICATIONS:
Experience and comfort solving problems in an ambiguous environment where there is constant change
Have the tenacity to thrive in a dynamic and fast-paced environment, inspire change, and collaborate with a variety of individuals and organizational partners
Experience designing and building scalable and robust data pipelines to enable data-driven decisions for the business
Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders
Rigorous attention to detail and accuracy.
Demonstrate d ability to troubleshoot technical problems and issues.
Passionate about programming and learning new technologies.
Experience planning and executing on-premises to AWS migrations
BA or BS degree Computer Engineering, Computer Science, or related fields.
Strong verbal and oral communication.

PREFERRED EXPERIENCE:
Experience with large scale enterprise streaming services such as Kafka.
Experience with Kubernetes and Docker containers or AWS Fargate.
Experience implementing applications with both Windows and Linux server OS
Experience with networking, security groups, or policy management in relation to Cloud resources across multiple operating systems, including UNIX, Linux, or Windows
Advance CS degree.",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932859684,Glassdoor,Global Atlantic Financial Group Opportunities,1614958555,,,"https://www.glassdoor.com/Overview/Working-at-Global-Atlantic-Financial-Group-EI_IE972487.11,42.htm","All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com.
COMPANY OVERVIEW
Global Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.

Global Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us.
We use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling.
SUMMARY
The Finance Platform Developer role partners with the Actuary team, IT data team and primary vendor to provide data development, support, and administration for the Actuarial Modeling/Data Management Platform. This position will be accountable for managing the data lifecycle and development throughout the Actuarial Modeling process.
This position can sit in our Boston or Des Moines offices.
Key responsibilities will include the following:
New Requests/Builds
Collaborate with Actuary Model Development to support any data needs for models
Collaborate with Actuary Valuation to support model analytics and approval workflow
Define backlog items and requirements for IT Data team and other supporting IT areas
Participate in testing and verification of technical solutions
General Support
Become a subject matter expert in Actuarial Modeling Platform Data Management capabilities
Is primary administrator of Actuarial Modeling Platform and appropriately manages required administrative tasks if needed
Responsible for the regular maintenance, updates, fixes and upgrades. This could include testing after upgrade or facilitating UAT
Ensures platform is running at optimal performance and levels
Maintain application run books to ensure appropriate documentation exists
Provide training to new and existing users on current and future functionality
Production Process
Manage and facilitate all incidents from Priority 1 to Priority 4, which includes, but not limited to, providing support to users of applications, responding to user-based questions, tickets and assists with troubleshooting issues within platform.
Manage day-to-day operational and tactical aspects of multiple projects or requests
Provides on-call assistance as requested, for after-hours issues and support needs
Resolve incidents if able to, otherwise escalate as needed (provide tier-2 incident response)
SKILLS
General development skills with proven experience across 2+ programming languages
Understanding of Life and Annuity insurance a plus
Experience working with technology vendors & Actuaries
Demonstrates excellent interpersonal communication skills and documentation skills
Proven Data management skills with understanding of Data flows across different platforms
Able to manage work across a development team
Work cross-functionally within IT, with an emphasis working with a data team
Self-disciplined, able to work independently, but also able to take direction when necessary
Self-motivated to identity and resolve issues and in advancing personal knowledge
Hands on experience with GITLAB
QUALIFICATIONS
An undergraduate degree in an IT related field or similar combination or education and experience
Experience working on Life and Annuity products
2+ years' experience in Data Integration and Data Management
Experience working in cloud environments
Hands on experience with SAS programming
Must have
Experience in the following technologies –Azure Data Factory and PowerBI
Experience in Data Integration and Data Management
Experience working with and actuarial or finance

Global Atlantic's base salary range is determined through an analysis of similar positions in the external labor market. The annual base salary range provided in this posting for this position is a nationwide market range and represents a broad range of salaries for this role across the country. Base pay is just one component of Global Atlantic's total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k), as well as a company match on your contributions), and sales incentives. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives. The base salary range for this role is $84,800 to $155,000.

#LI-AO1
#LI-Hybrid
TOTAL REWARDS STATEMENT
Global Atlantic's total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.
We are active in our communities-
New York: Red Hook Conservancy, Girls Who Invest and The Bowery Mission
Boston: Cradles to Crayons, Project Bread, Let's Get Ready, Rise Against Hunger, Salvation Army and many other local volunteer organizations in around the Boston area
Hartford: Habitat for Humanity, Foodshare, Humane Society, Hands on Hartford, Mercy Shelter and Dog Star Rescue
Indianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation
Batesville: American Cancer Society Relay for Life, Angels of Giving, Margaret Mary Health Foundation, Ripley County Community Foundation, Safe Passage, Batesville High School Sponsorships, local area youth sports and food pantries, as well as many others
Des Moines: United Way, Central Iowa Shelter & Services, Junior Achievement of Central Iowa and Make a Wish Foundation
Berwyn: Food drive and will be planning an event to help a local family over the holidays
Atlanta: Packaged Good Organization, which helps the most vulnerable community members with providing personalized care packages for people in need including the elderly, our armed forces, the homeless and hospitalized kids
Bermuda: Sponsor of a weekly feeding program operated by The Hamilton Seventh-Day Adventist Church
Social platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.
Global Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws. More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.
Employees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com.
Please click on the below links to learn more about Global Atlantic.
Global Atlantic Privacy Statement",FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,FALSE,TRUE
1008932864411,Glassdoor,LTIMindtree,202896978,80000,110000,"https://www.glassdoor.com/Overview/Working-at-LTIMindtree-EI_IE8441464.11,22.htm","Role: Senior Developer
Experience 4-6 Years
Location: USA – Hartford, CT
Must Have: AWS (S3), Python, Databricks
Good to have: Snowflake, Spark
Overview:
Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming analytics landscape.
Looking for Data Migration Engineer having an experience migrating data from on prem to cloud.
Must Have: AWS (S3), Python, Databricks
Good to have: Snowflake, Spark
Requirements:
• Strong python skills
• AWS/Cloud infrastructure knowledge (commonly used AWS services, IAM)
• Experience with building data pipelines using Databricks on AWS
• Knowledge and Hands-on Snowflake
• Experience in Agile methodologies and Atlassian tools like JIRA.
• Expertise in using version control tools like Git, Bitbucket
• Experience on CI/CD using Kubernetes, GIT and Monitoring and Alerting tools
• Experience on data migration from On-Prem databases to AWS Cloud on S3
Roles & resposibilities:
• Acts as a single point of contact for data migration to AWS projects for customer
• Provides innovative and cost-effective solution using AWS, Spark, python & databricks
• Develops solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unit
• As a leader in the Cloud Engineering you will be responsible for the overseeing development
• Learn/adapt quickly to new Technologies as per the business need
• Develop a team of Operations Excellence, building tools and capabilities that the Development teams leverage to maintain high levels of performance, scalability, security and availability
• Understand where to obtain information needed to make the appropriate decisions
• Demonstrate ability to break down a problem to manageable pieces and implement effective, timely solutions
• Identify the problem versus the symptoms
• Develop solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unit
Skills:
• The Candidate must have 3-5 yrs of experience in AWS, Python, Databricks
• Hands on experience on AWS Cloud platform especially S3, lamda, EC2, EMR
• Experience on spark scripting
• Has working knowledge on migrating relational and dimensional databases on AWS Cloud platform
• Relevant experience with ETL methods and with retrieving data from dimensional data models and data warehouses.
• Strong experience with relational databases and data access methods, especially SQL.
• Knowledge of Amazon AWS architecture and design
Job Type: Full-time
Salary: $100,000.00 - $1,500,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Day shift
Monday to Friday
Work Location: In person",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931272100,Glassdoor,The Swift Group,1926728892,69000,98000,"https://www.glassdoor.com/Overview/Working-at-The-Swift-Group-VA-EI_IE5604362.11,29.htm","Job Description
The Swift Group is looking for a Data Visualization/Tableau Engineer to join a team supporting data warehousing, business intelligence and reporting professionals.

Key Responsibilities:
Gather and analyze business reporting and data requirements
Design highly professional reports, dashboards and visual representation of business and warehouse data for process owners and executive leadership
Develop ad-hoc queries and reports based on requirements gathered from customers utilizing complex, custom-built SQL queries for the purposes of analytical reporting
Test and troubleshoot report and dashboard functionality, validate data and create test data and table structures through use of SQL
Performance tune SQL statements executed by reports and dashboards as required
Required Skills
4+ years of experience in engineering and maintaining Tableau dashboards, rich interactive visualizations, and reports using backend relational database (Oracle, PostgreSQL).
4+ years of experience in engineering automated Tableau reports using Tableau Server and Tableau Desktop.
3+ years of strong Structured Query Language (SQL) skills and experience optimizing queries.
Design and engineer efficient and optimized Tableau reports by leveraging best practices for data visualization and data blending.
Ensure appropriate data access, data security, and data governance policies are in place for Tableau reporting.
Experience in troubleshooting and resolving issues related to Tableau reports and data sources.
Bachelor's degree or equivalent experience
US citizenship with an active TS/SCI with Polygraph security clearance required
About iC-1 Solutions, LLC.
The Swift Group is a privately held, mission-driven and employee-focused services and solutions company headquartered in Reston, Virginia. Founded in 2019, The Swift Group supports Civilian, Defense, and Intelligence Community customers, across the country and around the globe.

The Swift Groups is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.",FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932855492,Glassdoor,N/A,1797317630,,,N/A,"Introduction
Are you looking for a work environment where diversity and inclusion thrive? Submit your application for our Senior Data Integration Engineer opening with HCA today and find out what it truly means to be a part of the HCA Healthcare team.
Benefits
HCA offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.
We are seeking a Senior Data Integration Engineer for our team to ensure that we continue to provide all patients with high quality, efficient care. Did you get into our industry for these reasons? We are an amazing team that works hard to support each other and are seeking a phenomenal addition like you who feels patient care is as meaningful as we do. We want you to apply!
Job Summary and Qualifications
JOB SUMMARY
The Senior Data Integration Engineer provides technical leadership responsible for defining, documenting, and maintaining integration requirements, including management of message specifications and mappings between inputs and outputs. The individual must be able to collaborate with stakeholders, business leaders, product owners/analysts, and technical architects across the enterprise to understand business needs and lead the integration of solutions, including definition and development (business processes, technology, data, etc.) to support business goals and initiatives for projects projected to deliver significant business value or prevent significant technical or operational risk. Collaborate with business representatives at all levels of the organization and across the enterprise, and consistently providing high-quality services on multiple complex projects/engagements and also supporting enterprise Meditech Expanse migrations.
The Consulting Data Engineer must leverage a consistent framework to discover and assess the business environment, processes, data, and conditions. Facilitate defining and analyzing business needs and requirements for new and enhanced products, services, or optimized business processes for the implementation of Meditech Expanse. The individual ensures all testing requirements get satisfied and testing results documented. Provides tactical leadership for certification and deployment of new integrations impacting the growth of the entire HCA enterprise. Works with functional, technical, and project teams to deliver timely and practical solutions, follows processes and standards and builds relationships with key stakeholders.
Candidate must possess strong people skills, personal drive, and the ability to see strategy through to execution in a matrix reporting environment. Strong written, verbal, and presentation skills are required. The candidate will lead, develop, and support integration efforts encompassing many platforms, including current and future Cloverleaf 6.x platforms. This role will involve knowledge of data formats using XML, HL7, FHIR, X.12, and protocols of TCP/IP, FTP/sFTP, Visual Studio, C#, and schemas (DTD, XSD), along with Cloverleaf and TcL (Tool Command Language) Scripting. Candidate must be able to work and communicate with various group members, both functional and technical, across HCA and other organizations to define requirements, resolve issues, and meet deadlines. Vast knowledge of HL7 and emerging knowledge of FHIR is expected.
GENERAL RESPONSIBILITIES
Assisting with Functional/Integrated System and User Acceptance Testing
Assist with promoting applications from development to QA to production.
Possess an understanding of business analysis tools and documentation methods.
Possess an understanding of integrated system data flows and typical design considerations.
Must be able to work with various group members, both functional and technical, across HCA and other organizations to define requirements, resolve issues, and meet deadlines.
Appropriately communicate and integrate with teams and constituencies across the company (strong written and verbal communication skills and effective relationship-building skills)
Lead and facilitate the completion of tasks and any subsequent implementation components.
Lead various projects (both large and small scale) in defining, documenting, piloting, and deployment of integrated solutions.
Lead undefined integration work related to acquisitions, EMR Expanse migrations, and divestitures, coordinating with technical teams and division/facility resources.
Work with all integration platforms (e.g., Cloverleaf, FHIR, and custom platforms or tooling) from intake, testing, deployment, and support processes as a function of integration delivery.
Work as the stakeholder liaison to elicit, analyze, communicate, and validate requirements for changes to business processes, data, policies, and information systems.
Coordinate work with development teams to ensure that requirements are understood and clarified.
Ensure our security, networking, and other requirements for solutions meet established policies.
5+ years of experience required
Bachelor’s degree preferred
OTHER/SPECIAL QUALIFICATIONS
Cloverleaf Level 1 or beyond Certification preferred
Familiarity with Lean/Agile techniques in a development environment desired
Demonstrated Integration Analyst experience preferred
PHYSICAL DEMANDS/WORKING CONDITIONS
Sitting at a desk for 4 to 5 hours viewing monitor and typing.
Ability to work long nights and weekends as deemed necessary
Some light travel may be required (less than 20%).
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Across HCA Healthcare’s more than 2,000 sites of care, our nurses and colleagues have a positive impact on patients, communities and healthcare.
Together, we uplift and elevate our purpose to give people a healthier tomorrow.""- Jane Englebright, PhD, RN CENP, FAAN
Senior Vice President and Chief Nursing Executive
If you find this opportunity compelling, we encourage you to apply for our Senior Data Integration Engineer opening. We promptly review all applications. Highly qualified candidates will be directly contacted by a member of our team. We are interviewing apply today!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932560856,Glassdoor,Concentra,1243598337,75000,108000,"https://www.glassdoor.com/Overview/Working-at-Concentra-EI_IE4169.11,20.htm","Overview:
The Data Engineer- Clinical Analytics is primarily focused on analytical processes with ability to implement database solutions and best practices in the realm of data science and machine learning projects. Essential software engineering skills with strong foundational knowledge on data movement and orchestration both on-premises and cloud environment. The Data Engineer supports and aligns with business decisions within Concentra by analyzing raw data, constructing, and maintaining data systems, and improving data quality and efficiency. Implements programming languages to develop and test architectures that enables data operations for predictive (i.e., machine learning/AI) or prescriptive modeling.
Responsibilities:
Analyze, develop, combine raw information, and maintain various data sources
Improve data quality and efficiency to build data systems and pipelines
Identify opportunities for data acquisition and collaborate with Application owners and Subject Matter Experts (SME) to document data domain knowledge
Implement ETL methods to prepare both structured and unstructured data for predictive and prescriptive modeling
Leverage data serialization techniques to meet project needs for use in various reporting platforms
Collaborate with Business Intelligence (BI) ETL Developers/Data Architect, Data Scientists, Reporting Analysts, and Subject Matter Experts (SME) to understand business goals
Understand enterprise project life cycle and prepare for integration and user acceptance testing methods.
Produce technical documentation by following enterprise standards and guidelines
Participate in relevant information-sharing activities
Serve as escalation point for application support and troubleshooting
Proactive identification of issues and opportunities that will have an impact on the business use of reports and ensure managerial awareness
Daily review outstanding issues to assure that troubleshooting and resolutions are current
Ensure all changes comply with change management policies and procedures
This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.
Qualifications:
Education Level: Bachelor’s Degree
Major: Computer Science or Computer Engineering
Degree must be from an accredited college or university

Job-Related Experience
Customarily has at least the following experience:
Customarily has at least three or more years in Software development / Data-Centric pipelines / Model-Centric pipelines
Relational Database experience
Documentation and publication

Job-Related Skills/Competencies
Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility
Ability to make decisions or solve problems by using logic to identify key facts, explore alternatives, and propose quality solutions
Outstanding customer service skills as well as the ability to deal with people in a manner which shows tact and professionalism
The ability to properly handle sensitive and confidential information (including HIPAA and PHI) in accordance with federal and state laws and company policies
Strong SQL development and performance tuning skills
Competencies with Oracle, SQLServer, SSIS, Sybase, NoSQL, Python, Azure, Docker, Git, and Visual Studio
Experience with Data Lakes, Lake Houses, and ELT is preferred
Experience with Azure ML, Azure Data Factory, Azure Data Bricks, Azure Data Flow, and Azure Functions is preferred
Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility
Ability to make decisions or solve problems by using logic to identify key facts, explore alternatives, and propose quality solutions
Outstanding customer service skills as well as the ability to deal with people in a manner which shows tact and professionalism
The ability to properly handle sensitive and confidential information (including HIPAA and PHI) in accordance with federal and state laws and company policies
Highly organized
Communication skills to be able to effectively speak and write in a clear and professional manner
Skilled at listening and providing feedback
Additional Data:
Employee Benefits
401(k) Retirement Plan with Employer Match
Medical, Vision, Prescription, Telehealth, & Dental Plans
Life & Disability Insurance
Paid Time Off
Colleague Referral Bonus Program
Tuition Reimbursement
Commuter Benefits
Dependent Care Spending Account
Employee Discounts
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation, if required.

*This job requires access to confidential and sensitive information, requiring ongoing discretion and secure information management*

Concentra is an Equal Opportunity Employer, including disability/veterans",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932783527,Glassdoor,Eaton,194568485,,,"https://www.glassdoor.com/Overview/Working-at-Eaton-EI_IE221.11,16.htm","Eaton’s NAS North American Sales division is currently seeking a Lead Sales Engineer - Data Center Vertical to join our Data Center sales team. This is a hybrid-based position and candidates must reside within 50 miles of our Indianapolis, IN location. Relocation assistance will be offered.
The expected annual salary range for this role is $83651.58 - $122688.98 a year. This position is also eligible for a variable incentive program.
Please note the salary information shown above is a general guideline only. Salaries are based upon candidate skills, experience, and qualifications, as well as market and business considerations.
What you’ll do:
Position Overview:
The primary function of the Lead Sales Engineer is to sell assigned product lines to targeted customers in targeted market areas. This position will be responsible to achieve the assigned sales goal consistent with the expectations of a thoroughly seasoned professional sales engineer for the assigned product categories while under little supervision. It will be an expectation to optimize sales volume, product mix and profit margin, while increasing sales in the marketplace. This position will need to coordinate sales for the assigned customer and distributor base. It has the responsibility to manage all aspects of the customer relationship, providing sales and technical assistance through all customer channels: end customers, distributors, consulting engineers and contractors.
Making what matters work at Eaton takes the passion of every employee around the world. We create an environment where creativity, invention and discovery become reality, each and every day. It’s where bold, bright professionals like you can reach your full potential—and where you can help us reach ours.
In this function you will:
Develop and execute sales plans to meet performance expectations and requirements
Quote projects and negotiate correct required pricing
Prepare sales presentations to create product understanding and awareness
Build relationships with key customers to enhance long-term business prospects
Work with factories to resolve technical issues
Canvas the market to gain insight and adjust to ever changing pricing and delivery requirements
Assist the team to develop a coordinated sales effort while keeping management informed of market conditions
Obtain ongoing training on both functional and technical skills
When we embrace the different ideas, perspectives and backgrounds that make each of us unique, we — as individuals and as a company — are stronger.
Qualifications:
Required (Basic) Qualifications:
Bachelor’s degree from an accredited institution
Minimum five (5) years of electrical industry sales/marketing and/or engineering experience
Possess and maintain a valid and unrestricted driver’s license
Must be able to work in the United States without corporate sponsorship now and within the future
Preferred Qualifications:
Bachelor’s degree in Engineering
Knowledgeable of Eaton electrical products, services and competitors
Design/build knowledge in the data center marketplace
Ability to recognize and offer value-added value engineering (VAVE) options and suggestions/recommendations to our mission critical customers
Experience or exposure to a manufacturing organization
Skills:
Position Criteria:
Possess excellent communication skills
Ability to respond to a variety of circumstances while continuing to demonstrate superior selling skills for important customer services and applications
Electrical product knowledge
Ability to provide technical solutions built around customer needs
Skilled in time management
Possess negotiating skills while understanding and using techniques needed to close orders
Experience with preparing sales proposals that meet customer expectations
Robust presentation & training skills
Experience utilizing value added selling techniques
Strong work ethic, communications skills, competitiveness, willingness to learn and adept at building relationships
Experience working with quotation software
Ability to travel up to 25%
We are committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law.
Eaton considers qualified applicants regardless of criminal histories, consistent with local laws. To request a disability-related reasonable accommodation to assist you in your job search, application or interview process, please call us at 1-800-836-6345 to discuss your specific need. Only accommodation requests will be accepted by this phone number.
We know that good benefit programs are important to employees and their families. Eaton provides various Health and Welfare benefits as well as Retirement benefits, and several programs that provide for paid and unpaid time away from work. Click here for more detail: Eaton Benefits Overview. Please note that specific programs and options available to an employee may depend on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE
1008932700381,Glassdoor,N/A,1797317630,,,N/A,"Role: Lead Data Engineer /Databricks (On-site)
Location: Mt. Laurel, NJ
Full-time
Must have skills:
Databricks, Python, RDBMS, Powershell scripting, datawarehouse
Experience in ETL/Pipeline Development using tools such as Azure Databricks/Apache Spark and Azure
Data Factory with development expertise on batch and real-time data integration
Experience in programming using Python
RDBMS knowledge and experience in writing the Store Procedures
Experience in writing bash and Power shell scripting.
Job Type: Full-time
Salary: $110,000.00 - $130,000.00 per year
Compensation package:
Yearly pay
Experience level:
9 years
Ability to commute/relocate:
Mount Laurel, NJ 08054: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 10 years (Required)
Snowflake: 5 years (Required)
ETL: 10 years (Required)
Azure: 5 years (Required)
Work Location: In person",TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE
1008931510976,Glassdoor,Donor Network of Arizona,1800716239,,,"https://www.glassdoor.com/Overview/Working-at-Donor-Network-of-Arizona-EI_IE391659.11,35.htm","Data Integration and Process Automation Engineer-(non-remote role)
About Us:
Donor Network of Arizona’s mission is to make the most of life through the gift of organ and tissue donation. We challenge ourselves and others every day to realize Arizona's potential to save and improve lives. Every employee at Donor Network of Arizona is responsible for embracing the organizational culture by upholding the Donor Network of Arizona’s core values of Positive Energy, Passion and Eagerness.
About the Role:
The primary responsibilities of the Data Integration and Process Automation Engineer position are to manage all operational aspects of the organization’s databases (MS-SQL), systems integration and process automation initiatives, both operational and strategic. We are seeking to hire a technically skilled resource that can proactively manage a wide range of data and system engineering disciplines. To ensure success in this role you will need to be an excellent problem-solver and communicator that is fluent in data management and manipulation. Ultimately, the resource chosen for this role must have extensive knowledge of databases, their creation, administration and optimization while also possessing deep knowledge of system integration and process automation techniques and technologies. The scope and priorities of data integration this position will be responsible for will be determined by organizational priorities and aligned to data strategies governed by Business Intelligence leadership.
This position’s expected level of interaction with all DNA departments will be governed through the creation of IT Service Requests by both IT and non-IT resources, in support of departmental and project objectives. As an active IT Team member, this position’s duties include mandatory participation in proactive management of IT Service Requests on a rotating on-call schedule, during off-hour time periods.
We Offer:
Competitive Salary- from $107,500-$121,800 annually
Organizational Incentive Program Annually, up to 10% (7% at target)*
Very generous health benefits, including medical, dental and vision
Free telemedicine for entire household
Health Savings Account
Retirement savings plan with company matching program and 8% employer contribution opportunity
SmartDollar financial wellness program
Free employee assistance program
Life insurance and disability insurance paid by the employer
Award-winning employee wellness program
Generous paid time off (PTO) policy including 10 paid holidays
Tuition assistance program
Culture of community and work-life balance
Onsite gym and walking paths
Amazing culture:
Awarded Top Companies to Work for in Arizona for 2022 & 2023
Staff-run committees and clubs promote open communication, diversity, community involvement, and socialization opportunities
Family-friendly activities on site for all employees
Responsibilities:
Provides for the operational integrity of the organizations MS-SQL database servers including installation, performing upgrades, developing processes for optimizing database performance and security, setting and maintain database standards, managing database access, executing performance tuning, creating automation for repeating database tasks, diagnosing and troubleshoot database errors, recommending and implementing emerging database technologies, creating and managing database usage and performance reports.
Maintains primary ownership and responsibility for engineering job/process lifecycle disciplines related to supporting a rich system integration and process automation environment including (but not limited to) functional and process design creation, configuration, stabilization, performance tuning, build verification, quality control, change control, testing and documentation.
Closely supports the Business Intelligence (BI) and Finance teams with their advanced data integration and process automation initiatives by collaborating with their departmental resources to understand user and system requirements, workflows, use cases and specifications in creating integration and automation solution across the enterprise.
Extracts and/or loads data to support Finance, BI and other departmental operational workflows.
Develops PowerShell scripts / scripting jobs that adhere to standard software development methodologies (documentation, code reviews, unit testing.) to validate the solution.
Works with other IT staff and external vendors to define and configure cybersecurity measures to help mitigate risk for the DNA system environment.
Works with other IT staff and external vendors to define and configure server and software patching / updates to help mitigate risk for the DNA security profile.
Analyzes project requirements and functional specifications in support of DNA departmental data, integration, and automation goals.
Helps to lead the organization’s advancement of data integration and process automation projects throughout the business by being a subject matter expert, influencing and incorporating design for integration and automation standards.
Writes clear, concise, well-coordinated technical documentation to maintain standards and procedures.
Creates training materials and provides training on integration/automation process technologies.
As an IT Team member, takes a proactive approach in the assessment and management of IT Service Requests for both Level 1 (initial triage) and Level 2 (ticket escalation) instances.
Participates in 24 x 7 x 365 On-Call IT resource rotation schedule to field IT Service Requests from users related to workflow stoppage of production systems while maintaining alignment with well-defined executive management service objectives.
Follows established change control processes to implement planned changes to production and non-production systems.
Ethically handles and adheres to regulatory compliance of private data, including financial and/or healthcare data.
Qualifications:
Minimum Education
Bachelor's degree in Information Technology, Computer Science, Information Systems, or a related field, or equivalent detailed Information Technology experience in progressively complex systems integration and process automation environments.
Certification as a MCDBA, MCADS, MCADE or MCASA is advantageous.
Minimum Experience:
6+ years of relevant work experience as an Integration Architect
8+ years experience in delivering complex systems integrations and intelligent automations required.
8+ years of experience with Microsoft Windows Server OS and its components
5+ years’ experience as a database administrator and 3 years as a database engineer.
3+ years’ experience with Microsoft Azure SQL platform in a Windows environment
Knowledge of enterprise architecture, systems architecture, integration architecture and data architecture standards, frameworks, and practices
Strong working experience with SQL/PLSQL and relational databases such as Oracle, MS SQL Server, and NoSQL databases required.
Advanced knowledge of SQL and SQL server tools (SSAS, SSIS, SSRS) with a strong command of database security, backup and recovery, and performance monitoring standards
3+ years (Intermediate level) skills in major programming languages (C++/Objective C/C#/Java/Python, etc.) and desire to learn others.
Strong operational understanding of VMWare and VSphere server virtualization tools (ESXi Hypervisor, vCenter Server, etc.)
Understanding of relational and dimensional data modeling techniques
Familiarity with business integration / automation ESB platforms (Talend, Workato, MuleSoft, Boomi, Informatica, IntApp, SmartConnect, etc.) designed to automate and orchestrate the integration of IT/business processes and workflows; Proficiency, knowledge, and experience with eOne SmartConnect is a plus.
Experience integrating with Cloud/SaaS applications, APIs, SDK of packaged and legacy applications.
Skills Required:
Analytical mindset and good problem-solving skills with an attention to detail.
Excellent verbal and written communication skills.
Excellent project management skills and strong ability to prioritize.
Job Type: Full-time
Pay: $107,500.00 - $121,800.00 per year
Benefits:
401(k)
Dental insurance
Employee assistance program
Health insurance
Health savings account
Life insurance
Paid time off
Retirement plan
Tuition reimbursement
Vision insurance
Work Location: In person",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931110218,Glassdoor,N/A,1797317630,,,N/A,"Position Summary
The Senior/First Data Engineer will play a crucial role in building, maintaining, and enhancing ETL processes that drive our analytics and machine learning platforms. This individual will be responsible for developing actionable insights from complex data sets, and work closely with various business units to inform strategy and decision-making.
You will be the first hire in this function.
Location
SF Bay Area, NYC, or Remote
Key Responsibilities
ETL & Backend Development:
Design and optimize ETL pipelines.
Develop robust backend systems for large-scale data processing using Elixir and database solutions like Cassandra/ScyllaDB.
Data Architecture:
Design scalable and efficient data models for Cassandra and ScyllaDB.
Ensure data integrity, quality, and security.
Data Science Support:
Collaborate with data scientists, providing them with clean and reliable datasets.
Assist in implementing and scaling data science models.
Innovation & Research:
Stay abreast of latest technologies.
Recommend technical improvements for data processing and storage.
Qualifications
Required
Bachelor’s or Master’s degree in Computer Science, Engineering, or a related technical field.
5+ years of experience in backend development, with a strong focus on data engineering.
Technical skills: Expertise in Python, Java, Scala, and Elixer for backend and ETL processes.
Mastery of ETL tools/frameworks (e.g. Apache Kafka, Apache Airflow).
Deep knowledge of SQL/NoSQL databases, including Cassandra and ScyllaDB, and data warehousing solutions (e.g., Redshift, BigQueary, Snowflake).
Proficiency in cloud platforms (AWS, GCP, Azure) and distributed systems.
Familiarity with data science concepts, tools, and libraries (e.g. Pandas, Scikit-learn).
Soft Skills: Exceptional problem-solving skills.
Strong communication for technical and non-technical discussions.
Nice-to-have
Experience with cloud platforms like AWS, GCP, or Azure.
Exceptional communication skills, both verbal and written.
Expertise in machine learning algorithms and frameworks (e.g., TensorFlow, PyTorch, scikit-learn).
Benefits
Competitive salary ($150,000-$225,000/year) and stock options
Comprehensive health, dental, and vision plans
401(k)
Flexible working hours and remote work options
Regular team building events and activities",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932715546,Glassdoor,Seattle Childrens Hospital,78831438,,,"https://www.glassdoor.com/Overview/Working-at-Seattle-Children-s-EI_IE18613.11,29.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931750642,Glassdoor,ZoomInfo Technologies LLC,116518336,,,"https://www.glassdoor.com/Overview/Working-at-ZoomInfo-EI_IE22253.11,19.htm","At ZoomInfo, we encourage creativity, value innovation, demand teamwork, expect accountability and cherish results. We value your take charge, take initiative, get stuff done attitude and will help you unlock your growth potential. One great choice can change everything. Thrive with us at ZoomInfo.
About our Team
Our mission is to maximize the value of ZI's comprehensive B2B database through practical application of ML and Generative AI to solving real-world business challenges. To this end, the team has cultivated a powerful fusion of product thinking, ML, language models, and iterative methodologies which work together to deliver a robust suite of data products that inject data-driven intelligence into every facet of ZI. We actively research existing solutions and adapt them to fit our unique requirements, all while leaving ample room for creativity. We collaborate with other data scientists, product managers, ML engineers, subject-matter experts and key business stakeholders to form a cohesive unit dedicated to identifying critical gaps and defining effective approaches to solving the most valuable problems in our business. The result? An impressive array of both experimental and production-ready Data Science products that have a tangible impact on our customer's ability to generate revenue with their Go-to-Market motion. Embrace the opportunity to join our accomplished team on this transformative journey, where innovation and teamwork thrive, and where your contributions will shape the future of data-driven excellence.
About the Job
As part of our Innovation Data-Science team, you will be working on delivering solutions for a variety of business problems:
Collaborate with Data Scientists to understand data requirements and translate them into effective data engineering solutions.
Design, implement, and maintain scalable and efficient data pipelines for data processing, transformation, and analysis.
Work with large volumes of structured and unstructured data from various sources, ensuring data quality and reliability.
Optimize and fine-tune data pipelines for performance, throughput, and reliability.
Develop and maintain ETL (Extract, Transform, Load) processes that enable seamless integration of data into analytical platforms.
Ensure data security, privacy, and compliance with relevant regulations throughout the data engineering lifecycle.
Setting up monitoring systems to track data pipeline performance, data quality, and data integrity. Performing data validation to ensure data accuracy and consistency.
Monitor and troubleshoot data pipeline issues, proactively identifying and resolving bottlenecks or inconsistencies.
Manage and scale the computing infrastructure required for robust and scalable machine learning workloads.
Create deployment templates and scripts for model deployment and rollback.
Explore and implement innovative technologies and tools to enhance data engineering capabilities.
Document data pipelines, processes, and best practices for knowledge sharing and team collaboration.
Stay current with industry trends and best practices in data engineering and related technologies.
About You
Bachelor's or Master's degree in Computer Science, Data Engineering, or a related field.
3+ years of experience as a Data Engineer, preferably in a Data Science or analytics-focused environment.
Proficiency in programming languages such as Python, Java, or Scala.
Experience with data integration tools and ETL frameworks (e.g., Apache Spark, Apache Beam, Talend, Airflow, dbt).
Strong SQL skills and experience working with relational and NoSQL databases.
Familiarity with data warehousing concepts and technologies (e.g., Snowflake, Redshift, BigQuery).
Understanding of data modeling, schema design, and data normalization/denormalization.
Knowledge of code version control systems (e.g., Git) and collaborative development practices.
Excellent problem-solving skills and the ability to work in a fast-paced, dynamic environment.
Strong communication skills to collaborate with cross-functional teams and translate technical concepts to non-technical stakeholders.
Preferred:
Experience with cloud platforms such as AWS, Azure, or Google Cloud.
Knowledge of DevOps practices and tools (e.g. Jenkins, Terraform).
Previous exposure to Machine Learning frameworks and concepts.
Contributions to open-source projects or data engineering communities.


The US base salary range for this position is $118,500 to $148,000 + variable compensation + benefits.
Actual compensation offered will be based on factors such as the candidate's work location, qualifications, skills, experience and/or training. Your recruiter can share more information about the specific salary range for your desired work location during the hiring process.
We want our employees and their families to thrive. In addition to comprehensive benefits, we offer holistic mind, body and lifestyle programs designed for overall well-being. Learn more about ZoomInfo benefits here.
#LI-MH
#LI-Hybrid
About us:
ZoomInfo (NASDAQ: ZI) is the trusted go-to-market platform for businesses to find, acquire, and grow their customers. It delivers accurate, real-time data, insights, and technology to more than 35,000 companies worldwide. Businesses use ZoomInfo to increase efficiency, consolidate technology stacks, and align their sales and marketing teams — all in one platform.
ZoomInfo may use a software-based assessment as part of the recruitment process. More information about this tool, including the results of the most recent bias audit, is available here.
ZoomInfo is proud to be an Equal Opportunity employer. We are committed to equal employment opportunities for applicants and employees regardless of sex, race, age, color, national origin, sexual orientation, gender identity, marital status, disability status, religion, protected military or veteran status, medical condition, or any other characteristic or status protected by applicable law. At ZoomInfo, we also consider qualified candidates with criminal histories, consistent with legal requirements.",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE
1008932017425,Glassdoor,Meta,1411870659,,,"https://www.glassdoor.com/Overview/Working-at-Meta-EI_IE40772.11,15.htm","We are looking for a Data Engineer to join our eDiscovery & Information Governance Legal team. You will enjoy working with some of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into real world impact. The perfect candidate will have a background in a quantitative or technical field, a perfectionist mentality, and will have excellent communication skills. You are focused on accuracy, a self-starter, and have demonstrated success in building datasets to power and influence business decisions.


Data Engineer, Legal Responsibilities:
Independently design, build and launch new data extraction, transformation and loading processes in production
Mentor others and introduce the team to novel methods, efficient queries, programming tools
Collaborate with a variety of technical and non-technical stakeholders (including attorneys, engineers, and data scientists) to understand and identify data needs, understand business problems and implement and maintain any logging required
Work with colleagues in data infrastructure to triage and resolve issues and maintain integrity of data pipelines. Keep stakeholders informed of progress and resolution on key issues
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Advance Data Engineering best practices within the team
share and contribute to development of documentation, protocols and procedures, training guides, workflows, etc.



Minimum Qualifications:
3+ years of work experience in data engineering
Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience
Experience with distributed computing (Hive/Hadoop)
Experience using version control systems (e.g. Git/Mercurial)
Experience initiating and driving projects to completion with minimal guidance
Experience working cross-functionally and communicating technical content to general audiences



Preferred Qualifications:
Experience with Unix/Linux
MBA or Masters in a technical discipline
PHP experience
Experience working with non-technical partners
Experience visualizing data (e.g. Tableau, PowerBI)



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931261141,Glassdoor,SCIGON Solution,1316838274,,,"https://www.glassdoor.com/Overview/Working-at-SCIGON-Solutions-EI_IE716803.11,27.htm","Skills:
Extensive experience as a Data Engineer or similar role, with a focus on Scala, Java, and Python programming languages.
Proven expertise in Apache Spark, HBase, and Hive, with the ability to process and manipulate large datasets effectively.
Familiarity with AWS services (e.g., EMR, S3, Redshift) is a plus.
Experience with data migration from on-premises to cloud environments is desirable.
A bachelor's degree in Computer Science, Data Science, or a related field (a master's degree is a plus).
Strong problem-solving skills and attention to detail.
Excellent communication and teamwork abilities.
Responsibilities:
Develop Data Processing Solutions: Leverage your expertise in Scala (60%), Java, and Python to design, develop, and maintain data processing solutions that operate at scale, ensuring the efficiency, reliability, and performance of data workflows.
Big Data Mastery: Utilize your in-depth knowledge of Big Data technologies, including Apache Spark, HBase, and Hive, to process and manipulate large datasets efficiently.
Cloud Expertise: If you have experience with AWS, contribute to the migration of data processing systems from on-premises to the cloud, ensuring seamless and secure operations.
Data Migration: Collaborate on data migration initiatives, playing a pivotal role in transitioning data processing and handling systems to modern cloud-based platforms.
Data Handling: Employ best practices in data handling, ensuring the integrity, security, and accessibility of data assets while complying with relevant regulations.
Job Type: Contract
Pay: $58.00 - $68.00 per hour
Experience level:
5 years
6 years
Schedule:
Monday to Friday
Application Question(s):
Due to numerous fraudulent applications, we require candidates to show any valid IDs at the beginning of the video interview stage (We only need to see your name and photo, you can cover the rest of the details). Are you willing to provide it? (Yes/No):
Education:
Bachelor's (Preferred)
Experience:
Data Engineering: 5 years (Preferred)
Scala: 3 years (Preferred)
Java: 3 years (Preferred)
Python: 3 years (Preferred)
Apache Spark: 3 years (Preferred)
HBase, and Hive: 3 years (Preferred)
AWS Services: S3, Redshift: 3 years (Preferred)
data migration from on-premises to cloud environment: 3 years (Preferred)
AWS EMR: 3 years (Preferred)
AWS Airflow: 3 years (Preferred)
Industry: 5 years (Preferred)
Work Location: Remote",TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931671703,Glassdoor,"Daiichi Sankyo, Inc.",1034867918,81000,114000,"https://www.glassdoor.com/Overview/Working-at-Daiichi-Sankyo-EI_IE40063.11,25.htm","Join a Legacy of Innovation 110 Years and Counting!

Daiichi Sankyo Group is dedicated to the creation and supply of innovative pharmaceutical therapies to improve standards of care and address diversified, unmet medical needs of people globally by leveraging our world-class science and technology. With more than 100 years of scientific expertise and a presence in more than 20 countries, Daiichi Sankyo and its 16,000 employees around the world draw upon a rich legacy of innovation and a robust pipeline of promising new medicines to help people. Under the Group’s 2025 Vision to become a “Global Pharma Innovator with Competitive Advantage in Oncology,” Daiichi Sankyo is primarily focused on providing novel therapies in oncology, as well as other research areas centered around rare diseases and immune disorders.
Summary
The candidate will work in Informatics Data Architecture & Data Science team to deliver foundational data capabilities like Data Lakes, Master Data Management, NLP Integrations etc. for Clinical, Regulatory & Translational Research. The candidate will have direct accountability to evolving data lake platform for the R&D domain of Daiichi Sankyo globally. The candidate will be part of Dev Ops Team - responsible to build data platforms, test, deploy and support in accordance with DSI SDLC standards. This is a highly technical and hands on role.

Responsibilities

Defining database design, data flows and data integration techniques. Design and Build data solutions ensuring data quality, reliability, availability and data governance.
Evolve RD Master Data Management platform. Create Data processing routines for managing enterprise master data throughout the data lifecycle (capture, processing and consumption). Maximize business outcomes using MDM via improved data integrity, visibility, and accuracy.
Manage and Evolve global data lakes platforms – Develop Data Ingestion, Data Enrichment, Data DEIDENTIFICATION routines and RESTful API’s for consumption of data lakes data. Enable technologies, platforms and workflows to enable analysts and data scientists to focus on algorithms and analyses.
Serve as primary point of contact for implementation of complex data project. Provide technical expertise, risk analysis, business and technical assessment of change requests in relation to data platforms. Implement and document approved change requests.
Collaborates with domain experts in privacy, security, and compliance to ensure that the RD data platforms uphold privacy, security, and compliance requirements.
Qualifications: Successful candidates will be able to meet the qualifications below with or without a reasonable accommodation.
Education Qualifications (from an accredited college or university)

Bachelor's Degree or higher degree in Computer Science or a related discipline from an accredited college or university preferred
Experience Qualifications

4 or More Years experience in life sciences, pharma or informatics industry or commensurate experience preferred
4 or More Years 3 + years of experience with Clinical Trials Data, Genomics, Bio Marker & Regulatory Data preferred
4 or More Years 4 + years of experience with data integration tools using disparate data sources such as flat files, databases, xml files and/or unstructured data & web services preferred
4 or More Years 3 + years of experience with Master Data Management Technologies preferred
4 or More Years 3 + years of experience with RESTful API’s Development preferred
1 or More Years 2 + years of experience with NLP (Natural Language Processing) like Linguamatics etc. preferred
Extensive hands on experience with analyzing and designing data models for Data warehousing and Transactional applications with high availability/ scalability & performance. preferred
Strong in Unix shell/Perl scripting preferred
Proven ability to work in a global and highly matrix environment preferred
Familiarity with VALIDATED systems and understanding of regulatory and industry artifacts such as 21 CRF Part 11: Electronic Records, Electronic Signatures preferred
Daiichi Sankyo, Inc. is an equal opportunity/affirmative action employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008933193841,Glassdoor,Capgemini,161639144,82000,116000,"https://www.glassdoor.com/Overview/Working-at-Capgemini-EI_IE3803.11,20.htm","Duration: 9+ months
Job Description:

Actively and consistently supports all efforts to simplify and enhance the customer experience.
Create and maintain scalable, reliable, consistent and repeatable systems that support data operations for Reporting, Analytics, and Applications for Business Intelligence.
Gather and process raw data at scale (including writing scripts, web scraping, calling APIs, write SQL queries, etc.).
Use ETL processes in order to maintain, improve, clean, and manipulate data.
Profile data to measure quality, integrity, accuracy, and completeness.
Develop and implement tools, scripts, queries, and applications for ETL/ELT and data operations.
Design, build, and automate Business Intelligence Data Pipelines.
Deliver solutions by developing, testing, and implementing code and scripts.
Produce reports and uphold data delivery schedules.
Manage life cycle of multiple data sources.
Work closely with stakeholders on the data demand side (Analysts and BI Developers).
Increase speed to delivery by implementing workload/workflow automation solutions.
Perform other duties as assigned.

Ability to use a wide variety of open source technologies and cloud services
Basic coding/scripting experience using Python, R, shell scripts
Basic experience with SQL, Tableau, Looker, Alteryx, and ETL techniques
Basic background in Linux/Unix/CentOS installation and administration; Windows experience preferred
Basic knowledge in data storage that demonstrates knowledge of when to use a file system, relational database (i.e. Snowflake), or NoSQL variant
Experience with Spark
Basic familiarity with JavaScript API, Rest API or Data Extract APIs
Basic experience receiving, converting, and cleansing big data
Basic experience with visualization or BI tools, such as Tableau and Looker
Basic experience with data workflow/data prep platforms, such as Airflow, Infomatica, Pentaho, or Talend
Ability to identify and resolve end-to-end performance, network, server, and platform issues
Attention to detail with the ability to effectively prioritize and execute multiple tasks
Hands-on working experience with RDBMS, SQL, scripting, and coding
Linux/Unix/CentOS system admin 1
Basic coding/scripting experience using Python, R, shell scripts
Basic experience with data workflow/data prep platforms, such as Airflow
Basic knowledge of best practices and IT operations in an always-up, always-available service
Basic experience receiving, converting, and cleansing big data
Basic experience with visualization or BI tools, such as Tableau and Looker
Basic experience receiving, converting, and cleansing data
Basic knowledge of best practices and IT operations in an always-up, always-available service

Education

Degree in an engineering discipline or computer science, or related field, or with equivalent experience.

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.
A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.",TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931262611,Glassdoor,Amazon.com Services LLC,695687622,,,"https://www.glassdoor.com/Overview/Working-at-Amazon-EI_IE6036.11,17.htm","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
Are you fascinated with the idea of creating a digital representation of the world? What about building learning systems to create the most precise and accurate representation? Join the Geospatial Data team to build Maps for Amazon.

We build learning systems to identify road networks, POIs, and geocodes of addresses worldwide. Our delivery operations use these systems to determine the locations and plan the routes for delivery. Drivers use these systems to navigate to the delivery locations. Our mission is to vend geospatial data (e.g. maps, traffic, addresses, and locations/geocodes) that is both authoritative and fresh through an intuitive experience that enables every driver – independent of tenure and affinity – to succeed in their delivery tasks.

We are not creating another consumer-grade mapping solution, we are building systems that enable depth focused solutions. For example, we are interested in not only getting a person to an address like 300 Boren Ave N, we are also interested in helping them park, optimally group the packages for that stop based on proximity, find out if there is a mailing room in the building that is open at that time, and help them navigate quickly to that mailing room or alternative location. We are also interested in accurately estimating how long it would take. We incorporate the ability to leverage multiple modes of transportation and traffic awareness to find the most efficient paths for our drivers. We are also interested in making it easy to calculate paths to cover hundreds of delivery points. Several of these problems require us to build systems that can work with an ensemble of models as well as support the right segmentation of inputs to make good estimates on the outputs.

There are several unsolved or partially solved problems in this space; such as automatically adding new roads detected from sensor/video data into the larger road graph, detecting if a new road is in fact just a modification to an existing road (such as a change in curvature of an existing road due to a new sidewalk), accurately determining the bearing of a person when they start traveling by leveraging IMU sensor source, parsing unstructured addresses such as in countries like India, processing alternate solutions within microseconds on a mobile device without talking to a backend service and so on.

The technical domain is multi-faceted. We build low-latency, highly-available services, we build big data processing pipelines to refresh or produce new data, we train ML models, and we run science experiments. We also build platforms for these capabilities, ranging from ML and experimentation platforms to semantic graph data stores that links billions of geospatial artifacts for use by a number of different use cases.

Our key output metrics include location accuracy, coverage and accuracy of our road network for routing users to the correct location, predictive accuracy of service, and transit estimates. We also measure the operational impact of these inputs on delivery success and on the gaps between actual versus planned on zone times, transit times, and service times.

If you have an entrepreneurial spirit, know how to deliver, are deeply technical, highly innovative and long for the opportunity to build pioneering solutions to challenging problems, we want to talk to you.

Key job responsibilities
Participate in the design, implementation, and deployment of successful large-scale systems and services in support of our fulfillment operations and the businesses they support.

Participate in the definition of secure, scalable, and low-latency services and efficient physical processes.

Work in expert cross-functional teams delivering on demanding projects.

Functionally decompose complex problems into simple, straight-forward solutions.

Understand system inter-dependencies and limitations.

Share knowledge in performance, scalability, enterprise system architecture, and engineering best practices.

A day in the life
Collaborate with engineering and science teams on building state-of-the-art scalable, big data pipelines, ML Platform (for model training, lifecycle management and inference), high-availability services, and semantic graphs with geospatial data.

Analyze nuanced metrics to understand system behavior and innovate on solutions to optimize our success metrics.

Play a key role in the technology that empowers the delivery of millions of smiles every day around the world.

About the team
This role is within the LastMile, Geospatial Data organization. Geospatial data (e.g., maps, traffic, addresses, and locations) are foundational inputs enabling us to plan safe, efficient routes and guide drivers to their delivery/pickup points. The team for this position is developing learning systems for inferring geocodes and geofences for customer addresses, vending them and modeling them for complex building situations such as when mail rooms are present. The team leverages a knowledge graph, pulling together foundational geospatial data sets including addresses, parcels and maps data. The team infers geocodes for the best locations to park and the locations for delivery points. The the levels of fidelity and accuracy are world-class and critical for LastMile deliveries at scale.

We are open to hiring candidates to work out of one of the following locations:

Bellevue, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931954170,Glassdoor,Core,79061019,,,"https://www.glassdoor.com/Overview/Working-at-Core4ce-EI_IE4242800.11,18.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932769462,Glassdoor,AT&T,328749724,75000,112000,"https://www.glassdoor.com/Overview/Working-at-AT-and-T-EI_IE613.11,19.htm","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.
As a Principal Data Platform Engineer, you will provide software development and engineering support for AT&T’s internal threat data collection platform and security threat analysis program. The position will work with senior team members on various projects relating to the protection of devices, customers, assets, data, information technology and networks. Contributions will support innovation, strategic planning, technical proof of concepts, testing, lab work, and various other technical tasks associated with the cyber security programs. The position is highly technical and requires experience in critical software development technologies and techniques including large scale data platforms (e.g. Databricks), query languages (e.g. SQL) and data presentation (e.g. Splunk).
About the job:
Contributes software solutions to help bolster threat analytics platform’s data, tools and capabilities.
Designs solutions to address cross platform integration, automation, Splunk/Databricks optimization, public cloud transformation and Open Source software customization.
Analyzes complex security issues to provide technical solutions and help mitigate risk as part of AT&T Chief Security Office
Works as a collaborative member of an engineering team, communicating with peers and contributing to planning, task tracking and meeting project milestones.
Performs rigorous software and data testing and reliability engineering.
Qualifications:
Bachelor’s Degree in Information Systems, Engineering, Mathematics, Computer Science or Cyber Security or equivalent experience.
8 – 10 years of related experience
Extensive work with Databricks, Splunk, streaming data, data science and infrastructure deployment
Software development skills in multiple computer languages and development problem solving practices.
Expertise in agile software development, security data, security tools and data science
Agile software life cycle, Open Source analytics tools, security domain knowledge, data base administration and design
Databricks, Splunk, SQL, Linux, Amazon Web Services, Azure, Python, Java, CI/CD tools, SIEM tools desired
A career with us, a global leader in communications and technology, comes with big rewards. As part of our team, you’ll lead transformation surrounded by trailblazing industry leaders like you. You’ll be empowered to go above and beyond – making a difference through company-sponsored initiatives or connecting and networking through one of our many employee groups. And regardless of where you’re at in your career trajectory, you’ll be rewarded by the impact that comes with making a difference in the lives of millions. With AT&T, you’ll be a part of something greater, do incredible things and be rewarded with a chance to change the world.

Ready to join our team? Apply today
#LI-Onsite",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932141340,Glassdoor,N/A,1797317630,,,N/A,"Job Title- Data Engineer on W2
Experience-10+ yrs
Location- Chicago, Austin, California , New Jersey , Boston, Connecticut
Responsibilities
Work with our different teams to design and build data solutions for analytics and business data users.
Build, test and maintain complex data pipelines. Maintain the data domain metadata and data catalog.
Develop a strong contextual knowledge of the data in use to provide accuracy and effective data solutions.
Create and review technical and user-focused documentation for data solutions ( data models, data dictionaries, business glossaries, process and data flows, architecture diagrams, user guides, etc.)
Design and execute strategies for real-time data analysis and decision-making.
Actively promote and enhance best practices, standards, and audits to certify and preserve high-quality data that is fit for purpose.
Become a subject matter expert on new Data Warehouse technologies, as well as provide recommendations on making improvements.
Own, troubleshoot and resolve incidents, including escalating and managing problems with vendors.
Engage with cross-functional teams to deeply understand requirements, insights, and needs.
Be open and willing to learn new skills!
Requirements
Bachelor’s degree in computer science/ data processing or equivalent.
4 to 6 years of experience in data development and data warehousing.
Experience with data analytics and preparing data for analytics data users
Experience with cloud data warehouse platforms ( Data bricks is mandatory)
Expert in SQL and highly capable in Python and experience with data pipeline tools and Spark
Experience with orchestration and building automation tools (Jenkins, Harness, and Airflow preferred)
Ability to work independently and deliver high-quality results
Ability to work in an Agile environment (Scrum, Lean, Kanban, etc)
Outstanding communication and problem-solving skills
Knowledge of finance, accounting, capital markets, and lending preferred
Knowledge of customer data integration and customer data platforms preferred.
Job Type: Contract
Pay: $83,492.68 - $190,739.06 per year
Benefits:
Health insurance
Compensation package:
Bonus opportunities
Signing bonus
Experience level:
9 years
Schedule:
Monday to Friday
People with a criminal record are encouraged to apply
Experience:
Informatica: 9 years (Preferred)
SQL: 9 years (Preferred)
Data warehouse: 5 years (Preferred)
Work Location: On the road",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008933166045,Glassdoor,Premise,6031815,98000,143000,"https://www.glassdoor.com/Overview/Working-at-Premise-Data-Corporation-EI_IE952471.11,35.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931704871,Glassdoor,Michael Baker International,1016955888,,,"https://www.glassdoor.com/Overview/Working-at-Michael-Baker-International-EI_IE944.11,38.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931523535,Glassdoor,Analytica,1077832885,,,"https://www.glassdoor.com/Overview/Working-at-Analytica-EI_IE374619.11,20.htm","ANALYTICA is seeking a Senior Data Engineer to support a federal government client in the DC metro area (Note - your work location is REMOTE). In this assignment, you will be a team member serving the client in advancing the customers use data, metadata, as well as explore new technologies to better meet those needs.

This is a mission that takes some serious smarts, intense curiosity and a background in developing data solutions across the data lifecycle.

Analytica has been recognized by Inc. Magazine as the fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. As a core member you’ll work with a diverse team of professionals to solution matters, architect nuisances, and come up with alternatives. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.

Responsibilities include (But Are Not Necessarily Limited To):
Research, design, build, optimize and maintain reliable, efficient, and accessible data models, systems and pipelines/APIs etc.
Support, with guidance, the analytic and/or operational use of data.
Align closely with Enterprise partners in data science, architecture, governance, infrastructure, and security to apply standards and optimize production environments and practices.
Collaborate with business owners to optimize data collection, movement, storage, and usage to data process and data quality.
Convert concepts & ideas into workable prototypes (custom or COTS products) for client reviews and acceptance.
Translate business needs into:
data architecture solutions development within supported data systems.
data orchestration pipelines (source to target analysis & recommendations), data sourcing, cleansing, augmentation and quality control processes within supported data systems.
Prototype, test and integrate new data tools (i.e. data features and functionality) as defined by the product owners and business teams
Competency and skill set will determine level of placement within the posted job family.

Qualifications:
Bachelor’s degree in computer science, information systems management or similarly related degree.
7+ years of professional data solutions development and implementation experience with:
AWS (Glue, Athena, API Gateway)
SQL, NoSQL
Data developments with modeling tools such as Neo4J, Erwin, Embarcadero, transforming logical, physical, conceptual, reverse engineering & forward engineering.
Development with Alation and/or EASparx
Data Movement tools such as Informatica & others…
Unit testing
RESTful API Development
Desire and willingness to learn new data tools
Has an Agile mindset and iterative development process background
Help promote a culture of diversity and inclusion within the department and the larger organization
Value different ideas and opinions
Listen courageously and remain curious in all that you do
CMS data experience a must
CMS Public Trust clearance, EUA highly preferred
Valuable Experience:
AWS CDK and/or other AWS services (or comparable cloud data solutioning tools)
Experience with Git and CICD pipelines
Relational database design
Microservices / Containers (Docker, Kubernetes)
Informatica Intelligent Cloud Services (IICS)
Prior experience with CMS, preferably within clinical quality or standards area

About ANALYTICA: Analytica is a leading consulting and information technology solutions provider to public sector organizations supporting health, civilian, and national security missions. Founded in 2009 and headquartered in Bethesda, MD., the company is an established 8(a) small business that has been recognized by Inc. Magazine each of the past three years as one of the 250 fastest-growing companies in the U.S. Analytica specializes in providing software and systems engineering, information management, analytics & visualization, agile project management, and management consulting services. The company is appraised by the Software Engineering Institute (SEI) at CMMI® Maturity Level 3 and is an ISO 9001:2008 certified provider.

As a federal contractor, Analytica is required to verify that all employees are fully vaccinated against COVID-19. If you receive an offer and are unable to get vaccinated for religious or medical reasons, you may request a reasonable accommodation.
vR3cn1Uzfh",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932464938,Glassdoor,CarolinaEast Health System,2043175754,85000,118000,"https://www.glassdoor.com/Overview/Working-at-CarolinaEast-Health-System-EI_IE358638.11,37.htm","About CarolinaEast Medical Center
CarolinaEast Health System is dedicated to quality and compassionate care across the Coastal Carolina region. The flagship of the health system is a 350 bed full service medical center housing a complete complement of inpatient and outpatient services with the latest technology. CarolinaEast Health System employs 2,500 dedicated team members. We have physician practices in various specialties spanning four counties. Our employees create a culture of excellence that connects our patients to the same level of care that is usually found at larger medical centers while maintaining a friendly, community feel throughout our facilities. CarolinaEast offers a comprehensive benefits package to all full time employees as well as benefits to part time plus and part time employees.
Job Summary: Perform data analytics extraction. Support the fundamental structure of applications and relational databases. Understand solutions that enable one to investigate, analyze, and provide comprehensive resolution for service requests by using applicable monitoring and troubleshooting tools and techniques. Provide ongoing systems and user support of one or more computer applications. Consult in system design, build, configuration, and implementation within the appropriate tools used by the solution. Utilize technical expertise to configure the system and solve client issues. Provide advanced design and maintenance of programs using Visual Basic/Cerner Command Language/SQL. Create scripts, reports, and data files
Minimum Requirements: Associate's degree in Information Systems or related discipline. Ten years as a Systems Analyst and Programmer. Visual Basic/CCL/SQL programming skills and relational database knowledge. Health care experience.",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931545698,Glassdoor,Vaxcyte,55684741,,,"https://www.glassdoor.com/Overview/Working-at-Vaxcyte-EI_IE3511160.11,18.htm","Company Profile:
Vaxcyte, Inc. (Nasdaq: PCVX) is a vaccine innovation company engineering high-fidelity vaccines to protect humankind from the consequences of bacterial diseases. The Company is developing broad-spectrum conjugate and novel protein vaccines to prevent or treat bacterial infectious diseases. Vaxcyte’s lead candidate, VAX-24, is a 24-valent, broad-spectrum, carrier-sparing pneumococcal conjugate vaccine (PCV) being developed for the prevention of invasive pneumococcal disease (IPD). The Company is re-engineering the way highly complex immunizations are made through modern synthetic techniques, including advanced chemistry and our exclusively licensed XpressCFTM cell-free protein synthesis platform. Unlike conventional cell-based approaches, the Company’s system for producing difficult-to-make proteins and antigens is intended to accelerate its ability to efficiently create and deliver high-fidelity vaccines with enhanced immunological benefits. Vaxcyte’s pipeline also includes VAX-31, a 31-valent PCV candidate; VAX-A1, a prophylactic vaccine candidate designed to prevent Group A Strep infections; VAX-PG, a therapeutic vaccine candidate designed to slow or stop the progression of periodontal disease; and VAX-GI, a vaccine program designed to prevent Shigella. The Company is driven to eradicate or treat invasive bacterial infections, which have serious and costly health consequences when left unchecked. For more information, visit www.vaxcyte.com.
Vaxcyte, headquartered in San Carlos, CA, went public in June 2020 and currently has a team of approximately 180 employees and anticipates continued, significant growth. Following equity offerings in October 2022 and April 2023, which generated over $1.1 billion in net proceeds, the Company’s balance sheet is further strengthened to advance its pipeline of novel vaccines, including VAX-24. These financings followed positive data readouts from Vaxcyte’s Phase 1/2 proof-of-concept study evaluating VAX-24 in adults aged 18-64 and Phase 2 study in adults 65 and older. The Company believes these results support a best-in-class potential for VAX-24, which was designed to replace the current standard-of-care in adults and children. VAX-24 is being investigated for the prevention of IPD, which can be most serious for infants, young children, older adults and those with immune deficiencies or certain chronic health conditions. Given the global impact of pneumococcal disease remains significant, the public health community continues to advocate for vaccines that can offer broader protection to prevent IPD. Vaxcyte’s PCV franchise, consisting of VAX-24 and VAX-31, is designed specifically to address this need and has the potential to deliver the broadest protection for this very serious disease. We believe that our PCVs could receive regulatory approval based on successful completion of clinical studies utilizing well-defined surrogate immune endpoints, consistent with how other PCVs have obtained regulatory approval in the past, rather than requiring clinical field efficacy studies.
Summary:
We are seeking an experienced and detail-oriented Data Systems Engineer with knowledge of System administration and DevOps with on premise and cloud-based platforms to join our IT team. In this role you will implement and administer Windows Domain and Active Directory, compute, storage, database, networking and security implementation and management. Strong knowledge in domain controllers, group policies, Active Directory, cloud services, databases, and web app deployment are essential for this position.
Infrastructure Management:
Provision, configure, and maintain cloud and VMWare resources, including virtual machines, databases, storage, WebApps and networking components.
Monitor and optimize cloud infrastructure for performance, cost, and security.
Implement and maintain backup and disaster recovery solutions.
Ensure cloud resources are compliant with security policies and best practices.
System Administration:
Administer and maintain Windows-based servers and systems.
Configure and manage domain controllers and Active Directory services.
Implement and manage group policies to ensure security and compliance.
Troubleshoot and resolve issues related to Windows infrastructure.
Implement security updates and patches for Windows environments.
Database Administration:
Possess knowledge in configuring, administering, and optimizing relational databases hosted on cloud.
Understand the principles of database availability, security, and performance.
Collaborate with development teams to support database-related tasks.
Web Application Deployment in Azure:
Deploy web applications on cloud.
Configure and manage web app settings, scaling, and monitoring.
Ensure high availability and performance of web applications.
DevOps Integration (Basic):
Collaborate with development teams to support basic CI/CD pipelines on cloud platforms.
Assist in automation and scripting tasks to streamline administration processes.
Provide basic support for containerization technologies like Docker and Kubernetes.
Documentation and Training:
Maintain detailed documentation of infrastructure, systems, databases, Python web applications, and administration processes.
Provide training and support to internal teams regarding system administration, database management, and web app deployment.
Requirements:
Bachelor's degree in computer science, information technology, or a related field (or equivalent workexperience).
8 -12 years of experience in Systems Administration.
Proven experience as a Windows Administrator with knowledge in domain controllers, group policies, Active Directory.
Strong understanding of Azure services, networking, and security.
Expertise in Windows Server administration and troubleshooting.
Experience administering on premise VMWare infrastructure.
Proficiency in scripting and automation using PowerShell and/or other relevant tools.
Knowledge in PostgreSQL administration, including database setup, optimization, and maintenance.
Experience in deploying Python web applications in Azure.
Familiarity with DevOps practices, including CI/CD concepts and automation.
Excellent problem-solving and troubleshooting skills.
Strong communication and collaboration abilities.
Azure certifications (e.g., Azure Administrator, Azure Solutions Architect) and relevant Python web app deployment experience are highly desired.
All Vaxcyte employees require vaccination against COVID-19.
Reports to: Senior Director, CMC IT Systems
Location: San Carlos, CA
Compensation:
The compensation package will be competitive and includes comprehensive benefits and an equity component.
Salary Range: $171,000 – $185,000

Send resumes to:
careers@vaxcyte.com
Vaxcyte, Inc.
825 Industrial Road, Suite 300
San Carlos, CA 94070
We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.",TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931304210,Glassdoor,"CompuNet, Inc.",94137044,91000,134000,"https://www.glassdoor.com/Overview/Working-at-Compunet-EI_IE1293007.11,19.htm","Why join CompuNet?
CompuNet values its people more than any other asset—and realizes the contributions made by each employee reflect their education, experience, certifications, expertise and passions. We strive to take care of each other, do the right thing and help our customers succeed. We work to build lasting relationships and are proud that our customers across many industries see us as a trusted advisor. Putting the customer at the center of every engagement, our mission is to design, test, deploy and support the right IT solutions for every customer.
We offer a generous total compensation package for our employees, including competitive wages, medical, dental, vision, PTO, company-matching retirement plans, profit-sharing and more.
What You’ll do
Our engineers are the foundation of success for our customers and our business. We are seeking a Senior Solutions Engineer with a Data Center focus to join our team in either Portland, Oregon or Seattle, Washington. This role will provide value for our clients in both pre-sales design and post-sales implementation. This role will perform the following responsibilities:
Collaborate with the sales team to build a winning strategy for our clients.
Perform necessary Pre-Sales technical functions to create systems designs.
Build Bill of Materials (BoM), create illustrations and diagrams and provide Statements of Work (SoW).
Relay technical information to both technical and non-technical staff.
Post-Sales Implementation of systems designed.
Produce post Implementation project documentation.
Provide proficient end-user systems administration training (post implementation) of CompuNet installed solutions.
Develop strategic relationships with our key manufacturer Partner SE's.
Key Expectations of this role:
Listen to and address customer technical challenges and design the right solution that meets the customer business needs.
Ability to communicate on a high level regarding multiple technologies.
Relay technical information to both technical and non-technical staff.
Maintain existing certifications and grow to new areas with certification.
Participate in all team functions including calls, meetings, events, etc.
Technologies that this role will encompass are below:
Converged and Hyper-Converged (HCI) solutions
Storage
Block, File & Object
Connectivity
Fibre Channel
iSCSI
Virtualization
Design, deploy and maintenance
vSphere
Hyper-V
Virtual network connectivity
Cloud (some understanding preferred but not required)
Understanding of public & private clouds
Azure
AWS
GCP
Data Protection
Veeam
Cohesity
Rubrik
Backup and Restore (Not all are required)
Disaster Recovery
Business Continuity
Microsoft Active Directory (not required but recommended to have some level of understanding)
Baseline understanding of Microsoft Active Directory and Windows Server components like DHCP, DNS & PKI
Networking (Basic Networking)
Fundamentals required for connectivity between data center, hybrid and cloud components
Who you are
You’re a strong team player that is invested in helping your customers succeed and contributing to a great team. You have the following knowledge, skills, abilities and/or education:
8+ years of experience is a plus
Demonstrated ability to work independently and bring order to ambiguous situations
Ability to work on different projects in a simultaneous fashion (i.e. multiple customer projects in the same time period).
Ability to relay technical information to both technical and non-technical staff.
Exceptional problem solving and organizational skills.
Excellent time management and independent work skills.
Excellent verbal and written communication skills.
Willing to travel 25-50% of the time depending on client needs
Who we are
CompuNet, Inc. is an engineering-led Information Technology solution provider that offers consulting, design, and implementation services. Our team consists of highly skilled IT architects and engineers with a long history of designing IT solutions. Each customer works with a dedicated local team who understands their business, their infrastructure, and their goals. This team takes ownership for the entire project lifecycle, from discovery and design through deployment, training, and handoff.
We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE
1008931546553,Glassdoor,Publicis Sapient,145139170,,,"https://www.glassdoor.com/Overview/Working-at-Publicis-Sapient-EI_IE1646026.11,27.htm","Senior GCP Data Engineer
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value.
Job Description
Senior Data Engineering Google Cloud Platform (GCP) is responsible to develop and deliver effective cloud solutions for clients. This position requires in-depth knowledge and expertise in GCP services, architecture, and best practices. They will collaborate with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions. He will also be responsible for driving innovation and staying up-to-date with the latest GCP technologies and trends to provide industry-leading solutions.
Your Impact:
Collaborate with clients to understand their business requirements and design GCP architecture to meet their needs.
Develop and implement cloud strategies, best practices, and standards to ensure efficient and effective cloud utilization.
Work with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions on GCP.
Provide technical guidance and mentorship to the team to develop their skills and expertise in GCP.
Stay up-to-date with the latest GCP technologies, trends, and best practices and assess their applicability to client solutions.
Qualifications
Must have good implementation experience on various GCP’s Data Storage and Processing services such as BigQuery, Dataflow, Bigtable, Dataform, Data fusion, cloud spanner, Cloud SQL
Must have programmatic experience with tools like Javascript, Python, Apache Spark
What sets you apart:
Experience in complex migrations from legacy data warehousing solutions or on-prem datalakes to GCP
Experience in building real-time ingestion and processing frameworks on GCP.
Adaptability to learn new technologies and products as the job demands.
Multi-cloud & hybrid cloud experience
Any cloud certification
Additional Information
Gender-Neutral Policy
Access to Medical Plan
Employee engagement activities and events
Remote work
Additional Information
Pay Range:$103,000 -$145,000
The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. Actual range for this position may differ, depending on location and specific skillset required for the work itself.
Learn more about us at www.publicissapient.com or explore other career opportunities careers.publicissapient.com.
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200.",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE
1008931528189,Glassdoor,Discord,1496456246,144000,204000,"https://www.glassdoor.com/Overview/Working-at-Discord-EI_IE910317.11,18.htm","The central Data Platform seeks to build a self-service tooling platform to make the petabytes of data at Discord easily accessible for everyone at the company. We build full-stack applications, tooling, and frameworks to improve the productivity of teams at Discord, in particular our product, analytics, and machine learning teams. Our tooling covers the end-to-end lifecycle of data from acquisition to consumption. Reporting to the Engineering Manager of Data Products, you will work on strategy that is foundational to the company and product. To learn more about Discord Engineering,read our engineering blog here — including ""How We Create Insights From Trillion Data Points"" that this team is behind! What you'll be doing Lead end-to-end development of data tooling and frameworks, using modern technologies such as BigQuery, Apache Beam, Airflow, Dagster, dbt, Kubernetes, and Rust. Ensure tight-knit collaboration with leadership, cross-functional stake-holders and senior engineers across the organizationCollaborate with leadership and senior engineers across the team to define the technical vision and build on the technical roadmap for Data Platform. Work with Data Platform to ensure we have a platform with strong governance that respects our users' privacy throughout. Care deeply about business outcomes and constraints and keep them in mind as you solve hard, unbounded problems. Work with other Staff Engineers to make decisions for the organization and engineering function as a whole. Coach and mentor the next generation of technical leaders at Discord. What you should have 7+ years of experience as a Software Engineer. Empathy for both your internal and external users and seek feedback on your work. Ability to approach problems with first principles thinking, embrace ambiguity, and enjoy collaborative work on complex solutions. Experience defining architecture, tooling, and strategy for a large-scale data processing system. Proactive in staying up-to-date with industry trends and assessing new technologies to enhanse problem solving capabilities. Bonus Points Experience working with very high-scale data infrastructure and tooling Experience with data products on Google Cloud Platform, Kubernetes, or Airflow Full-stack development or product engineering experience The US base salary range for this full-time position is $214,000 to $233,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.#buildbelonging #LI-Remote #LI-Hybrid #LI-HY1 Benefits and Perks Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) Mental health resources and quarterly wellness stipends 14+ paid holidays, 4 weeks of PTO + use-what-you-need sick days Paid parental leave (plus fertility, adoption and other family planning benefits) Flexible long-term work options (remote and hybrid) Volunteer time off A diverse slate of Employee Resource Groups Plus commuter contributions and other perks for office-based employees About Us Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. We’re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It’s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE
1008931090358,Glassdoor,Discover Financial Services,2115406215,,,"https://www.glassdoor.com/Overview/Working-at-Discover-EI_IE13990.11,19.htm","Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.

Job Description:
At Discover, be part of a culture where diversity, teamwork, and collaboration reign. Join a company that is just as employee focused as it is on its customers and is consistently rewarded for both. We’re all about people, and our employees are why Discover is a great place to work. Be the reason we help millions of consumers build a brighter financial future and achieve yours along the way with a rewarding career.

The Senior Associate Data Engineer is responsible for designing, developing, maintaining, and testing data solutions for the product using the enterprise framework. This role will apply learned software delivery capabilities and have the desire to learn higher levels of craftmanship. Senior Associate Data Engineers contribute opinions to design decisions and actively participate in agile ceremonies. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.

Responsibilities
Independently executes a variety of data integration solutions, recognizes data related patterns, and solicits advice on potential approaches.
Contributes opinions to design decisions and understands design tradeoffs.
Develops skills in data warehouse tools, Cloud, agile and other technologies involved in data integration.
Regularly contributes to team agile ceremonies and helps new engineers with onboarding.
Troubleshoots production issues and defects.
Identifies and executes test scenarios and shares test results.
Participates in the on-call rotation for support.
Work with source team to determine data needs for reporting.
Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor’s Degree in Computer Science or related field
1+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of advanced beginner on the Dreyfus engineering scale
Preferred Qualifications

If we had our say, we’d also look for:
Experience in supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike)
1+ years of experience in Data Engineering using ETL Tools, preferably Abinito.
Experience working with relational databases (Oracle, Snowflake, SQL Server).
Knowledge of cloud platforms (AWS, GCP, Azure) .
Other programming languages (Unix scripting, Java, Python, JavaScript (React), Node.js etc.)
Knowledge of Application framework (Spring, Spring Boot, Hibernate, Eclipse, IntelliJ, Postman, Docker, Jenkins, Maven).
Knowledge of DevOps CI/CD framework, Open-Source concepts, key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs .
External applicants will be required to perform a technical interview.

#LI-GF1

Compensation: The base pay for this position generally ranges between $70,000.00 to $118,400.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931545292,Glassdoor,Shockwave Medical,1309665298,123000,167000,"https://www.glassdoor.com/Overview/Working-at-Shockwave-Medical-EI_IE910184.11,28.htm","Shockwave Medical, Inc. is a pioneer in the development and commercialization of Intravascular Lithotripsy (IVL) to treat complex calcified cardiovascular disease. Shockwave Medical aims to establish a new standard of care for medical device treatment of atherosclerotic cardiovascular disease through its differentiated and proprietary local delivery of sonic pressure waves for the treatment of calcified plaque.
Position Overview
The Senior Data Warehouse Engineer is a senior-level role responsible for the design, development, and maintenance of data warehousing solutions within a medical device company. This position plays a critical role in managing and optimizing data for analysis, reporting, and regulatory compliance.
Essential Job Functions
Data Warehouse Design: Design and architect data warehouse solutions to meet the organization's data storage and reporting needs, ensuring scalability and performance.
Data Integration: Integrate data from various sources, including medical device databases, ERP systems, and external sources, into the data warehouse.
ETL Development: Develop and maintain ETL (Extract, Transform, Load) processes to extract, transform, and load data into the data warehouse, ensuring data accuracy and quality.
Data Modeling: Design and implement data models that support analytical and reporting requirements, optimizing data retrieval and query performance.
Performance Optimization: Monitor and optimize data warehouse performance, identifying and resolving bottlenecks to ensure timely data availability.
Data Governance: Implement data governance practices, including data security, privacy, and compliance with industry regulations, such as FDA requirements for medical devices.
Data Quality: Establish and maintain data quality standards, implementing processes to cleanse and validate data within the data warehouse.
Documentation: Maintain comprehensive documentation of data warehouse architecture, ETL processes, and data models, ensuring knowledge transfer and compliance with quality standards.
Collaboration: Collaborate with business users, data analysts, and other stakeholders to understand reporting and analytical requirements, translating them into technical solutions.
Regulatory Compliance: Ensure that the data warehouse meets regulatory compliance requirements for the medical device industry, including data traceability and auditability.
Qualifications
Bachelor’s degree in computer science, Information Technology, or related field (Master's preferred).
Typically, 5+ years of experience in data warehousing and engineering roles.
Extensive experience as a Data Warehouse Engineer with a focus on designing and implementing data warehousing solutions.
Proficiency in data warehousing technologies, ETL tools, and database management systems (e.g., Azure, SQL Server, Oracle, Snowflake, Data Bricks).
Knowledge of medical device industry regulations, including FDA requirements, is highly desirable.
Strong analytical, problem-solving, and communication skills.
Experience with data modeling and database design.
Project management experience is a plus.
Market Range: $131,000 - 153,000
Exact compensation may vary based on skills, experience, and location.
Benefits
Shockwave Medical offers a competitive total compensation package as well as the following benefits and perks:

Core Benefits: Medical, Dental, Vision, Pre-tax and Roth 401k options with a fully vested match, Short-Term and Long-Term Disability, and Life Insurance, Employer contribution toward Health Savings Account (HSA), Competitive PTO balance

Perks: ESPP, Calm App, Pet Insurance, Student Loan Refinancing, Spot Bonus awards

EEO Employer",FALSE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008933126199,Glassdoor,ADP,582821685,,,"https://www.glassdoor.com/Overview/Working-at-ADP-EI_IE64.11,14.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932068532,Glassdoor,Kivyo,42629171,,,"https://www.glassdoor.com/Overview/Working-at-Kivyo-EI_IE4634974.11,16.htm","Job Type: Permanent / Full Time
Job Description Kivyo is the fastest growing top-tier Cloud Solutions and Services company supporting Global Enterprise Customer across Americas, Europe and Middle East. Kivyo is looking for highly talented hands-on Software Engineer in India to help accelerate our growing Professional Services consulting Cloud & DevOps practice. This is an excellent opportunity to join Intuitive’s global world class technology teams, working with some of the best and brightest engineers while also developing your skills and furthering your career working with some of the largest customers.
Skills and qualifications:
Bachelor’s degree in Computer Science, Mathematics, Statistics, or related field
Experience in leading an engineering team
8+ years of hands on Data Modeling / SQL development experience
Advanced SQL expertise (query creation, Windowing and tuning)
Experience with big data analytics or real time analytics solutions
Experience with Relational Databases (e.g. Oracle, MySQL) and/or NoSQL databases (eg HBase, MongoDB)
Experience with Agile (eg Scrum) and test driven development
Expertise in Data Structures, Algorithms and Concurrency
Additional Advantages:
Experience with Looker’s LookML (modeling language)
Experience building Microservices and APIs
Experience with Amazon Web Service (EC2, S3) or Google Cloud or Azure
Experience with Cloudera Impala, Hive, Hibernate
Hands-on experience with Hadoop, Spark, Kafka, ElasticSearch
Experience with Continuous Integration (CI) and Continuous Delivery (CD)
Contributing to an open source community",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE
1008932924087,Glassdoor,Great Wolf Lodge Resorts,1486825243,98000,137000,"https://www.glassdoor.com/Overview/Working-at-Great-Wolf-Lodge-EI_IE421051.11,27.htm","Job Summary: Great Wolf Lodge is seeking a talented and experienced Lead Data Engineer to join our Analytics team. As a Lead Data Engineer, you will play a pivotal role in shaping our data infrastructure and analytics capabilities, enabling data-driven decision-making across the organization. You will lead a team of data engineers and work closely with data scientists, analysts, and other stakeholders to design, build, and maintain data pipelines, databases, and data models to support analytics and reporting solutions, including performance management, data science, and personalization.

The Lead Data Engineer will collaborate closely with Technology, Finance, and Commercial Analytics to drive value through best-in-class data architecture and data model design.

Responsibilities:
Lead a team of data engineers in designing, developing, and maintaining data pipelines and ELT/ETL processes using Matillion and dbt.
Partner with both internal stakeholders and external vendors involved in project definition, design, and planning, and map the data journey from source through consumers (data visualization, applications, or predictive models).
Architect, implement, and maintain data warehouse and database systems for efficient data storage, retrieval, and analysis using Snowflake.
Design, develop, test, and deploy data models, data collection, and transformation components. Determine the best point for transformations, calculations, and joins (e.g., data lake, data warehouse, or Tableau data source).
Ensure data quality, consistency, and integrity by establishing data governance best practices and ensuring scalability and sustainability of business intelligence data architecture.
Stay current with industry trends and emerging technologies to drive innovation within the data engineering domain.
Oversee and conduct troubleshooting, performance tuning, optimization, and scalability of data infrastructure.
Mentor and coach team members to improve their technical skills and foster collaboration.
Act as a subject matter expert on data-related projects and communicate effectively with non-technical stakeholders.

Qualifications:
Bachelor's or Master’s Degree in Technology, Computer Science, or similar technical field.
5+ years experience with data engineering technologies such as SQL, ETL tools (Matillion and dbt), and Snowflake data warehousing
Experience designing and implementing conceptual, logical, and physical data models
Strong programming skills in languages like Python and/or R.
Experience with cloud platforms (AWS and Azure) and knowledge of cloud-based data services.
Excellent problem-solving skills, with a focus on data architecture and system design.
Strong communication and leadership skills, with the ability to work collaboratively in a team environment.
Ability to work from Great Wolf's Corporate Headquarters, currently operating on a hybrid-remote schedule: Mondays and Fridays optional work from home, Tuesdays, Wednesdays and Thursdays in-office.

Preferred Experience:
Familiarity with data visualization tools (e.g. Tableau) and analytics platforms.
2+ years in a leadership or senior role strongly preferred.",TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE
1008931202177,Glassdoor,Link Logistics Real Estate,1957454354,,,"https://www.glassdoor.com/Overview/Working-at-Link-Logistics-Real-Estate-EI_IE2520695.11,37.htm","Link Logistics Real Estate (“Link”) owns and operates the largest U.S.-only portfolio of logistics real estate, leasing warehouse space to everyone from e-commerce giants to mom-and-pop shops. Established by Blackstone in 2019, we combine scale, cutting-edge technology, and logistics expertise to help our customers grow their businesses. Our portfolio includes more than 500 million square feet in dynamic markets nationwide. About 6 percent of U.S. GDP—translating to some $1.4 trillion every year—flows through the space Link customers occupy in our facilities.
Because we believe that good business must be synonymous with doing good, strong environmental, social and governance practices are foundational to our identity as a firm. These practices include setting ambitious goals to combat climate change, partnering with local nonprofits, and prioritizing internal diversity, equity, and inclusion efforts. We seek to use our position, ideas, and influence to drive progress in our industry and the wider world. At Link, we give our customers space to grow—and we give people space to grow, too.
Employee: Link Logistics Real Estate Holdco LLC
Job Title: Senior Data Engineer
Worksite: 277 Park Ave, 46th Floor, New York, NY 10172
Job Description: Expand and optimize data and data pipeline architecture. Work with data analysts, data scientists, and data architects as part of the initiatives that support application development, system/platform integrations and day-to-day business. Work to connect disparate datasets will enable phenomenal business growth, as well as supporting unique machine learning models and environmental and sustainability initiatives. Create and maintain reliable, performant data pipeline architecture: Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. Assemble large, complex data sets that meet functional / non-functional business requirements. Use expertise and creativity to proactively identify, design, and implement internal process improvements: optimize data delivery, re-designing infrastructure for greater scalability, etc. Work with data and analytics experts to strive for greater functionality in our data systems. Performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Build processes supporting data transformation, data structures, metadata, dependency, and workload management. Manipulating, processing, and extracting value from large, disconnected datasets. Supporting and working with cross-functional teams in a dynamic environment. 100% Telecommuting.
Job Requirements: Bachelor’s degree, or foreign equivalent, in Computer Science or a related field, plus 3 years of experience in Data Engineering or related occupation. Additionally, the applicant must have professional experience with: 1) Python; 2) Orchestration tools such as Luigi, Airflow, DBT; 3) SQL knowledge and experience working with scalable distributed systems and databases (e.g., Snowflake, Databricks, Spark, Redshift, GBQ); 4) MS Azure; 5) Software development practices like DevOps and CI/CD tool chains (i.e., Jenkins, Spinnaker, Azure DevOps, GitHub); 6) Familiarity with modern analytics and metadata management tools (e.g., DBT, Looker); and 7) Continuous integration technologies, orchestration tools (e.g., Jenkins, Airflow).
Rate of Pay: $197,000 per year
To Apply: Please visit https://www.linklogistics.com/careers/ for a complete job description, requirement and to apply. Refer to Req #JR100402
EEO Statement
The Company is an equal opportunity employer. In accordance with applicable law, we prohibit discrimination against any applicant, employee, or other covered person based on any legally recognized basis, including, but not limited to: veteran status, uniformed servicemember status, race, color, caste, immigration status, religion, religious creed (including religious dress and grooming practices), sex, gender, gender expression, gender identity, marital status, sexual orientation, pregnancy (including childbirth, lactation or related medical conditions), age, national origin or ancestry, citizenship, physical or mental disability, genetic information (including testing and characteristics), protected leave status, domestic violence victim status, or any other consideration protected by federal, state or local law. We are committed to providing reasonable accommodations, if you need an accommodation to complete the application process, please email
People@linklogistics.com
.",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008932822186,Glassdoor,Equinix,1707651419,,,"https://www.glassdoor.com/Overview/Working-at-Equinix-EI_IE11296.11,18.htm","Data Center Facilities Engineer (entry level)
Equinix is the world’s digital infrastructure company, operating 240+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, sophisticated infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.
We are a fast-growing global company with 20 years of consecutive quarter over quarter of growth. Our innovative portfolio of high-performance products and services has created the largest, most active global ecosystem of 10,000+ companies, including 2,000+ networks and 3,000 cloud and IT service providers in 31 countries spanning six continents! We embrace diversity in thought and contribution and are committed to providing an equitable work environment that is foundational to our core values as a company and is vital to our success.
Do you want to be at the forefront of maintaining critical facilities infrastructure? Would you enjoy being part of a close-knit team delivering outstanding service to our data center customers? Then read about the role and requirements for an Equinix Critical Facilities Engineer!
Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, and public safety centers. Simply put - We cannot go dark. In this crucial role, a Critical Facilities Engineer:
Performs basic routine work orders under supervision, like repairs and maintenance to facility components.
Supervises the Building Monitoring System (BMS).
Responds to basic alarms.
Assists in routine incident management.
Receives detailed instructions and works under close supervision.
Ensure that a team is safe for all and call out any possible issues.
Coordinates with vendors on standard operating procedures.
Assists with routine maintenance activities and infrastructure projects.
Responsibilities in facility and infrastructure maintenance include performing checks, preventative, corrective maintenance, repair, and installations of on-site facility systems. Supervise the Building Monitoring System (BMS) alarm. Operate and maintain plumbing, fire suppression, and safety systems.
Ensure that vendor maintenance activities are carried out according to Equinix's standard operating procedures.
Respond to all on-site incidents, including failures, problems, and delays.
Supports routine work requests; supports auxiliary equipment and machines with problem-solving and repairs to avoid/minimize downtime. Supports infrastructure projects.
Collaborates with others to resolve facility incidents. Optimally collaborates within the department and with key partners.
Qualifications
Vocational/technical school training in HVAC and/or electrical, or one year of related experience
High School Diploma or equivalent
A natural curiosity and strong problem-solving skills
Experience working in a critical facility a plus
You perform all crucial job functions, including walking, standing, bending, stooping, climbing, lifting, and manual dexterity, with or without reasonable accommodation.
You can work days/nights/weekends/holidays if needed and required.
You can lift heavy equipment/items up to 50 pounds
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $41,000 to $63,000 per year • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $38,000 to $58,000 per year • Colorado, Nevada, Rhode Island: $34,000 to $52,000 per year Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $41,000 to $63,000 per year • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $38,000 to $58,000 per year • Colorado, Nevada, Rhode Island: $34,000 to $52,000 per year Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE
1008931252486,Glassdoor,HII,334424664,47000,73000,"https://www.glassdoor.com/Overview/Working-at-HII-EI_IE398616.11,14.htm","Date: Oct 17, 2023
Location: Hurlburt Field, FL, Florida, United States
Company: HII's Mission Technologies division
Requisition Number: 16622
Required Travel: 0 - 10%
Employment Type: Full Time/Salaried/Exempt
Security Clearance: Secret
Level of Experience: Entry Level

This opportunity resides with Live, Virtual, Constructive Solutions, a business group within HII’s Mission Technologies division. As a trusted partner to our military customers, we design, develop and operate systems that bring together service members from across the globe to help you train like you fight, because we understand that preparation requires full coordination—not readiness in piece parts.

Meet HII’s Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense – the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that’s right for you. Apply today. We look forward to meeting you.
Summary
HII Mission Technologies is seeking a Junior Network Data Engineer for the Decisive Mission Actions and Technology Services (DMATS) with the US Air Force Special Operations Command (AFSOC) at Hurlburt Field, Florida. The selected candidate must The selected candidate will support the design, implementation and maintenance of DoD computer networks, enabling communication between multiple computer based systems. #LI-MJ1
What you will do
Assist in the Identification and resolution of network issues, perform routine maintenance and protect data from cyber-attacks.
Supports the design and maintenance of the hardware and software of a network.
Works with the senior Network Engineer to Conduct testing of network systems.
Performs routine network maintenance, including basic troubleshooting and installation of upgrades and service packs.
Consults with network engineering team to suggest network solutions
Test and install new computer systems, hardware, software, and applications as per DoD and customer guidance.
Explore ways to improve network performance or reduce network costs
Maintain analytical systems, verifies the accuracy of the data, and act as liaison.
Manage all aspects of end-to-end data processing utilizing customized report building functions of systems.
Maintain technical expertise in all areas of network and computer hardware and software interconnection and interfacing, such as routers, switchers, firewalls, hubs, bridges, gateways, etc.
What you must have
Must have 0 years experience with Bachelors in Computer Science, Data Scientist, Statistics or related field; High School Diploma or equivalent and 4 years relevant progressive experience.
Must have Knowledge of cloud architectures.
Must have a CompTIA Security + Certificate.
Must be proficient in creating reports and presentations with Microsoft Office 365 products
Must have excellent verbal and written communication skills to present technical information to clients, stakeholders, and team members in a clear and concise manner
Must be a self-starter able to work independently or as part of a larger professional team
Must hold a current or active DoD Secret Security Clearance.
Must be a U.S. Citizen.
Preferred
Experience in DoD programs
Experience with Air Force programs
Certified Analytics Professional (CAP)
Cloudera Data Platform Generalist Certification
IBM Data Science Professional Certificate
Microsoft Certified: Azure AI Fundamentals
Microsoft Certified: Azure Data Scientist Associate
Open Certified Data Scientist (Open CDS)
SAS Certified AI and Machine Learning Professional
SAS Certified Data Scientist
Tensorflow Developer Certificate
Physical Requirements
May require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.
Why HII
We build the world’s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America’s top large company employers, we are a values and ethics driven organization that puts people’s safety and well-being first. Regardless of your role or where you serve, at HII, you’ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
Today’s challenges are bigger than ever, and the nation needs the best of us. It’s why we’re focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Technical Solutions.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE
1008931710116,Glassdoor,Cognizant Technology Solutions,1739566199,,,"https://www.glassdoor.com/Overview/Working-at-Cognizant-Technology-Solutions-EI_IE8014.11,41.htm","We are Cognizant Artificial Intelligence
Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. But clients need new business models built from analyzing customers and business operations at every angle to really understand them.
With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks

Role and Responsibilities:
5+ years of industry experience in software development data engineering or a related field with a solid track record of building services for manipulating processing datasets
Hands-on experience and advanced knowledge of AWS DataOps (i.e. IAM Lambda Step Functions EMR/Glue and DynamoDB)
Hands-on experience and advanced knowledge of SQL/Non-relational Data Modeling
Experience working with data streaming technologies (Kafka Spark Streaming etc.)
Designing and implementing complex ingestion and processing pipelines through orchestration
Design and implement API interfaces for engineering teams to interact with ingestion/processing pipelines
Design implement and support scalable multi-tenant service and data infrastructure solutions to integrate with multi heterogeneous data sources aggregate and retrieve data in a fast and secure mode curate data that can be used in reporting analysis machine learning models and ad-hoc data requests
Interface with other engineering and ML teams to extract transform and load data from a wide variety of data sources
Work with business product owners to understand gather and analyze their processing and extraction needs to solve problems

Salary and Other Compensation
The annual salary for this position is between USD ($110kp/a – $120kp/a) depending on experience and other qualifications of the successful candidate.
This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.
Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:
Medical/Dental/Vision/Life Insurance
Paid holidays plus Paid Time Off
401(k) plan and contributions
Long-term/Short-term Disability
Paid Parental Leave
Employee Stock Purchase Plan
Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.

#LI-JL1
#CB
#IND123

Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Oct 17 2023
About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.
Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.
Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.
If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",FALSE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008931852691,Glassdoor,Bloomberg,1433025906,,,"https://www.glassdoor.com/Overview/Working-at-Bloomberg-L-P-EI_IE3096.11,24.htm","Our Team:
Bloomberg's Data and Runtime Stability SRE team is trusted to administer the end-to-end environment for Bloomberg's installation of numerous services which support the applications that constitute Bloomberg's line of products. On any given day we're inventing, engineering, developing, building, coding, trouble-shooting and maintaining a wide range of: tools, monitors, frameworks, interfaces, protocols, solutions and best-practices. These components stitch together a robust suite of automated and self-healing systems that manage the services that Data and Runtime provides to the rest of the firm. We improve uptime, provision and balance resources, architect and coordinate operational procedures, administer backup and recovery processes, coordinate maintenance windows, manage replication and oversee workflows.

The Role:
In addition to managing the overall Data and Runtime environment, you'll work directly on installations of technologies that use services such as RabbitMQ, Comdb2, Kafka, Redis and many more; getting to collaborate every day with the application developers that create these applications to integrate the services they provide into the Bloomberg operational environment as well as Bloomberg products. So, not only will you have high-level-ownership and ""the classic SRE responsibilities"" such as: system tuning, performance analysis and the management of patches, installations, and upgrades; you'll also have immediate access to the experts that are designing and coding the Bloomberg specific components, APIs and methods. This means insight and entry to the lowest levels of how Bloomberg applications interact with each other and the Runtime environment for the purposes of both in-depth troubleshooting and enhancing stability, reliability, performance and feature-set.
We're open to trying new ideas, processes, and technologies. The right applicant will be imaginative, creative, self-motivated, and highly curious as innovation and initiative are highly valued here. Problem-solving, programming, logical frameworks, and Unix systems should all be second nature. We are looking for someone that will continually strive to improve our environment; regularly asking ""why?"" and saying: ""we can make this better!""

You'll need to have:
4+ years of programming experience with Python
A degree in Computer Science, Engineering or similar field of study or equivalent work experience
5+ years experience with Unix, Unix tools and shell scripting
Deep understanding of TCP/IP networking and the OSI model
Experience designing and automating repeatable processes in a client/server modeled environment
Experience supporting a highly available production systems
Ability to build and maintain highly sophisticated, performant, and scalable, critically important systems
Experience building monitors and alarms for system performance, status and stability
Experience with CI/CD systems and writing robust unit and system tests
We'd love to see:
Experience in Rapid framework
Experience analyzing existing systems and identifying shortcomings with concrete ideas for improvement
C programming skills
Experience designing stable, long-lasting APIs
Experience with Splunk/Humio and Grafana
Experience with GitHub and JIRA.

Bloomberg is an equal opportunity employer, and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or maternity/parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law.

Bloomberg provides reasonable adjustment/accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable adjustment/accommodation to apply for a job or to perform your job. Examples of reasonable adjustment/accommodation include but are not limited to making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you would prefer to discuss this confidentially, please email AMER_recruit@bloomberg.net (Americas), EMEA_recruit@bloomberg.net (Europe, the Middle East and Africa), or APAC_recruit@bloomberg.net (Asia-Pacific), based on the region you are submitting an application for.

Salary Range: 160,000 - 240,000 USD Annually + Benefits + Bonus

The referenced salary range is based on the Company's good faith belief at the time of posting. Actual compensation may vary based on factors such as geographic location, work experience, market conditions, education/training and skill level.

We offer one of the most comprehensive and generous benefits plans available and offer a range of total rewards that may include merit increases, incentive compensation [Exempt roles only], paid holidays, paid time off, medical, dental, vision, short and long term disability benefits, 401(k) +match, life insurance, and various wellness programs, among others. The Company does not provide benefits directly to contingent workers/contractors and interns.",TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE
1008933111950,Glassdoor,N/A,1797317630,,,N/A,"Responsibilities
Participate in the development of machine learning platform and open source communities
Responsible for the foundational research and product development, and continuously improve the R&D efficiency
Responsible for feature development, algorithm optimization of the platform, improving user experience and usability through cutting-edge or mature technologies
Participate in or lead design reviews with peers and stakeholders to decide amongst available technologies
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency)
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback
Minimum Qualifications
Bachelor’s degree or equivalent practical experience in computer science or related areas.
2 years of experience with software development in one or more programming languages (Python, Java, JavaScript, C/C++), or 1 year of experience with an advanced degree
2 years of experience with data structures or algorithms in either an academic or industry setting
Good communication and writing skills in English environment
Preferred Qualifications
Proficient in Java, familiar with Linux, Spring, Mybatis, Spring Cloud, MySQL, common NoSQL systems and distributed architecture
Familiar with the application of Kubernetes, Docker, DevOPS and other cloud native (Cloud Native) technologies, experience in medium and large-scale back-end application development is preferred, and experience in machine learning platform development is preferred
Familiar with underlying middleware and distributed technologies (such as RPC framework, cache, message system, etc.)
Familiar with the use/principle/tuning of common big data frameworks is preferred, such as Flume/Kafka/Hadoop/Hbase/Spark/Storm/ELK/ETL/kafka/Hive, etc.
About the Job
FedML, Inc. (https:/fedml.ai) empowers our clients to build & scale any machine learning or artificial intelligence models anywhere. That includes the latest foundation models as well as more traditional ML models. Our products cover both training, serving with a low-code UI MLOPs & LLMOps platform. We also offer a Federated Machine Learning solution for cross-silo training for data privacy sensitive applications.
Our earliest products power federated machine learning missions for clients in several industries, where data privacy, low latency serving, and low cost of data storage are important to the client. Our easy-to-use FedML MLOps solution enables data science and machine learning engineering to work seamlessly together to deploy & manage their model to production machines. Our federated learning and serving solutions support siloed edge devices, smartphones, and IoT.
Our next generation of solutions includes geo-distributed machine learning and serving that continues our tradition of delivering easy-to-use, simple, low-cost, and enterprise grade MLOPs solutions. Our MLOps and evolving LLMOps platform will always empower experimentation, observability, evaluation, governance, and collaboration for our clients’ AI & ML training and serving needs, as well as other general computing needs.
FedML supports vertical solutions across a broad range of industries (healthcare, finance, insurance, automotive, advertising, smart cities, IoT etc,) and applications (computer vision, natural language processing, data mining, and time-series forecasting). Its core technology is backed by more than 3 years of cutting-edge research of its co-founders who are recognized leaders in the federated machine learning community.
FedML's researchers and software engineers and product teams are busy developing the next-generation FedML platform for machine learning and artificial intelligence and we're looking to grow our team with skilled professionals who bring fresh ideas from all areas, including machine learning and its applications, computer vision, natural language processing, large-scale system design, distributed/cloud computing/systems, MLOps, security/privacy, mobile/IoT systems, and networking. We’re an early stage startup, hence you will work on projects which are critical to our customers' and our business needs. If you love to learn, and love to convert ideas into real and scalable machine learning infrastructure products and applications, FedML may be a great place for you.
Location
Our HQ is in Sunnyvale California. Preference is for someone local who can be at our office regularly. Hybrid is ok.
How to apply
If you are interested, please apply via the link.",TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE
1008931105380,Glassdoor,"Aktion Associates, Inc",1063483682,53000,79000,"https://www.glassdoor.com/Overview/Working-at-Aktion-Associates-EI_IE620537.11,28.htm","Data Center Engineer, Senior
About Aktion
Aktion Associates, Inc. is a national ERP software Reseller in the top 20 of the VAR 100 reseller market. We have a high growth technical environment with a workforce of over 200 professionals. We have a (3) year growth initiative to build our total workforce to 300. The workforce is highly skilled and consists of application consultants, software engineers, and networking engineers located throughout the U.S.

Role and Responsibilities:
VMware Expertise: Design, configure, and manage VMware virtualization solutions, including vSphere and vCloudDirector.
Networking Proficiency: Configure and maintain IOS-based network equipment and firewalls.
Windows Server and Active Directory:
Manage Windows Server environments, including installation, configuration, and patch management.
Administer Active Directory, including user account management, group policies, SSO, and domain controller maintenance.
Monitoring and Automation Proficiency:
Utilize N-central to monitor and manage network infrastructure and endpoints.
Create and customize monitoring scripts and alerts to proactively address issues.
Security and Compliance: Implement and maintain security measures to protect data center assets.
Infrastructure Design and Implementation: Collaborate with cross-functional teams to design and deploy data center solutions that meet business needs.
Education, Experience and Skills:
Bachelor's degree in computer science, information technology, or related field (preferred).
Extensive experience in data center engineering and administration.
Proficiency in enterprise VMware products, Cisco and Arista networking, Windows Server, Active Directory, and N-central.
Strong problem-solving skills and the ability to work under pressure.
Excellent communication and teamwork skills.
Relevant certifications (e.g., VMware Certified Professional, Cisco CCNA/CCNP, Microsoft Certified: Azure Administrator) are a plus.

This position offers a competitive salary, quarterly bonus, with the potential for performance-based year-end bonus. Aktion Associates offers a comprehensive benefits plan including an employer matching 401k plan.
If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please contact HR at hr@aktion.com and let us know the nature of your request and your contact information.
Aktion Associates is an Equal Opportunity Employer. Please visit www.aktion.com for more information about Aktion Associates",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008933126194,Glassdoor,ADP,582821685,,,"https://www.glassdoor.com/Overview/Working-at-ADP-EI_IE64.11,14.htm","ADP is hiring a Data Security Engineer

Are you ready to help us design the future-state to secure and govern our Data?

Well, this may be the role for you. Ready to make your mark?

As a Data Security Engineer, you will join a highly skilled and focused Global Security team, who provide excellent data protection services over the ADP Network platform and across ADP company assets. We protect sensitive ADP client and company data throughout the data life cycle.

You will need to leverage all your experience and be willing and eager to pick-up some new skills as well. Here are some skills that would be valuable to possess to be successful in role.

Programming Skills:
C#, Java, T-SQL, RegEx, PowerPlatform, PowerShell, C++/Rust, JavaScript & WebAPIs
Windows, Mac, & Linux application & development experience desired
Office Plug-In & SharePoint Framework (SPFx) experience desired

Technology Skills
FSRM, FCI, File System APIs & implementation (Windows, Linux, & MacOS wrt ADS and EFA)
Hashing, Tokenization, Digital Rights Management (DRM), MS Sensitivity Labels

Analysis Skills:
SQL, Graph API, and Reporting Tools

Data Security Knowledge
DLP (Storage, End Point, Network), File ACLs, Encryption & Key Management

Technology Platforms Knowledge
SharePoint, Splunk, Securiti.AI, ServiceNow, NetApp, Windows, Linux, MacOS

Leadership / Process Mindset
Advise, Develop, & Coordinate among multiple cross-discipline teams to establish sustainable processes to improve data security, while minimizing the impact to the average associate and reducing security incidents globally.

Like what you see? Apply now!

Learn more about ADP at tech.adp.com/careers

A little about ADP: We are a global leader in HR technology, offering the latest AI and machine learning-enhanced payroll, tax, HR, benefits, and much more. We believe our people make all the difference in cultivating an inclusive, down-to-earth culture that welcomes ideas, encourages innovation, and values belonging. A global Best Places to Work, Diversifying® Top 50 Company, Best CEO and company for women, LGBTQ+, multicultural talent, and more, ADP has a deep commitment to diversity, equity, and inclusion. Learn more about ADP's commitment on our YouTube channel: http://adp.careers/DEI_Videos

A little about the Data Security Team:

You will join a highly skilled and focused team providing excellent data security services, strategies, & processes. We protect sensitive ADP client and company data throughout the data life cycle. Responsibilities include protecting company and client data from exploitation or misuse, leading the design and implementation of data security and privacy policies, identifying weak control areas, and engineering relevant mitigating controls, and mitigating operational risks associated with data in motion and at rest. We help develop, enhance, and drive the vision & effectiveness of the data security program.

TO SUCCEED IN THIS ROLE:
Positive Professional. You have an upbeat, persistent style and the ability to produce creative solutions without fear of rejection. You can manage your time well, prioritize deliverables, and multi-task with the best of them. In addition, you can present your ideas in a clear, professional manner on paper, in-person, and over the phone. With your leadership skills, you are comfortable influencing, guiding and lending expertise to other teams & associates. You already possess a high degree of integrity, are trustworthy, and can work independently.
Subject Matter Expert. Solid programming experience will be key to being successful in this role... it will help you interface with the various product teams from an engineering perspective. Your experience with programming (in various language categories: scripting, procedural, functional, OO, etc.) for business applications & systems automation will help us deliver solutions to meet today's needs, and tomorrow's vision! Experience across Databases (SQL & Admin) and Business Intelligence (BI) reporting, as well as unstructured data technologies (NTFS, SMB, XFS, NFS, etc.) will help you jump right in.
Proven Experienced Winner. With your four to ten-plus years of experience in technology & cybersecurity roles, including: planning, implementing, and running security solutions. You have a track record of integrating both technological & people processes to ensure adoption success. You work well with key collaborators (security partners, technology teams, business units) to help improve or solution designs that adapt to ADP data platforms.
Technical Background You possess strong analytical skills and cross-functional knowledge of multiple technology and cybersecurity domains. You are superb at defining and documenting business processes and controls. Your background will lend strength based on your experience with Digital Rights Management (DRM), meta-data definitions, and encryption technologies & solutions. In addition, your knowledge and working experience with data loss prevention (DLP), and structured and unstructured data protection (UDP) technologies and approaches will help prevent unsafe and incorrect data disclosure, transmission, or exfiltration. You may possess a vast background (additional certificates help support your deep security knowledge (CISSP, GSEC, CISA, CISM, CRISC, MCSD), comprising of functional experience working in a global hybrid cloud environment, including AWS, Azure, O365, and GCP. Experience with Data Governance or Data Compliance Standards is valuable.
Fabulous Soft Skills. You recognize that with the pace that digital transformations drive, one must include the ability to communicate with various audiences that include executive leadership, business leaders, engineers, architects, clients, and associates. You know that it is important to possess great verbal communication skills to convey information to all levels. This includes exceptional written communication skills, documentation, and reporting. The sense-of-urgency, activator attitude you possess makes you a stellar candidate and highly sought after on project teams!
A college degree is great but not required. What is more important is having the attitude, skills, and experience to do the job.


WHAT YOU'LL DO:

Here is what you can expect on a typical day in the life of a at ADP.
Discover and analyze vulnerabilities in data repositories (databases, unstructured data: network/local storage, GitHub/Bitbucket, etc). Guide and contribute to efforts to gather and define requirements to develop prevention and detection capabilities that support ADP's data security policies. Interpret security and technical requirements from business requirements and communicate security risks to relevant stakeholders ranging from business leaders to engineers. Produce detailed solution designs for next generation data loss prevention and data protection capabilities and services. Continually improve program outcomes, address gaps, and reduce risk to ADP's infrastructure, processes, and sensitive data. Organize and coordinate supporting services for testing, deployment of new technical design specifications, and implementation and configuration of software suites.
Advise the business on data retention, security, & compliance concerns. Lead and influence multi-disciplinary teams in implementing and operating Cyber security controls. Work collaboratively with cross functional teams including strategic product managers, enterprise technology, privacy, and information security teams to create and drive a future vision for next generation data security in multiple cloud environments and data platforms. Provide input and feedback on security architectures, and influence others with your expertise. Your experience with data loss prevention platforms and collaborative approach will help shape ADP's security policies and standards for use in cloud and hybrid environments.
Maintain compliance with Internal Processes, Policies & Standards. Developing security guardrails, in alignment with business processes, to protect data collected and used at ADP. Analyze forensic information regarding security incidents to improve business processes & enhance security technologies. Lead efforts to gather/define requirements to develop prevention and detection capabilities that support ADP's data security policies, assess, and evaluate data security control effectiveness, enable comprehensive orchestration and automation to provide improved metrics and operational support, and identify and implement new security technologies and best practices into the company's critical applications.
Enable the comprehensive orchestration and automation of security processes to provide rapid incident response and gain efficiencies throughout the technical security services lifecycle.
Maintain an expert level understanding of emerging DLP security threats and the capabilities that provide relevant mitigating controls. Provide consulting services to the business units and IT organizations to educate and ensure adherence with ADP's data security standards and industry best practices. Develop and maintain vendor relationships that partner with cloud services. Ensure compliance, drive control coverage, and define technical policies for cloud security controls across multiple workloads and environments.
Drive the discovery and prioritize remediation of data controls to meet audit, compliance and ADP's data protection requirements, policies, and standards. Ensure global data security initiatives adhere to continually changing privacy and legal compliance requirements. Assess and evaluate end point and data security control effectiveness, and drive towards improved control effectiveness, consistency, and maturity across the organization.

YOU'LL LOVE WORKING HERE BECAUSE YOU CAN:
What we're doing here will surprise you. Whether we're leveraging one of the world's most comprehensive datasets that predicts the economic health of a nation, using the latest tech stacks to create adaptive, industry-changing platforms, or developing one of the Top 10 mobile applications for business, we're making a positive impact on the lives of millions of people around the world. Every day.
Deliver at epic scale. We deliver real user outcomes using strong judgment and good instincts. We are obsessed with the art of achieving simplicity with a focus on client happiness and productivity.
Join a company committed to equality and equity. Our goal is to affect lasting change through our actions.
Team collaboration. Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to net out the best solution.
Be surrounded by curious learners. We align ourselves with other smart people in an environment where we grow and elevate one another to the next level. We encourage our associates to listen, stay agile, and learn from mistakes.
Act like an owner & doer. Mission-driven and committed to navigating change, you will be encouraged to take on any challenge and solve complex problems. No tasks are beneath or too great for us. We are hands-on and willing to master our craft.
Give back to others. Always do the right thing for our clients and our community and humbly give back to the community where we live and work. Support our associates in times of need through ADP's Philanthropic Foundation.

Find out why people come to ADP and why they stay: https://youtu.be/ODb8lxBrxrY

(ADA version: https://youtu.be/IQjUCA8SOoA )

Actual salary may be above or below this range based on factors such as location, skills, and relevant experience.

In addition, this position may include additional compensation in the form of bonus, equity, or commissions.

If you are a full-time salaried or hourly worker, we offer the following benefits:
Medical, Dental, Vision, Life Insurance, Matched 401(k), Student Loan Repayment
Program, Wellness Program, Short- and Long-TermDisability, Charitable
Contribution Match, Holidays, Personal Days & Vacation, Paid Volunteer Time Off,
and more.
Salary range for this role is: $75,600 - $202,590 / year

Diversity, Equity, Inclusion & Equal Employment Opportunity at ADP: ADP affirms that inequality is detrimental to our associates, our clients, and the communities we serve. Our goal is to impact lasting change through our actions. Together, we unite for equality and equity. ADP is committed to equal employment opportunities regardless of any protected characteristic, including race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, or protected veteran status and will not discriminate against anyone on the basis of a disability. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.

Ethics at ADP: ADP has a long, proud history of conducting business with the highest ethical standards and full compliance with all applicable laws. We also expect our people to uphold our values with the highest level of integrity and behave in a manner that fosters an honest and respectful workplace. Click https://jobs.adp.com/life-at-adp/ to learn more about ADP's culture and our full set of values.",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE
1008932526669,Glassdoor,Apple,1131006548,,,"https://www.glassdoor.com/Overview/Working-at-Apple-EI_IE1138.11,16.htm","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200452999
Do you believe Machine Learning and AI can change the world? We truly believe it can. We are the Data Team of the System Intelligence and Machine Learning (SIML) group at Apple. We are responsible for building high quality datasets at scale. Every year, our team produces datasets used in the training of ML and AI-centric features for many Apple products, including iPhone, iPad, Mac, Apple Watch and even AirPods. Our work is used in very visible and important features, from the wallpaper on your iPhone Lock Screen, to the models that highlight the faces of your loved ones in your photos app, to the memories that your Apple products create from your photos, videos and music. We value collaboration and team-work. Our engineers are not afraid to manually browse the data to identify and troubleshoot problems. We expect the same from our new members. This is an exciting time to join us and have an impact on multiple key features at Apple!
Key Qualifications
5+ years of industry experience in building data pipelines, data processing infrastructure or data operations teams
Demonstrated prior experience in large language models, or generative AI
Proficient in Python, or another modern programming language
Proven track record of handling complex data projects with contributions to hiring, mentoring and growing engineers, establishing and enforcing the right software engineering culture for a software team
Experience in building data processing pipelines for curating data, training and evaluating models (experience in Airflow, KubeFlow or other pipelining tools)
Passionate about supporting day-to-day data operations and able to work efficiently with members of the team who are not engineers
Self-starter, able to handle ambiguity, navigate uncertainty, identify risks, and find the right people and tools to get the job done
We value collaboration and team-work. Our engineers are not afraid to manually browse the data to identify and troubleshoot problems. We expect the same from our new members.
Description
Our team works in close interaction with R&D, infrastructure and client teams, as well as with other groups and other functions across Apple (legal, privacy) and externally. This position focuses on designing and implementing flexible data pipelines and data tools based on advanced computer vision technology, NLP and humans in the loop. You will be responsible for the design and development of the data pipelines, automation, visualization and tools that constitute the end-to-end process for building models, from raw data to trained model to evaluation to deployment. You'll partner with data infrastructure and other teams to ensure that we have high quality, representative data. You'll work with ML engineers to refine the modeling process to enable faster iteration and better modeling decisions and deploy models more rapidly to customers. You'll collaborate with data scientists and analysts to build insights from customer analytics and feedback into the process to complete the cycle of continuous improvement. Your work will impact hundreds of millions of Apple's customers and help people communicate more easily in the languages and modalities of their choice.
Education & Experience
Bachelors, Masters or PhD in Computer Science, Mathematics, Physics, or a related field (or equivalent practical experience). Apple is an equal opportunity employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Apple is a drug-free workplace.
Additional Requirements
Strong understanding of applied machine learning topics is desirable
Experience with ETL frameworks like Airflow is desirable
Kubernetes and Docker experience is desirable
Strong knowledge of either NLP or Computer Vision is desirable
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932012870,Glassdoor,SK hynix America,1652146299,104000,164000,"https://www.glassdoor.com/Overview/Working-at-SK-hynix-America-EI_IE704360.11,27.htm","Job Title : Sr. Staff or Staff Engineer - Data & IO Design
Application Deadline: 11/3/2023
Location : San Jose, CA or Sacramento, CA
Job Type : Full-Time
In the rapidly growing NAND Flash space amid the era of big data, this is an exciting time to be at SK hynix NAND America - come join our NAND Design Team as a Sr. Staff/Staff Engineer and work on one of the most advanced 3D NAND technology portfolios in the world. SK hynix NAND America is the organization of Design, PE, Cell-Media integration, Pathfinding teams for developing advanced 3D NAND products.

Key Responsibilities:
Responsible for designing and developing data & IO design in 3D NAND Flash memory products
Design and build for higher IO speed at the block & transistor level
Design Data/IO circuit and develop circuit solutions that meet the area, power and performance within process distribution
Create test benches, simulate, and analyze the results
Perform parasitic extraction, run pre and post-layout simulations and analyze results
Work closely with layout designer
Minimum Qualifications:
At least 4 years experience of IO design with Bachelor’s degree
RX, TX, and IO pipeline circuits design and debugging experience
Understanding of circuit layout with layout review and supervision
Understanding of high speed IO operation mechanism
Experience of power/signal integration at high IO speed area
Good knowledge of Device physics at transistor level
Experience with commercial schematic and simulation tools
Benefits:
The base salary range for this full-time position is : $126,000 ~ $168,000
Individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training.
Additional compensation may include annual bonuses, discretionary bonuses and benefits.
The benefits include the following.
We provide top-class healthcare benefits including medical, dental, vision, employee assistance plans for employees and their dependents.
We provide multiple leave types which include paid time off, 11 holidays, 12 Happy Fridays (additional days off), family and medical leaves.
We provide market-competitive retirement programs (401(k) plans) for your future.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE
1008932395137,Glassdoor,Jacobs,391935831,64000,102000,"https://www.glassdoor.com/Overview/Working-at-Jacobs-EI_IE913.11,17.htm","Your Impact:

Your Impact:
The mission of the Jacobs Lone Wolf Team is to support, operate, and maintain the Distributed Continuity Integrated Network - Top Secret Enterprise Services (DCIN-TS ES). The DCIN-TS ES is a DoD provided, TS/SCI, integrated voice, video, and data, global communications network that facilitates collaboration among senior leaders and key staff.
Candidates are expected to have a strong work ethic and possess the ability to work as a critical member of a team in pursuit of mission objectives and in support of our customers. We value candidates who are detail-oriented while also being able to think and react quickly to emerging and unique problem sets. To be successful in this role, you'll be able to rapidly adapt and learn how to operate the front and back end of new products and processes.

Responsibilities:
The duties and responsibilities of the Data Storage and Backup Engineer include, but are not limited to, the following:
Perform administration tasks to manage and maintain an IT enterprise-centered data storage environment for Virtual Machine environments (Nutanix or VMware) hosting MS Windows servers and Linux environments.
Implement high performance storage solutions for enterprise capabilities in compliance with DISA STIG requirements and data retention policies.
Assist in the identification and diagnosis of complex performance, security, and technical issues.
Here’s What You’ll Need:

Basic Qualifications:
Must have active Top Secret clearance with SCI
Current DODD 8140/8570 IAT Level 2 certification (or higher) required (such as CCNA Security, Security+ CE, GICSP, GSEC, or SSCP)
Proactive self-starter demonstrating a positive, willing attitude and excellent verbal and written communication skills
Experience with Microsoft Office applications such as Excel, Word, PowerPoint, and Outlook
Ability to travel up to 10%
Minimum Experience:
At least 5 years of IT experience inclusive of the following minimum specific experience:
2 years of experience managing data storage for Virtual Machine environments (Nutanix or VMware) hosting MS Windows servers and Linux environments
1 year experience in system administration for data storage backup using Commvault software
Working knowledge of HPE data storage products (3PAR and Primera), StoreOnce, and tape back-up systems
Commvault Professional Foundations Exam
#divergent #dvscyber #lonewolf",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931914777,Glassdoor,Case Western Reserve University,558614550,58000,82000,"https://www.glassdoor.com/Overview/Working-at-Case-Western-Reserve-University-EI_IE26686.11,42.htm","Job Description

POSITION OBJECTIVE
Working under limited supervision, the Data and Operations Engineer will evaluate, select, and apply techniques, procedures, and criteria using judgment in making adaptations. Work is assigned as an objective to be reached and is reviewed for application of sound professional judgment The engineer will lead the development of computational biology workflows and management of computational-to-experimental discovery, validation, translation, and commercialization in the Brubaker Lab.

ESSENTIAL FUNCTIONS
Independently evaluate, select, and apply techniques, procedures, and criteria using their own judgment in making adaptations. Appropriately conceptualize, formulate, and implement computational workflows for analysis of microbiome multi-omics data. Appropriate data and code storage, version control, and reproducibility practices will be essential. Create actionable plans for testing computationally-derived hypotheses in the wet lab and ensure that equipment is maintained to achieve those objectives. (15%)
Investigate several possible variables and often there are no precedents for the choices that must be made. Devise statistical, data-driven, and hybrid methods for the integration and analysis of heterogenous host and microbiome data types from humans, cell culture systems, and animal models. (15%)
Design and develop complex platform algorithms and data management systems for the elucidation of microbiome-based therapeutics and the translation of these data from preclinical systems to clinical applications. Coordinate detailed phases of work related to responsibility for part of a major project or for an entire project of moderate scope. Lead the development of AI-based tools for microbiome-based pharmacology analyses. Manage team with complex objectives toward delivering actionable insights on microbiome therapeutic targets and strategies. (10%).
Develop technical and methodological solutions to complex engineering/ scientific problems requiring independent analytical thinking and advanced knowledge. Be able to identify weaknesses and areas for improvement in existing and developing data science workflows related to validity, reproducibility, and accuracy. Identify proposed solutions and work with interdisciplinary team and principal investigator to execute the solutions. (10%)
Develop creative new or improved equipment, materials, technologies, processes, methods, or software important to the advancement of the field. Develop a working understanding and expertise in usage of experimental equipment and how each piece of equipment and associated assay can be used to extend computational projects and validate data science-derived results. (10%)
Contribute technical expertise and perform research and development in support of programs/ projects; act as adviser/ consultant in area of specialty. Have experience in or capacity to develop mastery of biological data science. Support and lead the organizational development of a tech transfer program for microbiome targeted and microbiome-based therapeutics. (10%)
Contribute to portions of published articles or presentations; prepare and write reports; draft and prepare scientific papers. Will contribute to the preparation of manuscripts, abstracts, and technical reports. Will prepare publicly consumable and confidential software packages for laboratory projects. (10%)
May supervise technicians in the completion of assignments. Provide technical direction to other staff, associates, and/ or students, as needed. Will attend and facilitate weekly lab Data Meetings to discuss works in progress and will provide feedback to staff and trainees. Will work with staff and trainees to disseminate results, perform analysis, and design experiments. (10%)

NONESSENTIAL FUNCTIONS
Assist with management of budgets and administration (5%)
Perform other duties as assigned (5%).

CONTACTS
Department: Daily contact with supervisor to discuss research and maintain workflow.
University: Occasional contact with other departments to share information.
External: Limited or no contact with vendors to exchange information.
Students: Contact with student employees to exchange information.

SUPERVISORY RESPONSIBILITY
Provide technical direction to other staff, associates, and/ or students, as needed.

QUALIFICATIONS
Experience: 3 to 5 years of professional engineering experience.
Education: Bachelor’s degree in Engineering.

REQUIRED SKILLS
Has knowledge of commonly-used concepts, practices, and procedures within a computational biology. Specifically, the development of computational workflows for the analysis and integration of data from heterogeneous sources. Experience with git, AI, and reproducible code platforms preferred.
Relies on instructions and pre-established guidelines to perform the functions of the job. Able to problem solve in debugging code and planning out visualizations and interpretations of data to guide the wet lab experimental workflows.
Ability to operate laboratory equipment. Ability to learn new skills to complement existing strengths in computational analysis. Ability to learn or knowledge already skilled in cell culture, anaerobic culture, and preparation of biospecimens for molecular analysis.
Ability to meet consistent attendance.
Ability to interact with colleagues, supervisors and customers face to face.

WORKING CONDITIONS
General laboratory environment. May have exposure to hazards such as lasers, blood borne pathogens, bacteria, human biospecimens, pressurized gases, sharps, and other biosafety lab 2 level hazards. Will require some travel to national meetings on behalf of the laboratory.

Diversity Statement

In employment, as in education, Case Western Reserve University is committed to Equal Opportunity and Diversity. Women, veterans, members of underrepresented minority groups, and individuals with disabilities are encouraged to apply.
.
Reasonable Accommodations

Case Western Reserve University provides reasonable accommodations to applicants with disabilities. Applicants requiring a reasonable accommodation for any part of the application and hiring process should contact the Office of Equity at 216-368-3066 to request a reasonable accommodation. Determinations as to granting reasonable accommodations for any applicant will be made on a case-by-case basis.
.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE
1008932012871,Glassdoor,SK hynix America,1652146299,127000,184000,"https://www.glassdoor.com/Overview/Working-at-SK-hynix-America-EI_IE704360.11,27.htm","Job Title : Sr. Principal or Principal Engineer - Data & IO Design
Application Deadline: 11/3/2023
Location : San Jose, CA or Sacramento, CA
Job Type : Full-Time
In the rapidly growing NAND Flash space amid the era of big data, this is an exciting time to be at SK hynix NAND America - come join our NAND Design Team as a Principal/Senior Principal Engineer and work on one of the most advanced 3D NAND technology portfolios in the world. SK hynix NAND America is the organization of Design, PE, Cell-Media integration, Pathfinding teams for developing advanced 3D NAND products.

Key Responsibilities:
Responsible for designing and developing data & IO design in 3D NAND Flash memory products
Architect, design and build for higher IO speed at 3D NAND memory
Design Data/IO circuit and develop circuit solutions that meet the area, power and performance within process distribution
Develop advanced High Speed IO design
Lead the front-end/back-end HSIO tests in the post silicon
Work closely with the layout designers to optimize area and performance
Work with several cross-functional teams for resolving product level issues
Mentoring and instructing junior engineers along with ensuring timely product delivery
Minimum Qualifications:
At least 10 years experience of IO design with Bachelor’s degree
RX, TX, and IO pipeline circuits design and debugging experience
Experience with DDR IO interface trainings and Calibrations
Detailed understanding of high speed IO circuits layout
Understanding of high speed IO operation mechanism along with reliability mechanisms
Experience of power/signal integration at high IO speed area
Strong communication skills with ability to convey technical concepts to peers
Benefits:
The base salary range for this full-time position is : $182,000 ~ $257,000
Individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training.
Additional compensation may include annual bonuses, discretionary bonuses and benefits.
The benefits include the following.
We provide top-class healthcare benefits including medical, dental, vision, employee assistance plans for employees and their dependents.
We provide multiple leave types which include paid time off, 11 holidays, 12 Happy Fridays (additional days off), family and medical leaves.
We provide market-competitive retirement programs (401(k) plans) for your future.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE
1008932742698,Glassdoor,"Imagine One Technology & Management, Ltd.",1674263892,,,"https://www.glassdoor.com/Overview/Working-at-Imagine-One-EI_IE264165.11,22.htm",N/A,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932367135,Glassdoor,Northrop Grumman,66714307,,,"https://www.glassdoor.com/Overview/Working-at-Northrop-Grumman-EI_IE488.11,27.htm","Requisition ID: R10134780
Category: Engineering
Location: Edwards AFB, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Any (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 2
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman Aeronautics Systems has an opening for a Principal / Senior Principal Instrumentation and Data Acquisition Hardware Engineer to join our team of qualified, diverse individuals within our Test and Evaluation organization. This position will be located in EAFB, CA.
The selected candidate will join the Instrumentation and Data Acquisition Engineering team be part of the design, development, integration, configuration and test of a real-time, hardware in the loop (HITL), Data Acquisition Systems (DAS). They will perform a variety of duties in the electronic, mechanical, electromechanical, or software areas. Tasking will include design, development, verification and acceptance testing of data builds and real time Mission Control Room configuration files using Symvionics IADS software. The selected candidate will be responsible for coordinating integrated testing activities; reviewing and evaluating test requirements to ensure compliance with policies and procedures. Compilation of data and definition of changes required in testing procedures or new testing requirements will be necessary as well to help define automated test strategies. The selected candidate should be pro-active and self-motivated; ask not only “what”, but also “how” and “why.” Overtime, odd shifts, and weekend work will occasionally be required.
Key Responsibilities:
Promptly respond to technical issues that arise on the production floor utilizing work instructions, design models, and specifications.
Establish on article long term planning for installations.
Compile data and define changes required in testing procedures or new testing requirements.
Help define automated test strategies.
Clarify work instructions to operations staff; modifying as needed.
Drafting, opening, tracking, and closing Prep Items.
Creation of test Concept of Operations (ConOps) flows that maximizes the utility of test resources while meeting schedule and technical requirements and/or constraints.
Coordinate integrated testing activities; review and evaluate test requirements to ensure compliance with policies and procedures.
Identify process improvements, capture feedback from operations staff, and incorporate into the installation process.
Resolve issues by collaborating with other resource groups as needed.
Perform technical impact, planning, and strategy assessments for change implementation.
The selected Candidate must be willing to work various shifts depending on the business needs: 4x10 schedule (Mon-Thurs) 1st shift; 4x10 (Mon-Thurs) 2nd shift; 3x10 schedule (Fri, Sat, Sun) 1st shift; 3x10 schedule Fri, Sat, Sun) 2nd shift. Candidate must also be willing to accept work assignments that may include the Palmdale, CA location dependent on business needs.
Basic Qualifications:
This requisition may be filled at either a Principal or a Sr. Principal level.
Basic Qualifications for Principal:
A Bachelors in Science, Technology, Engineering or Math (STEM Degree).
A minimum of 5 years of applicable experience with a BS Degree or 3 years with a MS degree in STEM Field
Basic Qualifications for Sr Principal:
A Bachelors in Science, Technology, Engineering or Math (STEM Degree).
A minimum of 9 years of applicable experience with a BS Degree or 7 years with a MS degree in STEM Field
Basic Qualifications for Both Principal and Sr Principal Engineer
Must have the ability to obtain and maintain DoD Secret Clearance.
Must have ability to obtain and maintain Program Access (PAR) within a reasonable period, as determined by the company to meet its business needs.
Basic understanding of troubleshooting systems to identify and assist in the correct the root cause.
Experience assisting with the creation, editing and execution of procedures.
Experience assisting with data acquisition and data collection.
Experience with Microsoft Windows family of products, AutoCAD, MatLab.
Preferred Qualifications:
Electronics, Analog and Digital Communications, Digital Signal Processes, Computer Communication Networks, Embedded Systems
Experience working in Flight Test or Lab Test environments
Experience using oscilloscopes and waveform generators.
Experience working with Strain Gages, Accelerometers, Pressure Transducers and other commonly used instrumentation sensors
Basic knowledge of data bus architecture MIL-STD-1553, IEE-1394, ARINC-429, RS232 an RS422.
Experience using Symvionics IADS software and working in a Mission Control Room
Experience post-test processing data from a IRIG-106 CH10 recording
Experience using TTCWare Application Software
Experience working Curtiss-Wright TTC Data Acquisitions Systems
Ability to write scripts GUIs or small scale applications a plus.
Bachelor of Science degree in Electrical Engineering or a degree with Instrumentation data experience.
Salary Range: $95,000 - $142,400
Salary Range 2: $117,700 - $176,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE
1008931243381,Glassdoor,,0,64000,97000,"https://www.glassdoor.com/Overview/Working-at-1-Source-EI_IE140207.11,19.htm","Business Technology Integrators, (BTI), welcomes qualified applicants to submit their resumes for consideration to work in the areas of IT systems strategic planning and architecture development, systems engineering, software development, operations and maintenance, and cyber security. If you are interested in joining a highly motivated workforce, working in an exciting and challenging environment while receiving industry competitive benefits and recognition.
Data Management – ATLAS LCAT Systems Engineer 2
US Citizenship required.
Includes Top Secret/SCI with FS Poly Required
Active Security + CE Required

Facilitate the incremental migration of existing Agency Human Capital Management (HCM) data from the PeopleSoft HCM system to the new Cloud HCM environment.
o Develop and support modifications/extensions to the project's source data extraction, source data error identification, and source data transformation processes
o Support loading data, monitoring progress, and reporting errors.
o Support, compile, and summarize identified data issues and proposed fixes to the Maryland Program Office (MPO) for review and decision on resolution.
o Correct data ingest/validation issues.
Take a structured approach to decompose, identify, and define data handling solutions to meet role-based access control (RBAC) and attribute-based access control (ABAC) requirements through a variety of tools and techniques.
o Address client data tagging and Enterprise Data Header (EDH) requirements enabling the existing data model to be extended to capture information such as classification, sensitivity tags, and controls at the element level.
o Use the Cloud HCM data disposal tool to perform data deletion and purging.
o Support data governance using the Cloud HCM single authority data source to the element level and controls.
o Provide a publicly accessible data dictionary with element level conformal definitions that are continuously maintained; providing and capturing all additional client required elements during implementation.
o Move historical data from the legacy HCM system to a Database as a Service (DBaaS) Virtual Machine (VM) instance.
o Use Cloud HCM to manage data quality by leveraging build edits and a rules engine for data entry to control data as it is entered, and through workflows.
o Implement Mass Personnel Action Processing (PAR) corrections using automated methods to correct data.
o Provides support to client Master Data Management (MDM) initiatives through
data models, data controls, integration capabilities.

Desired Qualifications:
Functional experience in Peoplesoft HRMS 9.2
Technical experience in PeopleTools, including, but not limited to, developing & supporting Application Engines, PeopleCode, Data Mover, and Peoplesoft integration tools
Technical experience in Oracle RDBMS development, preferably SQL, PL/SQL
In lieu of PeopleSoft/HCM experience, a motivated self-starter who is willing to learn Oracle SaaS applications

Qualifications:
Fourteen (14) years’ experience as an engineer in programs and contracts of similar scope, type, and complexity
Technical flexibility to work with on-premises and cloud-based tools and applications
Bachelor’s degree in a technical discipline from an accredited college or university is required
Five (5) years of additional experience on projects with similar processes may be substituted for a bachelor’s degree",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
1008932107478,Glassdoor,"Amazon Data Services, Inc.",30623142,,,"https://www.glassdoor.com/Overview/Working-at-Amazon-EI_IE6036.11,17.htm","ABET accredited Bachelor’s degree in civil or structural engineering
5+ years experience in structural design for industrial or commercial projects
Professional Engineering (PE) License
Amazon Web Services (AWS) is seeking a Data Center Structural Engineer to join its design team in one of these locations: Seattle, WA USA | Austin, TX, USA | Dublin, OH, USA | Herndon, VA, USA.

AWS designs, builds, and operates Data Centers (DC) around the world and is a leader in worldwide cloud-computing infrastructure.

Engineers in AWS work to design resilient, cost effective DC facilities. Our team is responsible for achieving a world class uptime for our customers and drive to develop a fleet of buildings emphasizing security, safety, efficiency, and cost effectiveness, while finding new ways to meet AWS’s growing demand.

As a DC Structural Engineer at AWS, you will be part of the design team for Amazon DCs in our Americas Region and impact other projects around the world. As a Structural Engineer at AWS you will be part of a highly creative and efficient design team comprised of Architects, Engineers and Designers tasked with solving problems and challenging the status quo. As a subject matter expert, you will have a direct impact on the design of prototypical DC facilities, provide technical guidance to team members, review milestone drawings by consultants, solve large scale implementation issues, and be responsible for structural design requirements.

We are open to hiring candidates to work out of one of the following locations:

Austin, TX, USA | Dublin, OH, USA | Herndon, VA, USA | Seattle, WA, USA

Master’s degree in civil or structural engineering.
Proficiency in building codes, regulations, and standard including IBC and ASCE.
SE Engineering license.
Experience with the design, construction, operation, or maintenance of DCs.
Solid working proficiency with AutoCAD, Revit, Bluebeam, and MS Office Suite.
Detailed understanding of tilt-up and precast concrete structures, structural steel systems, seismic design, wind loading, snow loading, and forensic analysis of building design and construction defects.
Experience in value engineering for building structural systems.
Experience in design and calculation for auxiliary framing systems used to support cable tray, conduit, ductwork, etc.
Experience in design and review of non-structural components and non-building structures
Ability to evaluate the constructability of new technologies, and determine construction methods of data center equipment and facilities.
Ability to perform and present business case analysis.
Motivated, dependable and capable of working with limited oversight.
Ability and willingness to think outside of the box to find innovative solutions prior to and during the construction process to reduce costs without negative impacts on quality or reliability.
Excellent communication skills, attention to detail, maintain high quality standards.
Ability to effectively communicate design standards to internal and external project partners.
Basic understanding of large scale mechanical and electrical system components and designs.
Ability to manage multiple fast paced projects simultaneously.
Ability to travel internationally
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $77,300/year in our lowest geographic market up to $219,700/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE
